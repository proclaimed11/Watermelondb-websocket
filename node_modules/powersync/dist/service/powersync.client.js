import require$$0$4 from 'stream/consumers';
import require$$0 from 'stream/web';
import { Buffer as Buffer$1 } from 'buffer';
import require$$0$2 from 'http';
import require$$0$1 from 'util';
import require$$0$3 from 'https';
import require$$6 from 'stream';
import require$$9$1 from 'url';
import require$$0$5 from 'fs';
import require$$1$1 from 'path';
import require$$2 from 'os';
import require$$3$1 from 'crypto';
import { homedir } from 'node:os';
import path$1 from 'node:path';

var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

function getDefaultExportFromCjs (x) {
	return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
}

function getAugmentedNamespace(n) {
  if (n.__esModule) return n;
  var f = n.default;
	if (typeof f == "function") {
		var a = function a () {
			if (this instanceof a) {
        return Reflect.construct(f, arguments, this.constructor);
			}
			return f.apply(this, arguments);
		};
		a.prototype = f.prototype;
  } else a = {};
  Object.defineProperty(a, '__esModule', {value: true});
	Object.keys(n).forEach(function (k) {
		var d = Object.getOwnPropertyDescriptor(n, k);
		Object.defineProperty(a, k, d.get ? d : {
			enumerable: true,
			get: function () {
				return n[k];
			}
		});
	});
	return a;
}

var dist$8 = {};

var nodeClient = {};

var streaming = {};

var web$1 = {};

var crossStream = {};

Object.defineProperty(crossStream, "__esModule", { value: true });
crossStream.ByteLengthStrategy = crossStream.Transform = crossStream.Readable = void 0;
if (typeof window !== 'undefined') {
    crossStream.Readable = ReadableStream;
    crossStream.Transform = TransformStream;
    crossStream.ByteLengthStrategy = ByteLengthQueuingStrategy;
}
else {
    const webstream = require$$0;
    crossStream.Readable = webstream.ReadableStream;
    crossStream.Transform = webstream.TransformStream;
    crossStream.ByteLengthStrategy = webstream.ByteLengthQueuingStrategy;
}

var bson$5 = {};

var bufferArray = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.createReadableBufferArray = exports.readBufferFromChunksAndModify = exports.readBufferFromChunks = void 0;
	/**
	 * Read a given `size` number of bytes from a give array of `chunks` as a Buffer. The returned Buffer could be
	 * larger than the requested size. If the chunks array contains less than the requested size then null is
	 * returned
	 */
	const readBufferFromChunks = (chunks, size) => {
	    let batch = [];
	    let current_size = 0;
	    for (const chunk of chunks) {
	        batch.push(chunk);
	        current_size += chunk.length;
	        if (current_size >= size) {
	            return {
	                buffer: Buffer.concat(batch),
	                chunks_read: batch.length
	            };
	        }
	    }
	    return null;
	};
	exports.readBufferFromChunks = readBufferFromChunks;
	/**
	 * Read exactly `size` bytes from a given array of `chunks`, modifying the passed array to remove what
	 * was read.
	 *
	 * If more than `size` is read from the chunks array then the remainder is unshifted back onto the array
	 */
	const readBufferFromChunksAndModify = (chunks, size) => {
	    const res = (0, exports.readBufferFromChunks)(chunks, size);
	    if (!res) {
	        return null;
	    }
	    if (res.buffer.length > size) {
	        chunks.splice(0, res.chunks_read, res.buffer.slice(size));
	        return res.buffer.slice(0, size);
	    }
	    chunks.splice(0, res.chunks_read);
	    return res.buffer;
	};
	exports.readBufferFromChunksAndModify = readBufferFromChunksAndModify;
	/**
	 * Creates a abstraction on top of a compressed set of Buffer chunks that keeps track of the
	 * entire byte size of the chunks array.
	 *
	 * Offers methods to get the byte size, peak at a given amount of data and destructively read
	 * a given amount of data
	 */
	const createReadableBufferArray = () => {
	    let chunks = [];
	    let current_size = 0;
	    return {
	        push(...new_chunks) {
	            const normalized_chunks = new_chunks.map((chunk) => (Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk)));
	            chunks.push(...normalized_chunks);
	            current_size = new_chunks.reduce((size, chunk) => {
	                return size + chunk.length;
	            }, current_size);
	        },
	        read(size) {
	            const buffer = (0, exports.readBufferFromChunksAndModify)(chunks, size);
	            if (buffer) {
	                current_size -= size;
	            }
	            return buffer;
	        },
	        peek(size) {
	            if (current_size < size) {
	                return null;
	            }
	            const res = (0, exports.readBufferFromChunks)(chunks, 4);
	            if (!res) {
	                return null;
	            }
	            return res.buffer;
	        },
	        size() {
	            return current_size;
	        }
	    };
	};
	exports.createReadableBufferArray = createReadableBufferArray; 
} (bufferArray));

var constants$3 = {};

Object.defineProperty(constants$3, "__esModule", { value: true });
constants$3.TERMINATOR = void 0;
constants$3.TERMINATOR = Buffer.from([0x00, 0x00, 0x00, 0x00]);

var encoder = {};

/*! *****************************************************************************
Copyright (c) Microsoft Corporation.

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
***************************************************************************** */

/* global Reflect, Promise */
var _extendStatics = function extendStatics(d, b) {
  _extendStatics = Object.setPrototypeOf || {
    __proto__: []
  } instanceof Array && function (d, b) {
    d.__proto__ = b;
  } || function (d, b) {
    for (var p in b) {
      if (b.hasOwnProperty(p)) d[p] = b[p];
    }
  };

  return _extendStatics(d, b);
};

function __extends(d, b) {
  _extendStatics(d, b);

  function __() {
    this.constructor = d;
  }

  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}

var _assign = function __assign() {
  _assign = Object.assign || function __assign(t) {
    for (var s, i = 1, n = arguments.length; i < n; i++) {
      s = arguments[i];

      for (var p in s) {
        if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];
      }
    }

    return t;
  };

  return _assign.apply(this, arguments);
};

/** @public */
var BSONError$1 = /** @class */ (function (_super) {
    __extends(BSONError, _super);
    function BSONError(message) {
        var _this = _super.call(this, message) || this;
        Object.setPrototypeOf(_this, BSONError.prototype);
        return _this;
    }
    Object.defineProperty(BSONError.prototype, "name", {
        get: function () {
            return 'BSONError';
        },
        enumerable: false,
        configurable: true
    });
    return BSONError;
}(Error));
/** @public */
var BSONTypeError = /** @class */ (function (_super) {
    __extends(BSONTypeError, _super);
    function BSONTypeError(message) {
        var _this = _super.call(this, message) || this;
        Object.setPrototypeOf(_this, BSONTypeError.prototype);
        return _this;
    }
    Object.defineProperty(BSONTypeError.prototype, "name", {
        get: function () {
            return 'BSONTypeError';
        },
        enumerable: false,
        configurable: true
    });
    return BSONTypeError;
}(TypeError));

function checkForMath(potentialGlobal) {
    // eslint-disable-next-line eqeqeq
    return potentialGlobal && potentialGlobal.Math == Math && potentialGlobal;
}
// https://github.com/zloirock/core-js/issues/86#issuecomment-115759028
function getGlobal() {
    return (checkForMath(typeof globalThis === 'object' && globalThis) ||
        checkForMath(typeof window === 'object' && window) ||
        checkForMath(typeof self === 'object' && self) ||
        checkForMath(typeof global === 'object' && global) ||
        // eslint-disable-next-line @typescript-eslint/no-implied-eval
        Function('return this')());
}

/**
 * Normalizes our expected stringified form of a function across versions of node
 * @param fn - The function to stringify
 */
function normalizedFunctionString(fn) {
    return fn.toString().replace('function(', 'function (');
}
function isReactNative$1() {
    var g = getGlobal();
    return typeof g.navigator === 'object' && g.navigator.product === 'ReactNative';
}
var insecureRandomBytes = function insecureRandomBytes(size) {
    var insecureWarning = isReactNative$1()
        ? 'BSON: For React Native please polyfill crypto.getRandomValues, e.g. using: https://www.npmjs.com/package/react-native-get-random-values.'
        : 'BSON: No cryptographic implementation for random bytes present, falling back to a less secure implementation.';
    console.warn(insecureWarning);
    var result = Buffer$1.alloc(size);
    for (var i = 0; i < size; ++i)
        result[i] = Math.floor(Math.random() * 256);
    return result;
};
var detectRandomBytes = function () {
    {
        var requiredRandomBytes = void 0;
        try {
            requiredRandomBytes = require('crypto').randomBytes;
        }
        catch (e) {
            // keep the fallback
        }
        // NOTE: in transpiled cases the above require might return null/undefined
        return requiredRandomBytes || insecureRandomBytes;
    }
};
var randomBytes = detectRandomBytes();
function isAnyArrayBuffer$1(value) {
    return ['[object ArrayBuffer]', '[object SharedArrayBuffer]'].includes(Object.prototype.toString.call(value));
}
function isUint8Array$1(value) {
    return Object.prototype.toString.call(value) === '[object Uint8Array]';
}
function isBigInt64Array(value) {
    return Object.prototype.toString.call(value) === '[object BigInt64Array]';
}
function isBigUInt64Array(value) {
    return Object.prototype.toString.call(value) === '[object BigUint64Array]';
}
function isRegExp$1(d) {
    return Object.prototype.toString.call(d) === '[object RegExp]';
}
function isMap$2(d) {
    return Object.prototype.toString.call(d) === '[object Map]';
}
// To ensure that 0.4 of node works correctly
function isDate$1(d) {
    return isObjectLike(d) && Object.prototype.toString.call(d) === '[object Date]';
}
/**
 * @internal
 * this is to solve the `'someKey' in x` problem where x is unknown.
 * https://github.com/typescript-eslint/typescript-eslint/issues/1071#issuecomment-541955753
 */
function isObjectLike(candidate) {
    return typeof candidate === 'object' && candidate !== null;
}
function deprecate$1(fn, message) {
    var warned = false;
    function deprecated() {
        var args = [];
        for (var _i = 0; _i < arguments.length; _i++) {
            args[_i] = arguments[_i];
        }
        if (!warned) {
            console.warn(message);
            warned = true;
        }
        return fn.apply(this, args);
    }
    return deprecated;
}

/**
 * Makes sure that, if a Uint8Array is passed in, it is wrapped in a Buffer.
 *
 * @param potentialBuffer - The potential buffer
 * @returns Buffer the input if potentialBuffer is a buffer, or a buffer that
 * wraps a passed in Uint8Array
 * @throws BSONTypeError If anything other than a Buffer or Uint8Array is passed in
 */
function ensureBuffer(potentialBuffer) {
    if (ArrayBuffer.isView(potentialBuffer)) {
        return Buffer$1.from(potentialBuffer.buffer, potentialBuffer.byteOffset, potentialBuffer.byteLength);
    }
    if (isAnyArrayBuffer$1(potentialBuffer)) {
        return Buffer$1.from(potentialBuffer);
    }
    throw new BSONTypeError('Must use either Buffer or TypedArray');
}

// Validation regex for v4 uuid (validates with or without dashes)
var VALIDATION_REGEX = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-4[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|[0-9a-f]{12}4[0-9a-f]{3}[89ab][0-9a-f]{15})$/i;
var uuidValidateString = function (str) {
    return typeof str === 'string' && VALIDATION_REGEX.test(str);
};
var uuidHexStringToBuffer = function (hexString) {
    if (!uuidValidateString(hexString)) {
        throw new BSONTypeError('UUID string representations must be a 32 or 36 character hex string (dashes excluded/included). Format: "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" or "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx".');
    }
    var sanitizedHexString = hexString.replace(/-/g, '');
    return Buffer$1.from(sanitizedHexString, 'hex');
};
var bufferToUuidHexString = function (buffer, includeDashes) {
    if (includeDashes === void 0) { includeDashes = true; }
    return includeDashes
        ? buffer.toString('hex', 0, 4) +
            '-' +
            buffer.toString('hex', 4, 6) +
            '-' +
            buffer.toString('hex', 6, 8) +
            '-' +
            buffer.toString('hex', 8, 10) +
            '-' +
            buffer.toString('hex', 10, 16)
        : buffer.toString('hex');
};

/** @internal */
var BSON_INT32_MAX$1 = 0x7fffffff;
/** @internal */
var BSON_INT32_MIN$1 = -0x80000000;
/** @internal */
var BSON_INT64_MAX$1 = Math.pow(2, 63) - 1;
/** @internal */
var BSON_INT64_MIN$1 = -Math.pow(2, 63);
/**
 * Any integer up to 2^53 can be precisely represented by a double.
 * @internal
 */
var JS_INT_MAX$1 = Math.pow(2, 53);
/**
 * Any integer down to -2^53 can be precisely represented by a double.
 * @internal
 */
var JS_INT_MIN$1 = -Math.pow(2, 53);
/** Number BSON Type @internal */
var BSON_DATA_NUMBER$1 = 1;
/** String BSON Type @internal */
var BSON_DATA_STRING$1 = 2;
/** Object BSON Type @internal */
var BSON_DATA_OBJECT$1 = 3;
/** Array BSON Type @internal */
var BSON_DATA_ARRAY$1 = 4;
/** Binary BSON Type @internal */
var BSON_DATA_BINARY$1 = 5;
/** Binary BSON Type @internal */
var BSON_DATA_UNDEFINED$1 = 6;
/** ObjectId BSON Type @internal */
var BSON_DATA_OID$1 = 7;
/** Boolean BSON Type @internal */
var BSON_DATA_BOOLEAN$1 = 8;
/** Date BSON Type @internal */
var BSON_DATA_DATE$1 = 9;
/** null BSON Type @internal */
var BSON_DATA_NULL$1 = 10;
/** RegExp BSON Type @internal */
var BSON_DATA_REGEXP$1 = 11;
/** Code BSON Type @internal */
var BSON_DATA_DBPOINTER$1 = 12;
/** Code BSON Type @internal */
var BSON_DATA_CODE$1 = 13;
/** Symbol BSON Type @internal */
var BSON_DATA_SYMBOL$1 = 14;
/** Code with Scope BSON Type @internal */
var BSON_DATA_CODE_W_SCOPE$1 = 15;
/** 32 bit Integer BSON Type @internal */
var BSON_DATA_INT$1 = 16;
/** Timestamp BSON Type @internal */
var BSON_DATA_TIMESTAMP$1 = 17;
/** Long BSON Type @internal */
var BSON_DATA_LONG$1 = 18;
/** Decimal128 BSON Type @internal */
var BSON_DATA_DECIMAL128$1 = 19;
/** MinKey BSON Type @internal */
var BSON_DATA_MIN_KEY$1 = 0xff;
/** MaxKey BSON Type @internal */
var BSON_DATA_MAX_KEY$1 = 0x7f;
/** Binary Default Type @internal */
var BSON_BINARY_SUBTYPE_DEFAULT$1 = 0;
/** Binary Function Type @internal */
var BSON_BINARY_SUBTYPE_FUNCTION = 1;
/** Binary Byte Array Type @internal */
var BSON_BINARY_SUBTYPE_BYTE_ARRAY = 2;
/** Binary Deprecated UUID Type @deprecated Please use BSON_BINARY_SUBTYPE_UUID_NEW @internal */
var BSON_BINARY_SUBTYPE_UUID = 3;
/** Binary UUID Type @internal */
var BSON_BINARY_SUBTYPE_UUID_NEW$1 = 4;
/** Binary MD5 Type @internal */
var BSON_BINARY_SUBTYPE_MD5 = 5;
/** Encrypted BSON type @internal */
var BSON_BINARY_SUBTYPE_ENCRYPTED = 6;
/** Column BSON type @internal */
var BSON_BINARY_SUBTYPE_COLUMN = 7;
/** Binary User Defined Type @internal */
var BSON_BINARY_SUBTYPE_USER_DEFINED = 128;

/**
 * A class representation of the BSON Binary type.
 * @public
 * @category BSONType
 */
var Binary$1 = /** @class */ (function () {
    /**
     * Create a new Binary instance.
     *
     * This constructor can accept a string as its first argument. In this case,
     * this string will be encoded using ISO-8859-1, **not** using UTF-8.
     * This is almost certainly not what you want. Use `new Binary(Buffer.from(string))`
     * instead to convert the string to a Buffer using UTF-8 first.
     *
     * @param buffer - a buffer object containing the binary data.
     * @param subType - the option binary type.
     */
    function Binary(buffer, subType) {
        if (!(this instanceof Binary))
            return new Binary(buffer, subType);
        if (!(buffer == null) &&
            !(typeof buffer === 'string') &&
            !ArrayBuffer.isView(buffer) &&
            !(buffer instanceof ArrayBuffer) &&
            !Array.isArray(buffer)) {
            throw new BSONTypeError('Binary can only be constructed from string, Buffer, TypedArray, or Array<number>');
        }
        this.sub_type = subType !== null && subType !== void 0 ? subType : Binary.BSON_BINARY_SUBTYPE_DEFAULT;
        if (buffer == null) {
            // create an empty binary buffer
            this.buffer = Buffer$1.alloc(Binary.BUFFER_SIZE);
            this.position = 0;
        }
        else {
            if (typeof buffer === 'string') {
                // string
                this.buffer = Buffer$1.from(buffer, 'binary');
            }
            else if (Array.isArray(buffer)) {
                // number[]
                this.buffer = Buffer$1.from(buffer);
            }
            else {
                // Buffer | TypedArray | ArrayBuffer
                this.buffer = ensureBuffer(buffer);
            }
            this.position = this.buffer.byteLength;
        }
    }
    /**
     * Updates this binary with byte_value.
     *
     * @param byteValue - a single byte we wish to write.
     */
    Binary.prototype.put = function (byteValue) {
        // If it's a string and a has more than one character throw an error
        if (typeof byteValue === 'string' && byteValue.length !== 1) {
            throw new BSONTypeError('only accepts single character String');
        }
        else if (typeof byteValue !== 'number' && byteValue.length !== 1)
            throw new BSONTypeError('only accepts single character Uint8Array or Array');
        // Decode the byte value once
        var decodedByte;
        if (typeof byteValue === 'string') {
            decodedByte = byteValue.charCodeAt(0);
        }
        else if (typeof byteValue === 'number') {
            decodedByte = byteValue;
        }
        else {
            decodedByte = byteValue[0];
        }
        if (decodedByte < 0 || decodedByte > 255) {
            throw new BSONTypeError('only accepts number in a valid unsigned byte range 0-255');
        }
        if (this.buffer.length > this.position) {
            this.buffer[this.position++] = decodedByte;
        }
        else {
            var buffer = Buffer$1.alloc(Binary.BUFFER_SIZE + this.buffer.length);
            // Combine the two buffers together
            this.buffer.copy(buffer, 0, 0, this.buffer.length);
            this.buffer = buffer;
            this.buffer[this.position++] = decodedByte;
        }
    };
    /**
     * Writes a buffer or string to the binary.
     *
     * @param sequence - a string or buffer to be written to the Binary BSON object.
     * @param offset - specify the binary of where to write the content.
     */
    Binary.prototype.write = function (sequence, offset) {
        offset = typeof offset === 'number' ? offset : this.position;
        // If the buffer is to small let's extend the buffer
        if (this.buffer.length < offset + sequence.length) {
            var buffer = Buffer$1.alloc(this.buffer.length + sequence.length);
            this.buffer.copy(buffer, 0, 0, this.buffer.length);
            // Assign the new buffer
            this.buffer = buffer;
        }
        if (ArrayBuffer.isView(sequence)) {
            this.buffer.set(ensureBuffer(sequence), offset);
            this.position =
                offset + sequence.byteLength > this.position ? offset + sequence.length : this.position;
        }
        else if (typeof sequence === 'string') {
            this.buffer.write(sequence, offset, sequence.length, 'binary');
            this.position =
                offset + sequence.length > this.position ? offset + sequence.length : this.position;
        }
    };
    /**
     * Reads **length** bytes starting at **position**.
     *
     * @param position - read from the given position in the Binary.
     * @param length - the number of bytes to read.
     */
    Binary.prototype.read = function (position, length) {
        length = length && length > 0 ? length : this.position;
        // Let's return the data based on the type we have
        return this.buffer.slice(position, position + length);
    };
    /**
     * Returns the value of this binary as a string.
     * @param asRaw - Will skip converting to a string
     * @remarks
     * This is handy when calling this function conditionally for some key value pairs and not others
     */
    Binary.prototype.value = function (asRaw) {
        asRaw = !!asRaw;
        // Optimize to serialize for the situation where the data == size of buffer
        if (asRaw && this.buffer.length === this.position) {
            return this.buffer;
        }
        // If it's a node.js buffer object
        if (asRaw) {
            return this.buffer.slice(0, this.position);
        }
        return this.buffer.toString('binary', 0, this.position);
    };
    /** the length of the binary sequence */
    Binary.prototype.length = function () {
        return this.position;
    };
    Binary.prototype.toJSON = function () {
        return this.buffer.toString('base64');
    };
    Binary.prototype.toString = function (format) {
        return this.buffer.toString(format);
    };
    /** @internal */
    Binary.prototype.toExtendedJSON = function (options) {
        options = options || {};
        var base64String = this.buffer.toString('base64');
        var subType = Number(this.sub_type).toString(16);
        if (options.legacy) {
            return {
                $binary: base64String,
                $type: subType.length === 1 ? '0' + subType : subType
            };
        }
        return {
            $binary: {
                base64: base64String,
                subType: subType.length === 1 ? '0' + subType : subType
            }
        };
    };
    Binary.prototype.toUUID = function () {
        if (this.sub_type === Binary.SUBTYPE_UUID) {
            return new UUID$1(this.buffer.slice(0, this.position));
        }
        throw new BSONError$1("Binary sub_type \"".concat(this.sub_type, "\" is not supported for converting to UUID. Only \"").concat(Binary.SUBTYPE_UUID, "\" is currently supported."));
    };
    /** @internal */
    Binary.fromExtendedJSON = function (doc, options) {
        options = options || {};
        var data;
        var type;
        if ('$binary' in doc) {
            if (options.legacy && typeof doc.$binary === 'string' && '$type' in doc) {
                type = doc.$type ? parseInt(doc.$type, 16) : 0;
                data = Buffer$1.from(doc.$binary, 'base64');
            }
            else {
                if (typeof doc.$binary !== 'string') {
                    type = doc.$binary.subType ? parseInt(doc.$binary.subType, 16) : 0;
                    data = Buffer$1.from(doc.$binary.base64, 'base64');
                }
            }
        }
        else if ('$uuid' in doc) {
            type = 4;
            data = uuidHexStringToBuffer(doc.$uuid);
        }
        if (!data) {
            throw new BSONTypeError("Unexpected Binary Extended JSON format ".concat(JSON.stringify(doc)));
        }
        return type === BSON_BINARY_SUBTYPE_UUID_NEW$1 ? new UUID$1(data) : new Binary(data, type);
    };
    /** @internal */
    Binary.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    Binary.prototype.inspect = function () {
        var asBuffer = this.value(true);
        return "new Binary(Buffer.from(\"".concat(asBuffer.toString('hex'), "\", \"hex\"), ").concat(this.sub_type, ")");
    };
    /**
     * Binary default subtype
     * @internal
     */
    Binary.BSON_BINARY_SUBTYPE_DEFAULT = 0;
    /** Initial buffer default size */
    Binary.BUFFER_SIZE = 256;
    /** Default BSON type */
    Binary.SUBTYPE_DEFAULT = 0;
    /** Function BSON type */
    Binary.SUBTYPE_FUNCTION = 1;
    /** Byte Array BSON type */
    Binary.SUBTYPE_BYTE_ARRAY = 2;
    /** Deprecated UUID BSON type @deprecated Please use SUBTYPE_UUID */
    Binary.SUBTYPE_UUID_OLD = 3;
    /** UUID BSON type */
    Binary.SUBTYPE_UUID = 4;
    /** MD5 BSON type */
    Binary.SUBTYPE_MD5 = 5;
    /** Encrypted BSON type */
    Binary.SUBTYPE_ENCRYPTED = 6;
    /** Column BSON type */
    Binary.SUBTYPE_COLUMN = 7;
    /** User BSON type */
    Binary.SUBTYPE_USER_DEFINED = 128;
    return Binary;
}());
Object.defineProperty(Binary$1.prototype, '_bsontype', { value: 'Binary' });
var UUID_BYTE_LENGTH$1 = 16;
/**
 * A class representation of the BSON UUID type.
 * @public
 */
var UUID$1 = /** @class */ (function (_super) {
    __extends(UUID, _super);
    /**
     * Create an UUID type
     *
     * @param input - Can be a 32 or 36 character hex string (dashes excluded/included) or a 16 byte binary Buffer.
     */
    function UUID(input) {
        var _this = this;
        var bytes;
        var hexStr;
        if (input == null) {
            bytes = UUID.generate();
        }
        else if (input instanceof UUID) {
            bytes = Buffer$1.from(input.buffer);
            hexStr = input.__id;
        }
        else if (ArrayBuffer.isView(input) && input.byteLength === UUID_BYTE_LENGTH$1) {
            bytes = ensureBuffer(input);
        }
        else if (typeof input === 'string') {
            bytes = uuidHexStringToBuffer(input);
        }
        else {
            throw new BSONTypeError('Argument passed in UUID constructor must be a UUID, a 16 byte Buffer or a 32/36 character hex string (dashes excluded/included, format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx).');
        }
        _this = _super.call(this, bytes, BSON_BINARY_SUBTYPE_UUID_NEW$1) || this;
        _this.__id = hexStr;
        return _this;
    }
    Object.defineProperty(UUID.prototype, "id", {
        /**
         * The UUID bytes
         * @readonly
         */
        get: function () {
            return this.buffer;
        },
        set: function (value) {
            this.buffer = value;
            if (UUID.cacheHexString) {
                this.__id = bufferToUuidHexString(value);
            }
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Returns the UUID id as a 32 or 36 character hex string representation, excluding/including dashes (defaults to 36 character dash separated)
     * @param includeDashes - should the string exclude dash-separators.
     * */
    UUID.prototype.toHexString = function (includeDashes) {
        if (includeDashes === void 0) { includeDashes = true; }
        if (UUID.cacheHexString && this.__id) {
            return this.__id;
        }
        var uuidHexString = bufferToUuidHexString(this.id, includeDashes);
        if (UUID.cacheHexString) {
            this.__id = uuidHexString;
        }
        return uuidHexString;
    };
    /**
     * Converts the id into a 36 character (dashes included) hex string, unless a encoding is specified.
     */
    UUID.prototype.toString = function (encoding) {
        return encoding ? this.id.toString(encoding) : this.toHexString();
    };
    /**
     * Converts the id into its JSON string representation.
     * A 36 character (dashes included) hex string in the format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
     */
    UUID.prototype.toJSON = function () {
        return this.toHexString();
    };
    /**
     * Compares the equality of this UUID with `otherID`.
     *
     * @param otherId - UUID instance to compare against.
     */
    UUID.prototype.equals = function (otherId) {
        if (!otherId) {
            return false;
        }
        if (otherId instanceof UUID) {
            return otherId.id.equals(this.id);
        }
        try {
            return new UUID(otherId).id.equals(this.id);
        }
        catch (_a) {
            return false;
        }
    };
    /**
     * Creates a Binary instance from the current UUID.
     */
    UUID.prototype.toBinary = function () {
        return new Binary$1(this.id, Binary$1.SUBTYPE_UUID);
    };
    /**
     * Generates a populated buffer containing a v4 uuid
     */
    UUID.generate = function () {
        var bytes = randomBytes(UUID_BYTE_LENGTH$1);
        // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`
        // Kindly borrowed from https://github.com/uuidjs/uuid/blob/master/src/v4.js
        bytes[6] = (bytes[6] & 0x0f) | 0x40;
        bytes[8] = (bytes[8] & 0x3f) | 0x80;
        return Buffer$1.from(bytes);
    };
    /**
     * Checks if a value is a valid bson UUID
     * @param input - UUID, string or Buffer to validate.
     */
    UUID.isValid = function (input) {
        if (!input) {
            return false;
        }
        if (input instanceof UUID) {
            return true;
        }
        if (typeof input === 'string') {
            return uuidValidateString(input);
        }
        if (isUint8Array$1(input)) {
            // check for length & uuid version (https://tools.ietf.org/html/rfc4122#section-4.1.3)
            if (input.length !== UUID_BYTE_LENGTH$1) {
                return false;
            }
            return (input[6] & 0xf0) === 0x40 && (input[8] & 0x80) === 0x80;
        }
        return false;
    };
    /**
     * Creates an UUID from a hex string representation of an UUID.
     * @param hexString - 32 or 36 character hex string (dashes excluded/included).
     */
    UUID.createFromHexString = function (hexString) {
        var buffer = uuidHexStringToBuffer(hexString);
        return new UUID(buffer);
    };
    /**
     * Converts to a string representation of this Id.
     *
     * @returns return the 36 character hex string representation.
     * @internal
     */
    UUID.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    UUID.prototype.inspect = function () {
        return "new UUID(\"".concat(this.toHexString(), "\")");
    };
    return UUID;
}(Binary$1));

/**
 * A class representation of the BSON Code type.
 * @public
 * @category BSONType
 */
var Code$1 = /** @class */ (function () {
    /**
     * @param code - a string or function.
     * @param scope - an optional scope for the function.
     */
    function Code(code, scope) {
        if (!(this instanceof Code))
            return new Code(code, scope);
        this.code = code;
        this.scope = scope;
    }
    Code.prototype.toJSON = function () {
        return { code: this.code, scope: this.scope };
    };
    /** @internal */
    Code.prototype.toExtendedJSON = function () {
        if (this.scope) {
            return { $code: this.code, $scope: this.scope };
        }
        return { $code: this.code };
    };
    /** @internal */
    Code.fromExtendedJSON = function (doc) {
        return new Code(doc.$code, doc.$scope);
    };
    /** @internal */
    Code.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    Code.prototype.inspect = function () {
        var codeJson = this.toJSON();
        return "new Code(\"".concat(String(codeJson.code), "\"").concat(codeJson.scope ? ", ".concat(JSON.stringify(codeJson.scope)) : '', ")");
    };
    return Code;
}());
Object.defineProperty(Code$1.prototype, '_bsontype', { value: 'Code' });

/** @internal */
function isDBRefLike$1(value) {
    return (isObjectLike(value) &&
        value.$id != null &&
        typeof value.$ref === 'string' &&
        (value.$db == null || typeof value.$db === 'string'));
}
/**
 * A class representation of the BSON DBRef type.
 * @public
 * @category BSONType
 */
var DBRef$1 = /** @class */ (function () {
    /**
     * @param collection - the collection name.
     * @param oid - the reference ObjectId.
     * @param db - optional db name, if omitted the reference is local to the current db.
     */
    function DBRef(collection, oid, db, fields) {
        if (!(this instanceof DBRef))
            return new DBRef(collection, oid, db, fields);
        // check if namespace has been provided
        var parts = collection.split('.');
        if (parts.length === 2) {
            db = parts.shift();
            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
            collection = parts.shift();
        }
        this.collection = collection;
        this.oid = oid;
        this.db = db;
        this.fields = fields || {};
    }
    Object.defineProperty(DBRef.prototype, "namespace", {
        // Property provided for compatibility with the 1.x parser
        // the 1.x parser used a "namespace" property, while 4.x uses "collection"
        /** @internal */
        get: function () {
            return this.collection;
        },
        set: function (value) {
            this.collection = value;
        },
        enumerable: false,
        configurable: true
    });
    DBRef.prototype.toJSON = function () {
        var o = Object.assign({
            $ref: this.collection,
            $id: this.oid
        }, this.fields);
        if (this.db != null)
            o.$db = this.db;
        return o;
    };
    /** @internal */
    DBRef.prototype.toExtendedJSON = function (options) {
        options = options || {};
        var o = {
            $ref: this.collection,
            $id: this.oid
        };
        if (options.legacy) {
            return o;
        }
        if (this.db)
            o.$db = this.db;
        o = Object.assign(o, this.fields);
        return o;
    };
    /** @internal */
    DBRef.fromExtendedJSON = function (doc) {
        var copy = Object.assign({}, doc);
        delete copy.$ref;
        delete copy.$id;
        delete copy.$db;
        return new DBRef(doc.$ref, doc.$id, doc.$db, copy);
    };
    /** @internal */
    DBRef.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    DBRef.prototype.inspect = function () {
        // NOTE: if OID is an ObjectId class it will just print the oid string.
        var oid = this.oid === undefined || this.oid.toString === undefined ? this.oid : this.oid.toString();
        return "new DBRef(\"".concat(this.namespace, "\", new ObjectId(\"").concat(String(oid), "\")").concat(this.db ? ", \"".concat(this.db, "\"") : '', ")");
    };
    return DBRef;
}());
Object.defineProperty(DBRef$1.prototype, '_bsontype', { value: 'DBRef' });

/**
 * wasm optimizations, to do native i64 multiplication and divide
 */
var wasm$1 = undefined;
try {
    wasm$1 = new WebAssembly.Instance(new WebAssembly.Module(
    // prettier-ignore
    new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;
}
catch (_a) {
    // no wasm support
}
var TWO_PWR_16_DBL$1 = 1 << 16;
var TWO_PWR_24_DBL$1 = 1 << 24;
var TWO_PWR_32_DBL$1 = TWO_PWR_16_DBL$1 * TWO_PWR_16_DBL$1;
var TWO_PWR_64_DBL$1 = TWO_PWR_32_DBL$1 * TWO_PWR_32_DBL$1;
var TWO_PWR_63_DBL$1 = TWO_PWR_64_DBL$1 / 2;
/** A cache of the Long representations of small integer values. */
var INT_CACHE$1 = {};
/** A cache of the Long representations of small unsigned integer values. */
var UINT_CACHE$1 = {};
/**
 * A class representing a 64-bit integer
 * @public
 * @category BSONType
 * @remarks
 * The internal representation of a long is the two given signed, 32-bit values.
 * We use 32-bit pieces because these are the size of integers on which
 * Javascript performs bit-operations.  For operations like addition and
 * multiplication, we split each number into 16 bit pieces, which can easily be
 * multiplied within Javascript's floating-point representation without overflow
 * or change in sign.
 * In the algorithms below, we frequently reduce the negative case to the
 * positive case by negating the input(s) and then post-processing the result.
 * Note that we must ALWAYS check specially whether those values are MIN_VALUE
 * (-2^63) because -MIN_VALUE == MIN_VALUE (since 2^63 cannot be represented as
 * a positive number, it overflows back into a negative).  Not handling this
 * case would often result in infinite recursion.
 * Common constant values ZERO, ONE, NEG_ONE, etc. are found as static properties on this class.
 */
var Long$1 = /** @class */ (function () {
    /**
     * Constructs a 64 bit two's-complement integer, given its low and high 32 bit values as *signed* integers.
     *  See the from* functions below for more convenient ways of constructing Longs.
     *
     * Acceptable signatures are:
     * - Long(low, high, unsigned?)
     * - Long(bigint, unsigned?)
     * - Long(string, unsigned?)
     *
     * @param low - The low (signed) 32 bits of the long
     * @param high - The high (signed) 32 bits of the long
     * @param unsigned - Whether unsigned or not, defaults to signed
     */
    function Long(low, high, unsigned) {
        if (low === void 0) { low = 0; }
        if (!(this instanceof Long))
            return new Long(low, high, unsigned);
        if (typeof low === 'bigint') {
            Object.assign(this, Long.fromBigInt(low, !!high));
        }
        else if (typeof low === 'string') {
            Object.assign(this, Long.fromString(low, !!high));
        }
        else {
            this.low = low | 0;
            this.high = high | 0;
            this.unsigned = !!unsigned;
        }
        Object.defineProperty(this, '__isLong__', {
            value: true,
            configurable: false,
            writable: false,
            enumerable: false
        });
    }
    /**
     * Returns a Long representing the 64 bit integer that comes by concatenating the given low and high bits.
     * Each is assumed to use 32 bits.
     * @param lowBits - The low 32 bits
     * @param highBits - The high 32 bits
     * @param unsigned - Whether unsigned or not, defaults to signed
     * @returns The corresponding Long value
     */
    Long.fromBits = function (lowBits, highBits, unsigned) {
        return new Long(lowBits, highBits, unsigned);
    };
    /**
     * Returns a Long representing the given 32 bit integer value.
     * @param value - The 32 bit integer in question
     * @param unsigned - Whether unsigned or not, defaults to signed
     * @returns The corresponding Long value
     */
    Long.fromInt = function (value, unsigned) {
        var obj, cachedObj, cache;
        if (unsigned) {
            value >>>= 0;
            if ((cache = 0 <= value && value < 256)) {
                cachedObj = UINT_CACHE$1[value];
                if (cachedObj)
                    return cachedObj;
            }
            obj = Long.fromBits(value, (value | 0) < 0 ? -1 : 0, true);
            if (cache)
                UINT_CACHE$1[value] = obj;
            return obj;
        }
        else {
            value |= 0;
            if ((cache = -128 <= value && value < 128)) {
                cachedObj = INT_CACHE$1[value];
                if (cachedObj)
                    return cachedObj;
            }
            obj = Long.fromBits(value, value < 0 ? -1 : 0, false);
            if (cache)
                INT_CACHE$1[value] = obj;
            return obj;
        }
    };
    /**
     * Returns a Long representing the given value, provided that it is a finite number. Otherwise, zero is returned.
     * @param value - The number in question
     * @param unsigned - Whether unsigned or not, defaults to signed
     * @returns The corresponding Long value
     */
    Long.fromNumber = function (value, unsigned) {
        if (isNaN(value))
            return unsigned ? Long.UZERO : Long.ZERO;
        if (unsigned) {
            if (value < 0)
                return Long.UZERO;
            if (value >= TWO_PWR_64_DBL$1)
                return Long.MAX_UNSIGNED_VALUE;
        }
        else {
            if (value <= -TWO_PWR_63_DBL$1)
                return Long.MIN_VALUE;
            if (value + 1 >= TWO_PWR_63_DBL$1)
                return Long.MAX_VALUE;
        }
        if (value < 0)
            return Long.fromNumber(-value, unsigned).neg();
        return Long.fromBits(value % TWO_PWR_32_DBL$1 | 0, (value / TWO_PWR_32_DBL$1) | 0, unsigned);
    };
    /**
     * Returns a Long representing the given value, provided that it is a finite number. Otherwise, zero is returned.
     * @param value - The number in question
     * @param unsigned - Whether unsigned or not, defaults to signed
     * @returns The corresponding Long value
     */
    Long.fromBigInt = function (value, unsigned) {
        return Long.fromString(value.toString(), unsigned);
    };
    /**
     * Returns a Long representation of the given string, written using the specified radix.
     * @param str - The textual representation of the Long
     * @param unsigned - Whether unsigned or not, defaults to signed
     * @param radix - The radix in which the text is written (2-36), defaults to 10
     * @returns The corresponding Long value
     */
    Long.fromString = function (str, unsigned, radix) {
        if (str.length === 0)
            throw Error('empty string');
        if (str === 'NaN' || str === 'Infinity' || str === '+Infinity' || str === '-Infinity')
            return Long.ZERO;
        if (typeof unsigned === 'number') {
            // For goog.math.long compatibility
            (radix = unsigned), (unsigned = false);
        }
        else {
            unsigned = !!unsigned;
        }
        radix = radix || 10;
        if (radix < 2 || 36 < radix)
            throw RangeError('radix');
        var p;
        if ((p = str.indexOf('-')) > 0)
            throw Error('interior hyphen');
        else if (p === 0) {
            return Long.fromString(str.substring(1), unsigned, radix).neg();
        }
        // Do several (8) digits each time through the loop, so as to
        // minimize the calls to the very expensive emulated div.
        var radixToPower = Long.fromNumber(Math.pow(radix, 8));
        var result = Long.ZERO;
        for (var i = 0; i < str.length; i += 8) {
            var size = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size), radix);
            if (size < 8) {
                var power = Long.fromNumber(Math.pow(radix, size));
                result = result.mul(power).add(Long.fromNumber(value));
            }
            else {
                result = result.mul(radixToPower);
                result = result.add(Long.fromNumber(value));
            }
        }
        result.unsigned = unsigned;
        return result;
    };
    /**
     * Creates a Long from its byte representation.
     * @param bytes - Byte representation
     * @param unsigned - Whether unsigned or not, defaults to signed
     * @param le - Whether little or big endian, defaults to big endian
     * @returns The corresponding Long value
     */
    Long.fromBytes = function (bytes, unsigned, le) {
        return le ? Long.fromBytesLE(bytes, unsigned) : Long.fromBytesBE(bytes, unsigned);
    };
    /**
     * Creates a Long from its little endian byte representation.
     * @param bytes - Little endian byte representation
     * @param unsigned - Whether unsigned or not, defaults to signed
     * @returns The corresponding Long value
     */
    Long.fromBytesLE = function (bytes, unsigned) {
        return new Long(bytes[0] | (bytes[1] << 8) | (bytes[2] << 16) | (bytes[3] << 24), bytes[4] | (bytes[5] << 8) | (bytes[6] << 16) | (bytes[7] << 24), unsigned);
    };
    /**
     * Creates a Long from its big endian byte representation.
     * @param bytes - Big endian byte representation
     * @param unsigned - Whether unsigned or not, defaults to signed
     * @returns The corresponding Long value
     */
    Long.fromBytesBE = function (bytes, unsigned) {
        return new Long((bytes[4] << 24) | (bytes[5] << 16) | (bytes[6] << 8) | bytes[7], (bytes[0] << 24) | (bytes[1] << 16) | (bytes[2] << 8) | bytes[3], unsigned);
    };
    /**
     * Tests if the specified object is a Long.
     */
    Long.isLong = function (value) {
        return isObjectLike(value) && value['__isLong__'] === true;
    };
    /**
     * Converts the specified value to a Long.
     * @param unsigned - Whether unsigned or not, defaults to signed
     */
    Long.fromValue = function (val, unsigned) {
        if (typeof val === 'number')
            return Long.fromNumber(val, unsigned);
        if (typeof val === 'string')
            return Long.fromString(val, unsigned);
        // Throws for non-objects, converts non-instanceof Long:
        return Long.fromBits(val.low, val.high, typeof unsigned === 'boolean' ? unsigned : val.unsigned);
    };
    /** Returns the sum of this and the specified Long. */
    Long.prototype.add = function (addend) {
        if (!Long.isLong(addend))
            addend = Long.fromValue(addend);
        // Divide each number into 4 chunks of 16 bits, and then sum the chunks.
        var a48 = this.high >>> 16;
        var a32 = this.high & 0xffff;
        var a16 = this.low >>> 16;
        var a00 = this.low & 0xffff;
        var b48 = addend.high >>> 16;
        var b32 = addend.high & 0xffff;
        var b16 = addend.low >>> 16;
        var b00 = addend.low & 0xffff;
        var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
        c00 += a00 + b00;
        c16 += c00 >>> 16;
        c00 &= 0xffff;
        c16 += a16 + b16;
        c32 += c16 >>> 16;
        c16 &= 0xffff;
        c32 += a32 + b32;
        c48 += c32 >>> 16;
        c32 &= 0xffff;
        c48 += a48 + b48;
        c48 &= 0xffff;
        return Long.fromBits((c16 << 16) | c00, (c48 << 16) | c32, this.unsigned);
    };
    /**
     * Returns the sum of this and the specified Long.
     * @returns Sum
     */
    Long.prototype.and = function (other) {
        if (!Long.isLong(other))
            other = Long.fromValue(other);
        return Long.fromBits(this.low & other.low, this.high & other.high, this.unsigned);
    };
    /**
     * Compares this Long's value with the specified's.
     * @returns 0 if they are the same, 1 if the this is greater and -1 if the given one is greater
     */
    Long.prototype.compare = function (other) {
        if (!Long.isLong(other))
            other = Long.fromValue(other);
        if (this.eq(other))
            return 0;
        var thisNeg = this.isNegative(), otherNeg = other.isNegative();
        if (thisNeg && !otherNeg)
            return -1;
        if (!thisNeg && otherNeg)
            return 1;
        // At this point the sign bits are the same
        if (!this.unsigned)
            return this.sub(other).isNegative() ? -1 : 1;
        // Both are positive if at least one is unsigned
        return other.high >>> 0 > this.high >>> 0 ||
            (other.high === this.high && other.low >>> 0 > this.low >>> 0)
            ? -1
            : 1;
    };
    /** This is an alias of {@link Long.compare} */
    Long.prototype.comp = function (other) {
        return this.compare(other);
    };
    /**
     * Returns this Long divided by the specified. The result is signed if this Long is signed or unsigned if this Long is unsigned.
     * @returns Quotient
     */
    Long.prototype.divide = function (divisor) {
        if (!Long.isLong(divisor))
            divisor = Long.fromValue(divisor);
        if (divisor.isZero())
            throw Error('division by zero');
        // use wasm support if present
        if (wasm$1) {
            // guard against signed division overflow: the largest
            // negative number / -1 would be 1 larger than the largest
            // positive number, due to two's complement.
            if (!this.unsigned &&
                this.high === -0x80000000 &&
                divisor.low === -1 &&
                divisor.high === -1) {
                // be consistent with non-wasm code path
                return this;
            }
            var low = (this.unsigned ? wasm$1.div_u : wasm$1.div_s)(this.low, this.high, divisor.low, divisor.high);
            return Long.fromBits(low, wasm$1.get_high(), this.unsigned);
        }
        if (this.isZero())
            return this.unsigned ? Long.UZERO : Long.ZERO;
        var approx, rem, res;
        if (!this.unsigned) {
            // This section is only relevant for signed longs and is derived from the
            // closure library as a whole.
            if (this.eq(Long.MIN_VALUE)) {
                if (divisor.eq(Long.ONE) || divisor.eq(Long.NEG_ONE))
                    return Long.MIN_VALUE;
                // recall that -MIN_VALUE == MIN_VALUE
                else if (divisor.eq(Long.MIN_VALUE))
                    return Long.ONE;
                else {
                    // At this point, we have |other| >= 2, so |this/other| < |MIN_VALUE|.
                    var halfThis = this.shr(1);
                    approx = halfThis.div(divisor).shl(1);
                    if (approx.eq(Long.ZERO)) {
                        return divisor.isNegative() ? Long.ONE : Long.NEG_ONE;
                    }
                    else {
                        rem = this.sub(divisor.mul(approx));
                        res = approx.add(rem.div(divisor));
                        return res;
                    }
                }
            }
            else if (divisor.eq(Long.MIN_VALUE))
                return this.unsigned ? Long.UZERO : Long.ZERO;
            if (this.isNegative()) {
                if (divisor.isNegative())
                    return this.neg().div(divisor.neg());
                return this.neg().div(divisor).neg();
            }
            else if (divisor.isNegative())
                return this.div(divisor.neg()).neg();
            res = Long.ZERO;
        }
        else {
            // The algorithm below has not been made for unsigned longs. It's therefore
            // required to take special care of the MSB prior to running it.
            if (!divisor.unsigned)
                divisor = divisor.toUnsigned();
            if (divisor.gt(this))
                return Long.UZERO;
            if (divisor.gt(this.shru(1)))
                // 15 >>> 1 = 7 ; with divisor = 8 ; true
                return Long.UONE;
            res = Long.UZERO;
        }
        // Repeat the following until the remainder is less than other:  find a
        // floating-point that approximates remainder / other *from below*, add this
        // into the result, and subtract it from the remainder.  It is critical that
        // the approximate value is less than or equal to the real value so that the
        // remainder never becomes negative.
        // eslint-disable-next-line @typescript-eslint/no-this-alias
        rem = this;
        while (rem.gte(divisor)) {
            // Approximate the result of division. This may be a little greater or
            // smaller than the actual value.
            approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));
            // We will tweak the approximate result by changing it in the 48-th digit or
            // the smallest non-fractional digit, whichever is larger.
            var log2 = Math.ceil(Math.log(approx) / Math.LN2);
            var delta = log2 <= 48 ? 1 : Math.pow(2, log2 - 48);
            // Decrease the approximation until it is smaller than the remainder.  Note
            // that if it is too large, the product overflows and is negative.
            var approxRes = Long.fromNumber(approx);
            var approxRem = approxRes.mul(divisor);
            while (approxRem.isNegative() || approxRem.gt(rem)) {
                approx -= delta;
                approxRes = Long.fromNumber(approx, this.unsigned);
                approxRem = approxRes.mul(divisor);
            }
            // We know the answer can't be zero... and actually, zero would cause
            // infinite recursion since we would make no progress.
            if (approxRes.isZero())
                approxRes = Long.ONE;
            res = res.add(approxRes);
            rem = rem.sub(approxRem);
        }
        return res;
    };
    /**This is an alias of {@link Long.divide} */
    Long.prototype.div = function (divisor) {
        return this.divide(divisor);
    };
    /**
     * Tests if this Long's value equals the specified's.
     * @param other - Other value
     */
    Long.prototype.equals = function (other) {
        if (!Long.isLong(other))
            other = Long.fromValue(other);
        if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)
            return false;
        return this.high === other.high && this.low === other.low;
    };
    /** This is an alias of {@link Long.equals} */
    Long.prototype.eq = function (other) {
        return this.equals(other);
    };
    /** Gets the high 32 bits as a signed integer. */
    Long.prototype.getHighBits = function () {
        return this.high;
    };
    /** Gets the high 32 bits as an unsigned integer. */
    Long.prototype.getHighBitsUnsigned = function () {
        return this.high >>> 0;
    };
    /** Gets the low 32 bits as a signed integer. */
    Long.prototype.getLowBits = function () {
        return this.low;
    };
    /** Gets the low 32 bits as an unsigned integer. */
    Long.prototype.getLowBitsUnsigned = function () {
        return this.low >>> 0;
    };
    /** Gets the number of bits needed to represent the absolute value of this Long. */
    Long.prototype.getNumBitsAbs = function () {
        if (this.isNegative()) {
            // Unsigned Longs are never negative
            return this.eq(Long.MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();
        }
        var val = this.high !== 0 ? this.high : this.low;
        var bit;
        for (bit = 31; bit > 0; bit--)
            if ((val & (1 << bit)) !== 0)
                break;
        return this.high !== 0 ? bit + 33 : bit + 1;
    };
    /** Tests if this Long's value is greater than the specified's. */
    Long.prototype.greaterThan = function (other) {
        return this.comp(other) > 0;
    };
    /** This is an alias of {@link Long.greaterThan} */
    Long.prototype.gt = function (other) {
        return this.greaterThan(other);
    };
    /** Tests if this Long's value is greater than or equal the specified's. */
    Long.prototype.greaterThanOrEqual = function (other) {
        return this.comp(other) >= 0;
    };
    /** This is an alias of {@link Long.greaterThanOrEqual} */
    Long.prototype.gte = function (other) {
        return this.greaterThanOrEqual(other);
    };
    /** This is an alias of {@link Long.greaterThanOrEqual} */
    Long.prototype.ge = function (other) {
        return this.greaterThanOrEqual(other);
    };
    /** Tests if this Long's value is even. */
    Long.prototype.isEven = function () {
        return (this.low & 1) === 0;
    };
    /** Tests if this Long's value is negative. */
    Long.prototype.isNegative = function () {
        return !this.unsigned && this.high < 0;
    };
    /** Tests if this Long's value is odd. */
    Long.prototype.isOdd = function () {
        return (this.low & 1) === 1;
    };
    /** Tests if this Long's value is positive. */
    Long.prototype.isPositive = function () {
        return this.unsigned || this.high >= 0;
    };
    /** Tests if this Long's value equals zero. */
    Long.prototype.isZero = function () {
        return this.high === 0 && this.low === 0;
    };
    /** Tests if this Long's value is less than the specified's. */
    Long.prototype.lessThan = function (other) {
        return this.comp(other) < 0;
    };
    /** This is an alias of {@link Long#lessThan}. */
    Long.prototype.lt = function (other) {
        return this.lessThan(other);
    };
    /** Tests if this Long's value is less than or equal the specified's. */
    Long.prototype.lessThanOrEqual = function (other) {
        return this.comp(other) <= 0;
    };
    /** This is an alias of {@link Long.lessThanOrEqual} */
    Long.prototype.lte = function (other) {
        return this.lessThanOrEqual(other);
    };
    /** Returns this Long modulo the specified. */
    Long.prototype.modulo = function (divisor) {
        if (!Long.isLong(divisor))
            divisor = Long.fromValue(divisor);
        // use wasm support if present
        if (wasm$1) {
            var low = (this.unsigned ? wasm$1.rem_u : wasm$1.rem_s)(this.low, this.high, divisor.low, divisor.high);
            return Long.fromBits(low, wasm$1.get_high(), this.unsigned);
        }
        return this.sub(this.div(divisor).mul(divisor));
    };
    /** This is an alias of {@link Long.modulo} */
    Long.prototype.mod = function (divisor) {
        return this.modulo(divisor);
    };
    /** This is an alias of {@link Long.modulo} */
    Long.prototype.rem = function (divisor) {
        return this.modulo(divisor);
    };
    /**
     * Returns the product of this and the specified Long.
     * @param multiplier - Multiplier
     * @returns Product
     */
    Long.prototype.multiply = function (multiplier) {
        if (this.isZero())
            return Long.ZERO;
        if (!Long.isLong(multiplier))
            multiplier = Long.fromValue(multiplier);
        // use wasm support if present
        if (wasm$1) {
            var low = wasm$1.mul(this.low, this.high, multiplier.low, multiplier.high);
            return Long.fromBits(low, wasm$1.get_high(), this.unsigned);
        }
        if (multiplier.isZero())
            return Long.ZERO;
        if (this.eq(Long.MIN_VALUE))
            return multiplier.isOdd() ? Long.MIN_VALUE : Long.ZERO;
        if (multiplier.eq(Long.MIN_VALUE))
            return this.isOdd() ? Long.MIN_VALUE : Long.ZERO;
        if (this.isNegative()) {
            if (multiplier.isNegative())
                return this.neg().mul(multiplier.neg());
            else
                return this.neg().mul(multiplier).neg();
        }
        else if (multiplier.isNegative())
            return this.mul(multiplier.neg()).neg();
        // If both longs are small, use float multiplication
        if (this.lt(Long.TWO_PWR_24) && multiplier.lt(Long.TWO_PWR_24))
            return Long.fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);
        // Divide each long into 4 chunks of 16 bits, and then add up 4x4 products.
        // We can skip products that would overflow.
        var a48 = this.high >>> 16;
        var a32 = this.high & 0xffff;
        var a16 = this.low >>> 16;
        var a00 = this.low & 0xffff;
        var b48 = multiplier.high >>> 16;
        var b32 = multiplier.high & 0xffff;
        var b16 = multiplier.low >>> 16;
        var b00 = multiplier.low & 0xffff;
        var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
        c00 += a00 * b00;
        c16 += c00 >>> 16;
        c00 &= 0xffff;
        c16 += a16 * b00;
        c32 += c16 >>> 16;
        c16 &= 0xffff;
        c16 += a00 * b16;
        c32 += c16 >>> 16;
        c16 &= 0xffff;
        c32 += a32 * b00;
        c48 += c32 >>> 16;
        c32 &= 0xffff;
        c32 += a16 * b16;
        c48 += c32 >>> 16;
        c32 &= 0xffff;
        c32 += a00 * b32;
        c48 += c32 >>> 16;
        c32 &= 0xffff;
        c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;
        c48 &= 0xffff;
        return Long.fromBits((c16 << 16) | c00, (c48 << 16) | c32, this.unsigned);
    };
    /** This is an alias of {@link Long.multiply} */
    Long.prototype.mul = function (multiplier) {
        return this.multiply(multiplier);
    };
    /** Returns the Negation of this Long's value. */
    Long.prototype.negate = function () {
        if (!this.unsigned && this.eq(Long.MIN_VALUE))
            return Long.MIN_VALUE;
        return this.not().add(Long.ONE);
    };
    /** This is an alias of {@link Long.negate} */
    Long.prototype.neg = function () {
        return this.negate();
    };
    /** Returns the bitwise NOT of this Long. */
    Long.prototype.not = function () {
        return Long.fromBits(~this.low, ~this.high, this.unsigned);
    };
    /** Tests if this Long's value differs from the specified's. */
    Long.prototype.notEquals = function (other) {
        return !this.equals(other);
    };
    /** This is an alias of {@link Long.notEquals} */
    Long.prototype.neq = function (other) {
        return this.notEquals(other);
    };
    /** This is an alias of {@link Long.notEquals} */
    Long.prototype.ne = function (other) {
        return this.notEquals(other);
    };
    /**
     * Returns the bitwise OR of this Long and the specified.
     */
    Long.prototype.or = function (other) {
        if (!Long.isLong(other))
            other = Long.fromValue(other);
        return Long.fromBits(this.low | other.low, this.high | other.high, this.unsigned);
    };
    /**
     * Returns this Long with bits shifted to the left by the given amount.
     * @param numBits - Number of bits
     * @returns Shifted Long
     */
    Long.prototype.shiftLeft = function (numBits) {
        if (Long.isLong(numBits))
            numBits = numBits.toInt();
        if ((numBits &= 63) === 0)
            return this;
        else if (numBits < 32)
            return Long.fromBits(this.low << numBits, (this.high << numBits) | (this.low >>> (32 - numBits)), this.unsigned);
        else
            return Long.fromBits(0, this.low << (numBits - 32), this.unsigned);
    };
    /** This is an alias of {@link Long.shiftLeft} */
    Long.prototype.shl = function (numBits) {
        return this.shiftLeft(numBits);
    };
    /**
     * Returns this Long with bits arithmetically shifted to the right by the given amount.
     * @param numBits - Number of bits
     * @returns Shifted Long
     */
    Long.prototype.shiftRight = function (numBits) {
        if (Long.isLong(numBits))
            numBits = numBits.toInt();
        if ((numBits &= 63) === 0)
            return this;
        else if (numBits < 32)
            return Long.fromBits((this.low >>> numBits) | (this.high << (32 - numBits)), this.high >> numBits, this.unsigned);
        else
            return Long.fromBits(this.high >> (numBits - 32), this.high >= 0 ? 0 : -1, this.unsigned);
    };
    /** This is an alias of {@link Long.shiftRight} */
    Long.prototype.shr = function (numBits) {
        return this.shiftRight(numBits);
    };
    /**
     * Returns this Long with bits logically shifted to the right by the given amount.
     * @param numBits - Number of bits
     * @returns Shifted Long
     */
    Long.prototype.shiftRightUnsigned = function (numBits) {
        if (Long.isLong(numBits))
            numBits = numBits.toInt();
        numBits &= 63;
        if (numBits === 0)
            return this;
        else {
            var high = this.high;
            if (numBits < 32) {
                var low = this.low;
                return Long.fromBits((low >>> numBits) | (high << (32 - numBits)), high >>> numBits, this.unsigned);
            }
            else if (numBits === 32)
                return Long.fromBits(high, 0, this.unsigned);
            else
                return Long.fromBits(high >>> (numBits - 32), 0, this.unsigned);
        }
    };
    /** This is an alias of {@link Long.shiftRightUnsigned} */
    Long.prototype.shr_u = function (numBits) {
        return this.shiftRightUnsigned(numBits);
    };
    /** This is an alias of {@link Long.shiftRightUnsigned} */
    Long.prototype.shru = function (numBits) {
        return this.shiftRightUnsigned(numBits);
    };
    /**
     * Returns the difference of this and the specified Long.
     * @param subtrahend - Subtrahend
     * @returns Difference
     */
    Long.prototype.subtract = function (subtrahend) {
        if (!Long.isLong(subtrahend))
            subtrahend = Long.fromValue(subtrahend);
        return this.add(subtrahend.neg());
    };
    /** This is an alias of {@link Long.subtract} */
    Long.prototype.sub = function (subtrahend) {
        return this.subtract(subtrahend);
    };
    /** Converts the Long to a 32 bit integer, assuming it is a 32 bit integer. */
    Long.prototype.toInt = function () {
        return this.unsigned ? this.low >>> 0 : this.low;
    };
    /** Converts the Long to a the nearest floating-point representation of this value (double, 53 bit mantissa). */
    Long.prototype.toNumber = function () {
        if (this.unsigned)
            return (this.high >>> 0) * TWO_PWR_32_DBL$1 + (this.low >>> 0);
        return this.high * TWO_PWR_32_DBL$1 + (this.low >>> 0);
    };
    /** Converts the Long to a BigInt (arbitrary precision). */
    Long.prototype.toBigInt = function () {
        return BigInt(this.toString());
    };
    /**
     * Converts this Long to its byte representation.
     * @param le - Whether little or big endian, defaults to big endian
     * @returns Byte representation
     */
    Long.prototype.toBytes = function (le) {
        return le ? this.toBytesLE() : this.toBytesBE();
    };
    /**
     * Converts this Long to its little endian byte representation.
     * @returns Little endian byte representation
     */
    Long.prototype.toBytesLE = function () {
        var hi = this.high, lo = this.low;
        return [
            lo & 0xff,
            (lo >>> 8) & 0xff,
            (lo >>> 16) & 0xff,
            lo >>> 24,
            hi & 0xff,
            (hi >>> 8) & 0xff,
            (hi >>> 16) & 0xff,
            hi >>> 24
        ];
    };
    /**
     * Converts this Long to its big endian byte representation.
     * @returns Big endian byte representation
     */
    Long.prototype.toBytesBE = function () {
        var hi = this.high, lo = this.low;
        return [
            hi >>> 24,
            (hi >>> 16) & 0xff,
            (hi >>> 8) & 0xff,
            hi & 0xff,
            lo >>> 24,
            (lo >>> 16) & 0xff,
            (lo >>> 8) & 0xff,
            lo & 0xff
        ];
    };
    /**
     * Converts this Long to signed.
     */
    Long.prototype.toSigned = function () {
        if (!this.unsigned)
            return this;
        return Long.fromBits(this.low, this.high, false);
    };
    /**
     * Converts the Long to a string written in the specified radix.
     * @param radix - Radix (2-36), defaults to 10
     * @throws RangeError If `radix` is out of range
     */
    Long.prototype.toString = function (radix) {
        radix = radix || 10;
        if (radix < 2 || 36 < radix)
            throw RangeError('radix');
        if (this.isZero())
            return '0';
        if (this.isNegative()) {
            // Unsigned Longs are never negative
            if (this.eq(Long.MIN_VALUE)) {
                // We need to change the Long value before it can be negated, so we remove
                // the bottom-most digit in this base and then recurse to do the rest.
                var radixLong = Long.fromNumber(radix), div = this.div(radixLong), rem1 = div.mul(radixLong).sub(this);
                return div.toString(radix) + rem1.toInt().toString(radix);
            }
            else
                return '-' + this.neg().toString(radix);
        }
        // Do several (6) digits each time through the loop, so as to
        // minimize the calls to the very expensive emulated div.
        var radixToPower = Long.fromNumber(Math.pow(radix, 6), this.unsigned);
        // eslint-disable-next-line @typescript-eslint/no-this-alias
        var rem = this;
        var result = '';
        // eslint-disable-next-line no-constant-condition
        while (true) {
            var remDiv = rem.div(radixToPower);
            var intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0;
            var digits = intval.toString(radix);
            rem = remDiv;
            if (rem.isZero()) {
                return digits + result;
            }
            else {
                while (digits.length < 6)
                    digits = '0' + digits;
                result = '' + digits + result;
            }
        }
    };
    /** Converts this Long to unsigned. */
    Long.prototype.toUnsigned = function () {
        if (this.unsigned)
            return this;
        return Long.fromBits(this.low, this.high, true);
    };
    /** Returns the bitwise XOR of this Long and the given one. */
    Long.prototype.xor = function (other) {
        if (!Long.isLong(other))
            other = Long.fromValue(other);
        return Long.fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);
    };
    /** This is an alias of {@link Long.isZero} */
    Long.prototype.eqz = function () {
        return this.isZero();
    };
    /** This is an alias of {@link Long.lessThanOrEqual} */
    Long.prototype.le = function (other) {
        return this.lessThanOrEqual(other);
    };
    /*
     ****************************************************************
     *                  BSON SPECIFIC ADDITIONS                     *
     ****************************************************************
     */
    Long.prototype.toExtendedJSON = function (options) {
        if (options && options.relaxed)
            return this.toNumber();
        return { $numberLong: this.toString() };
    };
    Long.fromExtendedJSON = function (doc, options) {
        var result = Long.fromString(doc.$numberLong);
        return options && options.relaxed ? result.toNumber() : result;
    };
    /** @internal */
    Long.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    Long.prototype.inspect = function () {
        return "new Long(\"".concat(this.toString(), "\"").concat(this.unsigned ? ', true' : '', ")");
    };
    Long.TWO_PWR_24 = Long.fromInt(TWO_PWR_24_DBL$1);
    /** Maximum unsigned value. */
    Long.MAX_UNSIGNED_VALUE = Long.fromBits(0xffffffff | 0, 0xffffffff | 0, true);
    /** Signed zero */
    Long.ZERO = Long.fromInt(0);
    /** Unsigned zero. */
    Long.UZERO = Long.fromInt(0, true);
    /** Signed one. */
    Long.ONE = Long.fromInt(1);
    /** Unsigned one. */
    Long.UONE = Long.fromInt(1, true);
    /** Signed negative one. */
    Long.NEG_ONE = Long.fromInt(-1);
    /** Maximum signed value. */
    Long.MAX_VALUE = Long.fromBits(0xffffffff | 0, 0x7fffffff | 0, false);
    /** Minimum signed value. */
    Long.MIN_VALUE = Long.fromBits(0, 0x80000000 | 0, false);
    return Long;
}());
Object.defineProperty(Long$1.prototype, '__isLong__', { value: true });
Object.defineProperty(Long$1.prototype, '_bsontype', { value: 'Long' });

var PARSE_STRING_REGEXP$1 = /^(\+|-)?(\d+|(\d*\.\d*))?(E|e)?([-+])?(\d+)?$/;
var PARSE_INF_REGEXP$1 = /^(\+|-)?(Infinity|inf)$/i;
var PARSE_NAN_REGEXP$1 = /^(\+|-)?NaN$/i;
var EXPONENT_MAX$1 = 6111;
var EXPONENT_MIN$1 = -6176;
var EXPONENT_BIAS$1 = 6176;
var MAX_DIGITS$1 = 34;
// Nan value bits as 32 bit values (due to lack of longs)
var NAN_BUFFER$1 = [
    0x7c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
].reverse();
// Infinity value bits 32 bit values (due to lack of longs)
var INF_NEGATIVE_BUFFER$1 = [
    0xf8, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
].reverse();
var INF_POSITIVE_BUFFER$1 = [
    0x78, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
].reverse();
var EXPONENT_REGEX$1 = /^([-+])?(\d+)?$/;
// Extract least significant 5 bits
var COMBINATION_MASK$1 = 0x1f;
// Extract least significant 14 bits
var EXPONENT_MASK$1 = 0x3fff;
// Value of combination field for Inf
var COMBINATION_INFINITY$1 = 30;
// Value of combination field for NaN
var COMBINATION_NAN$1 = 31;
// Detect if the value is a digit
function isDigit$2(value) {
    return !isNaN(parseInt(value, 10));
}
// Divide two uint128 values
function divideu128$1(value) {
    var DIVISOR = Long$1.fromNumber(1000 * 1000 * 1000);
    var _rem = Long$1.fromNumber(0);
    if (!value.parts[0] && !value.parts[1] && !value.parts[2] && !value.parts[3]) {
        return { quotient: value, rem: _rem };
    }
    for (var i = 0; i <= 3; i++) {
        // Adjust remainder to match value of next dividend
        _rem = _rem.shiftLeft(32);
        // Add the divided to _rem
        _rem = _rem.add(new Long$1(value.parts[i], 0));
        value.parts[i] = _rem.div(DIVISOR).low;
        _rem = _rem.modulo(DIVISOR);
    }
    return { quotient: value, rem: _rem };
}
// Multiply two Long values and return the 128 bit value
function multiply64x2$1(left, right) {
    if (!left && !right) {
        return { high: Long$1.fromNumber(0), low: Long$1.fromNumber(0) };
    }
    var leftHigh = left.shiftRightUnsigned(32);
    var leftLow = new Long$1(left.getLowBits(), 0);
    var rightHigh = right.shiftRightUnsigned(32);
    var rightLow = new Long$1(right.getLowBits(), 0);
    var productHigh = leftHigh.multiply(rightHigh);
    var productMid = leftHigh.multiply(rightLow);
    var productMid2 = leftLow.multiply(rightHigh);
    var productLow = leftLow.multiply(rightLow);
    productHigh = productHigh.add(productMid.shiftRightUnsigned(32));
    productMid = new Long$1(productMid.getLowBits(), 0)
        .add(productMid2)
        .add(productLow.shiftRightUnsigned(32));
    productHigh = productHigh.add(productMid.shiftRightUnsigned(32));
    productLow = productMid.shiftLeft(32).add(new Long$1(productLow.getLowBits(), 0));
    // Return the 128 bit result
    return { high: productHigh, low: productLow };
}
function lessThan$1(left, right) {
    // Make values unsigned
    var uhleft = left.high >>> 0;
    var uhright = right.high >>> 0;
    // Compare high bits first
    if (uhleft < uhright) {
        return true;
    }
    else if (uhleft === uhright) {
        var ulleft = left.low >>> 0;
        var ulright = right.low >>> 0;
        if (ulleft < ulright)
            return true;
    }
    return false;
}
function invalidErr$1(string, message) {
    throw new BSONTypeError("\"".concat(string, "\" is not a valid Decimal128 string - ").concat(message));
}
/**
 * A class representation of the BSON Decimal128 type.
 * @public
 * @category BSONType
 */
var Decimal128$1 = /** @class */ (function () {
    /**
     * @param bytes - a buffer containing the raw Decimal128 bytes in little endian order,
     *                or a string representation as returned by .toString()
     */
    function Decimal128(bytes) {
        if (!(this instanceof Decimal128))
            return new Decimal128(bytes);
        if (typeof bytes === 'string') {
            this.bytes = Decimal128.fromString(bytes).bytes;
        }
        else if (isUint8Array$1(bytes)) {
            if (bytes.byteLength !== 16) {
                throw new BSONTypeError('Decimal128 must take a Buffer of 16 bytes');
            }
            this.bytes = bytes;
        }
        else {
            throw new BSONTypeError('Decimal128 must take a Buffer or string');
        }
    }
    /**
     * Create a Decimal128 instance from a string representation
     *
     * @param representation - a numeric string representation.
     */
    Decimal128.fromString = function (representation) {
        // Parse state tracking
        var isNegative = false;
        var sawRadix = false;
        var foundNonZero = false;
        // Total number of significant digits (no leading or trailing zero)
        var significantDigits = 0;
        // Total number of significand digits read
        var nDigitsRead = 0;
        // Total number of digits (no leading zeros)
        var nDigits = 0;
        // The number of the digits after radix
        var radixPosition = 0;
        // The index of the first non-zero in *str*
        var firstNonZero = 0;
        // Digits Array
        var digits = [0];
        // The number of digits in digits
        var nDigitsStored = 0;
        // Insertion pointer for digits
        var digitsInsert = 0;
        // The index of the first non-zero digit
        var firstDigit = 0;
        // The index of the last digit
        var lastDigit = 0;
        // Exponent
        var exponent = 0;
        // loop index over array
        var i = 0;
        // The high 17 digits of the significand
        var significandHigh = new Long$1(0, 0);
        // The low 17 digits of the significand
        var significandLow = new Long$1(0, 0);
        // The biased exponent
        var biasedExponent = 0;
        // Read index
        var index = 0;
        // Naively prevent against REDOS attacks.
        // TODO: implementing a custom parsing for this, or refactoring the regex would yield
        //       further gains.
        if (representation.length >= 7000) {
            throw new BSONTypeError('' + representation + ' not a valid Decimal128 string');
        }
        // Results
        var stringMatch = representation.match(PARSE_STRING_REGEXP$1);
        var infMatch = representation.match(PARSE_INF_REGEXP$1);
        var nanMatch = representation.match(PARSE_NAN_REGEXP$1);
        // Validate the string
        if ((!stringMatch && !infMatch && !nanMatch) || representation.length === 0) {
            throw new BSONTypeError('' + representation + ' not a valid Decimal128 string');
        }
        if (stringMatch) {
            // full_match = stringMatch[0]
            // sign = stringMatch[1]
            var unsignedNumber = stringMatch[2];
            // stringMatch[3] is undefined if a whole number (ex "1", 12")
            // but defined if a number w/ decimal in it (ex "1.0, 12.2")
            var e = stringMatch[4];
            var expSign = stringMatch[5];
            var expNumber = stringMatch[6];
            // they provided e, but didn't give an exponent number. for ex "1e"
            if (e && expNumber === undefined)
                invalidErr$1(representation, 'missing exponent power');
            // they provided e, but didn't give a number before it. for ex "e1"
            if (e && unsignedNumber === undefined)
                invalidErr$1(representation, 'missing exponent base');
            if (e === undefined && (expSign || expNumber)) {
                invalidErr$1(representation, 'missing e before exponent');
            }
        }
        // Get the negative or positive sign
        if (representation[index] === '+' || representation[index] === '-') {
            isNegative = representation[index++] === '-';
        }
        // Check if user passed Infinity or NaN
        if (!isDigit$2(representation[index]) && representation[index] !== '.') {
            if (representation[index] === 'i' || representation[index] === 'I') {
                return new Decimal128(Buffer$1.from(isNegative ? INF_NEGATIVE_BUFFER$1 : INF_POSITIVE_BUFFER$1));
            }
            else if (representation[index] === 'N') {
                return new Decimal128(Buffer$1.from(NAN_BUFFER$1));
            }
        }
        // Read all the digits
        while (isDigit$2(representation[index]) || representation[index] === '.') {
            if (representation[index] === '.') {
                if (sawRadix)
                    invalidErr$1(representation, 'contains multiple periods');
                sawRadix = true;
                index = index + 1;
                continue;
            }
            if (nDigitsStored < 34) {
                if (representation[index] !== '0' || foundNonZero) {
                    if (!foundNonZero) {
                        firstNonZero = nDigitsRead;
                    }
                    foundNonZero = true;
                    // Only store 34 digits
                    digits[digitsInsert++] = parseInt(representation[index], 10);
                    nDigitsStored = nDigitsStored + 1;
                }
            }
            if (foundNonZero)
                nDigits = nDigits + 1;
            if (sawRadix)
                radixPosition = radixPosition + 1;
            nDigitsRead = nDigitsRead + 1;
            index = index + 1;
        }
        if (sawRadix && !nDigitsRead)
            throw new BSONTypeError('' + representation + ' not a valid Decimal128 string');
        // Read exponent if exists
        if (representation[index] === 'e' || representation[index] === 'E') {
            // Read exponent digits
            var match = representation.substr(++index).match(EXPONENT_REGEX$1);
            // No digits read
            if (!match || !match[2])
                return new Decimal128(Buffer$1.from(NAN_BUFFER$1));
            // Get exponent
            exponent = parseInt(match[0], 10);
            // Adjust the index
            index = index + match[0].length;
        }
        // Return not a number
        if (representation[index])
            return new Decimal128(Buffer$1.from(NAN_BUFFER$1));
        // Done reading input
        // Find first non-zero digit in digits
        firstDigit = 0;
        if (!nDigitsStored) {
            firstDigit = 0;
            lastDigit = 0;
            digits[0] = 0;
            nDigits = 1;
            nDigitsStored = 1;
            significantDigits = 0;
        }
        else {
            lastDigit = nDigitsStored - 1;
            significantDigits = nDigits;
            if (significantDigits !== 1) {
                while (digits[firstNonZero + significantDigits - 1] === 0) {
                    significantDigits = significantDigits - 1;
                }
            }
        }
        // Normalization of exponent
        // Correct exponent based on radix position, and shift significand as needed
        // to represent user input
        // Overflow prevention
        if (exponent <= radixPosition && radixPosition - exponent > 1 << 14) {
            exponent = EXPONENT_MIN$1;
        }
        else {
            exponent = exponent - radixPosition;
        }
        // Attempt to normalize the exponent
        while (exponent > EXPONENT_MAX$1) {
            // Shift exponent to significand and decrease
            lastDigit = lastDigit + 1;
            if (lastDigit - firstDigit > MAX_DIGITS$1) {
                // Check if we have a zero then just hard clamp, otherwise fail
                var digitsString = digits.join('');
                if (digitsString.match(/^0+$/)) {
                    exponent = EXPONENT_MAX$1;
                    break;
                }
                invalidErr$1(representation, 'overflow');
            }
            exponent = exponent - 1;
        }
        while (exponent < EXPONENT_MIN$1 || nDigitsStored < nDigits) {
            // Shift last digit. can only do this if < significant digits than # stored.
            if (lastDigit === 0 && significantDigits < nDigitsStored) {
                exponent = EXPONENT_MIN$1;
                significantDigits = 0;
                break;
            }
            if (nDigitsStored < nDigits) {
                // adjust to match digits not stored
                nDigits = nDigits - 1;
            }
            else {
                // adjust to round
                lastDigit = lastDigit - 1;
            }
            if (exponent < EXPONENT_MAX$1) {
                exponent = exponent + 1;
            }
            else {
                // Check if we have a zero then just hard clamp, otherwise fail
                var digitsString = digits.join('');
                if (digitsString.match(/^0+$/)) {
                    exponent = EXPONENT_MAX$1;
                    break;
                }
                invalidErr$1(representation, 'overflow');
            }
        }
        // Round
        // We've normalized the exponent, but might still need to round.
        if (lastDigit - firstDigit + 1 < significantDigits) {
            var endOfString = nDigitsRead;
            // If we have seen a radix point, 'string' is 1 longer than we have
            // documented with ndigits_read, so inc the position of the first nonzero
            // digit and the position that digits are read to.
            if (sawRadix) {
                firstNonZero = firstNonZero + 1;
                endOfString = endOfString + 1;
            }
            // if negative, we need to increment again to account for - sign at start.
            if (isNegative) {
                firstNonZero = firstNonZero + 1;
                endOfString = endOfString + 1;
            }
            var roundDigit = parseInt(representation[firstNonZero + lastDigit + 1], 10);
            var roundBit = 0;
            if (roundDigit >= 5) {
                roundBit = 1;
                if (roundDigit === 5) {
                    roundBit = digits[lastDigit] % 2 === 1 ? 1 : 0;
                    for (i = firstNonZero + lastDigit + 2; i < endOfString; i++) {
                        if (parseInt(representation[i], 10)) {
                            roundBit = 1;
                            break;
                        }
                    }
                }
            }
            if (roundBit) {
                var dIdx = lastDigit;
                for (; dIdx >= 0; dIdx--) {
                    if (++digits[dIdx] > 9) {
                        digits[dIdx] = 0;
                        // overflowed most significant digit
                        if (dIdx === 0) {
                            if (exponent < EXPONENT_MAX$1) {
                                exponent = exponent + 1;
                                digits[dIdx] = 1;
                            }
                            else {
                                return new Decimal128(Buffer$1.from(isNegative ? INF_NEGATIVE_BUFFER$1 : INF_POSITIVE_BUFFER$1));
                            }
                        }
                    }
                }
            }
        }
        // Encode significand
        // The high 17 digits of the significand
        significandHigh = Long$1.fromNumber(0);
        // The low 17 digits of the significand
        significandLow = Long$1.fromNumber(0);
        // read a zero
        if (significantDigits === 0) {
            significandHigh = Long$1.fromNumber(0);
            significandLow = Long$1.fromNumber(0);
        }
        else if (lastDigit - firstDigit < 17) {
            var dIdx = firstDigit;
            significandLow = Long$1.fromNumber(digits[dIdx++]);
            significandHigh = new Long$1(0, 0);
            for (; dIdx <= lastDigit; dIdx++) {
                significandLow = significandLow.multiply(Long$1.fromNumber(10));
                significandLow = significandLow.add(Long$1.fromNumber(digits[dIdx]));
            }
        }
        else {
            var dIdx = firstDigit;
            significandHigh = Long$1.fromNumber(digits[dIdx++]);
            for (; dIdx <= lastDigit - 17; dIdx++) {
                significandHigh = significandHigh.multiply(Long$1.fromNumber(10));
                significandHigh = significandHigh.add(Long$1.fromNumber(digits[dIdx]));
            }
            significandLow = Long$1.fromNumber(digits[dIdx++]);
            for (; dIdx <= lastDigit; dIdx++) {
                significandLow = significandLow.multiply(Long$1.fromNumber(10));
                significandLow = significandLow.add(Long$1.fromNumber(digits[dIdx]));
            }
        }
        var significand = multiply64x2$1(significandHigh, Long$1.fromString('100000000000000000'));
        significand.low = significand.low.add(significandLow);
        if (lessThan$1(significand.low, significandLow)) {
            significand.high = significand.high.add(Long$1.fromNumber(1));
        }
        // Biased exponent
        biasedExponent = exponent + EXPONENT_BIAS$1;
        var dec = { low: Long$1.fromNumber(0), high: Long$1.fromNumber(0) };
        // Encode combination, exponent, and significand.
        if (significand.high.shiftRightUnsigned(49).and(Long$1.fromNumber(1)).equals(Long$1.fromNumber(1))) {
            // Encode '11' into bits 1 to 3
            dec.high = dec.high.or(Long$1.fromNumber(0x3).shiftLeft(61));
            dec.high = dec.high.or(Long$1.fromNumber(biasedExponent).and(Long$1.fromNumber(0x3fff).shiftLeft(47)));
            dec.high = dec.high.or(significand.high.and(Long$1.fromNumber(0x7fffffffffff)));
        }
        else {
            dec.high = dec.high.or(Long$1.fromNumber(biasedExponent & 0x3fff).shiftLeft(49));
            dec.high = dec.high.or(significand.high.and(Long$1.fromNumber(0x1ffffffffffff)));
        }
        dec.low = significand.low;
        // Encode sign
        if (isNegative) {
            dec.high = dec.high.or(Long$1.fromString('9223372036854775808'));
        }
        // Encode into a buffer
        var buffer = Buffer$1.alloc(16);
        index = 0;
        // Encode the low 64 bits of the decimal
        // Encode low bits
        buffer[index++] = dec.low.low & 0xff;
        buffer[index++] = (dec.low.low >> 8) & 0xff;
        buffer[index++] = (dec.low.low >> 16) & 0xff;
        buffer[index++] = (dec.low.low >> 24) & 0xff;
        // Encode high bits
        buffer[index++] = dec.low.high & 0xff;
        buffer[index++] = (dec.low.high >> 8) & 0xff;
        buffer[index++] = (dec.low.high >> 16) & 0xff;
        buffer[index++] = (dec.low.high >> 24) & 0xff;
        // Encode the high 64 bits of the decimal
        // Encode low bits
        buffer[index++] = dec.high.low & 0xff;
        buffer[index++] = (dec.high.low >> 8) & 0xff;
        buffer[index++] = (dec.high.low >> 16) & 0xff;
        buffer[index++] = (dec.high.low >> 24) & 0xff;
        // Encode high bits
        buffer[index++] = dec.high.high & 0xff;
        buffer[index++] = (dec.high.high >> 8) & 0xff;
        buffer[index++] = (dec.high.high >> 16) & 0xff;
        buffer[index++] = (dec.high.high >> 24) & 0xff;
        // Return the new Decimal128
        return new Decimal128(buffer);
    };
    /** Create a string representation of the raw Decimal128 value */
    Decimal128.prototype.toString = function () {
        // Note: bits in this routine are referred to starting at 0,
        // from the sign bit, towards the coefficient.
        // decoded biased exponent (14 bits)
        var biased_exponent;
        // the number of significand digits
        var significand_digits = 0;
        // the base-10 digits in the significand
        var significand = new Array(36);
        for (var i = 0; i < significand.length; i++)
            significand[i] = 0;
        // read pointer into significand
        var index = 0;
        // true if the number is zero
        var is_zero = false;
        // the most significant significand bits (50-46)
        var significand_msb;
        // temporary storage for significand decoding
        var significand128 = { parts: [0, 0, 0, 0] };
        // indexing variables
        var j, k;
        // Output string
        var string = [];
        // Unpack index
        index = 0;
        // Buffer reference
        var buffer = this.bytes;
        // Unpack the low 64bits into a long
        // bits 96 - 127
        var low = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);
        // bits 64 - 95
        var midl = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);
        // Unpack the high 64bits into a long
        // bits 32 - 63
        var midh = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);
        // bits 0 - 31
        var high = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);
        // Unpack index
        index = 0;
        // Create the state of the decimal
        var dec = {
            low: new Long$1(low, midl),
            high: new Long$1(midh, high)
        };
        if (dec.high.lessThan(Long$1.ZERO)) {
            string.push('-');
        }
        // Decode combination field and exponent
        // bits 1 - 5
        var combination = (high >> 26) & COMBINATION_MASK$1;
        if (combination >> 3 === 3) {
            // Check for 'special' values
            if (combination === COMBINATION_INFINITY$1) {
                return string.join('') + 'Infinity';
            }
            else if (combination === COMBINATION_NAN$1) {
                return 'NaN';
            }
            else {
                biased_exponent = (high >> 15) & EXPONENT_MASK$1;
                significand_msb = 0x08 + ((high >> 14) & 0x01);
            }
        }
        else {
            significand_msb = (high >> 14) & 0x07;
            biased_exponent = (high >> 17) & EXPONENT_MASK$1;
        }
        // unbiased exponent
        var exponent = biased_exponent - EXPONENT_BIAS$1;
        // Create string of significand digits
        // Convert the 114-bit binary number represented by
        // (significand_high, significand_low) to at most 34 decimal
        // digits through modulo and division.
        significand128.parts[0] = (high & 0x3fff) + ((significand_msb & 0xf) << 14);
        significand128.parts[1] = midh;
        significand128.parts[2] = midl;
        significand128.parts[3] = low;
        if (significand128.parts[0] === 0 &&
            significand128.parts[1] === 0 &&
            significand128.parts[2] === 0 &&
            significand128.parts[3] === 0) {
            is_zero = true;
        }
        else {
            for (k = 3; k >= 0; k--) {
                var least_digits = 0;
                // Perform the divide
                var result = divideu128$1(significand128);
                significand128 = result.quotient;
                least_digits = result.rem.low;
                // We now have the 9 least significant digits (in base 2).
                // Convert and output to string.
                if (!least_digits)
                    continue;
                for (j = 8; j >= 0; j--) {
                    // significand[k * 9 + j] = Math.round(least_digits % 10);
                    significand[k * 9 + j] = least_digits % 10;
                    // least_digits = Math.round(least_digits / 10);
                    least_digits = Math.floor(least_digits / 10);
                }
            }
        }
        // Output format options:
        // Scientific - [-]d.dddE(+/-)dd or [-]dE(+/-)dd
        // Regular    - ddd.ddd
        if (is_zero) {
            significand_digits = 1;
            significand[index] = 0;
        }
        else {
            significand_digits = 36;
            while (!significand[index]) {
                significand_digits = significand_digits - 1;
                index = index + 1;
            }
        }
        // the exponent if scientific notation is used
        var scientific_exponent = significand_digits - 1 + exponent;
        // The scientific exponent checks are dictated by the string conversion
        // specification and are somewhat arbitrary cutoffs.
        //
        // We must check exponent > 0, because if this is the case, the number
        // has trailing zeros.  However, we *cannot* output these trailing zeros,
        // because doing so would change the precision of the value, and would
        // change stored data if the string converted number is round tripped.
        if (scientific_exponent >= 34 || scientific_exponent <= -7 || exponent > 0) {
            // Scientific format
            // if there are too many significant digits, we should just be treating numbers
            // as + or - 0 and using the non-scientific exponent (this is for the "invalid
            // representation should be treated as 0/-0" spec cases in decimal128-1.json)
            if (significand_digits > 34) {
                string.push("".concat(0));
                if (exponent > 0)
                    string.push("E+".concat(exponent));
                else if (exponent < 0)
                    string.push("E".concat(exponent));
                return string.join('');
            }
            string.push("".concat(significand[index++]));
            significand_digits = significand_digits - 1;
            if (significand_digits) {
                string.push('.');
            }
            for (var i = 0; i < significand_digits; i++) {
                string.push("".concat(significand[index++]));
            }
            // Exponent
            string.push('E');
            if (scientific_exponent > 0) {
                string.push("+".concat(scientific_exponent));
            }
            else {
                string.push("".concat(scientific_exponent));
            }
        }
        else {
            // Regular format with no decimal place
            if (exponent >= 0) {
                for (var i = 0; i < significand_digits; i++) {
                    string.push("".concat(significand[index++]));
                }
            }
            else {
                var radix_position = significand_digits + exponent;
                // non-zero digits before radix
                if (radix_position > 0) {
                    for (var i = 0; i < radix_position; i++) {
                        string.push("".concat(significand[index++]));
                    }
                }
                else {
                    string.push('0');
                }
                string.push('.');
                // add leading zeros after radix
                while (radix_position++ < 0) {
                    string.push('0');
                }
                for (var i = 0; i < significand_digits - Math.max(radix_position - 1, 0); i++) {
                    string.push("".concat(significand[index++]));
                }
            }
        }
        return string.join('');
    };
    Decimal128.prototype.toJSON = function () {
        return { $numberDecimal: this.toString() };
    };
    /** @internal */
    Decimal128.prototype.toExtendedJSON = function () {
        return { $numberDecimal: this.toString() };
    };
    /** @internal */
    Decimal128.fromExtendedJSON = function (doc) {
        return Decimal128.fromString(doc.$numberDecimal);
    };
    /** @internal */
    Decimal128.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    Decimal128.prototype.inspect = function () {
        return "new Decimal128(\"".concat(this.toString(), "\")");
    };
    return Decimal128;
}());
Object.defineProperty(Decimal128$1.prototype, '_bsontype', { value: 'Decimal128' });

/**
 * A class representation of the BSON Double type.
 * @public
 * @category BSONType
 */
var Double$1 = /** @class */ (function () {
    /**
     * Create a Double type
     *
     * @param value - the number we want to represent as a double.
     */
    function Double(value) {
        if (!(this instanceof Double))
            return new Double(value);
        if (value instanceof Number) {
            value = value.valueOf();
        }
        this.value = +value;
    }
    /**
     * Access the number value.
     *
     * @returns returns the wrapped double number.
     */
    Double.prototype.valueOf = function () {
        return this.value;
    };
    Double.prototype.toJSON = function () {
        return this.value;
    };
    Double.prototype.toString = function (radix) {
        return this.value.toString(radix);
    };
    /** @internal */
    Double.prototype.toExtendedJSON = function (options) {
        if (options && (options.legacy || (options.relaxed && isFinite(this.value)))) {
            return this.value;
        }
        if (Object.is(Math.sign(this.value), -0)) {
            // NOTE: JavaScript has +0 and -0, apparently to model limit calculations. If a user
            // explicitly provided `-0` then we need to ensure the sign makes it into the output
            return { $numberDouble: "-".concat(this.value.toFixed(1)) };
        }
        return {
            $numberDouble: Number.isInteger(this.value) ? this.value.toFixed(1) : this.value.toString()
        };
    };
    /** @internal */
    Double.fromExtendedJSON = function (doc, options) {
        var doubleValue = parseFloat(doc.$numberDouble);
        return options && options.relaxed ? doubleValue : new Double(doubleValue);
    };
    /** @internal */
    Double.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    Double.prototype.inspect = function () {
        var eJSON = this.toExtendedJSON();
        return "new Double(".concat(eJSON.$numberDouble, ")");
    };
    return Double;
}());
Object.defineProperty(Double$1.prototype, '_bsontype', { value: 'Double' });

/**
 * A class representation of a BSON Int32 type.
 * @public
 * @category BSONType
 */
var Int32$1 = /** @class */ (function () {
    /**
     * Create an Int32 type
     *
     * @param value - the number we want to represent as an int32.
     */
    function Int32(value) {
        if (!(this instanceof Int32))
            return new Int32(value);
        if (value instanceof Number) {
            value = value.valueOf();
        }
        this.value = +value | 0;
    }
    /**
     * Access the number value.
     *
     * @returns returns the wrapped int32 number.
     */
    Int32.prototype.valueOf = function () {
        return this.value;
    };
    Int32.prototype.toString = function (radix) {
        return this.value.toString(radix);
    };
    Int32.prototype.toJSON = function () {
        return this.value;
    };
    /** @internal */
    Int32.prototype.toExtendedJSON = function (options) {
        if (options && (options.relaxed || options.legacy))
            return this.value;
        return { $numberInt: this.value.toString() };
    };
    /** @internal */
    Int32.fromExtendedJSON = function (doc, options) {
        return options && options.relaxed ? parseInt(doc.$numberInt, 10) : new Int32(doc.$numberInt);
    };
    /** @internal */
    Int32.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    Int32.prototype.inspect = function () {
        return "new Int32(".concat(this.valueOf(), ")");
    };
    return Int32;
}());
Object.defineProperty(Int32$1.prototype, '_bsontype', { value: 'Int32' });

/**
 * A class representation of the BSON MaxKey type.
 * @public
 * @category BSONType
 */
var MaxKey$1 = /** @class */ (function () {
    function MaxKey() {
        if (!(this instanceof MaxKey))
            return new MaxKey();
    }
    /** @internal */
    MaxKey.prototype.toExtendedJSON = function () {
        return { $maxKey: 1 };
    };
    /** @internal */
    MaxKey.fromExtendedJSON = function () {
        return new MaxKey();
    };
    /** @internal */
    MaxKey.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    MaxKey.prototype.inspect = function () {
        return 'new MaxKey()';
    };
    return MaxKey;
}());
Object.defineProperty(MaxKey$1.prototype, '_bsontype', { value: 'MaxKey' });

/**
 * A class representation of the BSON MinKey type.
 * @public
 * @category BSONType
 */
var MinKey$1 = /** @class */ (function () {
    function MinKey() {
        if (!(this instanceof MinKey))
            return new MinKey();
    }
    /** @internal */
    MinKey.prototype.toExtendedJSON = function () {
        return { $minKey: 1 };
    };
    /** @internal */
    MinKey.fromExtendedJSON = function () {
        return new MinKey();
    };
    /** @internal */
    MinKey.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    MinKey.prototype.inspect = function () {
        return 'new MinKey()';
    };
    return MinKey;
}());
Object.defineProperty(MinKey$1.prototype, '_bsontype', { value: 'MinKey' });

// Regular expression that checks for hex value
var checkForHexRegExp$1 = new RegExp('^[0-9a-fA-F]{24}$');
// Unique sequence for the current process (initialized on first use)
var PROCESS_UNIQUE$1 = null;
var kId = Symbol('id');
/**
 * A class representation of the BSON ObjectId type.
 * @public
 * @category BSONType
 */
var ObjectId$1 = /** @class */ (function () {
    /**
     * Create an ObjectId type
     *
     * @param inputId - Can be a 24 character hex string, 12 byte binary Buffer, or a number.
     */
    function ObjectId(inputId) {
        if (!(this instanceof ObjectId))
            return new ObjectId(inputId);
        // workingId is set based on type of input and whether valid id exists for the input
        var workingId;
        if (typeof inputId === 'object' && inputId && 'id' in inputId) {
            if (typeof inputId.id !== 'string' && !ArrayBuffer.isView(inputId.id)) {
                throw new BSONTypeError('Argument passed in must have an id that is of type string or Buffer');
            }
            if ('toHexString' in inputId && typeof inputId.toHexString === 'function') {
                workingId = Buffer$1.from(inputId.toHexString(), 'hex');
            }
            else {
                workingId = inputId.id;
            }
        }
        else {
            workingId = inputId;
        }
        // the following cases use workingId to construct an ObjectId
        if (workingId == null || typeof workingId === 'number') {
            // The most common use case (blank id, new objectId instance)
            // Generate a new id
            this[kId] = ObjectId.generate(typeof workingId === 'number' ? workingId : undefined);
        }
        else if (ArrayBuffer.isView(workingId) && workingId.byteLength === 12) {
            // If intstanceof matches we can escape calling ensure buffer in Node.js environments
            this[kId] = workingId instanceof Buffer$1 ? workingId : ensureBuffer(workingId);
        }
        else if (typeof workingId === 'string') {
            if (workingId.length === 12) {
                var bytes = Buffer$1.from(workingId);
                if (bytes.byteLength === 12) {
                    this[kId] = bytes;
                }
                else {
                    throw new BSONTypeError('Argument passed in must be a string of 12 bytes');
                }
            }
            else if (workingId.length === 24 && checkForHexRegExp$1.test(workingId)) {
                this[kId] = Buffer$1.from(workingId, 'hex');
            }
            else {
                throw new BSONTypeError('Argument passed in must be a string of 12 bytes or a string of 24 hex characters or an integer');
            }
        }
        else {
            throw new BSONTypeError('Argument passed in does not match the accepted types');
        }
        // If we are caching the hex string
        if (ObjectId.cacheHexString) {
            this.__id = this.id.toString('hex');
        }
    }
    Object.defineProperty(ObjectId.prototype, "id", {
        /**
         * The ObjectId bytes
         * @readonly
         */
        get: function () {
            return this[kId];
        },
        set: function (value) {
            this[kId] = value;
            if (ObjectId.cacheHexString) {
                this.__id = value.toString('hex');
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ObjectId.prototype, "generationTime", {
        /**
         * The generation time of this ObjectId instance
         * @deprecated Please use getTimestamp / createFromTime which returns an int32 epoch
         */
        get: function () {
            return this.id.readInt32BE(0);
        },
        set: function (value) {
            // Encode time into first 4 bytes
            this.id.writeUInt32BE(value, 0);
        },
        enumerable: false,
        configurable: true
    });
    /** Returns the ObjectId id as a 24 character hex string representation */
    ObjectId.prototype.toHexString = function () {
        if (ObjectId.cacheHexString && this.__id) {
            return this.__id;
        }
        var hexString = this.id.toString('hex');
        if (ObjectId.cacheHexString && !this.__id) {
            this.__id = hexString;
        }
        return hexString;
    };
    /**
     * Update the ObjectId index
     * @privateRemarks
     * Used in generating new ObjectId's on the driver
     * @internal
     */
    ObjectId.getInc = function () {
        return (ObjectId.index = (ObjectId.index + 1) % 0xffffff);
    };
    /**
     * Generate a 12 byte id buffer used in ObjectId's
     *
     * @param time - pass in a second based timestamp.
     */
    ObjectId.generate = function (time) {
        if ('number' !== typeof time) {
            time = Math.floor(Date.now() / 1000);
        }
        var inc = ObjectId.getInc();
        var buffer = Buffer$1.alloc(12);
        // 4-byte timestamp
        buffer.writeUInt32BE(time, 0);
        // set PROCESS_UNIQUE if yet not initialized
        if (PROCESS_UNIQUE$1 === null) {
            PROCESS_UNIQUE$1 = randomBytes(5);
        }
        // 5-byte process unique
        buffer[4] = PROCESS_UNIQUE$1[0];
        buffer[5] = PROCESS_UNIQUE$1[1];
        buffer[6] = PROCESS_UNIQUE$1[2];
        buffer[7] = PROCESS_UNIQUE$1[3];
        buffer[8] = PROCESS_UNIQUE$1[4];
        // 3-byte counter
        buffer[11] = inc & 0xff;
        buffer[10] = (inc >> 8) & 0xff;
        buffer[9] = (inc >> 16) & 0xff;
        return buffer;
    };
    /**
     * Converts the id into a 24 character hex string for printing
     *
     * @param format - The Buffer toString format parameter.
     */
    ObjectId.prototype.toString = function (format) {
        // Is the id a buffer then use the buffer toString method to return the format
        if (format)
            return this.id.toString(format);
        return this.toHexString();
    };
    /** Converts to its JSON the 24 character hex string representation. */
    ObjectId.prototype.toJSON = function () {
        return this.toHexString();
    };
    /**
     * Compares the equality of this ObjectId with `otherID`.
     *
     * @param otherId - ObjectId instance to compare against.
     */
    ObjectId.prototype.equals = function (otherId) {
        if (otherId === undefined || otherId === null) {
            return false;
        }
        if (otherId instanceof ObjectId) {
            return this[kId][11] === otherId[kId][11] && this[kId].equals(otherId[kId]);
        }
        if (typeof otherId === 'string' &&
            ObjectId.isValid(otherId) &&
            otherId.length === 12 &&
            isUint8Array$1(this.id)) {
            return otherId === Buffer$1.prototype.toString.call(this.id, 'latin1');
        }
        if (typeof otherId === 'string' && ObjectId.isValid(otherId) && otherId.length === 24) {
            return otherId.toLowerCase() === this.toHexString();
        }
        if (typeof otherId === 'string' && ObjectId.isValid(otherId) && otherId.length === 12) {
            return Buffer$1.from(otherId).equals(this.id);
        }
        if (typeof otherId === 'object' &&
            'toHexString' in otherId &&
            typeof otherId.toHexString === 'function') {
            var otherIdString = otherId.toHexString();
            var thisIdString = this.toHexString().toLowerCase();
            return typeof otherIdString === 'string' && otherIdString.toLowerCase() === thisIdString;
        }
        return false;
    };
    /** Returns the generation date (accurate up to the second) that this ID was generated. */
    ObjectId.prototype.getTimestamp = function () {
        var timestamp = new Date();
        var time = this.id.readUInt32BE(0);
        timestamp.setTime(Math.floor(time) * 1000);
        return timestamp;
    };
    /** @internal */
    ObjectId.createPk = function () {
        return new ObjectId();
    };
    /**
     * Creates an ObjectId from a second based number, with the rest of the ObjectId zeroed out. Used for comparisons or sorting the ObjectId.
     *
     * @param time - an integer number representing a number of seconds.
     */
    ObjectId.createFromTime = function (time) {
        var buffer = Buffer$1.from([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]);
        // Encode time into first 4 bytes
        buffer.writeUInt32BE(time, 0);
        // Return the new objectId
        return new ObjectId(buffer);
    };
    /**
     * Creates an ObjectId from a hex string representation of an ObjectId.
     *
     * @param hexString - create a ObjectId from a passed in 24 character hexstring.
     */
    ObjectId.createFromHexString = function (hexString) {
        // Throw an error if it's not a valid setup
        if (typeof hexString === 'undefined' || (hexString != null && hexString.length !== 24)) {
            throw new BSONTypeError('Argument passed in must be a single String of 12 bytes or a string of 24 hex characters');
        }
        return new ObjectId(Buffer$1.from(hexString, 'hex'));
    };
    /**
     * Checks if a value is a valid bson ObjectId
     *
     * @param id - ObjectId instance to validate.
     */
    ObjectId.isValid = function (id) {
        if (id == null)
            return false;
        try {
            new ObjectId(id);
            return true;
        }
        catch (_a) {
            return false;
        }
    };
    /** @internal */
    ObjectId.prototype.toExtendedJSON = function () {
        if (this.toHexString)
            return { $oid: this.toHexString() };
        return { $oid: this.toString('hex') };
    };
    /** @internal */
    ObjectId.fromExtendedJSON = function (doc) {
        return new ObjectId(doc.$oid);
    };
    /**
     * Converts to a string representation of this Id.
     *
     * @returns return the 24 character hex string representation.
     * @internal
     */
    ObjectId.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    ObjectId.prototype.inspect = function () {
        return "new ObjectId(\"".concat(this.toHexString(), "\")");
    };
    /** @internal */
    ObjectId.index = Math.floor(Math.random() * 0xffffff);
    return ObjectId;
}());
// Deprecated methods
Object.defineProperty(ObjectId$1.prototype, 'generate', {
    value: deprecate$1(function (time) { return ObjectId$1.generate(time); }, 'Please use the static `ObjectId.generate(time)` instead')
});
Object.defineProperty(ObjectId$1.prototype, 'getInc', {
    value: deprecate$1(function () { return ObjectId$1.getInc(); }, 'Please use the static `ObjectId.getInc()` instead')
});
Object.defineProperty(ObjectId$1.prototype, 'get_inc', {
    value: deprecate$1(function () { return ObjectId$1.getInc(); }, 'Please use the static `ObjectId.getInc()` instead')
});
Object.defineProperty(ObjectId$1, 'get_inc', {
    value: deprecate$1(function () { return ObjectId$1.getInc(); }, 'Please use the static `ObjectId.getInc()` instead')
});
Object.defineProperty(ObjectId$1.prototype, '_bsontype', { value: 'ObjectID' });

function alphabetize$1(str) {
    return str.split('').sort().join('');
}
/**
 * A class representation of the BSON RegExp type.
 * @public
 * @category BSONType
 */
var BSONRegExp$1 = /** @class */ (function () {
    /**
     * @param pattern - The regular expression pattern to match
     * @param options - The regular expression options
     */
    function BSONRegExp(pattern, options) {
        if (!(this instanceof BSONRegExp))
            return new BSONRegExp(pattern, options);
        this.pattern = pattern;
        this.options = alphabetize$1(options !== null && options !== void 0 ? options : '');
        if (this.pattern.indexOf('\x00') !== -1) {
            throw new BSONError$1("BSON Regex patterns cannot contain null bytes, found: ".concat(JSON.stringify(this.pattern)));
        }
        if (this.options.indexOf('\x00') !== -1) {
            throw new BSONError$1("BSON Regex options cannot contain null bytes, found: ".concat(JSON.stringify(this.options)));
        }
        // Validate options
        for (var i = 0; i < this.options.length; i++) {
            if (!(this.options[i] === 'i' ||
                this.options[i] === 'm' ||
                this.options[i] === 'x' ||
                this.options[i] === 'l' ||
                this.options[i] === 's' ||
                this.options[i] === 'u')) {
                throw new BSONError$1("The regular expression option [".concat(this.options[i], "] is not supported"));
            }
        }
    }
    BSONRegExp.parseOptions = function (options) {
        return options ? options.split('').sort().join('') : '';
    };
    /** @internal */
    BSONRegExp.prototype.toExtendedJSON = function (options) {
        options = options || {};
        if (options.legacy) {
            return { $regex: this.pattern, $options: this.options };
        }
        return { $regularExpression: { pattern: this.pattern, options: this.options } };
    };
    /** @internal */
    BSONRegExp.fromExtendedJSON = function (doc) {
        if ('$regex' in doc) {
            if (typeof doc.$regex !== 'string') {
                // This is for $regex query operators that have extended json values.
                if (doc.$regex._bsontype === 'BSONRegExp') {
                    return doc;
                }
            }
            else {
                return new BSONRegExp(doc.$regex, BSONRegExp.parseOptions(doc.$options));
            }
        }
        if ('$regularExpression' in doc) {
            return new BSONRegExp(doc.$regularExpression.pattern, BSONRegExp.parseOptions(doc.$regularExpression.options));
        }
        throw new BSONTypeError("Unexpected BSONRegExp EJSON object form: ".concat(JSON.stringify(doc)));
    };
    return BSONRegExp;
}());
Object.defineProperty(BSONRegExp$1.prototype, '_bsontype', { value: 'BSONRegExp' });

/**
 * A class representation of the BSON Symbol type.
 * @public
 * @category BSONType
 */
var BSONSymbol$1 = /** @class */ (function () {
    /**
     * @param value - the string representing the symbol.
     */
    function BSONSymbol(value) {
        if (!(this instanceof BSONSymbol))
            return new BSONSymbol(value);
        this.value = value;
    }
    /** Access the wrapped string value. */
    BSONSymbol.prototype.valueOf = function () {
        return this.value;
    };
    BSONSymbol.prototype.toString = function () {
        return this.value;
    };
    /** @internal */
    BSONSymbol.prototype.inspect = function () {
        return "new BSONSymbol(\"".concat(this.value, "\")");
    };
    BSONSymbol.prototype.toJSON = function () {
        return this.value;
    };
    /** @internal */
    BSONSymbol.prototype.toExtendedJSON = function () {
        return { $symbol: this.value };
    };
    /** @internal */
    BSONSymbol.fromExtendedJSON = function (doc) {
        return new BSONSymbol(doc.$symbol);
    };
    /** @internal */
    BSONSymbol.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    return BSONSymbol;
}());
Object.defineProperty(BSONSymbol$1.prototype, '_bsontype', { value: 'Symbol' });

/** @public */
var LongWithoutOverridesClass$1 = Long$1;
/**
 * @public
 * @category BSONType
 * */
var Timestamp$1 = /** @class */ (function (_super) {
    __extends(Timestamp, _super);
    function Timestamp(low, high) {
        var _this = this;
        // eslint-disable-next-line @typescript-eslint/ban-ts-comment
        // @ts-expect-error
        if (!(_this instanceof Timestamp))
            return new Timestamp(low, high);
        if (Long$1.isLong(low)) {
            _this = _super.call(this, low.low, low.high, true) || this;
        }
        else if (isObjectLike(low) && typeof low.t !== 'undefined' && typeof low.i !== 'undefined') {
            _this = _super.call(this, low.i, low.t, true) || this;
        }
        else {
            _this = _super.call(this, low, high, true) || this;
        }
        Object.defineProperty(_this, '_bsontype', {
            value: 'Timestamp',
            writable: false,
            configurable: false,
            enumerable: false
        });
        return _this;
    }
    Timestamp.prototype.toJSON = function () {
        return {
            $timestamp: this.toString()
        };
    };
    /** Returns a Timestamp represented by the given (32-bit) integer value. */
    Timestamp.fromInt = function (value) {
        return new Timestamp(Long$1.fromInt(value, true));
    };
    /** Returns a Timestamp representing the given number value, provided that it is a finite number. Otherwise, zero is returned. */
    Timestamp.fromNumber = function (value) {
        return new Timestamp(Long$1.fromNumber(value, true));
    };
    /**
     * Returns a Timestamp for the given high and low bits. Each is assumed to use 32 bits.
     *
     * @param lowBits - the low 32-bits.
     * @param highBits - the high 32-bits.
     */
    Timestamp.fromBits = function (lowBits, highBits) {
        return new Timestamp(lowBits, highBits);
    };
    /**
     * Returns a Timestamp from the given string, optionally using the given radix.
     *
     * @param str - the textual representation of the Timestamp.
     * @param optRadix - the radix in which the text is written.
     */
    Timestamp.fromString = function (str, optRadix) {
        return new Timestamp(Long$1.fromString(str, true, optRadix));
    };
    /** @internal */
    Timestamp.prototype.toExtendedJSON = function () {
        return { $timestamp: { t: this.high >>> 0, i: this.low >>> 0 } };
    };
    /** @internal */
    Timestamp.fromExtendedJSON = function (doc) {
        return new Timestamp(doc.$timestamp);
    };
    /** @internal */
    Timestamp.prototype[Symbol.for('nodejs.util.inspect.custom')] = function () {
        return this.inspect();
    };
    Timestamp.prototype.inspect = function () {
        return "new Timestamp({ t: ".concat(this.getHighBits(), ", i: ").concat(this.getLowBits(), " })");
    };
    Timestamp.MAX_VALUE = Long$1.MAX_UNSIGNED_VALUE;
    return Timestamp;
}(LongWithoutOverridesClass$1));

function isBSONType$1(value) {
    return (isObjectLike(value) && Reflect.has(value, '_bsontype') && typeof value._bsontype === 'string');
}
// INT32 boundaries
var BSON_INT32_MAX$2 = 0x7fffffff;
var BSON_INT32_MIN$2 = -0x80000000;
// INT64 boundaries
// const BSON_INT64_MAX = 0x7fffffffffffffff; // TODO(NODE-4377): This number cannot be precisely represented in JS
var BSON_INT64_MAX$2 = 0x8000000000000000;
var BSON_INT64_MIN$2 = -0x8000000000000000;
// all the types where we don't need to do any special processing and can just pass the EJSON
//straight to type.fromExtendedJSON
var keysToCodecs$1 = {
    $oid: ObjectId$1,
    $binary: Binary$1,
    $uuid: Binary$1,
    $symbol: BSONSymbol$1,
    $numberInt: Int32$1,
    $numberDecimal: Decimal128$1,
    $numberDouble: Double$1,
    $numberLong: Long$1,
    $minKey: MinKey$1,
    $maxKey: MaxKey$1,
    $regex: BSONRegExp$1,
    $regularExpression: BSONRegExp$1,
    $timestamp: Timestamp$1
};
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function deserializeValue$1(value, options) {
    if (options === void 0) { options = {}; }
    if (typeof value === 'number') {
        if (options.relaxed || options.legacy) {
            return value;
        }
        // if it's an integer, should interpret as smallest BSON integer
        // that can represent it exactly. (if out of range, interpret as double.)
        if (Math.floor(value) === value) {
            if (value >= BSON_INT32_MIN$2 && value <= BSON_INT32_MAX$2)
                return new Int32$1(value);
            if (value >= BSON_INT64_MIN$2 && value <= BSON_INT64_MAX$2)
                return Long$1.fromNumber(value);
        }
        // If the number is a non-integer or out of integer range, should interpret as BSON Double.
        return new Double$1(value);
    }
    // from here on out we're looking for bson types, so bail if its not an object
    if (value == null || typeof value !== 'object')
        return value;
    // upgrade deprecated undefined to null
    if (value.$undefined)
        return null;
    var keys = Object.keys(value).filter(function (k) { return k.startsWith('$') && value[k] != null; });
    for (var i = 0; i < keys.length; i++) {
        var c = keysToCodecs$1[keys[i]];
        if (c)
            return c.fromExtendedJSON(value, options);
    }
    if (value.$date != null) {
        var d = value.$date;
        var date = new Date();
        if (options.legacy) {
            if (typeof d === 'number')
                date.setTime(d);
            else if (typeof d === 'string')
                date.setTime(Date.parse(d));
        }
        else {
            if (typeof d === 'string')
                date.setTime(Date.parse(d));
            else if (Long$1.isLong(d))
                date.setTime(d.toNumber());
            else if (typeof d === 'number' && options.relaxed)
                date.setTime(d);
        }
        return date;
    }
    if (value.$code != null) {
        var copy = Object.assign({}, value);
        if (value.$scope) {
            copy.$scope = deserializeValue$1(value.$scope);
        }
        return Code$1.fromExtendedJSON(value);
    }
    if (isDBRefLike$1(value) || value.$dbPointer) {
        var v = value.$ref ? value : value.$dbPointer;
        // we run into this in a "degenerate EJSON" case (with $id and $ref order flipped)
        // because of the order JSON.parse goes through the document
        if (v instanceof DBRef$1)
            return v;
        var dollarKeys = Object.keys(v).filter(function (k) { return k.startsWith('$'); });
        var valid_1 = true;
        dollarKeys.forEach(function (k) {
            if (['$ref', '$id', '$db'].indexOf(k) === -1)
                valid_1 = false;
        });
        // only make DBRef if $ keys are all valid
        if (valid_1)
            return DBRef$1.fromExtendedJSON(v);
    }
    return value;
}
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function serializeArray$1(array, options) {
    return array.map(function (v, index) {
        options.seenObjects.push({ propertyName: "index ".concat(index), obj: null });
        try {
            return serializeValue$1(v, options);
        }
        finally {
            options.seenObjects.pop();
        }
    });
}
function getISOString$1(date) {
    var isoStr = date.toISOString();
    // we should only show milliseconds in timestamp if they're non-zero
    return date.getUTCMilliseconds() !== 0 ? isoStr : isoStr.slice(0, -5) + 'Z';
}
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function serializeValue$1(value, options) {
    if ((typeof value === 'object' || typeof value === 'function') && value !== null) {
        var index = options.seenObjects.findIndex(function (entry) { return entry.obj === value; });
        if (index !== -1) {
            var props = options.seenObjects.map(function (entry) { return entry.propertyName; });
            var leadingPart = props
                .slice(0, index)
                .map(function (prop) { return "".concat(prop, " -> "); })
                .join('');
            var alreadySeen = props[index];
            var circularPart = ' -> ' +
                props
                    .slice(index + 1, props.length - 1)
                    .map(function (prop) { return "".concat(prop, " -> "); })
                    .join('');
            var current = props[props.length - 1];
            var leadingSpace = ' '.repeat(leadingPart.length + alreadySeen.length / 2);
            var dashes = '-'.repeat(circularPart.length + (alreadySeen.length + current.length) / 2 - 1);
            throw new BSONTypeError('Converting circular structure to EJSON:\n' +
                "    ".concat(leadingPart).concat(alreadySeen).concat(circularPart).concat(current, "\n") +
                "    ".concat(leadingSpace, "\\").concat(dashes, "/"));
        }
        options.seenObjects[options.seenObjects.length - 1].obj = value;
    }
    if (Array.isArray(value))
        return serializeArray$1(value, options);
    if (value === undefined)
        return null;
    if (value instanceof Date || isDate$1(value)) {
        var dateNum = value.getTime(), 
        // is it in year range 1970-9999?
        inRange = dateNum > -1 && dateNum < 253402318800000;
        if (options.legacy) {
            return options.relaxed && inRange
                ? { $date: value.getTime() }
                : { $date: getISOString$1(value) };
        }
        return options.relaxed && inRange
            ? { $date: getISOString$1(value) }
            : { $date: { $numberLong: value.getTime().toString() } };
    }
    if (typeof value === 'number' && (!options.relaxed || !isFinite(value))) {
        // it's an integer
        if (Math.floor(value) === value) {
            var int32Range = value >= BSON_INT32_MIN$2 && value <= BSON_INT32_MAX$2, int64Range = value >= BSON_INT64_MIN$2 && value <= BSON_INT64_MAX$2;
            // interpret as being of the smallest BSON integer type that can represent the number exactly
            if (int32Range)
                return { $numberInt: value.toString() };
            if (int64Range)
                return { $numberLong: value.toString() };
        }
        return { $numberDouble: value.toString() };
    }
    if (value instanceof RegExp || isRegExp$1(value)) {
        var flags = value.flags;
        if (flags === undefined) {
            var match = value.toString().match(/[gimuy]*$/);
            if (match) {
                flags = match[0];
            }
        }
        var rx = new BSONRegExp$1(value.source, flags);
        return rx.toExtendedJSON(options);
    }
    if (value != null && typeof value === 'object')
        return serializeDocument$1(value, options);
    return value;
}
var BSON_TYPE_MAPPINGS$1 = {
    Binary: function (o) { return new Binary$1(o.value(), o.sub_type); },
    Code: function (o) { return new Code$1(o.code, o.scope); },
    DBRef: function (o) { return new DBRef$1(o.collection || o.namespace, o.oid, o.db, o.fields); },
    Decimal128: function (o) { return new Decimal128$1(o.bytes); },
    Double: function (o) { return new Double$1(o.value); },
    Int32: function (o) { return new Int32$1(o.value); },
    Long: function (o) {
        return Long$1.fromBits(
        // underscore variants for 1.x backwards compatibility
        o.low != null ? o.low : o.low_, o.low != null ? o.high : o.high_, o.low != null ? o.unsigned : o.unsigned_);
    },
    MaxKey: function () { return new MaxKey$1(); },
    MinKey: function () { return new MinKey$1(); },
    ObjectID: function (o) { return new ObjectId$1(o); },
    ObjectId: function (o) { return new ObjectId$1(o); },
    BSONRegExp: function (o) { return new BSONRegExp$1(o.pattern, o.options); },
    Symbol: function (o) { return new BSONSymbol$1(o.value); },
    Timestamp: function (o) { return Timestamp$1.fromBits(o.low, o.high); }
};
// eslint-disable-next-line @typescript-eslint/no-explicit-any
function serializeDocument$1(doc, options) {
    if (doc == null || typeof doc !== 'object')
        throw new BSONError$1('not an object instance');
    var bsontype = doc._bsontype;
    if (typeof bsontype === 'undefined') {
        // It's a regular object. Recursively serialize its property values.
        var _doc = {};
        for (var name in doc) {
            options.seenObjects.push({ propertyName: name, obj: null });
            try {
                var value = serializeValue$1(doc[name], options);
                if (name === '__proto__') {
                    Object.defineProperty(_doc, name, {
                        value: value,
                        writable: true,
                        enumerable: true,
                        configurable: true
                    });
                }
                else {
                    _doc[name] = value;
                }
            }
            finally {
                options.seenObjects.pop();
            }
        }
        return _doc;
    }
    else if (isBSONType$1(doc)) {
        // the "document" is really just a BSON type object
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        var outDoc = doc;
        if (typeof outDoc.toExtendedJSON !== 'function') {
            // There's no EJSON serialization function on the object. It's probably an
            // object created by a previous version of this library (or another library)
            // that's duck-typing objects to look like they were generated by this library).
            // Copy the object into this library's version of that type.
            var mapper = BSON_TYPE_MAPPINGS$1[doc._bsontype];
            if (!mapper) {
                throw new BSONTypeError('Unrecognized or invalid _bsontype: ' + doc._bsontype);
            }
            outDoc = mapper(outDoc);
        }
        // Two BSON types may have nested objects that may need to be serialized too
        if (bsontype === 'Code' && outDoc.scope) {
            outDoc = new Code$1(outDoc.code, serializeValue$1(outDoc.scope, options));
        }
        else if (bsontype === 'DBRef' && outDoc.oid) {
            outDoc = new DBRef$1(serializeValue$1(outDoc.collection, options), serializeValue$1(outDoc.oid, options), serializeValue$1(outDoc.db, options), serializeValue$1(outDoc.fields, options));
        }
        return outDoc.toExtendedJSON(options);
    }
    else {
        throw new BSONError$1('_bsontype must be a string, but was: ' + typeof bsontype);
    }
}
/**
 * EJSON parse / stringify API
 * @public
 */
// the namespace here is used to emulate `export * as EJSON from '...'`
// which as of now (sept 2020) api-extractor does not support
// eslint-disable-next-line @typescript-eslint/no-namespace
var EJSON$1;
(function (EJSON) {
    /**
     * Parse an Extended JSON string, constructing the JavaScript value or object described by that
     * string.
     *
     * @example
     * ```js
     * const { EJSON } = require('bson');
     * const text = '{ "int32": { "$numberInt": "10" } }';
     *
     * // prints { int32: { [String: '10'] _bsontype: 'Int32', value: '10' } }
     * console.log(EJSON.parse(text, { relaxed: false }));
     *
     * // prints { int32: 10 }
     * console.log(EJSON.parse(text));
     * ```
     */
    function parse(text, options) {
        var finalOptions = Object.assign({}, { relaxed: true, legacy: false }, options);
        // relaxed implies not strict
        if (typeof finalOptions.relaxed === 'boolean')
            finalOptions.strict = !finalOptions.relaxed;
        if (typeof finalOptions.strict === 'boolean')
            finalOptions.relaxed = !finalOptions.strict;
        return JSON.parse(text, function (key, value) {
            if (key.indexOf('\x00') !== -1) {
                throw new BSONError$1("BSON Document field names cannot contain null bytes, found: ".concat(JSON.stringify(key)));
            }
            return deserializeValue$1(value, finalOptions);
        });
    }
    EJSON.parse = parse;
    /**
     * Converts a BSON document to an Extended JSON string, optionally replacing values if a replacer
     * function is specified or optionally including only the specified properties if a replacer array
     * is specified.
     *
     * @param value - The value to convert to extended JSON
     * @param replacer - A function that alters the behavior of the stringification process, or an array of String and Number objects that serve as a whitelist for selecting/filtering the properties of the value object to be included in the JSON string. If this value is null or not provided, all properties of the object are included in the resulting JSON string
     * @param space - A String or Number object that's used to insert white space into the output JSON string for readability purposes.
     * @param options - Optional settings
     *
     * @example
     * ```js
     * const { EJSON } = require('bson');
     * const Int32 = require('mongodb').Int32;
     * const doc = { int32: new Int32(10) };
     *
     * // prints '{"int32":{"$numberInt":"10"}}'
     * console.log(EJSON.stringify(doc, { relaxed: false }));
     *
     * // prints '{"int32":10}'
     * console.log(EJSON.stringify(doc));
     * ```
     */
    function stringify(value, 
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    replacer, space, options) {
        if (space != null && typeof space === 'object') {
            options = space;
            space = 0;
        }
        if (replacer != null && typeof replacer === 'object' && !Array.isArray(replacer)) {
            options = replacer;
            replacer = undefined;
            space = 0;
        }
        var serializeOptions = Object.assign({ relaxed: true, legacy: false }, options, {
            seenObjects: [{ propertyName: '(root)', obj: null }]
        });
        var doc = serializeValue$1(value, serializeOptions);
        return JSON.stringify(doc, replacer, space);
    }
    EJSON.stringify = stringify;
    /**
     * Serializes an object to an Extended JSON string, and reparse it as a JavaScript object.
     *
     * @param value - The object to serialize
     * @param options - Optional settings passed to the `stringify` function
     */
    function serialize(value, options) {
        options = options || {};
        return JSON.parse(stringify(value, options));
    }
    EJSON.serialize = serialize;
    /**
     * Deserializes an Extended JSON object into a plain JavaScript object with native/BSON types
     *
     * @param ejson - The Extended JSON object to deserialize
     * @param options - Optional settings passed to the parse method
     */
    function deserialize(ejson, options) {
        options = options || {};
        return parse(JSON.stringify(ejson), options);
    }
    EJSON.deserialize = deserialize;
})(EJSON$1 || (EJSON$1 = {}));

/* eslint-disable @typescript-eslint/no-explicit-any */
/** @public */
var bsonMap;
var bsonGlobal = getGlobal();
if (bsonGlobal.Map) {
    bsonMap = bsonGlobal.Map;
}
else {
    // We will return a polyfill
    bsonMap = /** @class */ (function () {
        function Map(array) {
            if (array === void 0) { array = []; }
            this._keys = [];
            this._values = {};
            for (var i = 0; i < array.length; i++) {
                if (array[i] == null)
                    continue; // skip null and undefined
                var entry = array[i];
                var key = entry[0];
                var value = entry[1];
                // Add the key to the list of keys in order
                this._keys.push(key);
                // Add the key and value to the values dictionary with a point
                // to the location in the ordered keys list
                this._values[key] = { v: value, i: this._keys.length - 1 };
            }
        }
        Map.prototype.clear = function () {
            this._keys = [];
            this._values = {};
        };
        Map.prototype.delete = function (key) {
            var value = this._values[key];
            if (value == null)
                return false;
            // Delete entry
            delete this._values[key];
            // Remove the key from the ordered keys list
            this._keys.splice(value.i, 1);
            return true;
        };
        Map.prototype.entries = function () {
            var _this = this;
            var index = 0;
            return {
                next: function () {
                    var key = _this._keys[index++];
                    return {
                        value: key !== undefined ? [key, _this._values[key].v] : undefined,
                        done: key !== undefined ? false : true
                    };
                }
            };
        };
        Map.prototype.forEach = function (callback, self) {
            self = self || this;
            for (var i = 0; i < this._keys.length; i++) {
                var key = this._keys[i];
                // Call the forEach callback
                callback.call(self, this._values[key].v, key, self);
            }
        };
        Map.prototype.get = function (key) {
            return this._values[key] ? this._values[key].v : undefined;
        };
        Map.prototype.has = function (key) {
            return this._values[key] != null;
        };
        Map.prototype.keys = function () {
            var _this = this;
            var index = 0;
            return {
                next: function () {
                    var key = _this._keys[index++];
                    return {
                        value: key !== undefined ? key : undefined,
                        done: key !== undefined ? false : true
                    };
                }
            };
        };
        Map.prototype.set = function (key, value) {
            if (this._values[key]) {
                this._values[key].v = value;
                return this;
            }
            // Add the key to the list of keys in order
            this._keys.push(key);
            // Add the key and value to the values dictionary with a point
            // to the location in the ordered keys list
            this._values[key] = { v: value, i: this._keys.length - 1 };
            return this;
        };
        Map.prototype.values = function () {
            var _this = this;
            var index = 0;
            return {
                next: function () {
                    var key = _this._keys[index++];
                    return {
                        value: key !== undefined ? _this._values[key].v : undefined,
                        done: key !== undefined ? false : true
                    };
                }
            };
        };
        Object.defineProperty(Map.prototype, "size", {
            get: function () {
                return this._keys.length;
            },
            enumerable: false,
            configurable: true
        });
        return Map;
    }());
}

function calculateObjectSize$1(object, serializeFunctions, ignoreUndefined) {
    var totalLength = 4 + 1;
    if (Array.isArray(object)) {
        for (var i = 0; i < object.length; i++) {
            totalLength += calculateElement$1(i.toString(), object[i], serializeFunctions, true, ignoreUndefined);
        }
    }
    else {
        // If we have toBSON defined, override the current object
        if (typeof (object === null || object === void 0 ? void 0 : object.toBSON) === 'function') {
            object = object.toBSON();
        }
        // Calculate size
        for (var key in object) {
            totalLength += calculateElement$1(key, object[key], serializeFunctions, false, ignoreUndefined);
        }
    }
    return totalLength;
}
/** @internal */
function calculateElement$1(name, 
// eslint-disable-next-line @typescript-eslint/no-explicit-any
value, serializeFunctions, isArray, ignoreUndefined) {
    if (serializeFunctions === void 0) { serializeFunctions = false; }
    if (isArray === void 0) { isArray = false; }
    if (ignoreUndefined === void 0) { ignoreUndefined = false; }
    // If we have toBSON defined, override the current object
    if (typeof (value === null || value === void 0 ? void 0 : value.toBSON) === 'function') {
        value = value.toBSON();
    }
    switch (typeof value) {
        case 'string':
            return 1 + Buffer$1.byteLength(name, 'utf8') + 1 + 4 + Buffer$1.byteLength(value, 'utf8') + 1;
        case 'number':
            if (Math.floor(value) === value &&
                value >= JS_INT_MIN$1 &&
                value <= JS_INT_MAX$1) {
                if (value >= BSON_INT32_MIN$1 && value <= BSON_INT32_MAX$1) {
                    // 32 bit
                    return (name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) + (4 + 1);
                }
                else {
                    return (name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) + (8 + 1);
                }
            }
            else {
                // 64 bit
                return (name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) + (8 + 1);
            }
        case 'undefined':
            if (isArray || !ignoreUndefined)
                return (name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) + 1;
            return 0;
        case 'boolean':
            return (name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) + (1 + 1);
        case 'object':
            if (value == null || value['_bsontype'] === 'MinKey' || value['_bsontype'] === 'MaxKey') {
                return (name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) + 1;
            }
            else if (value['_bsontype'] === 'ObjectId' || value['_bsontype'] === 'ObjectID') {
                return (name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) + (12 + 1);
            }
            else if (value instanceof Date || isDate$1(value)) {
                return (name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) + (8 + 1);
            }
            else if (ArrayBuffer.isView(value) ||
                value instanceof ArrayBuffer ||
                isAnyArrayBuffer$1(value)) {
                return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) + (1 + 4 + 1) + value.byteLength);
            }
            else if (value['_bsontype'] === 'Long' ||
                value['_bsontype'] === 'Double' ||
                value['_bsontype'] === 'Timestamp') {
                return (name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) + (8 + 1);
            }
            else if (value['_bsontype'] === 'Decimal128') {
                return (name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) + (16 + 1);
            }
            else if (value['_bsontype'] === 'Code') {
                // Calculate size depending on the availability of a scope
                if (value.scope != null && Object.keys(value.scope).length > 0) {
                    return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) +
                        1 +
                        4 +
                        4 +
                        Buffer$1.byteLength(value.code.toString(), 'utf8') +
                        1 +
                        calculateObjectSize$1(value.scope, serializeFunctions, ignoreUndefined));
                }
                else {
                    return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) +
                        1 +
                        4 +
                        Buffer$1.byteLength(value.code.toString(), 'utf8') +
                        1);
                }
            }
            else if (value['_bsontype'] === 'Binary') {
                var binary = value;
                // Check what kind of subtype we have
                if (binary.sub_type === Binary$1.SUBTYPE_BYTE_ARRAY) {
                    return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) +
                        (binary.position + 1 + 4 + 1 + 4));
                }
                else {
                    return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) + (binary.position + 1 + 4 + 1));
                }
            }
            else if (value['_bsontype'] === 'Symbol') {
                return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) +
                    Buffer$1.byteLength(value.value, 'utf8') +
                    4 +
                    1 +
                    1);
            }
            else if (value['_bsontype'] === 'DBRef') {
                // Set up correct object for serialization
                var ordered_values = Object.assign({
                    $ref: value.collection,
                    $id: value.oid
                }, value.fields);
                // Add db reference if it exists
                if (value.db != null) {
                    ordered_values['$db'] = value.db;
                }
                return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) +
                    1 +
                    calculateObjectSize$1(ordered_values, serializeFunctions, ignoreUndefined));
            }
            else if (value instanceof RegExp || isRegExp$1(value)) {
                return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) +
                    1 +
                    Buffer$1.byteLength(value.source, 'utf8') +
                    1 +
                    (value.global ? 1 : 0) +
                    (value.ignoreCase ? 1 : 0) +
                    (value.multiline ? 1 : 0) +
                    1);
            }
            else if (value['_bsontype'] === 'BSONRegExp') {
                return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) +
                    1 +
                    Buffer$1.byteLength(value.pattern, 'utf8') +
                    1 +
                    Buffer$1.byteLength(value.options, 'utf8') +
                    1);
            }
            else {
                return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) +
                    calculateObjectSize$1(value, serializeFunctions, ignoreUndefined) +
                    1);
            }
        case 'function':
            // WTF for 0.4.X where typeof /someregexp/ === 'function'
            if (value instanceof RegExp || isRegExp$1(value) || String.call(value) === '[object RegExp]') {
                return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) +
                    1 +
                    Buffer$1.byteLength(value.source, 'utf8') +
                    1 +
                    (value.global ? 1 : 0) +
                    (value.ignoreCase ? 1 : 0) +
                    (value.multiline ? 1 : 0) +
                    1);
            }
            else {
                if (serializeFunctions && value.scope != null && Object.keys(value.scope).length > 0) {
                    return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) +
                        1 +
                        4 +
                        4 +
                        Buffer$1.byteLength(normalizedFunctionString(value), 'utf8') +
                        1 +
                        calculateObjectSize$1(value.scope, serializeFunctions, ignoreUndefined));
                }
                else if (serializeFunctions) {
                    return ((name != null ? Buffer$1.byteLength(name, 'utf8') + 1 : 0) +
                        1 +
                        4 +
                        Buffer$1.byteLength(normalizedFunctionString(value), 'utf8') +
                        1);
                }
            }
    }
    return 0;
}

var FIRST_BIT = 0x80;
var FIRST_TWO_BITS = 0xc0;
var FIRST_THREE_BITS = 0xe0;
var FIRST_FOUR_BITS = 0xf0;
var FIRST_FIVE_BITS = 0xf8;
var TWO_BIT_CHAR = 0xc0;
var THREE_BIT_CHAR = 0xe0;
var FOUR_BIT_CHAR = 0xf0;
var CONTINUING_CHAR = 0x80;
/**
 * Determines if the passed in bytes are valid utf8
 * @param bytes - An array of 8-bit bytes. Must be indexable and have length property
 * @param start - The index to start validating
 * @param end - The index to end validating
 */
function validateUtf8(bytes, start, end) {
    var continuation = 0;
    for (var i = start; i < end; i += 1) {
        var byte = bytes[i];
        if (continuation) {
            if ((byte & FIRST_TWO_BITS) !== CONTINUING_CHAR) {
                return false;
            }
            continuation -= 1;
        }
        else if (byte & FIRST_BIT) {
            if ((byte & FIRST_THREE_BITS) === TWO_BIT_CHAR) {
                continuation = 1;
            }
            else if ((byte & FIRST_FOUR_BITS) === THREE_BIT_CHAR) {
                continuation = 2;
            }
            else if ((byte & FIRST_FIVE_BITS) === FOUR_BIT_CHAR) {
                continuation = 3;
            }
            else {
                return false;
            }
        }
    }
    return !continuation;
}

// Internal long versions
var JS_INT_MAX_LONG$1 = Long$1.fromNumber(JS_INT_MAX$1);
var JS_INT_MIN_LONG$1 = Long$1.fromNumber(JS_INT_MIN$1);
var functionCache = {};
function deserialize$1(buffer, options, isArray) {
    options = options == null ? {} : options;
    var index = options && options.index ? options.index : 0;
    // Read the document size
    var size = buffer[index] |
        (buffer[index + 1] << 8) |
        (buffer[index + 2] << 16) |
        (buffer[index + 3] << 24);
    if (size < 5) {
        throw new BSONError$1("bson size must be >= 5, is ".concat(size));
    }
    if (options.allowObjectSmallerThanBufferSize && buffer.length < size) {
        throw new BSONError$1("buffer length ".concat(buffer.length, " must be >= bson size ").concat(size));
    }
    if (!options.allowObjectSmallerThanBufferSize && buffer.length !== size) {
        throw new BSONError$1("buffer length ".concat(buffer.length, " must === bson size ").concat(size));
    }
    if (size + index > buffer.byteLength) {
        throw new BSONError$1("(bson size ".concat(size, " + options.index ").concat(index, " must be <= buffer length ").concat(buffer.byteLength, ")"));
    }
    // Illegal end value
    if (buffer[index + size - 1] !== 0) {
        throw new BSONError$1("One object, sized correctly, with a spot for an EOO, but the EOO isn't 0x00");
    }
    // Start deserializtion
    return deserializeObject$1(buffer, index, options, isArray);
}
var allowedDBRefKeys$1 = /^\$ref$|^\$id$|^\$db$/;
function deserializeObject$1(buffer, index, options, isArray) {
    if (isArray === void 0) { isArray = false; }
    var evalFunctions = options['evalFunctions'] == null ? false : options['evalFunctions'];
    var cacheFunctions = options['cacheFunctions'] == null ? false : options['cacheFunctions'];
    var fieldsAsRaw = options['fieldsAsRaw'] == null ? null : options['fieldsAsRaw'];
    // Return raw bson buffer instead of parsing it
    var raw = options['raw'] == null ? false : options['raw'];
    // Return BSONRegExp objects instead of native regular expressions
    var bsonRegExp = typeof options['bsonRegExp'] === 'boolean' ? options['bsonRegExp'] : false;
    // Controls the promotion of values vs wrapper classes
    var promoteBuffers = options['promoteBuffers'] == null ? false : options['promoteBuffers'];
    var promoteLongs = options['promoteLongs'] == null ? true : options['promoteLongs'];
    var promoteValues = options['promoteValues'] == null ? true : options['promoteValues'];
    // Ensures default validation option if none given
    var validation = options.validation == null ? { utf8: true } : options.validation;
    // Shows if global utf-8 validation is enabled or disabled
    var globalUTFValidation = true;
    // Reflects utf-8 validation setting regardless of global or specific key validation
    var validationSetting;
    // Set of keys either to enable or disable validation on
    var utf8KeysSet = new Set();
    // Check for boolean uniformity and empty validation option
    var utf8ValidatedKeys = validation.utf8;
    if (typeof utf8ValidatedKeys === 'boolean') {
        validationSetting = utf8ValidatedKeys;
    }
    else {
        globalUTFValidation = false;
        var utf8ValidationValues = Object.keys(utf8ValidatedKeys).map(function (key) {
            return utf8ValidatedKeys[key];
        });
        if (utf8ValidationValues.length === 0) {
            throw new BSONError$1('UTF-8 validation setting cannot be empty');
        }
        if (typeof utf8ValidationValues[0] !== 'boolean') {
            throw new BSONError$1('Invalid UTF-8 validation option, must specify boolean values');
        }
        validationSetting = utf8ValidationValues[0];
        // Ensures boolean uniformity in utf-8 validation (all true or all false)
        if (!utf8ValidationValues.every(function (item) { return item === validationSetting; })) {
            throw new BSONError$1('Invalid UTF-8 validation option - keys must be all true or all false');
        }
    }
    // Add keys to set that will either be validated or not based on validationSetting
    if (!globalUTFValidation) {
        for (var _i = 0, _a = Object.keys(utf8ValidatedKeys); _i < _a.length; _i++) {
            var key = _a[_i];
            utf8KeysSet.add(key);
        }
    }
    // Set the start index
    var startIndex = index;
    // Validate that we have at least 4 bytes of buffer
    if (buffer.length < 5)
        throw new BSONError$1('corrupt bson message < 5 bytes long');
    // Read the document size
    var size = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);
    // Ensure buffer is valid size
    if (size < 5 || size > buffer.length)
        throw new BSONError$1('corrupt bson message');
    // Create holding object
    var object = isArray ? [] : {};
    // Used for arrays to skip having to perform utf8 decoding
    var arrayIndex = 0;
    var done = false;
    var isPossibleDBRef = isArray ? false : null;
    // While we have more left data left keep parsing
    var dataview = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength);
    while (!done) {
        // Read the type
        var elementType = buffer[index++];
        // If we get a zero it's the last byte, exit
        if (elementType === 0)
            break;
        // Get the start search index
        var i = index;
        // Locate the end of the c string
        while (buffer[i] !== 0x00 && i < buffer.length) {
            i++;
        }
        // If are at the end of the buffer there is a problem with the document
        if (i >= buffer.byteLength)
            throw new BSONError$1('Bad BSON Document: illegal CString');
        // Represents the key
        var name = isArray ? arrayIndex++ : buffer.toString('utf8', index, i);
        // shouldValidateKey is true if the key should be validated, false otherwise
        var shouldValidateKey = true;
        if (globalUTFValidation || utf8KeysSet.has(name)) {
            shouldValidateKey = validationSetting;
        }
        else {
            shouldValidateKey = !validationSetting;
        }
        if (isPossibleDBRef !== false && name[0] === '$') {
            isPossibleDBRef = allowedDBRefKeys$1.test(name);
        }
        var value = void 0;
        index = i + 1;
        if (elementType === BSON_DATA_STRING$1) {
            var stringSize = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            if (stringSize <= 0 ||
                stringSize > buffer.length - index ||
                buffer[index + stringSize - 1] !== 0) {
                throw new BSONError$1('bad string length in bson');
            }
            value = getValidatedString(buffer, index, index + stringSize - 1, shouldValidateKey);
            index = index + stringSize;
        }
        else if (elementType === BSON_DATA_OID$1) {
            var oid = Buffer$1.alloc(12);
            buffer.copy(oid, 0, index, index + 12);
            value = new ObjectId$1(oid);
            index = index + 12;
        }
        else if (elementType === BSON_DATA_INT$1 && promoteValues === false) {
            value = new Int32$1(buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24));
        }
        else if (elementType === BSON_DATA_INT$1) {
            value =
                buffer[index++] |
                    (buffer[index++] << 8) |
                    (buffer[index++] << 16) |
                    (buffer[index++] << 24);
        }
        else if (elementType === BSON_DATA_NUMBER$1 && promoteValues === false) {
            value = new Double$1(dataview.getFloat64(index, true));
            index = index + 8;
        }
        else if (elementType === BSON_DATA_NUMBER$1) {
            value = dataview.getFloat64(index, true);
            index = index + 8;
        }
        else if (elementType === BSON_DATA_DATE$1) {
            var lowBits = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            var highBits = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            value = new Date(new Long$1(lowBits, highBits).toNumber());
        }
        else if (elementType === BSON_DATA_BOOLEAN$1) {
            if (buffer[index] !== 0 && buffer[index] !== 1)
                throw new BSONError$1('illegal boolean type value');
            value = buffer[index++] === 1;
        }
        else if (elementType === BSON_DATA_OBJECT$1) {
            var _index = index;
            var objectSize = buffer[index] |
                (buffer[index + 1] << 8) |
                (buffer[index + 2] << 16) |
                (buffer[index + 3] << 24);
            if (objectSize <= 0 || objectSize > buffer.length - index)
                throw new BSONError$1('bad embedded document length in bson');
            // We have a raw value
            if (raw) {
                value = buffer.slice(index, index + objectSize);
            }
            else {
                var objectOptions = options;
                if (!globalUTFValidation) {
                    objectOptions = _assign(_assign({}, options), { validation: { utf8: shouldValidateKey } });
                }
                value = deserializeObject$1(buffer, _index, objectOptions, false);
            }
            index = index + objectSize;
        }
        else if (elementType === BSON_DATA_ARRAY$1) {
            var _index = index;
            var objectSize = buffer[index] |
                (buffer[index + 1] << 8) |
                (buffer[index + 2] << 16) |
                (buffer[index + 3] << 24);
            var arrayOptions = options;
            // Stop index
            var stopIndex = index + objectSize;
            // All elements of array to be returned as raw bson
            if (fieldsAsRaw && fieldsAsRaw[name]) {
                arrayOptions = {};
                for (var n in options) {
                    arrayOptions[n] = options[n];
                }
                arrayOptions['raw'] = true;
            }
            if (!globalUTFValidation) {
                arrayOptions = _assign(_assign({}, arrayOptions), { validation: { utf8: shouldValidateKey } });
            }
            value = deserializeObject$1(buffer, _index, arrayOptions, true);
            index = index + objectSize;
            if (buffer[index - 1] !== 0)
                throw new BSONError$1('invalid array terminator byte');
            if (index !== stopIndex)
                throw new BSONError$1('corrupted array bson');
        }
        else if (elementType === BSON_DATA_UNDEFINED$1) {
            value = undefined;
        }
        else if (elementType === BSON_DATA_NULL$1) {
            value = null;
        }
        else if (elementType === BSON_DATA_LONG$1) {
            // Unpack the low and high bits
            var lowBits = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            var highBits = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            var long = new Long$1(lowBits, highBits);
            // Promote the long if possible
            if (promoteLongs && promoteValues === true) {
                value =
                    long.lessThanOrEqual(JS_INT_MAX_LONG$1) && long.greaterThanOrEqual(JS_INT_MIN_LONG$1)
                        ? long.toNumber()
                        : long;
            }
            else {
                value = long;
            }
        }
        else if (elementType === BSON_DATA_DECIMAL128$1) {
            // Buffer to contain the decimal bytes
            var bytes = Buffer$1.alloc(16);
            // Copy the next 16 bytes into the bytes buffer
            buffer.copy(bytes, 0, index, index + 16);
            // Update index
            index = index + 16;
            // Assign the new Decimal128 value
            var decimal128 = new Decimal128$1(bytes);
            // If we have an alternative mapper use that
            if ('toObject' in decimal128 && typeof decimal128.toObject === 'function') {
                value = decimal128.toObject();
            }
            else {
                value = decimal128;
            }
        }
        else if (elementType === BSON_DATA_BINARY$1) {
            var binarySize = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            var totalBinarySize = binarySize;
            var subType = buffer[index++];
            // Did we have a negative binary size, throw
            if (binarySize < 0)
                throw new BSONError$1('Negative binary type element size found');
            // Is the length longer than the document
            if (binarySize > buffer.byteLength)
                throw new BSONError$1('Binary type size larger than document size');
            // Decode as raw Buffer object if options specifies it
            if (buffer['slice'] != null) {
                // If we have subtype 2 skip the 4 bytes for the size
                if (subType === Binary$1.SUBTYPE_BYTE_ARRAY) {
                    binarySize =
                        buffer[index++] |
                            (buffer[index++] << 8) |
                            (buffer[index++] << 16) |
                            (buffer[index++] << 24);
                    if (binarySize < 0)
                        throw new BSONError$1('Negative binary type element size found for subtype 0x02');
                    if (binarySize > totalBinarySize - 4)
                        throw new BSONError$1('Binary type with subtype 0x02 contains too long binary size');
                    if (binarySize < totalBinarySize - 4)
                        throw new BSONError$1('Binary type with subtype 0x02 contains too short binary size');
                }
                if (promoteBuffers && promoteValues) {
                    value = buffer.slice(index, index + binarySize);
                }
                else {
                    value = new Binary$1(buffer.slice(index, index + binarySize), subType);
                    if (subType === BSON_BINARY_SUBTYPE_UUID_NEW$1) {
                        value = value.toUUID();
                    }
                }
            }
            else {
                var _buffer = Buffer$1.alloc(binarySize);
                // If we have subtype 2 skip the 4 bytes for the size
                if (subType === Binary$1.SUBTYPE_BYTE_ARRAY) {
                    binarySize =
                        buffer[index++] |
                            (buffer[index++] << 8) |
                            (buffer[index++] << 16) |
                            (buffer[index++] << 24);
                    if (binarySize < 0)
                        throw new BSONError$1('Negative binary type element size found for subtype 0x02');
                    if (binarySize > totalBinarySize - 4)
                        throw new BSONError$1('Binary type with subtype 0x02 contains too long binary size');
                    if (binarySize < totalBinarySize - 4)
                        throw new BSONError$1('Binary type with subtype 0x02 contains too short binary size');
                }
                // Copy the data
                for (i = 0; i < binarySize; i++) {
                    _buffer[i] = buffer[index + i];
                }
                if (promoteBuffers && promoteValues) {
                    value = _buffer;
                }
                else if (subType === BSON_BINARY_SUBTYPE_UUID_NEW$1) {
                    value = new Binary$1(buffer.slice(index, index + binarySize), subType).toUUID();
                }
                else {
                    value = new Binary$1(buffer.slice(index, index + binarySize), subType);
                }
            }
            // Update the index
            index = index + binarySize;
        }
        else if (elementType === BSON_DATA_REGEXP$1 && bsonRegExp === false) {
            // Get the start search index
            i = index;
            // Locate the end of the c string
            while (buffer[i] !== 0x00 && i < buffer.length) {
                i++;
            }
            // If are at the end of the buffer there is a problem with the document
            if (i >= buffer.length)
                throw new BSONError$1('Bad BSON Document: illegal CString');
            // Return the C string
            var source = buffer.toString('utf8', index, i);
            // Create the regexp
            index = i + 1;
            // Get the start search index
            i = index;
            // Locate the end of the c string
            while (buffer[i] !== 0x00 && i < buffer.length) {
                i++;
            }
            // If are at the end of the buffer there is a problem with the document
            if (i >= buffer.length)
                throw new BSONError$1('Bad BSON Document: illegal CString');
            // Return the C string
            var regExpOptions = buffer.toString('utf8', index, i);
            index = i + 1;
            // For each option add the corresponding one for javascript
            var optionsArray = new Array(regExpOptions.length);
            // Parse options
            for (i = 0; i < regExpOptions.length; i++) {
                switch (regExpOptions[i]) {
                    case 'm':
                        optionsArray[i] = 'm';
                        break;
                    case 's':
                        optionsArray[i] = 'g';
                        break;
                    case 'i':
                        optionsArray[i] = 'i';
                        break;
                }
            }
            value = new RegExp(source, optionsArray.join(''));
        }
        else if (elementType === BSON_DATA_REGEXP$1 && bsonRegExp === true) {
            // Get the start search index
            i = index;
            // Locate the end of the c string
            while (buffer[i] !== 0x00 && i < buffer.length) {
                i++;
            }
            // If are at the end of the buffer there is a problem with the document
            if (i >= buffer.length)
                throw new BSONError$1('Bad BSON Document: illegal CString');
            // Return the C string
            var source = buffer.toString('utf8', index, i);
            index = i + 1;
            // Get the start search index
            i = index;
            // Locate the end of the c string
            while (buffer[i] !== 0x00 && i < buffer.length) {
                i++;
            }
            // If are at the end of the buffer there is a problem with the document
            if (i >= buffer.length)
                throw new BSONError$1('Bad BSON Document: illegal CString');
            // Return the C string
            var regExpOptions = buffer.toString('utf8', index, i);
            index = i + 1;
            // Set the object
            value = new BSONRegExp$1(source, regExpOptions);
        }
        else if (elementType === BSON_DATA_SYMBOL$1) {
            var stringSize = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            if (stringSize <= 0 ||
                stringSize > buffer.length - index ||
                buffer[index + stringSize - 1] !== 0) {
                throw new BSONError$1('bad string length in bson');
            }
            var symbol = getValidatedString(buffer, index, index + stringSize - 1, shouldValidateKey);
            value = promoteValues ? symbol : new BSONSymbol$1(symbol);
            index = index + stringSize;
        }
        else if (elementType === BSON_DATA_TIMESTAMP$1) {
            var lowBits = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            var highBits = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            value = new Timestamp$1(lowBits, highBits);
        }
        else if (elementType === BSON_DATA_MIN_KEY$1) {
            value = new MinKey$1();
        }
        else if (elementType === BSON_DATA_MAX_KEY$1) {
            value = new MaxKey$1();
        }
        else if (elementType === BSON_DATA_CODE$1) {
            var stringSize = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            if (stringSize <= 0 ||
                stringSize > buffer.length - index ||
                buffer[index + stringSize - 1] !== 0) {
                throw new BSONError$1('bad string length in bson');
            }
            var functionString = getValidatedString(buffer, index, index + stringSize - 1, shouldValidateKey);
            // If we are evaluating the functions
            if (evalFunctions) {
                // If we have cache enabled let's look for the md5 of the function in the cache
                if (cacheFunctions) {
                    // Got to do this to avoid V8 deoptimizing the call due to finding eval
                    value = isolateEval(functionString, functionCache, object);
                }
                else {
                    value = isolateEval(functionString);
                }
            }
            else {
                value = new Code$1(functionString);
            }
            // Update parse index position
            index = index + stringSize;
        }
        else if (elementType === BSON_DATA_CODE_W_SCOPE$1) {
            var totalSize = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            // Element cannot be shorter than totalSize + stringSize + documentSize + terminator
            if (totalSize < 4 + 4 + 4 + 1) {
                throw new BSONError$1('code_w_scope total size shorter minimum expected length');
            }
            // Get the code string size
            var stringSize = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            // Check if we have a valid string
            if (stringSize <= 0 ||
                stringSize > buffer.length - index ||
                buffer[index + stringSize - 1] !== 0) {
                throw new BSONError$1('bad string length in bson');
            }
            // Javascript function
            var functionString = getValidatedString(buffer, index, index + stringSize - 1, shouldValidateKey);
            // Update parse index position
            index = index + stringSize;
            // Parse the element
            var _index = index;
            // Decode the size of the object document
            var objectSize = buffer[index] |
                (buffer[index + 1] << 8) |
                (buffer[index + 2] << 16) |
                (buffer[index + 3] << 24);
            // Decode the scope object
            var scopeObject = deserializeObject$1(buffer, _index, options, false);
            // Adjust the index
            index = index + objectSize;
            // Check if field length is too short
            if (totalSize < 4 + 4 + objectSize + stringSize) {
                throw new BSONError$1('code_w_scope total size is too short, truncating scope');
            }
            // Check if totalSize field is too long
            if (totalSize > 4 + 4 + objectSize + stringSize) {
                throw new BSONError$1('code_w_scope total size is too long, clips outer document');
            }
            // If we are evaluating the functions
            if (evalFunctions) {
                // If we have cache enabled let's look for the md5 of the function in the cache
                if (cacheFunctions) {
                    // Got to do this to avoid V8 deoptimizing the call due to finding eval
                    value = isolateEval(functionString, functionCache, object);
                }
                else {
                    value = isolateEval(functionString);
                }
                value.scope = scopeObject;
            }
            else {
                value = new Code$1(functionString, scopeObject);
            }
        }
        else if (elementType === BSON_DATA_DBPOINTER$1) {
            // Get the code string size
            var stringSize = buffer[index++] |
                (buffer[index++] << 8) |
                (buffer[index++] << 16) |
                (buffer[index++] << 24);
            // Check if we have a valid string
            if (stringSize <= 0 ||
                stringSize > buffer.length - index ||
                buffer[index + stringSize - 1] !== 0)
                throw new BSONError$1('bad string length in bson');
            // Namespace
            if (validation != null && validation.utf8) {
                if (!validateUtf8(buffer, index, index + stringSize - 1)) {
                    throw new BSONError$1('Invalid UTF-8 string in BSON document');
                }
            }
            var namespace = buffer.toString('utf8', index, index + stringSize - 1);
            // Update parse index position
            index = index + stringSize;
            // Read the oid
            var oidBuffer = Buffer$1.alloc(12);
            buffer.copy(oidBuffer, 0, index, index + 12);
            var oid = new ObjectId$1(oidBuffer);
            // Update the index
            index = index + 12;
            // Upgrade to DBRef type
            value = new DBRef$1(namespace, oid);
        }
        else {
            throw new BSONError$1("Detected unknown BSON type ".concat(elementType.toString(16), " for fieldname \"").concat(name, "\""));
        }
        if (name === '__proto__') {
            Object.defineProperty(object, name, {
                value: value,
                writable: true,
                enumerable: true,
                configurable: true
            });
        }
        else {
            object[name] = value;
        }
    }
    // Check if the deserialization was against a valid array/object
    if (size !== index - startIndex) {
        if (isArray)
            throw new BSONError$1('corrupt array bson');
        throw new BSONError$1('corrupt object bson');
    }
    // if we did not find "$ref", "$id", "$db", or found an extraneous $key, don't make a DBRef
    if (!isPossibleDBRef)
        return object;
    if (isDBRefLike$1(object)) {
        var copy = Object.assign({}, object);
        delete copy.$ref;
        delete copy.$id;
        delete copy.$db;
        return new DBRef$1(object.$ref, object.$id, object.$db, copy);
    }
    return object;
}
/**
 * Ensure eval is isolated, store the result in functionCache.
 *
 * @internal
 */
function isolateEval(functionString, functionCache, object) {
    // eslint-disable-next-line @typescript-eslint/no-implied-eval
    if (!functionCache)
        return new Function(functionString);
    // Check for cache hit, eval if missing and return cached function
    if (functionCache[functionString] == null) {
        // eslint-disable-next-line @typescript-eslint/no-implied-eval
        functionCache[functionString] = new Function(functionString);
    }
    // Set the object
    return functionCache[functionString].bind(object);
}
function getValidatedString(buffer, start, end, shouldValidateUtf8) {
    var value = buffer.toString('utf8', start, end);
    // if utf8 validation is on, do the check
    if (shouldValidateUtf8) {
        for (var i = 0; i < value.length; i++) {
            if (value.charCodeAt(i) === 0xfffd) {
                if (!validateUtf8(buffer, start, end)) {
                    throw new BSONError$1('Invalid UTF-8 string in BSON document');
                }
                break;
            }
        }
    }
    return value;
}

var regexp$1 = /\x00/; // eslint-disable-line no-control-regex
var ignoreKeys$1 = new Set(['$db', '$ref', '$id', '$clusterTime']);
/*
 * isArray indicates if we are writing to a BSON array (type 0x04)
 * which forces the "key" which really an array index as a string to be written as ascii
 * This will catch any errors in index as a string generation
 */
function serializeString$1(buffer, key, value, index, isArray) {
    // Encode String type
    buffer[index++] = BSON_DATA_STRING$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes + 1;
    buffer[index - 1] = 0;
    // Write the string
    var size = buffer.write(value, index + 4, undefined, 'utf8');
    // Write the size of the string to buffer
    buffer[index + 3] = ((size + 1) >> 24) & 0xff;
    buffer[index + 2] = ((size + 1) >> 16) & 0xff;
    buffer[index + 1] = ((size + 1) >> 8) & 0xff;
    buffer[index] = (size + 1) & 0xff;
    // Update index
    index = index + 4 + size;
    // Write zero
    buffer[index++] = 0;
    return index;
}
var SPACE_FOR_FLOAT64 = new Uint8Array(8);
var DV_FOR_FLOAT64 = new DataView(SPACE_FOR_FLOAT64.buffer, SPACE_FOR_FLOAT64.byteOffset, SPACE_FOR_FLOAT64.byteLength);
function serializeNumber$1(buffer, key, value, index, isArray) {
    // We have an integer value
    // TODO(NODE-2529): Add support for big int
    if (Number.isInteger(value) &&
        value >= BSON_INT32_MIN$1 &&
        value <= BSON_INT32_MAX$1) {
        // If the value fits in 32 bits encode as int32
        // Set int type 32 bits or less
        buffer[index++] = BSON_DATA_INT$1;
        // Number of written bytes
        var numberOfWrittenBytes = !isArray
            ? buffer.write(key, index, undefined, 'utf8')
            : buffer.write(key, index, undefined, 'ascii');
        // Encode the name
        index = index + numberOfWrittenBytes;
        buffer[index++] = 0;
        // Write the int value
        buffer[index++] = value & 0xff;
        buffer[index++] = (value >> 8) & 0xff;
        buffer[index++] = (value >> 16) & 0xff;
        buffer[index++] = (value >> 24) & 0xff;
    }
    else {
        // Encode as double
        buffer[index++] = BSON_DATA_NUMBER$1;
        // Number of written bytes
        var numberOfWrittenBytes = !isArray
            ? buffer.write(key, index, undefined, 'utf8')
            : buffer.write(key, index, undefined, 'ascii');
        // Encode the name
        index = index + numberOfWrittenBytes;
        buffer[index++] = 0;
        // Write float
        DV_FOR_FLOAT64.setFloat64(0, value, true);
        buffer.set(SPACE_FOR_FLOAT64, index);
        // Adjust index
        index = index + 8;
    }
    return index;
}
function serializeNull$1(buffer, key, _, index, isArray) {
    // Set long type
    buffer[index++] = BSON_DATA_NULL$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    return index;
}
function serializeBoolean$1(buffer, key, value, index, isArray) {
    // Write the type
    buffer[index++] = BSON_DATA_BOOLEAN$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    // Encode the boolean value
    buffer[index++] = value ? 1 : 0;
    return index;
}
function serializeDate$1(buffer, key, value, index, isArray) {
    // Write the type
    buffer[index++] = BSON_DATA_DATE$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    // Write the date
    var dateInMilis = Long$1.fromNumber(value.getTime());
    var lowBits = dateInMilis.getLowBits();
    var highBits = dateInMilis.getHighBits();
    // Encode low bits
    buffer[index++] = lowBits & 0xff;
    buffer[index++] = (lowBits >> 8) & 0xff;
    buffer[index++] = (lowBits >> 16) & 0xff;
    buffer[index++] = (lowBits >> 24) & 0xff;
    // Encode high bits
    buffer[index++] = highBits & 0xff;
    buffer[index++] = (highBits >> 8) & 0xff;
    buffer[index++] = (highBits >> 16) & 0xff;
    buffer[index++] = (highBits >> 24) & 0xff;
    return index;
}
function serializeRegExp$1(buffer, key, value, index, isArray) {
    // Write the type
    buffer[index++] = BSON_DATA_REGEXP$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    if (value.source && value.source.match(regexp$1) != null) {
        throw Error('value ' + value.source + ' must not contain null bytes');
    }
    // Adjust the index
    index = index + buffer.write(value.source, index, undefined, 'utf8');
    // Write zero
    buffer[index++] = 0x00;
    // Write the parameters
    if (value.ignoreCase)
        buffer[index++] = 0x69; // i
    if (value.global)
        buffer[index++] = 0x73; // s
    if (value.multiline)
        buffer[index++] = 0x6d; // m
    // Add ending zero
    buffer[index++] = 0x00;
    return index;
}
function serializeBSONRegExp$1(buffer, key, value, index, isArray) {
    // Write the type
    buffer[index++] = BSON_DATA_REGEXP$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    // Check the pattern for 0 bytes
    if (value.pattern.match(regexp$1) != null) {
        // The BSON spec doesn't allow keys with null bytes because keys are
        // null-terminated.
        throw Error('pattern ' + value.pattern + ' must not contain null bytes');
    }
    // Adjust the index
    index = index + buffer.write(value.pattern, index, undefined, 'utf8');
    // Write zero
    buffer[index++] = 0x00;
    // Write the options
    index = index + buffer.write(value.options.split('').sort().join(''), index, undefined, 'utf8');
    // Add ending zero
    buffer[index++] = 0x00;
    return index;
}
function serializeMinMax$1(buffer, key, value, index, isArray) {
    // Write the type of either min or max key
    if (value === null) {
        buffer[index++] = BSON_DATA_NULL$1;
    }
    else if (value._bsontype === 'MinKey') {
        buffer[index++] = BSON_DATA_MIN_KEY$1;
    }
    else {
        buffer[index++] = BSON_DATA_MAX_KEY$1;
    }
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    return index;
}
function serializeObjectId$1(buffer, key, value, index, isArray) {
    // Write the type
    buffer[index++] = BSON_DATA_OID$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    // Write the objectId into the shared buffer
    if (typeof value.id === 'string') {
        buffer.write(value.id, index, undefined, 'binary');
    }
    else if (isUint8Array$1(value.id)) {
        // Use the standard JS methods here because buffer.copy() is buggy with the
        // browser polyfill
        buffer.set(value.id.subarray(0, 12), index);
    }
    else {
        throw new BSONTypeError('object [' + JSON.stringify(value) + '] is not a valid ObjectId');
    }
    // Adjust index
    return index + 12;
}
function serializeBuffer$1(buffer, key, value, index, isArray) {
    // Write the type
    buffer[index++] = BSON_DATA_BINARY$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    // Get size of the buffer (current write point)
    var size = value.length;
    // Write the size of the string to buffer
    buffer[index++] = size & 0xff;
    buffer[index++] = (size >> 8) & 0xff;
    buffer[index++] = (size >> 16) & 0xff;
    buffer[index++] = (size >> 24) & 0xff;
    // Write the default subtype
    buffer[index++] = BSON_BINARY_SUBTYPE_DEFAULT$1;
    // Copy the content form the binary field to the buffer
    buffer.set(ensureBuffer(value), index);
    // Adjust the index
    index = index + size;
    return index;
}
function serializeObject$1(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, isArray, path) {
    if (checkKeys === void 0) { checkKeys = false; }
    if (depth === void 0) { depth = 0; }
    if (serializeFunctions === void 0) { serializeFunctions = false; }
    if (ignoreUndefined === void 0) { ignoreUndefined = true; }
    if (isArray === void 0) { isArray = false; }
    if (path === void 0) { path = []; }
    for (var i = 0; i < path.length; i++) {
        if (path[i] === value)
            throw new BSONError$1('cyclic dependency detected');
    }
    // Push value to stack
    path.push(value);
    // Write the type
    buffer[index++] = Array.isArray(value) ? BSON_DATA_ARRAY$1 : BSON_DATA_OBJECT$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    var endIndex = serializeInto$1(buffer, value, checkKeys, index, depth + 1, serializeFunctions, ignoreUndefined, path);
    // Pop stack
    path.pop();
    return endIndex;
}
function serializeDecimal128$1(buffer, key, value, index, isArray) {
    buffer[index++] = BSON_DATA_DECIMAL128$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    // Write the data from the value
    // Prefer the standard JS methods because their typechecking is not buggy,
    // unlike the `buffer` polyfill's.
    buffer.set(value.bytes.subarray(0, 16), index);
    return index + 16;
}
function serializeLong$1(buffer, key, value, index, isArray) {
    // Write the type
    buffer[index++] =
        value._bsontype === 'Long' ? BSON_DATA_LONG$1 : BSON_DATA_TIMESTAMP$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    // Write the date
    var lowBits = value.getLowBits();
    var highBits = value.getHighBits();
    // Encode low bits
    buffer[index++] = lowBits & 0xff;
    buffer[index++] = (lowBits >> 8) & 0xff;
    buffer[index++] = (lowBits >> 16) & 0xff;
    buffer[index++] = (lowBits >> 24) & 0xff;
    // Encode high bits
    buffer[index++] = highBits & 0xff;
    buffer[index++] = (highBits >> 8) & 0xff;
    buffer[index++] = (highBits >> 16) & 0xff;
    buffer[index++] = (highBits >> 24) & 0xff;
    return index;
}
function serializeInt32$1(buffer, key, value, index, isArray) {
    value = value.valueOf();
    // Set int type 32 bits or less
    buffer[index++] = BSON_DATA_INT$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    // Write the int value
    buffer[index++] = value & 0xff;
    buffer[index++] = (value >> 8) & 0xff;
    buffer[index++] = (value >> 16) & 0xff;
    buffer[index++] = (value >> 24) & 0xff;
    return index;
}
function serializeDouble$1(buffer, key, value, index, isArray) {
    // Encode as double
    buffer[index++] = BSON_DATA_NUMBER$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    // Write float
    DV_FOR_FLOAT64.setFloat64(0, value.value, true);
    buffer.set(SPACE_FOR_FLOAT64, index);
    // Adjust index
    index = index + 8;
    return index;
}
function serializeFunction$1(buffer, key, value, index, _checkKeys, _depth, isArray) {
    buffer[index++] = BSON_DATA_CODE$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    // Function string
    var functionString = normalizedFunctionString(value);
    // Write the string
    var size = buffer.write(functionString, index + 4, undefined, 'utf8') + 1;
    // Write the size of the string to buffer
    buffer[index] = size & 0xff;
    buffer[index + 1] = (size >> 8) & 0xff;
    buffer[index + 2] = (size >> 16) & 0xff;
    buffer[index + 3] = (size >> 24) & 0xff;
    // Update index
    index = index + 4 + size - 1;
    // Write zero
    buffer[index++] = 0;
    return index;
}
function serializeCode$1(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, isArray) {
    if (checkKeys === void 0) { checkKeys = false; }
    if (depth === void 0) { depth = 0; }
    if (serializeFunctions === void 0) { serializeFunctions = false; }
    if (ignoreUndefined === void 0) { ignoreUndefined = true; }
    if (isArray === void 0) { isArray = false; }
    if (value.scope && typeof value.scope === 'object') {
        // Write the type
        buffer[index++] = BSON_DATA_CODE_W_SCOPE$1;
        // Number of written bytes
        var numberOfWrittenBytes = !isArray
            ? buffer.write(key, index, undefined, 'utf8')
            : buffer.write(key, index, undefined, 'ascii');
        // Encode the name
        index = index + numberOfWrittenBytes;
        buffer[index++] = 0;
        // Starting index
        var startIndex = index;
        // Serialize the function
        // Get the function string
        var functionString = typeof value.code === 'string' ? value.code : value.code.toString();
        // Index adjustment
        index = index + 4;
        // Write string into buffer
        var codeSize = buffer.write(functionString, index + 4, undefined, 'utf8') + 1;
        // Write the size of the string to buffer
        buffer[index] = codeSize & 0xff;
        buffer[index + 1] = (codeSize >> 8) & 0xff;
        buffer[index + 2] = (codeSize >> 16) & 0xff;
        buffer[index + 3] = (codeSize >> 24) & 0xff;
        // Write end 0
        buffer[index + 4 + codeSize - 1] = 0;
        // Write the
        index = index + codeSize + 4;
        //
        // Serialize the scope value
        var endIndex = serializeInto$1(buffer, value.scope, checkKeys, index, depth + 1, serializeFunctions, ignoreUndefined);
        index = endIndex - 1;
        // Writ the total
        var totalSize = endIndex - startIndex;
        // Write the total size of the object
        buffer[startIndex++] = totalSize & 0xff;
        buffer[startIndex++] = (totalSize >> 8) & 0xff;
        buffer[startIndex++] = (totalSize >> 16) & 0xff;
        buffer[startIndex++] = (totalSize >> 24) & 0xff;
        // Write trailing zero
        buffer[index++] = 0;
    }
    else {
        buffer[index++] = BSON_DATA_CODE$1;
        // Number of written bytes
        var numberOfWrittenBytes = !isArray
            ? buffer.write(key, index, undefined, 'utf8')
            : buffer.write(key, index, undefined, 'ascii');
        // Encode the name
        index = index + numberOfWrittenBytes;
        buffer[index++] = 0;
        // Function string
        var functionString = value.code.toString();
        // Write the string
        var size = buffer.write(functionString, index + 4, undefined, 'utf8') + 1;
        // Write the size of the string to buffer
        buffer[index] = size & 0xff;
        buffer[index + 1] = (size >> 8) & 0xff;
        buffer[index + 2] = (size >> 16) & 0xff;
        buffer[index + 3] = (size >> 24) & 0xff;
        // Update index
        index = index + 4 + size - 1;
        // Write zero
        buffer[index++] = 0;
    }
    return index;
}
function serializeBinary$1(buffer, key, value, index, isArray) {
    // Write the type
    buffer[index++] = BSON_DATA_BINARY$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    // Extract the buffer
    var data = value.value(true);
    // Calculate size
    var size = value.position;
    // Add the deprecated 02 type 4 bytes of size to total
    if (value.sub_type === Binary$1.SUBTYPE_BYTE_ARRAY)
        size = size + 4;
    // Write the size of the string to buffer
    buffer[index++] = size & 0xff;
    buffer[index++] = (size >> 8) & 0xff;
    buffer[index++] = (size >> 16) & 0xff;
    buffer[index++] = (size >> 24) & 0xff;
    // Write the subtype to the buffer
    buffer[index++] = value.sub_type;
    // If we have binary type 2 the 4 first bytes are the size
    if (value.sub_type === Binary$1.SUBTYPE_BYTE_ARRAY) {
        size = size - 4;
        buffer[index++] = size & 0xff;
        buffer[index++] = (size >> 8) & 0xff;
        buffer[index++] = (size >> 16) & 0xff;
        buffer[index++] = (size >> 24) & 0xff;
    }
    // Write the data to the object
    buffer.set(data, index);
    // Adjust the index
    index = index + value.position;
    return index;
}
function serializeSymbol$1(buffer, key, value, index, isArray) {
    // Write the type
    buffer[index++] = BSON_DATA_SYMBOL$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    // Write the string
    var size = buffer.write(value.value, index + 4, undefined, 'utf8') + 1;
    // Write the size of the string to buffer
    buffer[index] = size & 0xff;
    buffer[index + 1] = (size >> 8) & 0xff;
    buffer[index + 2] = (size >> 16) & 0xff;
    buffer[index + 3] = (size >> 24) & 0xff;
    // Update index
    index = index + 4 + size - 1;
    // Write zero
    buffer[index++] = 0x00;
    return index;
}
function serializeDBRef$1(buffer, key, value, index, depth, serializeFunctions, isArray) {
    // Write the type
    buffer[index++] = BSON_DATA_OBJECT$1;
    // Number of written bytes
    var numberOfWrittenBytes = !isArray
        ? buffer.write(key, index, undefined, 'utf8')
        : buffer.write(key, index, undefined, 'ascii');
    // Encode the name
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    var startIndex = index;
    var output = {
        $ref: value.collection || value.namespace,
        $id: value.oid
    };
    if (value.db != null) {
        output.$db = value.db;
    }
    output = Object.assign(output, value.fields);
    var endIndex = serializeInto$1(buffer, output, false, index, depth + 1, serializeFunctions);
    // Calculate object size
    var size = endIndex - startIndex;
    // Write the size
    buffer[startIndex++] = size & 0xff;
    buffer[startIndex++] = (size >> 8) & 0xff;
    buffer[startIndex++] = (size >> 16) & 0xff;
    buffer[startIndex++] = (size >> 24) & 0xff;
    // Set index
    return endIndex;
}
function serializeInto$1(buffer, object, checkKeys, startingIndex, depth, serializeFunctions, ignoreUndefined, path) {
    if (checkKeys === void 0) { checkKeys = false; }
    if (startingIndex === void 0) { startingIndex = 0; }
    if (depth === void 0) { depth = 0; }
    if (serializeFunctions === void 0) { serializeFunctions = false; }
    if (ignoreUndefined === void 0) { ignoreUndefined = true; }
    if (path === void 0) { path = []; }
    startingIndex = startingIndex || 0;
    path = path || [];
    // Push the object to the path
    path.push(object);
    // Start place to serialize into
    var index = startingIndex + 4;
    // Special case isArray
    if (Array.isArray(object)) {
        // Get object keys
        for (var i = 0; i < object.length; i++) {
            var key = "".concat(i);
            var value = object[i];
            // Is there an override value
            if (typeof (value === null || value === void 0 ? void 0 : value.toBSON) === 'function') {
                value = value.toBSON();
            }
            if (typeof value === 'string') {
                index = serializeString$1(buffer, key, value, index, true);
            }
            else if (typeof value === 'number') {
                index = serializeNumber$1(buffer, key, value, index, true);
            }
            else if (typeof value === 'bigint') {
                throw new BSONTypeError('Unsupported type BigInt, please use Decimal128');
            }
            else if (typeof value === 'boolean') {
                index = serializeBoolean$1(buffer, key, value, index, true);
            }
            else if (value instanceof Date || isDate$1(value)) {
                index = serializeDate$1(buffer, key, value, index, true);
            }
            else if (value === undefined) {
                index = serializeNull$1(buffer, key, value, index, true);
            }
            else if (value === null) {
                index = serializeNull$1(buffer, key, value, index, true);
            }
            else if (value['_bsontype'] === 'ObjectId' || value['_bsontype'] === 'ObjectID') {
                index = serializeObjectId$1(buffer, key, value, index, true);
            }
            else if (isUint8Array$1(value)) {
                index = serializeBuffer$1(buffer, key, value, index, true);
            }
            else if (value instanceof RegExp || isRegExp$1(value)) {
                index = serializeRegExp$1(buffer, key, value, index, true);
            }
            else if (typeof value === 'object' && value['_bsontype'] == null) {
                index = serializeObject$1(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, true, path);
            }
            else if (typeof value === 'object' &&
                isBSONType$1(value) &&
                value._bsontype === 'Decimal128') {
                index = serializeDecimal128$1(buffer, key, value, index, true);
            }
            else if (value['_bsontype'] === 'Long' || value['_bsontype'] === 'Timestamp') {
                index = serializeLong$1(buffer, key, value, index, true);
            }
            else if (value['_bsontype'] === 'Double') {
                index = serializeDouble$1(buffer, key, value, index, true);
            }
            else if (typeof value === 'function' && serializeFunctions) {
                index = serializeFunction$1(buffer, key, value, index, checkKeys, depth, true);
            }
            else if (value['_bsontype'] === 'Code') {
                index = serializeCode$1(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, true);
            }
            else if (value['_bsontype'] === 'Binary') {
                index = serializeBinary$1(buffer, key, value, index, true);
            }
            else if (value['_bsontype'] === 'Symbol') {
                index = serializeSymbol$1(buffer, key, value, index, true);
            }
            else if (value['_bsontype'] === 'DBRef') {
                index = serializeDBRef$1(buffer, key, value, index, depth, serializeFunctions, true);
            }
            else if (value['_bsontype'] === 'BSONRegExp') {
                index = serializeBSONRegExp$1(buffer, key, value, index, true);
            }
            else if (value['_bsontype'] === 'Int32') {
                index = serializeInt32$1(buffer, key, value, index, true);
            }
            else if (value['_bsontype'] === 'MinKey' || value['_bsontype'] === 'MaxKey') {
                index = serializeMinMax$1(buffer, key, value, index, true);
            }
            else if (typeof value['_bsontype'] !== 'undefined') {
                throw new BSONTypeError("Unrecognized or invalid _bsontype: ".concat(String(value['_bsontype'])));
            }
        }
    }
    else if (object instanceof bsonMap || isMap$2(object)) {
        var iterator = object.entries();
        var done = false;
        while (!done) {
            // Unpack the next entry
            var entry = iterator.next();
            done = !!entry.done;
            // Are we done, then skip and terminate
            if (done)
                continue;
            // Get the entry values
            var key = entry.value[0];
            var value = entry.value[1];
            // Check the type of the value
            var type = typeof value;
            // Check the key and throw error if it's illegal
            if (typeof key === 'string' && !ignoreKeys$1.has(key)) {
                if (key.match(regexp$1) != null) {
                    // The BSON spec doesn't allow keys with null bytes because keys are
                    // null-terminated.
                    throw Error('key ' + key + ' must not contain null bytes');
                }
                if (checkKeys) {
                    if ('$' === key[0]) {
                        throw Error('key ' + key + " must not start with '$'");
                    }
                    else if (~key.indexOf('.')) {
                        throw Error('key ' + key + " must not contain '.'");
                    }
                }
            }
            if (type === 'string') {
                index = serializeString$1(buffer, key, value, index);
            }
            else if (type === 'number') {
                index = serializeNumber$1(buffer, key, value, index);
            }
            else if (type === 'bigint' || isBigInt64Array(value) || isBigUInt64Array(value)) {
                throw new BSONTypeError('Unsupported type BigInt, please use Decimal128');
            }
            else if (type === 'boolean') {
                index = serializeBoolean$1(buffer, key, value, index);
            }
            else if (value instanceof Date || isDate$1(value)) {
                index = serializeDate$1(buffer, key, value, index);
            }
            else if (value === null || (value === undefined && ignoreUndefined === false)) {
                index = serializeNull$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'ObjectId' || value['_bsontype'] === 'ObjectID') {
                index = serializeObjectId$1(buffer, key, value, index);
            }
            else if (isUint8Array$1(value)) {
                index = serializeBuffer$1(buffer, key, value, index);
            }
            else if (value instanceof RegExp || isRegExp$1(value)) {
                index = serializeRegExp$1(buffer, key, value, index);
            }
            else if (type === 'object' && value['_bsontype'] == null) {
                index = serializeObject$1(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, false, path);
            }
            else if (type === 'object' && value['_bsontype'] === 'Decimal128') {
                index = serializeDecimal128$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'Long' || value['_bsontype'] === 'Timestamp') {
                index = serializeLong$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'Double') {
                index = serializeDouble$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'Code') {
                index = serializeCode$1(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined);
            }
            else if (typeof value === 'function' && serializeFunctions) {
                index = serializeFunction$1(buffer, key, value, index, checkKeys, depth, serializeFunctions);
            }
            else if (value['_bsontype'] === 'Binary') {
                index = serializeBinary$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'Symbol') {
                index = serializeSymbol$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'DBRef') {
                index = serializeDBRef$1(buffer, key, value, index, depth, serializeFunctions);
            }
            else if (value['_bsontype'] === 'BSONRegExp') {
                index = serializeBSONRegExp$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'Int32') {
                index = serializeInt32$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'MinKey' || value['_bsontype'] === 'MaxKey') {
                index = serializeMinMax$1(buffer, key, value, index);
            }
            else if (typeof value['_bsontype'] !== 'undefined') {
                throw new BSONTypeError("Unrecognized or invalid _bsontype: ".concat(String(value['_bsontype'])));
            }
        }
    }
    else {
        if (typeof (object === null || object === void 0 ? void 0 : object.toBSON) === 'function') {
            // Provided a custom serialization method
            object = object.toBSON();
            if (object != null && typeof object !== 'object') {
                throw new BSONTypeError('toBSON function did not return an object');
            }
        }
        // Iterate over all the keys
        for (var key in object) {
            var value = object[key];
            // Is there an override value
            if (typeof (value === null || value === void 0 ? void 0 : value.toBSON) === 'function') {
                value = value.toBSON();
            }
            // Check the type of the value
            var type = typeof value;
            // Check the key and throw error if it's illegal
            if (typeof key === 'string' && !ignoreKeys$1.has(key)) {
                if (key.match(regexp$1) != null) {
                    // The BSON spec doesn't allow keys with null bytes because keys are
                    // null-terminated.
                    throw Error('key ' + key + ' must not contain null bytes');
                }
                if (checkKeys) {
                    if ('$' === key[0]) {
                        throw Error('key ' + key + " must not start with '$'");
                    }
                    else if (~key.indexOf('.')) {
                        throw Error('key ' + key + " must not contain '.'");
                    }
                }
            }
            if (type === 'string') {
                index = serializeString$1(buffer, key, value, index);
            }
            else if (type === 'number') {
                index = serializeNumber$1(buffer, key, value, index);
            }
            else if (type === 'bigint') {
                throw new BSONTypeError('Unsupported type BigInt, please use Decimal128');
            }
            else if (type === 'boolean') {
                index = serializeBoolean$1(buffer, key, value, index);
            }
            else if (value instanceof Date || isDate$1(value)) {
                index = serializeDate$1(buffer, key, value, index);
            }
            else if (value === undefined) {
                if (ignoreUndefined === false)
                    index = serializeNull$1(buffer, key, value, index);
            }
            else if (value === null) {
                index = serializeNull$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'ObjectId' || value['_bsontype'] === 'ObjectID') {
                index = serializeObjectId$1(buffer, key, value, index);
            }
            else if (isUint8Array$1(value)) {
                index = serializeBuffer$1(buffer, key, value, index);
            }
            else if (value instanceof RegExp || isRegExp$1(value)) {
                index = serializeRegExp$1(buffer, key, value, index);
            }
            else if (type === 'object' && value['_bsontype'] == null) {
                index = serializeObject$1(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, false, path);
            }
            else if (type === 'object' && value['_bsontype'] === 'Decimal128') {
                index = serializeDecimal128$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'Long' || value['_bsontype'] === 'Timestamp') {
                index = serializeLong$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'Double') {
                index = serializeDouble$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'Code') {
                index = serializeCode$1(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined);
            }
            else if (typeof value === 'function' && serializeFunctions) {
                index = serializeFunction$1(buffer, key, value, index, checkKeys, depth, serializeFunctions);
            }
            else if (value['_bsontype'] === 'Binary') {
                index = serializeBinary$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'Symbol') {
                index = serializeSymbol$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'DBRef') {
                index = serializeDBRef$1(buffer, key, value, index, depth, serializeFunctions);
            }
            else if (value['_bsontype'] === 'BSONRegExp') {
                index = serializeBSONRegExp$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'Int32') {
                index = serializeInt32$1(buffer, key, value, index);
            }
            else if (value['_bsontype'] === 'MinKey' || value['_bsontype'] === 'MaxKey') {
                index = serializeMinMax$1(buffer, key, value, index);
            }
            else if (typeof value['_bsontype'] !== 'undefined') {
                throw new BSONTypeError("Unrecognized or invalid _bsontype: ".concat(String(value['_bsontype'])));
            }
        }
    }
    // Remove the path
    path.pop();
    // Final padding byte for object
    buffer[index++] = 0x00;
    // Final size
    var size = index - startingIndex;
    // Write the size of the object
    buffer[startingIndex++] = size & 0xff;
    buffer[startingIndex++] = (size >> 8) & 0xff;
    buffer[startingIndex++] = (size >> 16) & 0xff;
    buffer[startingIndex++] = (size >> 24) & 0xff;
    return index;
}

/** @internal */
// Default Max Size
var MAXSIZE$1 = 1024 * 1024 * 17;
// Current Internal Temporary Serialization Buffer
var buffer$1 = Buffer$1.alloc(MAXSIZE$1);
/**
 * Sets the size of the internal serialization buffer.
 *
 * @param size - The desired size for the internal serialization buffer
 * @public
 */
function setInternalBufferSize$1(size) {
    // Resize the internal serialization buffer if needed
    if (buffer$1.length < size) {
        buffer$1 = Buffer$1.alloc(size);
    }
}
/**
 * Serialize a Javascript object.
 *
 * @param object - the Javascript object to serialize.
 * @returns Buffer object containing the serialized object.
 * @public
 */
function serialize$1(object, options) {
    if (options === void 0) { options = {}; }
    // Unpack the options
    var checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;
    var serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;
    var ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;
    var minInternalBufferSize = typeof options.minInternalBufferSize === 'number' ? options.minInternalBufferSize : MAXSIZE$1;
    // Resize the internal serialization buffer if needed
    if (buffer$1.length < minInternalBufferSize) {
        buffer$1 = Buffer$1.alloc(minInternalBufferSize);
    }
    // Attempt to serialize
    var serializationIndex = serializeInto$1(buffer$1, object, checkKeys, 0, 0, serializeFunctions, ignoreUndefined, []);
    // Create the final buffer
    var finishedBuffer = Buffer$1.alloc(serializationIndex);
    // Copy into the finished buffer
    buffer$1.copy(finishedBuffer, 0, 0, finishedBuffer.length);
    // Return the buffer
    return finishedBuffer;
}
/**
 * Serialize a Javascript object using a predefined Buffer and index into the buffer,
 * useful when pre-allocating the space for serialization.
 *
 * @param object - the Javascript object to serialize.
 * @param finalBuffer - the Buffer you pre-allocated to store the serialized BSON object.
 * @returns the index pointing to the last written byte in the buffer.
 * @public
 */
function serializeWithBufferAndIndex$1(object, finalBuffer, options) {
    if (options === void 0) { options = {}; }
    // Unpack the options
    var checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;
    var serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;
    var ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;
    var startIndex = typeof options.index === 'number' ? options.index : 0;
    // Attempt to serialize
    var serializationIndex = serializeInto$1(buffer$1, object, checkKeys, 0, 0, serializeFunctions, ignoreUndefined);
    buffer$1.copy(finalBuffer, startIndex, 0, serializationIndex);
    // Return the index
    return startIndex + serializationIndex - 1;
}
/**
 * Deserialize data as BSON.
 *
 * @param buffer - the buffer containing the serialized set of BSON documents.
 * @returns returns the deserialized Javascript Object.
 * @public
 */
function deserialize$2(buffer, options) {
    if (options === void 0) { options = {}; }
    return deserialize$1(buffer instanceof Buffer$1 ? buffer : ensureBuffer(buffer), options);
}
/**
 * Calculate the bson size for a passed in Javascript object.
 *
 * @param object - the Javascript object to calculate the BSON byte size for
 * @returns size of BSON object in bytes
 * @public
 */
function calculateObjectSize$2(object, options) {
    if (options === void 0) { options = {}; }
    options = options || {};
    var serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;
    var ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;
    return calculateObjectSize$1(object, serializeFunctions, ignoreUndefined);
}
/**
 * Deserialize stream data as BSON documents.
 *
 * @param data - the buffer containing the serialized set of BSON documents.
 * @param startIndex - the start index in the data Buffer where the deserialization is to start.
 * @param numberOfDocuments - number of documents to deserialize.
 * @param documents - an array where to store the deserialized documents.
 * @param docStartIndex - the index in the documents array from where to start inserting documents.
 * @param options - additional options used for the deserialization.
 * @returns next index in the buffer after deserialization **x** numbers of documents.
 * @public
 */
function deserializeStream$1(data, startIndex, numberOfDocuments, documents, docStartIndex, options) {
    var internalOptions = Object.assign({ allowObjectSmallerThanBufferSize: true, index: 0 }, options);
    var bufferData = ensureBuffer(data);
    var index = startIndex;
    // Loop over all documents
    for (var i = 0; i < numberOfDocuments; i++) {
        // Find size of the document
        var size = bufferData[index] |
            (bufferData[index + 1] << 8) |
            (bufferData[index + 2] << 16) |
            (bufferData[index + 3] << 24);
        // Update options with index
        internalOptions.index = index;
        // Parse the document at this point
        documents[docStartIndex + i] = deserialize$1(bufferData, internalOptions);
        // Adjust index by the document size
        index = index + size;
    }
    // Return object containing end index of parsing and list of documents
    return index;
}
/**
 * BSON default export
 * @deprecated Please use named exports
 * @privateRemarks
 * We want to someday deprecate the default export,
 * so none of the new TS types are being exported on the default
 * @public
 */
var BSON = {
    Binary: Binary$1,
    Code: Code$1,
    DBRef: DBRef$1,
    Decimal128: Decimal128$1,
    Double: Double$1,
    Int32: Int32$1,
    Long: Long$1,
    UUID: UUID$1,
    Map: bsonMap,
    MaxKey: MaxKey$1,
    MinKey: MinKey$1,
    ObjectId: ObjectId$1,
    ObjectID: ObjectId$1,
    BSONRegExp: BSONRegExp$1,
    BSONSymbol: BSONSymbol$1,
    Timestamp: Timestamp$1,
    EJSON: EJSON$1,
    setInternalBufferSize: setInternalBufferSize$1,
    serialize: serialize$1,
    serializeWithBufferAndIndex: serializeWithBufferAndIndex$1,
    deserialize: deserialize$2,
    calculateObjectSize: calculateObjectSize$2,
    deserializeStream: deserializeStream$1,
    BSONError: BSONError$1,
    BSONTypeError: BSONTypeError
};

var bson_esm = /*#__PURE__*/Object.freeze({
	__proto__: null,
	BSONError: BSONError$1,
	BSONRegExp: BSONRegExp$1,
	BSONSymbol: BSONSymbol$1,
	BSONTypeError: BSONTypeError,
	BSON_BINARY_SUBTYPE_BYTE_ARRAY: BSON_BINARY_SUBTYPE_BYTE_ARRAY,
	BSON_BINARY_SUBTYPE_COLUMN: BSON_BINARY_SUBTYPE_COLUMN,
	BSON_BINARY_SUBTYPE_DEFAULT: BSON_BINARY_SUBTYPE_DEFAULT$1,
	BSON_BINARY_SUBTYPE_ENCRYPTED: BSON_BINARY_SUBTYPE_ENCRYPTED,
	BSON_BINARY_SUBTYPE_FUNCTION: BSON_BINARY_SUBTYPE_FUNCTION,
	BSON_BINARY_SUBTYPE_MD5: BSON_BINARY_SUBTYPE_MD5,
	BSON_BINARY_SUBTYPE_USER_DEFINED: BSON_BINARY_SUBTYPE_USER_DEFINED,
	BSON_BINARY_SUBTYPE_UUID: BSON_BINARY_SUBTYPE_UUID,
	BSON_BINARY_SUBTYPE_UUID_NEW: BSON_BINARY_SUBTYPE_UUID_NEW$1,
	BSON_DATA_ARRAY: BSON_DATA_ARRAY$1,
	BSON_DATA_BINARY: BSON_DATA_BINARY$1,
	BSON_DATA_BOOLEAN: BSON_DATA_BOOLEAN$1,
	BSON_DATA_CODE: BSON_DATA_CODE$1,
	BSON_DATA_CODE_W_SCOPE: BSON_DATA_CODE_W_SCOPE$1,
	BSON_DATA_DATE: BSON_DATA_DATE$1,
	BSON_DATA_DBPOINTER: BSON_DATA_DBPOINTER$1,
	BSON_DATA_DECIMAL128: BSON_DATA_DECIMAL128$1,
	BSON_DATA_INT: BSON_DATA_INT$1,
	BSON_DATA_LONG: BSON_DATA_LONG$1,
	BSON_DATA_MAX_KEY: BSON_DATA_MAX_KEY$1,
	BSON_DATA_MIN_KEY: BSON_DATA_MIN_KEY$1,
	BSON_DATA_NULL: BSON_DATA_NULL$1,
	BSON_DATA_NUMBER: BSON_DATA_NUMBER$1,
	BSON_DATA_OBJECT: BSON_DATA_OBJECT$1,
	BSON_DATA_OID: BSON_DATA_OID$1,
	BSON_DATA_REGEXP: BSON_DATA_REGEXP$1,
	BSON_DATA_STRING: BSON_DATA_STRING$1,
	BSON_DATA_SYMBOL: BSON_DATA_SYMBOL$1,
	BSON_DATA_TIMESTAMP: BSON_DATA_TIMESTAMP$1,
	BSON_DATA_UNDEFINED: BSON_DATA_UNDEFINED$1,
	BSON_INT32_MAX: BSON_INT32_MAX$1,
	BSON_INT32_MIN: BSON_INT32_MIN$1,
	BSON_INT64_MAX: BSON_INT64_MAX$1,
	BSON_INT64_MIN: BSON_INT64_MIN$1,
	Binary: Binary$1,
	Code: Code$1,
	DBRef: DBRef$1,
	Decimal128: Decimal128$1,
	Double: Double$1,
	get EJSON () { return EJSON$1; },
	Int32: Int32$1,
	Long: Long$1,
	LongWithoutOverridesClass: LongWithoutOverridesClass$1,
	get Map () { return bsonMap; },
	MaxKey: MaxKey$1,
	MinKey: MinKey$1,
	ObjectID: ObjectId$1,
	ObjectId: ObjectId$1,
	Timestamp: Timestamp$1,
	UUID: UUID$1,
	calculateObjectSize: calculateObjectSize$2,
	default: BSON,
	deserialize: deserialize$2,
	deserializeStream: deserializeStream$1,
	serialize: serialize$1,
	serializeWithBufferAndIndex: serializeWithBufferAndIndex$1,
	setInternalBufferSize: setInternalBufferSize$1
});

var require$$1 = /*@__PURE__*/getAugmentedNamespace(bson_esm);

var __createBinding$g = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$g = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$g = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$g(result, mod, k);
    __setModuleDefault$g(result, mod);
    return result;
};
Object.defineProperty(encoder, "__esModule", { value: true });
encoder.createBSONStreamEncoder = void 0;
const stream$1 = __importStar$g(crossStream);
const constants$2 = __importStar$g(constants$3);
const bson$4 = __importStar$g(require$$1);
const createBSONStreamEncoder = (params) => {
    let readableStrategy = params?.readableStrategy;
    if (!readableStrategy) {
        readableStrategy = new stream$1.ByteLengthStrategy({
            highWaterMark: 1024 * 16
        });
    }
    return new stream$1.Transform({
        transform(chunk, controller) {
            controller.enqueue(bson$4.serialize(chunk, params?.serialize_options));
        },
        flush(controller) {
            if (params?.sendTerminatorOnEnd ?? true) {
                controller.enqueue(constants$2.TERMINATOR);
            }
        }
    }, params?.writableStrategy, readableStrategy);
};
encoder.createBSONStreamEncoder = createBSONStreamEncoder;

var decoder = {};

var __createBinding$f = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$f = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$f = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$f(result, mod, k);
    __setModuleDefault$f(result, mod);
    return result;
};
Object.defineProperty(decoder, "__esModule", { value: true });
decoder.createBSONStreamDecoder = void 0;
const buffer_array$1 = __importStar$f(bufferArray);
const stream = __importStar$f(crossStream);
const constants$1 = __importStar$f(constants$3);
const bson$3 = __importStar$f(require$$1);
const createBSONStreamDecoder = (params) => {
    const buffer = buffer_array$1.createReadableBufferArray();
    let frame_size = null;
    function* decodeFrames() {
        while (true) {
            if (frame_size === null) {
                frame_size = buffer.peek(4)?.readInt32LE(0) || null;
            }
            if (frame_size === null) {
                break;
            }
            if (buffer.size() < frame_size) {
                break;
            }
            const frame = buffer.read(frame_size);
            if (!frame) {
                break;
            }
            frame_size = null;
            yield bson$3.deserialize(frame, {
                promoteBuffers: true,
                validation: {
                    utf8: false
                },
                ...(params?.deserialize_options || {})
            });
        }
    }
    let writableStrategy = params?.writableStrategy;
    if (!writableStrategy) {
        writableStrategy = new stream.ByteLengthStrategy({
            highWaterMark: 1024 * 16
        });
    }
    return new stream.Transform({
        transform(chunk, controller) {
            buffer.push(chunk);
            for (const frame of decodeFrames()) {
                controller.enqueue(frame);
            }
        },
        flush(controller) {
            for (const frame of decodeFrames()) {
                controller.enqueue(frame);
            }
            const tail = buffer.peek(4);
            if (tail && Buffer.compare(constants$1.TERMINATOR, tail) === 0) {
                return;
            }
            if (params?.require_terminator === false) {
                return;
            }
            throw new Error('stream did not complete successfully');
        }
    }, writableStrategy, params?.readableStrategy);
};
decoder.createBSONStreamDecoder = createBSONStreamDecoder;

var header = {};

var __createBinding$e = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$e = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$e = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$e(result, mod, k);
    __setModuleDefault$e(result, mod);
    return result;
};
Object.defineProperty(header, "__esModule", { value: true });
header.prependHeaderToStream = header.extractHeaderFromStream = void 0;
const buffer_array = __importStar$e(bufferArray);
const bson$2 = __importStar$e(require$$1);
const extractHeaderFromStream = async (input_stream, params) => {
    const iterator = input_stream[Symbol.asyncIterator]();
    const buffer = buffer_array.createReadableBufferArray();
    let frame_size = null;
    async function* resplice(data, iterator) {
        if (data) {
            yield data;
        }
        while (true) {
            const next = await iterator.next();
            if (next.done) {
                return;
            }
            yield next.value;
        }
    }
    while (true) {
        const chunk = await iterator.next();
        if (chunk.done) {
            throw new Error('Stream did not complete successfully');
        }
        buffer.push(chunk.value);
        if (frame_size === null) {
            frame_size = buffer.peek(4)?.readInt32LE(0) || null;
        }
        if (frame_size === null) {
            continue;
        }
        const frame = buffer.read(frame_size);
        if (!frame) {
            continue;
        }
        const header = bson$2.deserialize(frame, {
            promoteBuffers: true,
            ...(params?.deserialize_options || {})
        });
        return {
            header: header,
            stream: resplice(buffer.read(buffer.size()), iterator)
        };
    }
};
header.extractHeaderFromStream = extractHeaderFromStream;
async function* prependHeaderToStream(header, input_stream) {
    yield bson$2.serialize(header);
    yield* input_stream;
}
header.prependHeaderToStream = prependHeaderToStream;

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(bufferArray, exports);
	__exportStar(constants$3, exports);
	__exportStar(encoder, exports);
	__exportStar(decoder, exports);
	__exportStar(header, exports); 
} (bson$5));

var transformers = {};

/**
 * A set of standard helpers for working with iterators.
 *
 * The majority of the utils included here can be removed if and when the tc39 iterator-helpers proposal lands:
 * https://github.com/tc39/proposal-iterator-helpers
 */
Object.defineProperty(transformers, "__esModule", { value: true });
transformers.drain = transformers.reduce = transformers.reduced = transformers.filter = transformers.map = transformers.concat = void 0;
/**
 * Takes n number of streams (or any AsyncIterators) and returns an AsyncGenerator that
 * yields the concatenated output of all input streams
 */
async function* concat$1(...sources) {
    for (const source of sources) {
        yield* source;
    }
}
transformers.concat = concat$1;
/**
 * Implements `Array.prototype.map` for iterables
 */
async function* map$1(iterable, transform) {
    for await (const element of iterable) {
        yield await transform(element);
    }
}
transformers.map = map$1;
/**
 * Implements `Array.prototype.filter` for iterables
 */
async function* filter(iterable, comparator) {
    for await (const element of iterable) {
        if (await comparator(element)) {
            yield element;
        }
    }
}
transformers.filter = filter;
const reduced = (value) => {
    return {
        __reduced: true,
        value
    };
};
transformers.reduced = reduced;
const isReducedValue = (value) => {
    return '__reduced' in value && value.__reduced;
};
/**
 * Implements `Array.prototype.reduce` for iterables.
 *
 * The reducer can return `reduced(accumulator)` to end execution early
 */
const reduce = async (iterable, reducer, init) => {
    let accumulator = init;
    for await (const element of iterable) {
        const result = await reducer(accumulator, element);
        if (isReducedValue(result)) {
            return result.value;
        }
        accumulator = result;
    }
    return accumulator;
};
transformers.reduce = reduce;
/**
 * Drain a given iterables contents into an array. This is kind of like `Array.from` except it works
 * with AsyncIterables
 */
const drain = async (iterator) => {
    const data = [];
    for await (const chunk of iterator) {
        data.push(chunk);
    }
    return data;
};
transformers.drain = drain;

var utils$8 = {};

var dist$7 = {};

var errors$3 = {};

/**
 * This error class is designed to give consumers of Journey Micro
 * a consistent way of "throwing" errors. Specifically, these errors
 * will give clients to Journey Micro implementations two things:
 *
 * 1. An consistent, static error code by which to easily classify errors
 * 2. An error message intended for humans
 *
 * Errors will usually assume that there is some client side error and default to 400 for
 * a rest-like response. This can be changed however to more accurately, in restful terms,
 * indicate what went wrong.
 *
 */
Object.defineProperty(errors$3, "__esModule", { value: true });
errors$3.ResourceConflict = errors$3.ResourceNotFound = errors$3.InternalServerError = errors$3.AuthorizationError = errors$3.ValidationError = errors$3.JourneyError = errors$3.ErrorSeverity = void 0;
var ErrorSeverity;
(function (ErrorSeverity) {
    ErrorSeverity["INFO"] = "info";
    ErrorSeverity["WARNING"] = "warning";
    ErrorSeverity["ERROR"] = "error";
})(ErrorSeverity || (errors$3.ErrorSeverity = ErrorSeverity = {}));
class JourneyError extends Error {
    constructor(data) {
        super(`[${data.code}] ${data.description}\n  ${data.details}`);
        this.is_journey_error = true;
        this.errorData = data;
        if (data.stack) {
            this.stack = data.stack;
        }
        this.name = data.name || this.constructor.name;
        this.errorData.name = this.name;
    }
    toString() {
        return this.stack;
    }
    toJSON() {
        if (process.env.NODE_ENV !== 'production') {
            return this.errorData;
        }
        return {
            name: this.errorData.name,
            code: this.errorData.code,
            status: this.errorData.status,
            description: this.errorData.description,
            details: this.errorData.details,
            trace_id: this.errorData.trace_id,
            severity: this.errorData.severity,
            origin: this.errorData.origin
        };
    }
    setTraceId(id) {
        this.errorData.trace_id = id;
    }
}
errors$3.JourneyError = JourneyError;
let ValidationError$1 = class ValidationError extends JourneyError {
    constructor(errors) {
        super({
            code: ValidationError.CODE,
            status: 400,
            description: 'Validation failed',
            details: JSON.stringify(errors)
        });
    }
};
errors$3.ValidationError = ValidationError$1;
ValidationError$1.CODE = 'VALIDATION_ERROR';
class AuthorizationError extends JourneyError {
    constructor(errors) {
        super({
            code: AuthorizationError.CODE,
            status: 401,
            description: 'Authorization failed',
            details: errors
        });
    }
}
errors$3.AuthorizationError = AuthorizationError;
AuthorizationError.CODE = 'AUTHORIZATION';
class InternalServerError extends JourneyError {
    constructor(err) {
        super({
            code: InternalServerError.CODE,
            severity: ErrorSeverity.ERROR,
            status: 500,
            description: 'Something went wrong',
            details: err.message,
            stack: process.env.NODE_ENV !== 'production' ? err.stack : undefined
        });
    }
}
errors$3.InternalServerError = InternalServerError;
InternalServerError.CODE = 'INTERNAL_SERVER_ERROR';
class ResourceNotFound extends JourneyError {
    constructor(resource, id) {
        const combinedId = id ? `${resource}/${id}` : resource;
        super({
            code: ResourceNotFound.CODE,
            status: 404,
            description: 'The requested resource does not exist on this server',
            details: `The resource ${combinedId} does not exist on this server`,
            severity: ErrorSeverity.INFO
        });
    }
}
errors$3.ResourceNotFound = ResourceNotFound;
ResourceNotFound.CODE = 'RESOURCE_NOT_FOUND';
class ResourceConflict extends JourneyError {
    constructor(details) {
        super({
            code: ResourceConflict.CODE,
            status: 409,
            description: 'The specified resource already exists on this server',
            details: details,
            severity: ErrorSeverity.INFO
        });
    }
}
errors$3.ResourceConflict = ResourceConflict;
ResourceConflict.CODE = 'RESOURCE_CONFLICT';

var utils$7 = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.matchesErrorCode = exports.getErrorData = exports.isJourneyError = void 0;
	const errors_1 = errors$3;
	const isJourneyError = (err) => {
	    const matches = err instanceof errors_1.JourneyError || err.is_journey_error;
	    return !!matches;
	};
	exports.isJourneyError = isJourneyError;
	const getErrorData = (err) => {
	    if (!(0, exports.isJourneyError)(err)) {
	        return;
	    }
	    return err.toJSON();
	};
	exports.getErrorData = getErrorData;
	const matchesErrorCode = (err, code) => {
	    if ((0, exports.isJourneyError)(err)) {
	        return err.errorData.code === code;
	    }
	    return false;
	};
	exports.matchesErrorCode = matchesErrorCode; 
} (utils$7));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(errors$3, exports);
	__exportStar(utils$7, exports); 
} (dist$7));

var __createBinding$d = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$d = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$d = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$d(result, mod, k);
    __setModuleDefault$d(result, mod);
    return result;
};
Object.defineProperty(utils$8, "__esModule", { value: true });
utils$8.validateDataStream = utils$8.readableFrom = utils$8.iterableFromReadable = void 0;
const micro_errors$1 = __importStar$d(dist$7);
const cross_stream = __importStar$d(crossStream);
/**
 * Construct an AsyncIterator from a given ReadableStream.
 *
 * This is only really intended to be used from browser runtimes or within code intended to
 * be used cross-platform. This is because Node ReadableStreams already implement AsyncIterators
 */
async function* iterableFromReadable(readable) {
    const reader = readable.getReader();
    try {
        while (true) {
            const res = await reader.read();
            if (res.done) {
                return;
            }
            yield res.value;
        }
    }
    finally {
        reader.releaseLock();
    }
}
utils$8.iterableFromReadable = iterableFromReadable;
/**
 * Construct a ReadableStream from a given Iterable or AsyncIterable.
 *
 * If the given iterable is already a readable then this is a noop
 */
const readableFrom = (iterable, strategy) => {
    if (iterable instanceof cross_stream.Readable) {
        return iterable;
    }
    let resume;
    return new cross_stream.Readable({
        start(controller) {
            void (async function () {
                for await (const chunk of iterable) {
                    controller.enqueue(chunk);
                    if (controller.desiredSize != null && controller.desiredSize <= 0) {
                        await new Promise((resolve) => {
                            resume = resolve;
                        });
                    }
                }
                controller.close();
            })().catch((err) => {
                controller.error(err);
            });
        },
        async pull() {
            resume?.();
        }
    }, strategy);
};
utils$8.readableFrom = readableFrom;
/**
 * Yield a generator that validates data flowing through it
 */
async function* validateDataStream(iterable, validator) {
    for await (const chunk of iterable) {
        const res = validator.validate(chunk);
        if (!res.valid) {
            throw new micro_errors$1.ValidationError(res.errors);
        }
        yield chunk;
    }
}
utils$8.validateDataStream = validateDataStream;

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.bson = exports.compat = void 0;
	exports.compat = __importStar(crossStream);
	exports.bson = __importStar(bson$5);
	__exportStar(transformers, exports);
	__exportStar(utils$8, exports); 
} (web$1));

var definitions$6 = {};

Object.defineProperty(definitions$6, "__esModule", { value: true });
definitions$6.METHOD = definitions$6.ContentType = definitions$6.Header = void 0;
var Header;
(function (Header) {
    Header["ContentType"] = "Content-Type";
    Header["Accept"] = "Accept";
    Header["Authorization"] = "Authorization";
    Header["UserAgent"] = "User-Agent";
})(Header || (definitions$6.Header = Header = {}));
var ContentType;
(function (ContentType) {
    ContentType["JSON"] = "application/json";
    ContentType["BSON"] = "application/bson";
    ContentType["HeaderStream"] = "application/vnd.journeyapps.raw+header";
    ContentType["BSONStream"] = "application/vnd.journeyapps.bson-stream+header";
})(ContentType || (definitions$6.ContentType = ContentType = {}));
var METHOD;
(function (METHOD) {
    METHOD["POST"] = "POST";
    METHOD["PUT"] = "PUT";
    METHOD["PATCH"] = "PATCH";
    METHOD["GET"] = "GET";
    METHOD["DELETE"] = "DELETE";
})(METHOD || (definitions$6.METHOD = METHOD = {}));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.headersForStream = exports.isBsonStream = exports.isHeaderStream = exports.isRawStream = exports.isStreamedPayload = exports.BsonStream = exports.HeaderStream = exports.RawStream = exports.StreamType = exports.ensureIterable = void 0;
	const micro_streaming = __importStar(web$1);
	const defs = __importStar(definitions$6);
	/**
	 * This is for web compatibility. Web based ReadableStreams are not iterable even though we type them as such
	 */
	const ensureIterable = (iterable) => {
	    if (iterable instanceof micro_streaming.compat.Readable && !(Symbol.asyncIterator in iterable)) {
	        return micro_streaming.iterableFromReadable(iterable);
	    }
	    return iterable;
	};
	exports.ensureIterable = ensureIterable;
	var StreamType;
	(function (StreamType) {
	    StreamType["Raw"] = "raw";
	    StreamType["Header"] = "header";
	    StreamType["Bson"] = "bson";
	})(StreamType || (exports.StreamType = StreamType = {}));
	class RawStream {
	    constructor(stream) {
	        this.type = StreamType.Raw;
	        this.header = undefined;
	        this.encode = () => {
	            return this.stream;
	        };
	        this.setHeader = () => {
	            return new RawStream(this.stream);
	        };
	        this.stream = stream;
	    }
	}
	exports.RawStream = RawStream;
	class HeaderStream {
	    constructor(stream, header) {
	        this.type = StreamType.Header;
	        this.encode = () => {
	            return micro_streaming.bson.prependHeaderToStream(this.header, (0, exports.ensureIterable)(this.stream));
	        };
	        this.setHeader = (header) => {
	            return new HeaderStream(this.stream, header);
	        };
	        this.stream = stream;
	        this.header = header;
	    }
	}
	exports.HeaderStream = HeaderStream;
	class BsonStream {
	    constructor(stream, header) {
	        this.type = StreamType.Bson;
	        this.setHeader = (header) => {
	            return new BsonStream(this.stream, header);
	        };
	        this.stream = stream;
	        this.header = header;
	    }
	    encode() {
	        const encoded = micro_streaming
	            .readableFrom(this.stream)
	            .pipeThrough(micro_streaming.bson.createBSONStreamEncoder());
	        return micro_streaming.bson.prependHeaderToStream(this.header, (0, exports.ensureIterable)(encoded));
	    }
	}
	exports.BsonStream = BsonStream;
	const isStreamedPayload = (payload) => {
	    return Object.values(StreamType).includes(payload?.type);
	};
	exports.isStreamedPayload = isStreamedPayload;
	const isRawStream = (payload) => {
	    return payload?.type === 'raw';
	};
	exports.isRawStream = isRawStream;
	const isHeaderStream = (payload) => {
	    return payload?.type === 'header';
	};
	exports.isHeaderStream = isHeaderStream;
	const isBsonStream = (payload) => {
	    return payload?.type === 'bson';
	};
	exports.isBsonStream = isBsonStream;
	const headersForStream = (stream) => {
	    switch (stream.type) {
	        case StreamType.Header: {
	            return {
	                [defs.Header.ContentType]: defs.ContentType.HeaderStream
	            };
	        }
	        case StreamType.Bson: {
	            return {
	                [defs.Header.ContentType]: defs.ContentType.BSONStream
	            };
	        }
	        default: {
	            return {};
	        }
	    }
	};
	exports.headersForStream = headersForStream; 
} (streaming));

var agentkeepalive = {exports: {}};

/**
 * Helpers.
 */

var s = 1000;
var m = s * 60;
var h = m * 60;
var d = h * 24;
var w = d * 7;
var y = d * 365.25;

/**
 * Parse or format the given `val`.
 *
 * Options:
 *
 *  - `long` verbose formatting [false]
 *
 * @param {String|Number} val
 * @param {Object} [options]
 * @throws {Error} throw an error if val is not a non-empty string or a number
 * @return {String|Number}
 * @api public
 */

var ms$2 = function (val, options) {
  options = options || {};
  var type = typeof val;
  if (type === 'string' && val.length > 0) {
    return parse$3(val);
  } else if (type === 'number' && isFinite(val)) {
    return options.long ? fmtLong(val) : fmtShort(val);
  }
  throw new Error(
    'val is not a non-empty string or a valid number. val=' +
      JSON.stringify(val)
  );
};

/**
 * Parse the given `str` and return milliseconds.
 *
 * @param {String} str
 * @return {Number}
 * @api private
 */

function parse$3(str) {
  str = String(str);
  if (str.length > 100) {
    return;
  }
  var match = /^(-?(?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(
    str
  );
  if (!match) {
    return;
  }
  var n = parseFloat(match[1]);
  var type = (match[2] || 'ms').toLowerCase();
  switch (type) {
    case 'years':
    case 'year':
    case 'yrs':
    case 'yr':
    case 'y':
      return n * y;
    case 'weeks':
    case 'week':
    case 'w':
      return n * w;
    case 'days':
    case 'day':
    case 'd':
      return n * d;
    case 'hours':
    case 'hour':
    case 'hrs':
    case 'hr':
    case 'h':
      return n * h;
    case 'minutes':
    case 'minute':
    case 'mins':
    case 'min':
    case 'm':
      return n * m;
    case 'seconds':
    case 'second':
    case 'secs':
    case 'sec':
    case 's':
      return n * s;
    case 'milliseconds':
    case 'millisecond':
    case 'msecs':
    case 'msec':
    case 'ms':
      return n;
    default:
      return undefined;
  }
}

/**
 * Short format for `ms`.
 *
 * @param {Number} ms
 * @return {String}
 * @api private
 */

function fmtShort(ms) {
  var msAbs = Math.abs(ms);
  if (msAbs >= d) {
    return Math.round(ms / d) + 'd';
  }
  if (msAbs >= h) {
    return Math.round(ms / h) + 'h';
  }
  if (msAbs >= m) {
    return Math.round(ms / m) + 'm';
  }
  if (msAbs >= s) {
    return Math.round(ms / s) + 's';
  }
  return ms + 'ms';
}

/**
 * Long format for `ms`.
 *
 * @param {Number} ms
 * @return {String}
 * @api private
 */

function fmtLong(ms) {
  var msAbs = Math.abs(ms);
  if (msAbs >= d) {
    return plural(ms, msAbs, d, 'day');
  }
  if (msAbs >= h) {
    return plural(ms, msAbs, h, 'hour');
  }
  if (msAbs >= m) {
    return plural(ms, msAbs, m, 'minute');
  }
  if (msAbs >= s) {
    return plural(ms, msAbs, s, 'second');
  }
  return ms + ' ms';
}

/**
 * Pluralization helper.
 */

function plural(ms, msAbs, n, name) {
  var isPlural = msAbs >= n * 1.5;
  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');
}

/*!
 * humanize-ms - index.js
 * Copyright(c) 2014 dead_horse <dead_horse@qq.com>
 * MIT Licensed
 */

/**
 * Module dependencies.
 */

var util$1 = require$$0$1;
var ms$1 = ms$2;

var humanizeMs = function (t) {
  if (typeof t === 'number') return t;
  var r = ms$1(t);
  if (r === undefined) {
    var err = new Error(util$1.format('humanize-ms(%j) result undefined', t));
    console.warn(err.stack);
  }
  return r;
};

var constants = {
  // agent
  CURRENT_ID: Symbol('agentkeepalive#currentId'),
  CREATE_ID: Symbol('agentkeepalive#createId'),
  INIT_SOCKET: Symbol('agentkeepalive#initSocket'),
  CREATE_HTTPS_CONNECTION: Symbol('agentkeepalive#createHttpsConnection'),
  // socket
  SOCKET_CREATED_TIME: Symbol('agentkeepalive#socketCreatedTime'),
  SOCKET_NAME: Symbol('agentkeepalive#socketName'),
  SOCKET_REQUEST_COUNT: Symbol('agentkeepalive#socketRequestCount'),
  SOCKET_REQUEST_FINISHED_COUNT: Symbol('agentkeepalive#socketRequestFinishedCount'),
};

const OriginalAgent = require$$0$2.Agent;
const ms = humanizeMs;
const debug = require$$0$1.debuglog('agentkeepalive');
const {
  INIT_SOCKET: INIT_SOCKET$1,
  CURRENT_ID,
  CREATE_ID,
  SOCKET_CREATED_TIME,
  SOCKET_NAME,
  SOCKET_REQUEST_COUNT,
  SOCKET_REQUEST_FINISHED_COUNT,
} = constants;

// OriginalAgent come from
// - https://github.com/nodejs/node/blob/v8.12.0/lib/_http_agent.js
// - https://github.com/nodejs/node/blob/v10.12.0/lib/_http_agent.js

// node <= 10
let defaultTimeoutListenerCount = 1;
const majorVersion = parseInt(process.version.split('.', 1)[0].substring(1));
if (majorVersion >= 11 && majorVersion <= 12) {
  defaultTimeoutListenerCount = 2;
} else if (majorVersion >= 13) {
  defaultTimeoutListenerCount = 3;
}

function deprecate(message) {
  console.log('[agentkeepalive:deprecated] %s', message);
}

class Agent extends OriginalAgent {
  constructor(options) {
    options = options || {};
    options.keepAlive = options.keepAlive !== false;
    // default is keep-alive and 4s free socket timeout
    // see https://medium.com/ssense-tech/reduce-networking-errors-in-nodejs-23b4eb9f2d83
    if (options.freeSocketTimeout === undefined) {
      options.freeSocketTimeout = 4000;
    }
    // Legacy API: keepAliveTimeout should be rename to `freeSocketTimeout`
    if (options.keepAliveTimeout) {
      deprecate('options.keepAliveTimeout is deprecated, please use options.freeSocketTimeout instead');
      options.freeSocketTimeout = options.keepAliveTimeout;
      delete options.keepAliveTimeout;
    }
    // Legacy API: freeSocketKeepAliveTimeout should be rename to `freeSocketTimeout`
    if (options.freeSocketKeepAliveTimeout) {
      deprecate('options.freeSocketKeepAliveTimeout is deprecated, please use options.freeSocketTimeout instead');
      options.freeSocketTimeout = options.freeSocketKeepAliveTimeout;
      delete options.freeSocketKeepAliveTimeout;
    }

    // Sets the socket to timeout after timeout milliseconds of inactivity on the socket.
    // By default is double free socket timeout.
    if (options.timeout === undefined) {
      // make sure socket default inactivity timeout >= 8s
      options.timeout = Math.max(options.freeSocketTimeout * 2, 8000);
    }

    // support humanize format
    options.timeout = ms(options.timeout);
    options.freeSocketTimeout = ms(options.freeSocketTimeout);
    options.socketActiveTTL = options.socketActiveTTL ? ms(options.socketActiveTTL) : 0;

    super(options);

    this[CURRENT_ID] = 0;

    // create socket success counter
    this.createSocketCount = 0;
    this.createSocketCountLastCheck = 0;

    this.createSocketErrorCount = 0;
    this.createSocketErrorCountLastCheck = 0;

    this.closeSocketCount = 0;
    this.closeSocketCountLastCheck = 0;

    // socket error event count
    this.errorSocketCount = 0;
    this.errorSocketCountLastCheck = 0;

    // request finished counter
    this.requestCount = 0;
    this.requestCountLastCheck = 0;

    // including free socket timeout counter
    this.timeoutSocketCount = 0;
    this.timeoutSocketCountLastCheck = 0;

    this.on('free', socket => {
      // https://github.com/nodejs/node/pull/32000
      // Node.js native agent will check socket timeout eqs agent.options.timeout.
      // Use the ttl or freeSocketTimeout to overwrite.
      const timeout = this.calcSocketTimeout(socket);
      if (timeout > 0 && socket.timeout !== timeout) {
        socket.setTimeout(timeout);
      }
    });
  }

  get freeSocketKeepAliveTimeout() {
    deprecate('agent.freeSocketKeepAliveTimeout is deprecated, please use agent.options.freeSocketTimeout instead');
    return this.options.freeSocketTimeout;
  }

  get timeout() {
    deprecate('agent.timeout is deprecated, please use agent.options.timeout instead');
    return this.options.timeout;
  }

  get socketActiveTTL() {
    deprecate('agent.socketActiveTTL is deprecated, please use agent.options.socketActiveTTL instead');
    return this.options.socketActiveTTL;
  }

  calcSocketTimeout(socket) {
    /**
     * return <= 0: should free socket
     * return > 0: should update socket timeout
     * return undefined: not find custom timeout
     */
    let freeSocketTimeout = this.options.freeSocketTimeout;
    const socketActiveTTL = this.options.socketActiveTTL;
    if (socketActiveTTL) {
      // check socketActiveTTL
      const aliveTime = Date.now() - socket[SOCKET_CREATED_TIME];
      const diff = socketActiveTTL - aliveTime;
      if (diff <= 0) {
        return diff;
      }
      if (freeSocketTimeout && diff < freeSocketTimeout) {
        freeSocketTimeout = diff;
      }
    }
    // set freeSocketTimeout
    if (freeSocketTimeout) {
      // set free keepalive timer
      // try to use socket custom freeSocketTimeout first, support headers['keep-alive']
      // https://github.com/node-modules/urllib/blob/b76053020923f4d99a1c93cf2e16e0c5ba10bacf/lib/urllib.js#L498
      const customFreeSocketTimeout = socket.freeSocketTimeout || socket.freeSocketKeepAliveTimeout;
      return customFreeSocketTimeout || freeSocketTimeout;
    }
  }

  keepSocketAlive(socket) {
    const result = super.keepSocketAlive(socket);
    // should not keepAlive, do nothing
    if (!result) return result;

    const customTimeout = this.calcSocketTimeout(socket);
    if (typeof customTimeout === 'undefined') {
      return true;
    }
    if (customTimeout <= 0) {
      debug('%s(requests: %s, finished: %s) free but need to destroy by TTL, request count %s, diff is %s',
        socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT], customTimeout);
      return false;
    }
    if (socket.timeout !== customTimeout) {
      socket.setTimeout(customTimeout);
    }
    return true;
  }

  // only call on addRequest
  reuseSocket(...args) {
    // reuseSocket(socket, req)
    super.reuseSocket(...args);
    const socket = args[0];
    const req = args[1];
    req.reusedSocket = true;
    const agentTimeout = this.options.timeout;
    if (getSocketTimeout(socket) !== agentTimeout) {
      // reset timeout before use
      socket.setTimeout(agentTimeout);
      debug('%s reset timeout to %sms', socket[SOCKET_NAME], agentTimeout);
    }
    socket[SOCKET_REQUEST_COUNT]++;
    debug('%s(requests: %s, finished: %s) reuse on addRequest, timeout %sms',
      socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT],
      getSocketTimeout(socket));
  }

  [CREATE_ID]() {
    const id = this[CURRENT_ID]++;
    if (this[CURRENT_ID] === Number.MAX_SAFE_INTEGER) this[CURRENT_ID] = 0;
    return id;
  }

  [INIT_SOCKET$1](socket, options) {
    // bugfix here.
    // https on node 8, 10 won't set agent.options.timeout by default
    // TODO: need to fix on node itself
    if (options.timeout) {
      const timeout = getSocketTimeout(socket);
      if (!timeout) {
        socket.setTimeout(options.timeout);
      }
    }

    if (this.options.keepAlive) {
      // Disable Nagle's algorithm: http://blog.caustik.com/2012/04/08/scaling-node-js-to-100k-concurrent-connections/
      // https://fengmk2.com/benchmark/nagle-algorithm-delayed-ack-mock.html
      socket.setNoDelay(true);
    }
    this.createSocketCount++;
    if (this.options.socketActiveTTL) {
      socket[SOCKET_CREATED_TIME] = Date.now();
    }
    // don't show the hole '-----BEGIN CERTIFICATE----' key string
    socket[SOCKET_NAME] = `sock[${this[CREATE_ID]()}#${options._agentKey}]`.split('-----BEGIN', 1)[0];
    socket[SOCKET_REQUEST_COUNT] = 1;
    socket[SOCKET_REQUEST_FINISHED_COUNT] = 0;
    installListeners(this, socket, options);
  }

  createConnection(options, oncreate) {
    let called = false;
    const onNewCreate = (err, socket) => {
      if (called) return;
      called = true;

      if (err) {
        this.createSocketErrorCount++;
        return oncreate(err);
      }
      this[INIT_SOCKET$1](socket, options);
      oncreate(err, socket);
    };

    const newSocket = super.createConnection(options, onNewCreate);
    if (newSocket) onNewCreate(null, newSocket);
    return newSocket;
  }

  get statusChanged() {
    const changed = this.createSocketCount !== this.createSocketCountLastCheck ||
      this.createSocketErrorCount !== this.createSocketErrorCountLastCheck ||
      this.closeSocketCount !== this.closeSocketCountLastCheck ||
      this.errorSocketCount !== this.errorSocketCountLastCheck ||
      this.timeoutSocketCount !== this.timeoutSocketCountLastCheck ||
      this.requestCount !== this.requestCountLastCheck;
    if (changed) {
      this.createSocketCountLastCheck = this.createSocketCount;
      this.createSocketErrorCountLastCheck = this.createSocketErrorCount;
      this.closeSocketCountLastCheck = this.closeSocketCount;
      this.errorSocketCountLastCheck = this.errorSocketCount;
      this.timeoutSocketCountLastCheck = this.timeoutSocketCount;
      this.requestCountLastCheck = this.requestCount;
    }
    return changed;
  }

  getCurrentStatus() {
    return {
      createSocketCount: this.createSocketCount,
      createSocketErrorCount: this.createSocketErrorCount,
      closeSocketCount: this.closeSocketCount,
      errorSocketCount: this.errorSocketCount,
      timeoutSocketCount: this.timeoutSocketCount,
      requestCount: this.requestCount,
      freeSockets: inspect(this.freeSockets),
      sockets: inspect(this.sockets),
      requests: inspect(this.requests),
    };
  }
}

// node 8 don't has timeout attribute on socket
// https://github.com/nodejs/node/pull/21204/files#diff-e6ef024c3775d787c38487a6309e491dR408
function getSocketTimeout(socket) {
  return socket.timeout || socket._idleTimeout;
}

function installListeners(agent, socket, options) {
  debug('%s create, timeout %sms', socket[SOCKET_NAME], getSocketTimeout(socket));

  // listener socket events: close, timeout, error, free
  function onFree() {
    // create and socket.emit('free') logic
    // https://github.com/nodejs/node/blob/master/lib/_http_agent.js#L311
    // no req on the socket, it should be the new socket
    if (!socket._httpMessage && socket[SOCKET_REQUEST_COUNT] === 1) return;

    socket[SOCKET_REQUEST_FINISHED_COUNT]++;
    agent.requestCount++;
    debug('%s(requests: %s, finished: %s) free',
      socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT]);

    // should reuse on pedding requests?
    const name = agent.getName(options);
    if (socket.writable && agent.requests[name] && agent.requests[name].length) {
      // will be reuse on agent free listener
      socket[SOCKET_REQUEST_COUNT]++;
      debug('%s(requests: %s, finished: %s) will be reuse on agent free event',
        socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT]);
    }
  }
  socket.on('free', onFree);

  function onClose(isError) {
    debug('%s(requests: %s, finished: %s) close, isError: %s',
      socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT], isError);
    agent.closeSocketCount++;
  }
  socket.on('close', onClose);

  // start socket timeout handler
  function onTimeout() {
    // onTimeout and emitRequestTimeout(_http_client.js)
    // https://github.com/nodejs/node/blob/v12.x/lib/_http_client.js#L711
    const listenerCount = socket.listeners('timeout').length;
    // node <= 10, default listenerCount is 1, onTimeout
    // 11 < node <= 12, default listenerCount is 2, onTimeout and emitRequestTimeout
    // node >= 13, default listenerCount is 3, onTimeout,
    //   onTimeout(https://github.com/nodejs/node/pull/32000/files#diff-5f7fb0850412c6be189faeddea6c5359R333)
    //   and emitRequestTimeout
    const timeout = getSocketTimeout(socket);
    const req = socket._httpMessage;
    const reqTimeoutListenerCount = req && req.listeners('timeout').length || 0;
    debug('%s(requests: %s, finished: %s) timeout after %sms, listeners %s, defaultTimeoutListenerCount %s, hasHttpRequest %s, HttpRequest timeoutListenerCount %s',
      socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT],
      timeout, listenerCount, defaultTimeoutListenerCount, !!req, reqTimeoutListenerCount);
    if (debug.enabled) {
      debug('timeout listeners: %s', socket.listeners('timeout').map(f => f.name).join(', '));
    }
    agent.timeoutSocketCount++;
    const name = agent.getName(options);
    if (agent.freeSockets[name] && agent.freeSockets[name].indexOf(socket) !== -1) {
      // free socket timeout, destroy quietly
      socket.destroy();
      // Remove it from freeSockets list immediately to prevent new requests
      // from being sent through this socket.
      agent.removeSocket(socket, options);
      debug('%s is free, destroy quietly', socket[SOCKET_NAME]);
    } else {
      // if there is no any request socket timeout handler,
      // agent need to handle socket timeout itself.
      //
      // custom request socket timeout handle logic must follow these rules:
      //  1. Destroy socket first
      //  2. Must emit socket 'agentRemove' event tell agent remove socket
      //     from freeSockets list immediately.
      //     Otherise you may be get 'socket hang up' error when reuse
      //     free socket and timeout happen in the same time.
      if (reqTimeoutListenerCount === 0) {
        const error = new Error('Socket timeout');
        error.code = 'ERR_SOCKET_TIMEOUT';
        error.timeout = timeout;
        // must manually call socket.end() or socket.destroy() to end the connection.
        // https://nodejs.org/dist/latest-v10.x/docs/api/net.html#net_socket_settimeout_timeout_callback
        socket.destroy(error);
        agent.removeSocket(socket, options);
        debug('%s destroy with timeout error', socket[SOCKET_NAME]);
      }
    }
  }
  socket.on('timeout', onTimeout);

  function onError(err) {
    const listenerCount = socket.listeners('error').length;
    debug('%s(requests: %s, finished: %s) error: %s, listenerCount: %s',
      socket[SOCKET_NAME], socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT],
      err, listenerCount);
    agent.errorSocketCount++;
    if (listenerCount === 1) {
      // if socket don't contain error event handler, don't catch it, emit it again
      debug('%s emit uncaught error event', socket[SOCKET_NAME]);
      socket.removeListener('error', onError);
      socket.emit('error', err);
    }
  }
  socket.on('error', onError);

  function onRemove() {
    debug('%s(requests: %s, finished: %s) agentRemove',
      socket[SOCKET_NAME],
      socket[SOCKET_REQUEST_COUNT], socket[SOCKET_REQUEST_FINISHED_COUNT]);
    // We need this function for cases like HTTP 'upgrade'
    // (defined by WebSockets) where we need to remove a socket from the
    // pool because it'll be locked up indefinitely
    socket.removeListener('close', onClose);
    socket.removeListener('error', onError);
    socket.removeListener('free', onFree);
    socket.removeListener('timeout', onTimeout);
    socket.removeListener('agentRemove', onRemove);
  }
  socket.on('agentRemove', onRemove);
}

var agent = Agent;

function inspect(obj) {
  const res = {};
  for (const key in obj) {
    res[key] = obj[key].length;
  }
  return res;
}

const OriginalHttpsAgent = require$$0$3.Agent;
const HttpAgent = agent;
const {
  INIT_SOCKET,
  CREATE_HTTPS_CONNECTION,
} = constants;

class HttpsAgent extends HttpAgent {
  constructor(options) {
    super(options);

    this.defaultPort = 443;
    this.protocol = 'https:';
    this.maxCachedSessions = this.options.maxCachedSessions;
    /* istanbul ignore next */
    if (this.maxCachedSessions === undefined) {
      this.maxCachedSessions = 100;
    }

    this._sessionCache = {
      map: {},
      list: [],
    };
  }

  createConnection(options, oncreate) {
    const socket = this[CREATE_HTTPS_CONNECTION](options, oncreate);
    this[INIT_SOCKET](socket, options);
    return socket;
  }
}

// https://github.com/nodejs/node/blob/master/lib/https.js#L89
HttpsAgent.prototype[CREATE_HTTPS_CONNECTION] = OriginalHttpsAgent.prototype.createConnection;

[
  'getName',
  '_getSession',
  '_cacheSession',
  // https://github.com/nodejs/node/pull/4982
  '_evictSession',
].forEach(function(method) {
  /* istanbul ignore next */
  if (typeof OriginalHttpsAgent.prototype[method] === 'function') {
    HttpsAgent.prototype[method] = OriginalHttpsAgent.prototype[method];
  }
});

var https_agent = HttpsAgent;

agentkeepalive.exports = agent;
agentkeepalive.exports.HttpsAgent = https_agent;
agentkeepalive.exports.constants = constants;

var agentkeepaliveExports = agentkeepalive.exports;

var request = {};

var decoders = {};

var errors$2 = {};

var __createBinding$c = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$c = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$c = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$c(result, mod, k);
    __setModuleDefault$c(result, mod);
    return result;
};
Object.defineProperty(errors$2, "__esModule", { value: true });
errors$2.UnparsableServiceResponse = errors$2.TimeoutError = void 0;
const micro_errors = __importStar$c(dist$7);
class TimeoutError extends Error {
    constructor() {
        super();
        this.message = 'Request timed out';
        this.name = 'TimeoutError';
    }
}
errors$2.TimeoutError = TimeoutError;
class UnparsableServiceResponse extends micro_errors.JourneyError {
    constructor(endpoint, status, raw) {
        super({
            code: 'UNPARSABLE_SERVICE_RESPONSE',
            status: status,
            description: 'Could not parse service response',
            details: `${endpoint}\n${raw || 'unparseable'}`
        });
    }
}
errors$2.UnparsableServiceResponse = UnparsableServiceResponse;

var codecs$5 = {};

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.DEFAULT_CODECS = exports.BSONCodec = exports.JSONCodec = void 0;
	const defs = __importStar(definitions$6);
	const bson = __importStar(require$$1);
	exports.JSONCodec = {
	    encode: (data) => JSON.stringify(data),
	    decode: (data) => {
	        let raw;
	        if (data instanceof ArrayBuffer) {
	            const decoder = new TextDecoder('utf-8');
	            raw = decoder.decode(data);
	        }
	        else {
	            raw = data.toString();
	        }
	        return JSON.parse(raw);
	    }
	};
	exports.BSONCodec = {
	    encode: (data) => {
	        return bson.serialize(data, {
	            ignoreUndefined: true
	        });
	    },
	    decode: (data) => {
	        return bson.deserialize(data, {
	            promoteBuffers: true
	        });
	    }
	};
	exports.DEFAULT_CODECS = {
	    [defs.ContentType.JSON]: exports.JSONCodec,
	    [defs.ContentType.BSON]: exports.BSONCodec
	}; 
} (codecs$5));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.decodeServiceResponse = exports.decodeResponse = void 0;
	const micro_errors = __importStar(dist$7);
	const defs = __importStar(definitions$6);
	const errors = __importStar(errors$2);
	const codecs = __importStar(codecs$5);
	const decodeResponse = async (response, meta) => {
	    const content_type = response.headers.get(defs.Header.ContentType) || defs.ContentType.JSON;
	    // extract the first part of Content-Type - i.e "[application/json]; charset-utf8"
	    const codec = codecs.DEFAULT_CODECS[content_type.replace(/(?!<.*);.*/, '')];
	    if (!codec) {
	        const raw = await response.text();
	        throw new errors.UnparsableServiceResponse(`${meta.method} ${meta.url}`, response.status, raw);
	    }
	    return codec.decode(await response.arrayBuffer());
	};
	exports.decodeResponse = decodeResponse;
	const decodeServiceResponse = async (response, meta) => {
	    const { data, error } = await (0, exports.decodeResponse)(response, meta);
	    if (data) {
	        return data;
	    }
	    if (error) {
	        throw new micro_errors.JourneyError(error);
	    }
	    /**
	     * Not a JSON response, meaning it's not a standard response or error produced by journey-micro.
	     * This typically means something like a 404 or a 503 (gateway error).
	     * The body is usually meaningless in these cases.
	     * 3xx responses are also unexpected here.
	     */
	    if (response.status >= 300) {
	        throw new errors.UnparsableServiceResponse(`${meta.method} ${meta.url}`, response.status);
	    }
	    return null;
	};
	exports.decodeServiceResponse = decodeServiceResponse; 
} (decoders));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.request = void 0;
	const micro_streaming = __importStar(web$1);
	const streaming$1 = __importStar(streaming);
	const defs = __importStar(definitions$6);
	const decoders$1 = __importStar(decoders);
	const codecs = __importStar(codecs$5);
	const errors = __importStar(errors$2);
	const defaultRetryStrategy = (attempt) => {
	    return attempt * 200;
	};
	const createTimeout = (handler, timeout) => {
	    let t = setTimeout(handler, timeout);
	    let cleared = false;
	    return {
	        clear: () => {
	            if (cleared) {
	                return;
	            }
	            clearTimeout(t);
	            cleared = true;
	        },
	        heartbeat: () => {
	            if (cleared) {
	                return;
	            }
	            clearTimeout(t);
	            t = setTimeout(handler, timeout);
	        }
	    };
	};
	const request = async (url, params, attempt = 0) => {
	    let headers;
	    if (typeof params.headers === 'function') {
	        headers = await params.headers();
	    }
	    else {
	        headers = {
	            ...(params.headers || {})
	        };
	    }
	    headers = {
	        [defs.Header.Accept]: '*/*',
	        ...headers
	    };
	    if (params.user_agent) {
	        headers[defs.Header.UserAgent] = params.user_agent;
	    }
	    let body;
	    if (params.body) {
	        if (streaming$1.isStreamedPayload(params.body)) {
	            body = params.body.encode();
	        }
	        else {
	            const content_type = headers[defs.Header.ContentType] || defs.ContentType.JSON;
	            headers[defs.Header.ContentType] = content_type;
	            const codec = params.codecs?.[content_type] || codecs.DEFAULT_CODECS[content_type];
	            if (codec) {
	                body = codec.encode(params.body);
	            }
	            else {
	                if (!Buffer.isBuffer(params.body) && typeof params.body !== 'string') {
	                    throw new Error(`Unsupported body with type ${typeof params.body} and a Content-Type of ${content_type}. None of the configured codecs know how to convert the given body to a Buffer or string. Please provide a compatible codec`);
	                }
	                body = params.body;
	            }
	        }
	    }
	    const retryStrategy = params.retry_strategy || defaultRetryStrategy;
	    const abort_controller = new AbortController();
	    const timeout = params.timeout ?? 60000;
	    const read_timeout = params.read_timeout ?? 20000;
	    let request_timeout;
	    if (timeout > 0) {
	        request_timeout = createTimeout(() => {
	            abort_controller.abort();
	        }, timeout);
	    }
	    const decoder = params.decoder || decoders$1.decodeServiceResponse;
	    const max_attempts = (params.retry_attempts ?? 1) - 1;
	    try {
	        const res = await params.request(url, {
	            signal: abort_controller.signal,
	            method: params.method,
	            headers: headers,
	            body: body
	        });
	        // We throw here for it to be handled by the retry logic
	        if (res.status >= 500 && params.retryable) {
	            if (attempt <= max_attempts) {
	                throw res;
	            }
	        }
	        request_timeout?.clear();
	        const request_metadata = {
	            url,
	            method: params.method.toUpperCase()
	        };
	        return {
	            response: res,
	            stream: async () => {
	                if (res.status >= 300) {
	                    throw await decoder(res, request_metadata);
	                }
	                let stream_timeout;
	                return micro_streaming.readableFrom(res.body).pipeThrough(new micro_streaming.compat.Transform({
	                    start(controller) {
	                        if (read_timeout <= 0) {
	                            return;
	                        }
	                        stream_timeout = createTimeout(() => {
	                            controller.error(new errors.TimeoutError());
	                        }, read_timeout);
	                    },
	                    transform(chunk, controller) {
	                        stream_timeout?.heartbeat();
	                        controller.enqueue(chunk);
	                    },
	                    flush() {
	                        stream_timeout?.clear();
	                    }
	                }));
	            },
	            decode: () => decoder(res, request_metadata)
	        };
	    }
	    catch (err) {
	        request_timeout?.clear();
	        if (!params.retryable || attempt > max_attempts) {
	            if (err.name === 'AbortError') {
	                throw new errors.TimeoutError();
	            }
	            throw err;
	        }
	        await new Promise((resolve) => {
	            setTimeout(resolve, retryStrategy(attempt));
	        });
	        return (0, exports.request)(url, params, attempt + 1);
	    }
	};
	exports.request = request; 
} (request));

var utils$6 = {};

Object.defineProperty(utils$6, "__esModule", { value: true });
utils$6.join = utils$6.getHeader = utils$6.constructHeaders = void 0;
const constructHeaders = (collectors) => {
    return async () => {
        let headers = {};
        for (let collector of collectors) {
            if (!collector) {
                continue;
            }
            if (typeof collector === 'function') {
                headers = {
                    ...headers,
                    ...((await collector()) || {})
                };
            }
            else {
                headers = {
                    ...headers,
                    ...collector
                };
            }
        }
        return headers;
    };
};
utils$6.constructHeaders = constructHeaders;
/**
 * A small utility to get a key from a map in a case-insensitive way
 */
const getHeader = (headers, key) => {
    return Object.fromEntries(Object.entries(headers).map(([key, value]) => {
        return [key.toLowerCase(), value];
    }))[key.toLowerCase()];
};
utils$6.getHeader = getHeader;
/**
 * A weak clone of path.join from node that will work in the browser too. Joins all given
 * strings together with a '/' and then strips off duplicates.
 *
 * ["https://a/b/c/", "/d/e//f/"] => "https://a/b/c///d/e//f/" => "https://a/b/c/d/e/f/"
 */
const join = (...parts) => {
    const components = parts.join('/').split(/:\/\//);
    const deduped = (components[1] || components[0]).replace(/\/\/+/g, '/');
    if (components[1]) {
        return [components[0], deduped].join('://');
    }
    return deduped;
};
utils$6.join = join;

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	var __importDefault = (commonjsGlobal && commonjsGlobal.__importDefault) || function (mod) {
	    return (mod && mod.__esModule) ? mod : { "default": mod };
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.createNodeNetworkClient = void 0;
	const consumers = __importStar(require$$0$4);
	const streaming$1 = __importStar(streaming);
	const agentkeepalive_1 = __importDefault(agentkeepaliveExports);
	const requester = __importStar(request);
	const errors = __importStar(errors$2);
	const utils = __importStar(utils$6);
	const stream = __importStar(require$$6);
	const https = __importStar(require$$0$3);
	const http = __importStar(require$$0$2);
	const url_1 = require$$9$1;
	const default_agent_options = {
	    maxSockets: 100,
	    maxFreeSockets: 10,
	    timeout: 60000,
	    freeSocketTimeout: 30000 // free socket keepalive for 30 seconds
	};
	const createNodeNetworkClient = (options) => {
	    const agent_options = { ...default_agent_options };
	    if (options?.timeout != null) {
	        agent_options.timeout = options?.timeout;
	    }
	    const http_agent = new agentkeepalive_1.default(agent_options);
	    const https_agent = new agentkeepalive_1.default.HttpsAgent(agent_options);
	    return {
	        augment: (augmented) => {
	            return (0, exports.createNodeNetworkClient)({ ...augmented, ...options });
	        },
	        request: (url, params) => {
	            const service = process.env.MICRO_SERVICE_NAME;
	            const user_agent = `Journey SDK (node-client${service ? `,${service}` : ''})`;
	            let headers = {};
	            if (params.body && streaming$1.isStreamedPayload(params.body)) {
	                headers = streaming$1.headersForStream(params.body);
	            }
	            return requester.request(url, {
	                ...(options || {}),
	                ...params,
	                headers: utils.constructHeaders([headers, params.headers, options?.headers]),
	                user_agent: options?.user_agent || user_agent,
	                request: async (raw_url, params) => {
	                    const url = new url_1.URL(raw_url);
	                    let agent;
	                    let client;
	                    switch (url.protocol) {
	                        default:
	                        case 'http:': {
	                            agent = http_agent;
	                            client = http;
	                            break;
	                        }
	                        case 'https:': {
	                            agent = https_agent;
	                            client = https;
	                            break;
	                        }
	                    }
	                    return new Promise((resolve, reject) => {
	                        let aborted = false;
	                        const req = client.request(url, {
	                            signal: params.signal,
	                            method: params.method,
	                            headers: params.headers,
	                            agent
	                        }, (res) => {
	                            if (aborted) {
	                                return res.destroy(new Error('Aborted'));
	                            }
	                            resolve({
	                                headers: {
	                                    get: (key) => utils.getHeader(res.headers, key)
	                                },
	                                status: res.statusCode || 200,
	                                body: res,
	                                text: async () => {
	                                    return consumers.text(res);
	                                },
	                                arrayBuffer: async () => {
	                                    return consumers.arrayBuffer(res);
	                                }
	                            });
	                        });
	                        params.signal.addEventListener('abort', () => {
	                            req.destroy(new errors.TimeoutError());
	                            aborted = true;
	                        });
	                        req.once('error', reject);
	                        if (!params.body) {
	                            return req.end();
	                        }
	                        if (Buffer.isBuffer(params.body) || typeof params.body === 'string') {
	                            req.write(params.body);
	                            return req.end();
	                        }
	                        stream.pipeline(params.body, req, () => { });
	                    });
	                }
	            });
	        }
	    };
	};
	exports.createNodeNetworkClient = createNodeNetworkClient; 
} (nodeClient));

var web = {};

var webClient = {};

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.createWebNetworkClient = exports.iterableFromReadable = void 0;
	const micro_streaming = __importStar(web$1);
	const streaming$1 = __importStar(streaming);
	const requester = __importStar(request);
	const utils = __importStar(utils$6);
	async function* iterableFromReadable(readable) {
	    const reader = readable.getReader();
	    try {
	        while (true) {
	            const { done, value } = await reader.read();
	            if (done) {
	                return;
	            }
	            yield value;
	        }
	    }
	    finally {
	        reader.releaseLock();
	    }
	}
	exports.iterableFromReadable = iterableFromReadable;
	const createWebNetworkClient = (options) => {
	    return {
	        augment: (augmented) => {
	            return (0, exports.createWebNetworkClient)({ ...augmented, ...options });
	        },
	        request: async (url, params) => {
	            let headers = {};
	            let body;
	            if (params.body) {
	                if (streaming$1.isStreamedPayload(params.body)) {
	                    if (options?.buffer_streams ?? true) {
	                        body = Buffer.concat(await micro_streaming.drain(streaming$1.ensureIterable(params.body.encode())));
	                    }
	                    else {
	                        body = new streaming$1.RawStream(micro_streaming.readableFrom(params.body.encode()));
	                    }
	                    headers = streaming$1.headersForStream(params.body);
	                }
	                else {
	                    body = params.body;
	                }
	            }
	            return requester.request(url, {
	                ...(options || {}),
	                ...params,
	                headers: utils.constructHeaders([headers, params.headers, options?.headers]),
	                user_agent: options?.user_agent,
	                body: body,
	                request: async (url, params) => {
	                    return await fetch(url, params);
	                }
	            });
	        }
	    };
	};
	exports.createWebNetworkClient = createWebNetworkClient; 
} (webClient));

var fetchClients = {};

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(streaming, exports);
	__exportStar(decoders, exports);
	__exportStar(request, exports);
	__exportStar(errors$2, exports);
	__exportStar(codecs$5, exports); 
} (fetchClients));

var sdkClients = {};

var endpoints$1 = {};

var __createBinding$b = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$b = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$b = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$b(result, mod, k);
    __setModuleDefault$b(result, mod);
    return result;
};
Object.defineProperty(endpoints$1, "__esModule", { value: true });
endpoints$1.createEndpoint = void 0;
const micro_streaming = __importStar$b(web$1);
const defs$c = __importStar$b(definitions$6);
const definitions_1$1 = definitions$6;
const utils$5 = __importStar$b(utils$6);
const createEndpoint = (options) => {
    const request = async (payload, override) => {
        let request_options;
        if (typeof options === 'function') {
            request_options = options(payload);
        }
        else {
            request_options = options;
        }
        let method = request_options.method || defs$c.METHOD.POST;
        let body = request_options.payload || payload;
        /*
          In some cases we want the payload so we can dynamically construct a GET URL (`options` is a function),
          but don't want it automatically added to the body of the GET request
         */
        if (method === definitions_1$1.METHOD.GET) {
            body = null;
        }
        return await request_options.client.request(utils$5.join(request_options.endpoint, request_options.path), {
            method,
            ...request_options,
            body,
            ...(override || {})
        });
    };
    const defaultRequestFunction = async (params, override) => {
        const res = await request(params, override);
        return res.decode();
    };
    const streamedRequestFunction = async (params, override) => {
        const res = await request(params, override);
        const decode = async () => {
            const stream = await res.stream();
            return stream.pipeThrough(micro_streaming.bson.createBSONStreamDecoder());
        };
        return {
            response: res.response,
            stream: res.stream,
            decode: decode,
            [Symbol.asyncIterator]: async function* () {
                yield* micro_streaming.iterableFromReadable(await decode());
            }
        };
    };
    return Object.assign(defaultRequestFunction, {
        streamed: Object.assign(streamedRequestFunction, {
            request: request
        }),
        request: request
    });
};
endpoints$1.createEndpoint = createEndpoint;

var pagination = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.createPaginatedEndpoint = exports.paginate = void 0;
	const paginate = (endpoint) => {
	    return async function* (params) {
	        let more = true;
	        let cursor = params.cursor;
	        while (more) {
	            const res = await endpoint({
	                ...params,
	                cursor: cursor,
	                limit: params.limit || 50
	            });
	            yield res;
	            more = res.more;
	            cursor = res.cursor;
	        }
	    };
	};
	exports.paginate = paginate;
	const createPaginatedEndpoint = (endpoint) => {
	    return Object.assign(endpoint, {
	        paginate: (0, exports.paginate)(endpoint)
	    });
	};
	exports.createPaginatedEndpoint = createPaginatedEndpoint; 
} (pagination));

var sdkClient = {};

var __createBinding$a = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$a = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$a = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$a(result, mod, k);
    __setModuleDefault$a(result, mod);
    return result;
};
Object.defineProperty(sdkClient, "__esModule", { value: true });
sdkClient.SDKClient = sdkClient.CoreSDKClient = void 0;
const endpoints = __importStar$a(endpoints$1);
class CoreSDKClient {
    constructor(client, endpoint) {
        this.client = client;
        this.endpoint = endpoint;
    }
}
sdkClient.CoreSDKClient = CoreSDKClient;
class SDKClient extends CoreSDKClient {
    constructor(options) {
        super(options.client, options.endpoint);
        this.createEndpoint = (params) => {
            return endpoints.createEndpoint((payload) => {
                let resolved_params;
                if (typeof params === 'function') {
                    resolved_params = params(payload);
                }
                else {
                    resolved_params = params;
                }
                return {
                    client: this.client,
                    endpoint: this.endpoint,
                    ...resolved_params
                };
            });
        };
    }
}
sdkClient.SDKClient = SDKClient;

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(endpoints$1, exports);
	__exportStar(pagination, exports);
	__exportStar(sdkClient, exports); 
} (sdkClients));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(webClient, exports);
	__exportStar(fetchClients, exports);
	__exportStar(sdkClients, exports);
	__exportStar(definitions$6, exports);
	__exportStar(streaming, exports);
	__exportStar(utils$6, exports); 
} (web));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(nodeClient, exports);
	__exportStar(web, exports); 
} (dist$8));

var dist$6 = {};

var dist$5 = {};

var HostedConfig = {};

var dist$4 = {};

var definitions$5 = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.CodecType = void 0;
	(function (CodecType) {
	    CodecType["String"] = "string";
	    CodecType["Number"] = "number";
	    CodecType["Boolean"] = "boolean";
	    CodecType["Literal"] = "literal";
	    CodecType["Enum"] = "enum";
	    CodecType["Null"] = "null";
	    CodecType["Any"] = "any";
	    CodecType["Optional"] = "optional";
	    CodecType["Object"] = "object";
	    CodecType["Record"] = "record";
	    CodecType["Array"] = "array";
	    CodecType["Tuple"] = "tuple";
	    CodecType["Recursive"] = "recursive";
	    CodecType["Union"] = "union";
	    CodecType["Intersection"] = "intersection";
	})(exports.CodecType || (exports.CodecType = {})); 
} (definitions$5));

var jsonSchema = {};

var definitions$4 = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.TransformTarget = void 0;
	(function (TransformTarget) {
	    TransformTarget["Encoded"] = "encoded";
	    TransformTarget["Decoded"] = "decoded";
	})(exports.TransformTarget || (exports.TransformTarget = {})); 
} (definitions$4));

var generator = {};

var parsers$2 = {};

var combinators$1 = {};

var utils$4 = {};

Object.defineProperty(utils$4, "__esModule", { value: true });
utils$4.createParser = void 0;
const createParser = (tag, parser) => {
    return {
        tag,
        parse: parser
    };
};
utils$4.createParser = createParser;

var root$4 = {};

Object.defineProperty(root$4, "__esModule", { value: true });
root$4.RootParser = void 0;
const RootParser = (codec, options) => {
    const parser = options.parsers.find((parser) => parser.tag === codec._tag);
    if (!parser) {
        throw new Error(`No parser configured for codec ${codec._tag}`);
    }
    const schema = parser.parse(codec, options);
    if (codec.props.metadata?.description) {
        return {
            description: codec.props.metadata.description,
            ...schema
        };
    }
    return schema;
};
root$4.RootParser = RootParser;

Object.defineProperty(combinators$1, "__esModule", { value: true });
combinators$1.UnionParser = combinators$1.IntersectionParser = void 0;
const defs$b = definitions$5;
const utils_1$3 = utils$4;
const root$3 = root$4;
/**
 * Intersections are a bit complicated due to the way that additionalProperties works in JSON-Schema. To
 * support this we need to do different operations based on the type of codecs contained by the
 * intersection.
 *
 * If the intersection contains only object schemas then they are all merged under a single schema so
 * that `additionalProperties` applies against them simultaneously.
 *
 * If the intersection contains a mix of object schemas and unions then we need to construct the product
 * of all unions against a merge of all object schemas, combining them under a single `anyOf` definition.
 * Each product will be a merged schema with `additionalProperties` applying against all properties
 * contained within.
 *
 * Note: You can only really intersect object schemas and so we do not check for any other type of schema
 */
combinators$1.IntersectionParser = (0, utils_1$3.createParser)(defs$b.CodecType.Intersection, (codec, options) => {
    const schemas = codec.props.codecs.map((codec) => root$3.RootParser(codec, options));
    const unions = schemas.filter((schema) => !!schema.anyOf);
    const object_schemas = schemas.filter((schema) => schema.type === 'object');
    const mergeObjectSchemas = (...schemas) => {
        return {
            type: 'object',
            properties: schemas.reduce((properties, schema) => {
                return {
                    ...properties,
                    ...(schema.properties || {})
                };
            }, {}),
            additionalProperties: !!options?.allowAdditional,
            required: Array.from(new Set(schemas.reduce((required, schema) => {
                return required.concat(schema.required || []);
            }, [])))
        };
    };
    /**
     * If the intersection contains _only_ unions then we can return an `allOf` schema
     */
    if (unions.length > 0 && object_schemas.length === 0) {
        return {
            allOf: unions
        };
    }
    /**
     * If the intersection contains a mix of unions and object schemas then we need to merge all
     * object schemas into a single schema and product it with each union.
     *
     * {...merged_object_schemas} X unions
     */
    if (unions.length > 0) {
        const merged = mergeObjectSchemas(...object_schemas);
        return {
            anyOf: unions.reduce((schemas, union) => {
                return union.anyOf.reduce((schemas, union_schema) => {
                    return schemas.concat(mergeObjectSchemas(union_schema, merged));
                }, schemas);
            }, [])
        };
    }
    /**
     * Lastly, if the intersection contains only object schemas then we merge them into a single object schema
     */
    return mergeObjectSchemas(...schemas);
});
combinators$1.UnionParser = (0, utils_1$3.createParser)(defs$b.CodecType.Union, (codec, options) => {
    return {
        anyOf: codec.props.codecs.map((codec) => root$3.RootParser(codec, options))
    };
});

var primitives$1 = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.LiteralParser = exports.EnumParser = exports.AnyParser = exports.NullParser = exports.BooleanParser = exports.NumberParser = exports.StringParser = exports.createPrimitiveParser = void 0;
	const defs = definitions$5;
	const utils_1 = utils$4;
	const createPrimitiveParser = (type) => {
	    return (0, utils_1.createParser)(type, () => {
	        return { type };
	    });
	};
	exports.createPrimitiveParser = createPrimitiveParser;
	exports.StringParser = (0, exports.createPrimitiveParser)(defs.CodecType.String);
	exports.NumberParser = (0, exports.createPrimitiveParser)(defs.CodecType.Number);
	exports.BooleanParser = (0, exports.createPrimitiveParser)(defs.CodecType.Boolean);
	exports.NullParser = (0, exports.createPrimitiveParser)(defs.CodecType.Null);
	exports.AnyParser = (0, utils_1.createParser)(defs.CodecType.Any, () => {
	    return {};
	});
	exports.EnumParser = (0, utils_1.createParser)(defs.CodecType.Enum, (codec) => {
	    return {
	        type: 'string',
	        enum: Object.values(codec.props.enum)
	    };
	});
	exports.LiteralParser = (0, utils_1.createParser)(defs.CodecType.Literal, (codec) => {
	    return {
	        type: typeof codec.props.value,
	        const: codec.props.value
	    };
	}); 
} (primitives$1));

var recursive$2 = {};

Object.defineProperty(recursive$2, "__esModule", { value: true });
recursive$2.RecursiveParser = void 0;
const defs$a = definitions$5;
const utils_1$2 = utils$4;
const root$2 = root$4;
recursive$2.RecursiveParser = (0, utils_1$2.createParser)(defs$a.CodecType.Recursive, (codec, options) => {
    const ref = {
        $ref: `#/definitions/${codec.props.id}`
    };
    const cached = options.cache.get(codec.props.id);
    if (cached) {
        return ref;
    }
    options.cache.set(codec.props.id, {});
    /**
     * The schema is applied to the definition _after_ pushing the definition to the cache
     * to ensure that there are no cache misses from calling RootParser
     */
    options.cache.set(codec.props.id, root$2.RootParser(codec.props.resolver(), options));
    return ref;
});

var objects = {};

Object.defineProperty(objects, "__esModule", { value: true });
objects.RecordParser = objects.ObjectParser = void 0;
const defs$9 = definitions$5;
const utils_1$1 = utils$4;
const root$1 = root$4;
objects.ObjectParser = (0, utils_1$1.createParser)(defs$9.CodecType.Object, (codec, options) => {
    const entries = Object.entries(codec.props.shape);
    return {
        type: 'object',
        properties: entries.reduce((acc, [key, codec]) => {
            acc[key] = root$1.RootParser(codec, options);
            return acc;
        }, {}),
        additionalProperties: !!options?.allowAdditional,
        required: entries
            .filter(([, codec]) => {
            return codec.props.required;
        })
            .map(([key]) => key)
    };
});
objects.RecordParser = (0, utils_1$1.createParser)(defs$9.CodecType.Record, (codec, options) => {
    return {
        type: 'object',
        additionalProperties: root$1.RootParser(codec.props.type, options),
        properties: {},
        required: []
    };
});

var arrays$1 = {};

Object.defineProperty(arrays$1, "__esModule", { value: true });
arrays$1.TupleParser = arrays$1.ArrayParser = void 0;
const defs$8 = definitions$5;
const utils_1 = utils$4;
const root = root$4;
arrays$1.ArrayParser = (0, utils_1.createParser)(defs$8.CodecType.Array, (codec, options) => {
    return {
        type: 'array',
        items: root.RootParser(codec.props.type, options)
    };
});
arrays$1.TupleParser = (0, utils_1.createParser)(defs$8.CodecType.Tuple, (codec, options) => {
    return {
        type: 'array',
        items: codec.props.codecs.map((codec) => root.RootParser(codec, options)),
        minItems: codec.props.codecs.length,
        maxItems: codec.props.codecs.length
    };
});

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(combinators$1, exports);
	__exportStar(primitives$1, exports);
	__exportStar(recursive$2, exports);
	__exportStar(objects, exports);
	__exportStar(arrays$1, exports);
	__exportStar(root$4, exports); 
} (parsers$2));

Object.defineProperty(generator, "__esModule", { value: true });
generator.generateJSONSchema = void 0;
const defs$7 = definitions$4;
const p = parsers$2;
const generateJSONSchema = (codec, options) => {
    const parsers = [
        ...(options?.parsers || []),
        p.AnyParser,
        p.StringParser,
        p.NumberParser,
        p.BooleanParser,
        p.NullParser,
        p.LiteralParser,
        p.EnumParser,
        p.ObjectParser,
        p.RecordParser,
        p.ArrayParser,
        p.TupleParser,
        p.IntersectionParser,
        p.UnionParser,
        p.RecursiveParser
    ];
    const recursion_cache = new Map();
    const schema = p.RootParser(codec, {
        parsers,
        target: options?.target ?? defs$7.TransformTarget.Encoded,
        allowAdditional: options?.allowAdditional ?? false,
        cache: recursion_cache
    });
    return {
        definitions: Object.fromEntries(recursion_cache.entries()),
        ...schema
    };
};
generator.generateJSONSchema = generateJSONSchema;

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(definitions$4, exports);
	__exportStar(generator, exports);
	__exportStar(parsers$2, exports);
	__exportStar(utils$4, exports); 
} (jsonSchema));

var combinators = {};

var maps$1 = {};

var utils$3 = {};

Object.defineProperty(utils$3, "__esModule", { value: true });
utils$3.isCodecType = utils$3.TransformError = void 0;
class TransformError extends Error {
    constructor(errors) {
        super(Array.isArray(errors) ? errors.join(', ') : errors);
        this.errors = errors;
        this.name = 'TransformError';
    }
}
utils$3.TransformError = TransformError;
function isCodecType(codec, type) {
    return codec._tag === type;
}
utils$3.isCodecType = isCodecType;

var codec = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.optional = exports.union = exports.createUnionTransformer = exports.intersection = exports.createIntersectionTransformer = exports.codec = void 0;
	const defs = definitions$5;
	const utils = utils$3;
	const codec = (tag, encode, decode, props) => {
	    const c = {
	        _tag: tag,
	        props: {
	            ...(props || {}),
	            metadata: props?.metadata ?? {},
	            required: props?.required ?? true
	        },
	        encode,
	        decode,
	        and: (extention) => (0, exports.intersection)(c, extention),
	        or: (extention) => (0, exports.union)(c, extention),
	        meta: (metadata) => {
	            return (0, exports.codec)(tag, encode, decode, {
	                ...c.props,
	                metadata: {
	                    ...c.props.metadata,
	                    ...metadata
	                }
	            });
	        },
	        optional: () => (0, exports.optional)(c)
	    };
	    return c;
	};
	exports.codec = codec;
	const mergeSameCodecs = (tag, c1, c2) => {
	    const codecs = [];
	    if (utils.isCodecType(c1, tag)) {
	        codecs.push(...c1.props.codecs);
	    }
	    else {
	        codecs.push(c1);
	    }
	    if (utils.isCodecType(c2, tag)) {
	        codecs.push(...c2.props.codecs);
	    }
	    else {
	        codecs.push(c2);
	    }
	    return codecs;
	};
	const createIntersectionTransformer = (op, codecs) => (data) => {
	    return codecs.reduce((acc, codec) => {
	        return {
	            ...acc,
	            ...codec[op](data)
	        };
	    }, {});
	};
	exports.createIntersectionTransformer = createIntersectionTransformer;
	const intersection = (c1, c2) => {
	    const codecs = mergeSameCodecs(defs.CodecType.Intersection, c1, c2);
	    return (0, exports.codec)(defs.CodecType.Intersection, (0, exports.createIntersectionTransformer)('encode', codecs), (0, exports.createIntersectionTransformer)('decode', codecs), {
	        codecs: codecs
	    });
	};
	exports.intersection = intersection;
	const createUnionTransformer = (op, codecs) => (data) => {
	    const errors = [];
	    for (const codec of codecs) {
	        try {
	            return codec[op](data);
	        }
	        catch (err) {
	            errors.push(err);
	        }
	    }
	    throw new utils.TransformError(errors
	        .map((error) => {
	        if (error instanceof utils.TransformError) {
	            return error.errors;
	        }
	        return error.toString();
	    })
	        .flat());
	};
	exports.createUnionTransformer = createUnionTransformer;
	const union = (c1, c2) => {
	    const codecs = mergeSameCodecs(defs.CodecType.Union, c1, c2);
	    return (0, exports.codec)(defs.CodecType.Union, (0, exports.createUnionTransformer)('encode', codecs), (0, exports.createUnionTransformer)('decode', codecs), {
	        codecs
	    });
	};
	exports.union = union;
	const optional = (type) => {
	    if (!type.props.required) {
	        return type;
	    }
	    return (0, exports.codec)(type._tag, (data) => {
	        if (data === undefined) {
	            return undefined;
	        }
	        return type.encode(data);
	    }, (data) => {
	        if (data === undefined) {
	            return undefined;
	        }
	        return type.decode(data);
	    }, {
	        ...type.props,
	        required: false
	    });
	};
	exports.optional = optional; 
} (codec));

Object.defineProperty(maps$1, "__esModule", { value: true });
maps$1.record = maps$1.object = void 0;
const defs$6 = definitions$5;
const utils$2 = utils$3;
const codec_1$2 = codec;
const objectAssertion = (data) => {
    if (Array.isArray(data)) {
        throw new utils$2.TransformError('Expected a map but got an array');
    }
    if (typeof data !== 'object') {
        throw new utils$2.TransformError(`Expected a map but got ${typeof data}`);
    }
};
const object = (shape) => {
    const entries = Object.entries(shape);
    const transformer = (transformer) => (data) => {
        objectAssertion(data);
        return entries.reduce((acc, [key, codec]) => {
            const transformed = codec[transformer](data[key]);
            if (transformed !== undefined) {
                acc[key] = transformed;
            }
            return acc;
        }, {});
    };
    return (0, codec_1$2.codec)(defs$6.CodecType.Object, transformer('encode'), transformer('decode'), {
        shape
    });
};
maps$1.object = object;
const record = (type) => {
    const transformer = (transformer) => (data) => {
        objectAssertion(data);
        return Object.entries(data).reduce((acc, [key, value]) => {
            const transformed = type[transformer](value);
            if (transformed !== undefined) {
                acc[key] = transformed;
            }
            return acc;
        }, {});
    };
    return (0, codec_1$2.codec)(defs$6.CodecType.Record, transformer('encode'), transformer('decode'), {
        type
    });
};
maps$1.record = record;

Object.defineProperty(combinators, "__esModule", { value: true });
combinators.partial = combinators.omit = void 0;
const defs$5 = definitions$5;
const maps = maps$1;
const c = codec;
const omit = (codec, mask) => {
    const omitFromObjectCodec = (codec) => {
        const entries = Object.entries(codec.props.shape).filter(([key]) => {
            return !mask.includes(key);
        });
        return maps.object(Object.fromEntries(entries));
    };
    const omitFromIntersectionCodec = (codec) => {
        const codecs = codec.props.codecs.map(omitMaskFromCodec);
        return c.codec(defs$5.CodecType.Intersection, c.createIntersectionTransformer('encode', codecs), c.createIntersectionTransformer('decode', codecs), {
            codecs
        });
    };
    const omitFromUnionCodec = (codec) => {
        const codecs = codec.props.codecs.map(omitMaskFromCodec);
        return c.codec(defs$5.CodecType.Union, c.createUnionTransformer('encode', codecs), c.createUnionTransformer('decode', codecs), {
            codecs
        });
    };
    const omitMaskFromCodec = (codec) => {
        switch (codec._tag) {
            case defs$5.CodecType.Object: {
                return omitFromObjectCodec(codec);
            }
            case defs$5.CodecType.Intersection: {
                return omitFromIntersectionCodec(codec);
            }
            case defs$5.CodecType.Union: {
                return omitFromUnionCodec(codec);
            }
            default: {
                throw new Error(`Unsupported codec ${codec._tag}`);
            }
        }
    };
    return omitMaskFromCodec(codec);
};
combinators.omit = omit;
const partial = (codec) => {
    const partialObjectCodec = (codec) => {
        const entries = Object.entries(codec.props.shape).map(([key, codec]) => {
            return [key, codec.optional()];
        });
        return maps.object(Object.fromEntries(entries));
    };
    const partialIntersectionCodec = (codec) => {
        const codecs = codec.props.codecs.map(createPartialCodec);
        return c.codec(defs$5.CodecType.Intersection, c.createIntersectionTransformer('encode', codecs), c.createIntersectionTransformer('decode', codecs), {
            codecs
        });
    };
    const partialUnionCodec = (codec) => {
        const codecs = codec.props.codecs.map(createPartialCodec);
        return c.codec(defs$5.CodecType.Union, c.createUnionTransformer('encode', codecs), c.createUnionTransformer('decode', codecs), {
            codecs
        });
    };
    const createPartialCodec = (codec) => {
        switch (codec._tag) {
            case defs$5.CodecType.Object: {
                return partialObjectCodec(codec);
            }
            case defs$5.CodecType.Intersection: {
                return partialIntersectionCodec(codec);
            }
            case defs$5.CodecType.Union: {
                return partialUnionCodec(codec);
            }
        }
    };
    return createPartialCodec(codec);
};
combinators.partial = partial;

var primitives = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.Enum = exports.any = exports.Null = exports.literal = exports.number = exports.boolean = exports.string = exports.identityCodec = void 0;
	const defs = definitions$5;
	const utils = utils$3;
	const codec_1 = codec;
	const identityCodec = (type) => {
	    const transform = (data) => {
	        if (typeof data !== type) {
	            throw new utils.TransformError(`type must be ${type}, received ${typeof data}`);
	        }
	        return data;
	    };
	    return (0, codec_1.codec)(type, transform, transform);
	};
	exports.identityCodec = identityCodec;
	exports.string = (0, exports.identityCodec)(defs.CodecType.String);
	exports.boolean = (0, exports.identityCodec)(defs.CodecType.Boolean);
	exports.number = (0, exports.identityCodec)(defs.CodecType.Number);
	const literal = (literal) => {
	    const transform = (data) => {
	        if (data !== literal) {
	            throw new utils.TransformError(`Expected '${literal}' but go '${data}'`);
	        }
	        return data;
	    };
	    return (0, codec_1.codec)(defs.CodecType.Literal, transform, transform, {
	        value: literal
	    });
	};
	exports.literal = literal;
	const assertNull = (data) => {
	    if (data !== null) {
	        throw new utils.TransformError(`expected value to be null`);
	    }
	    return null;
	};
	exports.Null = (0, codec_1.codec)(defs.CodecType.Null, assertNull, assertNull);
	exports.any = (0, codec_1.codec)(defs.CodecType.Any, (data) => data, (data) => data);
	const Enum = (native_enum) => {
	    const values = Object.values(native_enum);
	    const transformer = (data) => {
	        if (!values.includes(data)) {
	            throw new utils.TransformError(`Expected ${data} to match one of ${values}`);
	        }
	        return data;
	    };
	    return (0, codec_1.codec)(defs.CodecType.Enum, transformer, transformer, {
	        enum: native_enum
	    });
	};
	exports.Enum = Enum; 
} (primitives));

var recursive$1 = {};

Object.defineProperty(recursive$1, "__esModule", { value: true });
recursive$1.recursive = void 0;
const defs$4 = definitions$5;
const codec_1$1 = codec;
const recursive = (id, resolver) => {
    return (0, codec_1$1.codec)(defs$4.CodecType.Recursive, (data) => {
        const codec = resolver();
        return codec.encode(data);
    }, (data) => {
        const codec = resolver();
        return codec.decode(data);
    }, {
        id: id,
        resolver: resolver
    });
};
recursive$1.recursive = recursive;

var arrays = {};

Object.defineProperty(arrays, "__esModule", { value: true });
arrays.tuple = arrays.array = void 0;
const defs$3 = definitions$5;
const utils$1 = utils$3;
const codec_1 = codec;
const array = (type) => {
    const assertion = (data) => {
        if (!Array.isArray(data)) {
            throw new utils$1.TransformError(`Expected an array but got ${typeof data}`);
        }
    };
    return (0, codec_1.codec)(defs$3.CodecType.Array, (data) => {
        assertion(data);
        return data.map(type.encode);
    }, (data) => {
        assertion(data);
        return data.map(type.decode);
    }, {
        type
    });
};
arrays.array = array;
const tuple = (tuple) => {
    const transformer = (transformation) => (data) => {
        if (!Array.isArray(data)) {
            throw new utils$1.TransformError(`Expected an array but got ${typeof data}`);
        }
        if (data.length !== tuple.length) {
            throw new utils$1.TransformError(`Given tuple does not match schema. Length mismatch ${tuple.length} !== ${data.length}`);
        }
        return tuple.map((codec, i) => {
            return codec[transformation](data[i]);
        });
    };
    return (0, codec_1.codec)(defs$3.CodecType.Tuple, transformer('encode'), transformer('decode'), {
        codecs: tuple
    });
};
arrays.tuple = tuple;

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(definitions$5, exports);
	__exportStar(jsonSchema, exports);
	__exportStar(combinators, exports);
	__exportStar(primitives, exports);
	__exportStar(recursive$1, exports);
	__exportStar(arrays, exports);
	__exportStar(codec, exports);
	__exportStar(maps$1, exports);
	__exportStar(utils$3, exports); 
} (dist$4));

var uri_all = {exports: {}};

/** @license URI.js v4.4.1 (c) 2011 Gary Court. License: http://github.com/garycourt/uri-js */

(function (module, exports) {
	(function (global, factory) {
		factory(exports) ;
	}(commonjsGlobal, (function (exports) {
	function merge() {
	    for (var _len = arguments.length, sets = Array(_len), _key = 0; _key < _len; _key++) {
	        sets[_key] = arguments[_key];
	    }

	    if (sets.length > 1) {
	        sets[0] = sets[0].slice(0, -1);
	        var xl = sets.length - 1;
	        for (var x = 1; x < xl; ++x) {
	            sets[x] = sets[x].slice(1, -1);
	        }
	        sets[xl] = sets[xl].slice(1);
	        return sets.join('');
	    } else {
	        return sets[0];
	    }
	}
	function subexp(str) {
	    return "(?:" + str + ")";
	}
	function typeOf(o) {
	    return o === undefined ? "undefined" : o === null ? "null" : Object.prototype.toString.call(o).split(" ").pop().split("]").shift().toLowerCase();
	}
	function toUpperCase(str) {
	    return str.toUpperCase();
	}
	function toArray(obj) {
	    return obj !== undefined && obj !== null ? obj instanceof Array ? obj : typeof obj.length !== "number" || obj.split || obj.setInterval || obj.call ? [obj] : Array.prototype.slice.call(obj) : [];
	}
	function assign(target, source) {
	    var obj = target;
	    if (source) {
	        for (var key in source) {
	            obj[key] = source[key];
	        }
	    }
	    return obj;
	}

	function buildExps(isIRI) {
	    var ALPHA$$ = "[A-Za-z]",
	        DIGIT$$ = "[0-9]",
	        HEXDIG$$ = merge(DIGIT$$, "[A-Fa-f]"),
	        PCT_ENCODED$ = subexp(subexp("%[EFef]" + HEXDIG$$ + "%" + HEXDIG$$ + HEXDIG$$ + "%" + HEXDIG$$ + HEXDIG$$) + "|" + subexp("%[89A-Fa-f]" + HEXDIG$$ + "%" + HEXDIG$$ + HEXDIG$$) + "|" + subexp("%" + HEXDIG$$ + HEXDIG$$)),
	        //expanded
	    GEN_DELIMS$$ = "[\\:\\/\\?\\#\\[\\]\\@]",
	        SUB_DELIMS$$ = "[\\!\\$\\&\\'\\(\\)\\*\\+\\,\\;\\=]",
	        RESERVED$$ = merge(GEN_DELIMS$$, SUB_DELIMS$$),
	        UCSCHAR$$ = isIRI ? "[\\xA0-\\u200D\\u2010-\\u2029\\u202F-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF]" : "[]",
	        //subset, excludes bidi control characters
	    IPRIVATE$$ = isIRI ? "[\\uE000-\\uF8FF]" : "[]",
	        //subset
	    UNRESERVED$$ = merge(ALPHA$$, DIGIT$$, "[\\-\\.\\_\\~]", UCSCHAR$$);
	        subexp(ALPHA$$ + merge(ALPHA$$, DIGIT$$, "[\\+\\-\\.]") + "*");
	        subexp(subexp(PCT_ENCODED$ + "|" + merge(UNRESERVED$$, SUB_DELIMS$$, "[\\:]")) + "*");
	        var DEC_OCTET_RELAXED$ = subexp(subexp("25[0-5]") + "|" + subexp("2[0-4]" + DIGIT$$) + "|" + subexp("1" + DIGIT$$ + DIGIT$$) + "|" + subexp("0?[1-9]" + DIGIT$$) + "|0?0?" + DIGIT$$),
	        //relaxed parsing rules
	    IPV4ADDRESS$ = subexp(DEC_OCTET_RELAXED$ + "\\." + DEC_OCTET_RELAXED$ + "\\." + DEC_OCTET_RELAXED$ + "\\." + DEC_OCTET_RELAXED$),
	        H16$ = subexp(HEXDIG$$ + "{1,4}"),
	        LS32$ = subexp(subexp(H16$ + "\\:" + H16$) + "|" + IPV4ADDRESS$),
	        IPV6ADDRESS1$ = subexp(subexp(H16$ + "\\:") + "{6}" + LS32$),
	        //                           6( h16 ":" ) ls32
	    IPV6ADDRESS2$ = subexp("\\:\\:" + subexp(H16$ + "\\:") + "{5}" + LS32$),
	        //                      "::" 5( h16 ":" ) ls32
	    IPV6ADDRESS3$ = subexp(subexp(H16$) + "?\\:\\:" + subexp(H16$ + "\\:") + "{4}" + LS32$),
	        //[               h16 ] "::" 4( h16 ":" ) ls32
	    IPV6ADDRESS4$ = subexp(subexp(subexp(H16$ + "\\:") + "{0,1}" + H16$) + "?\\:\\:" + subexp(H16$ + "\\:") + "{3}" + LS32$),
	        //[ *1( h16 ":" ) h16 ] "::" 3( h16 ":" ) ls32
	    IPV6ADDRESS5$ = subexp(subexp(subexp(H16$ + "\\:") + "{0,2}" + H16$) + "?\\:\\:" + subexp(H16$ + "\\:") + "{2}" + LS32$),
	        //[ *2( h16 ":" ) h16 ] "::" 2( h16 ":" ) ls32
	    IPV6ADDRESS6$ = subexp(subexp(subexp(H16$ + "\\:") + "{0,3}" + H16$) + "?\\:\\:" + H16$ + "\\:" + LS32$),
	        //[ *3( h16 ":" ) h16 ] "::"    h16 ":"   ls32
	    IPV6ADDRESS7$ = subexp(subexp(subexp(H16$ + "\\:") + "{0,4}" + H16$) + "?\\:\\:" + LS32$),
	        //[ *4( h16 ":" ) h16 ] "::"              ls32
	    IPV6ADDRESS8$ = subexp(subexp(subexp(H16$ + "\\:") + "{0,5}" + H16$) + "?\\:\\:" + H16$),
	        //[ *5( h16 ":" ) h16 ] "::"              h16
	    IPV6ADDRESS9$ = subexp(subexp(subexp(H16$ + "\\:") + "{0,6}" + H16$) + "?\\:\\:"),
	        //[ *6( h16 ":" ) h16 ] "::"
	    IPV6ADDRESS$ = subexp([IPV6ADDRESS1$, IPV6ADDRESS2$, IPV6ADDRESS3$, IPV6ADDRESS4$, IPV6ADDRESS5$, IPV6ADDRESS6$, IPV6ADDRESS7$, IPV6ADDRESS8$, IPV6ADDRESS9$].join("|")),
	        ZONEID$ = subexp(subexp(UNRESERVED$$ + "|" + PCT_ENCODED$) + "+");
	        //RFC 6874, with relaxed parsing rules
	    subexp("[vV]" + HEXDIG$$ + "+\\." + merge(UNRESERVED$$, SUB_DELIMS$$, "[\\:]") + "+");
	        //RFC 6874
	    subexp(subexp(PCT_ENCODED$ + "|" + merge(UNRESERVED$$, SUB_DELIMS$$)) + "*");
	        var PCHAR$ = subexp(PCT_ENCODED$ + "|" + merge(UNRESERVED$$, SUB_DELIMS$$, "[\\:\\@]"));
	        subexp(subexp(PCT_ENCODED$ + "|" + merge(UNRESERVED$$, SUB_DELIMS$$, "[\\@]")) + "+");
	        subexp(subexp(PCHAR$ + "|" + merge("[\\/\\?]", IPRIVATE$$)) + "*");
	    return {
	        NOT_SCHEME: new RegExp(merge("[^]", ALPHA$$, DIGIT$$, "[\\+\\-\\.]"), "g"),
	        NOT_USERINFO: new RegExp(merge("[^\\%\\:]", UNRESERVED$$, SUB_DELIMS$$), "g"),
	        NOT_HOST: new RegExp(merge("[^\\%\\[\\]\\:]", UNRESERVED$$, SUB_DELIMS$$), "g"),
	        NOT_PATH: new RegExp(merge("[^\\%\\/\\:\\@]", UNRESERVED$$, SUB_DELIMS$$), "g"),
	        NOT_PATH_NOSCHEME: new RegExp(merge("[^\\%\\/\\@]", UNRESERVED$$, SUB_DELIMS$$), "g"),
	        NOT_QUERY: new RegExp(merge("[^\\%]", UNRESERVED$$, SUB_DELIMS$$, "[\\:\\@\\/\\?]", IPRIVATE$$), "g"),
	        NOT_FRAGMENT: new RegExp(merge("[^\\%]", UNRESERVED$$, SUB_DELIMS$$, "[\\:\\@\\/\\?]"), "g"),
	        ESCAPE: new RegExp(merge("[^]", UNRESERVED$$, SUB_DELIMS$$), "g"),
	        UNRESERVED: new RegExp(UNRESERVED$$, "g"),
	        OTHER_CHARS: new RegExp(merge("[^\\%]", UNRESERVED$$, RESERVED$$), "g"),
	        PCT_ENCODED: new RegExp(PCT_ENCODED$, "g"),
	        IPV4ADDRESS: new RegExp("^(" + IPV4ADDRESS$ + ")$"),
	        IPV6ADDRESS: new RegExp("^\\[?(" + IPV6ADDRESS$ + ")" + subexp(subexp("\\%25|\\%(?!" + HEXDIG$$ + "{2})") + "(" + ZONEID$ + ")") + "?\\]?$") //RFC 6874, with relaxed parsing rules
	    };
	}
	var URI_PROTOCOL = buildExps(false);

	var IRI_PROTOCOL = buildExps(true);

	var slicedToArray = function () {
	  function sliceIterator(arr, i) {
	    var _arr = [];
	    var _n = true;
	    var _d = false;
	    var _e = undefined;

	    try {
	      for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done); _n = true) {
	        _arr.push(_s.value);

	        if (i && _arr.length === i) break;
	      }
	    } catch (err) {
	      _d = true;
	      _e = err;
	    } finally {
	      try {
	        if (!_n && _i["return"]) _i["return"]();
	      } finally {
	        if (_d) throw _e;
	      }
	    }

	    return _arr;
	  }

	  return function (arr, i) {
	    if (Array.isArray(arr)) {
	      return arr;
	    } else if (Symbol.iterator in Object(arr)) {
	      return sliceIterator(arr, i);
	    } else {
	      throw new TypeError("Invalid attempt to destructure non-iterable instance");
	    }
	  };
	}();













	var toConsumableArray = function (arr) {
	  if (Array.isArray(arr)) {
	    for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) arr2[i] = arr[i];

	    return arr2;
	  } else {
	    return Array.from(arr);
	  }
	};

	/** Highest positive signed 32-bit float value */

	var maxInt = 2147483647; // aka. 0x7FFFFFFF or 2^31-1

	/** Bootstring parameters */
	var base = 36;
	var tMin = 1;
	var tMax = 26;
	var skew = 38;
	var damp = 700;
	var initialBias = 72;
	var initialN = 128; // 0x80
	var delimiter = '-'; // '\x2D'

	/** Regular expressions */
	var regexPunycode = /^xn--/;
	var regexNonASCII = /[^\0-\x7E]/; // non-ASCII chars
	var regexSeparators = /[\x2E\u3002\uFF0E\uFF61]/g; // RFC 3490 separators

	/** Error messages */
	var errors = {
		'overflow': 'Overflow: input needs wider integers to process',
		'not-basic': 'Illegal input >= 0x80 (not a basic code point)',
		'invalid-input': 'Invalid input'
	};

	/** Convenience shortcuts */
	var baseMinusTMin = base - tMin;
	var floor = Math.floor;
	var stringFromCharCode = String.fromCharCode;

	/*--------------------------------------------------------------------------*/

	/**
	 * A generic error utility function.
	 * @private
	 * @param {String} type The error type.
	 * @returns {Error} Throws a `RangeError` with the applicable error message.
	 */
	function error$1(type) {
		throw new RangeError(errors[type]);
	}

	/**
	 * A generic `Array#map` utility function.
	 * @private
	 * @param {Array} array The array to iterate over.
	 * @param {Function} callback The function that gets called for every array
	 * item.
	 * @returns {Array} A new array of values returned by the callback function.
	 */
	function map(array, fn) {
		var result = [];
		var length = array.length;
		while (length--) {
			result[length] = fn(array[length]);
		}
		return result;
	}

	/**
	 * A simple `Array#map`-like wrapper to work with domain name strings or email
	 * addresses.
	 * @private
	 * @param {String} domain The domain name or email address.
	 * @param {Function} callback The function that gets called for every
	 * character.
	 * @returns {Array} A new string of characters returned by the callback
	 * function.
	 */
	function mapDomain(string, fn) {
		var parts = string.split('@');
		var result = '';
		if (parts.length > 1) {
			// In email addresses, only the domain name should be punycoded. Leave
			// the local part (i.e. everything up to `@`) intact.
			result = parts[0] + '@';
			string = parts[1];
		}
		// Avoid `split(regex)` for IE8 compatibility. See #17.
		string = string.replace(regexSeparators, '\x2E');
		var labels = string.split('.');
		var encoded = map(labels, fn).join('.');
		return result + encoded;
	}

	/**
	 * Creates an array containing the numeric code points of each Unicode
	 * character in the string. While JavaScript uses UCS-2 internally,
	 * this function will convert a pair of surrogate halves (each of which
	 * UCS-2 exposes as separate characters) into a single code point,
	 * matching UTF-16.
	 * @see `punycode.ucs2.encode`
	 * @see <https://mathiasbynens.be/notes/javascript-encoding>
	 * @memberOf punycode.ucs2
	 * @name decode
	 * @param {String} string The Unicode input string (UCS-2).
	 * @returns {Array} The new array of code points.
	 */
	function ucs2decode(string) {
		var output = [];
		var counter = 0;
		var length = string.length;
		while (counter < length) {
			var value = string.charCodeAt(counter++);
			if (value >= 0xD800 && value <= 0xDBFF && counter < length) {
				// It's a high surrogate, and there is a next character.
				var extra = string.charCodeAt(counter++);
				if ((extra & 0xFC00) == 0xDC00) {
					// Low surrogate.
					output.push(((value & 0x3FF) << 10) + (extra & 0x3FF) + 0x10000);
				} else {
					// It's an unmatched surrogate; only append this code unit, in case the
					// next code unit is the high surrogate of a surrogate pair.
					output.push(value);
					counter--;
				}
			} else {
				output.push(value);
			}
		}
		return output;
	}

	/**
	 * Creates a string based on an array of numeric code points.
	 * @see `punycode.ucs2.decode`
	 * @memberOf punycode.ucs2
	 * @name encode
	 * @param {Array} codePoints The array of numeric code points.
	 * @returns {String} The new Unicode string (UCS-2).
	 */
	var ucs2encode = function ucs2encode(array) {
		return String.fromCodePoint.apply(String, toConsumableArray(array));
	};

	/**
	 * Converts a basic code point into a digit/integer.
	 * @see `digitToBasic()`
	 * @private
	 * @param {Number} codePoint The basic numeric code point value.
	 * @returns {Number} The numeric value of a basic code point (for use in
	 * representing integers) in the range `0` to `base - 1`, or `base` if
	 * the code point does not represent a value.
	 */
	var basicToDigit = function basicToDigit(codePoint) {
		if (codePoint - 0x30 < 0x0A) {
			return codePoint - 0x16;
		}
		if (codePoint - 0x41 < 0x1A) {
			return codePoint - 0x41;
		}
		if (codePoint - 0x61 < 0x1A) {
			return codePoint - 0x61;
		}
		return base;
	};

	/**
	 * Converts a digit/integer into a basic code point.
	 * @see `basicToDigit()`
	 * @private
	 * @param {Number} digit The numeric value of a basic code point.
	 * @returns {Number} The basic code point whose value (when used for
	 * representing integers) is `digit`, which needs to be in the range
	 * `0` to `base - 1`. If `flag` is non-zero, the uppercase form is
	 * used; else, the lowercase form is used. The behavior is undefined
	 * if `flag` is non-zero and `digit` has no uppercase form.
	 */
	var digitToBasic = function digitToBasic(digit, flag) {
		//  0..25 map to ASCII a..z or A..Z
		// 26..35 map to ASCII 0..9
		return digit + 22 + 75 * (digit < 26) - ((flag != 0) << 5);
	};

	/**
	 * Bias adaptation function as per section 3.4 of RFC 3492.
	 * https://tools.ietf.org/html/rfc3492#section-3.4
	 * @private
	 */
	var adapt = function adapt(delta, numPoints, firstTime) {
		var k = 0;
		delta = firstTime ? floor(delta / damp) : delta >> 1;
		delta += floor(delta / numPoints);
		for (; /* no initialization */delta > baseMinusTMin * tMax >> 1; k += base) {
			delta = floor(delta / baseMinusTMin);
		}
		return floor(k + (baseMinusTMin + 1) * delta / (delta + skew));
	};

	/**
	 * Converts a Punycode string of ASCII-only symbols to a string of Unicode
	 * symbols.
	 * @memberOf punycode
	 * @param {String} input The Punycode string of ASCII-only symbols.
	 * @returns {String} The resulting string of Unicode symbols.
	 */
	var decode = function decode(input) {
		// Don't use UCS-2.
		var output = [];
		var inputLength = input.length;
		var i = 0;
		var n = initialN;
		var bias = initialBias;

		// Handle the basic code points: let `basic` be the number of input code
		// points before the last delimiter, or `0` if there is none, then copy
		// the first basic code points to the output.

		var basic = input.lastIndexOf(delimiter);
		if (basic < 0) {
			basic = 0;
		}

		for (var j = 0; j < basic; ++j) {
			// if it's not a basic code point
			if (input.charCodeAt(j) >= 0x80) {
				error$1('not-basic');
			}
			output.push(input.charCodeAt(j));
		}

		// Main decoding loop: start just after the last delimiter if any basic code
		// points were copied; start at the beginning otherwise.

		for (var index = basic > 0 ? basic + 1 : 0; index < inputLength;) /* no final expression */{

			// `index` is the index of the next character to be consumed.
			// Decode a generalized variable-length integer into `delta`,
			// which gets added to `i`. The overflow checking is easier
			// if we increase `i` as we go, then subtract off its starting
			// value at the end to obtain `delta`.
			var oldi = i;
			for (var w = 1, k = base;; /* no condition */k += base) {

				if (index >= inputLength) {
					error$1('invalid-input');
				}

				var digit = basicToDigit(input.charCodeAt(index++));

				if (digit >= base || digit > floor((maxInt - i) / w)) {
					error$1('overflow');
				}

				i += digit * w;
				var t = k <= bias ? tMin : k >= bias + tMax ? tMax : k - bias;

				if (digit < t) {
					break;
				}

				var baseMinusT = base - t;
				if (w > floor(maxInt / baseMinusT)) {
					error$1('overflow');
				}

				w *= baseMinusT;
			}

			var out = output.length + 1;
			bias = adapt(i - oldi, out, oldi == 0);

			// `i` was supposed to wrap around from `out` to `0`,
			// incrementing `n` each time, so we'll fix that now:
			if (floor(i / out) > maxInt - n) {
				error$1('overflow');
			}

			n += floor(i / out);
			i %= out;

			// Insert `n` at position `i` of the output.
			output.splice(i++, 0, n);
		}

		return String.fromCodePoint.apply(String, output);
	};

	/**
	 * Converts a string of Unicode symbols (e.g. a domain name label) to a
	 * Punycode string of ASCII-only symbols.
	 * @memberOf punycode
	 * @param {String} input The string of Unicode symbols.
	 * @returns {String} The resulting Punycode string of ASCII-only symbols.
	 */
	var encode = function encode(input) {
		var output = [];

		// Convert the input in UCS-2 to an array of Unicode code points.
		input = ucs2decode(input);

		// Cache the length.
		var inputLength = input.length;

		// Initialize the state.
		var n = initialN;
		var delta = 0;
		var bias = initialBias;

		// Handle the basic code points.
		var _iteratorNormalCompletion = true;
		var _didIteratorError = false;
		var _iteratorError = undefined;

		try {
			for (var _iterator = input[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {
				var _currentValue2 = _step.value;

				if (_currentValue2 < 0x80) {
					output.push(stringFromCharCode(_currentValue2));
				}
			}
		} catch (err) {
			_didIteratorError = true;
			_iteratorError = err;
		} finally {
			try {
				if (!_iteratorNormalCompletion && _iterator.return) {
					_iterator.return();
				}
			} finally {
				if (_didIteratorError) {
					throw _iteratorError;
				}
			}
		}

		var basicLength = output.length;
		var handledCPCount = basicLength;

		// `handledCPCount` is the number of code points that have been handled;
		// `basicLength` is the number of basic code points.

		// Finish the basic string with a delimiter unless it's empty.
		if (basicLength) {
			output.push(delimiter);
		}

		// Main encoding loop:
		while (handledCPCount < inputLength) {

			// All non-basic code points < n have been handled already. Find the next
			// larger one:
			var m = maxInt;
			var _iteratorNormalCompletion2 = true;
			var _didIteratorError2 = false;
			var _iteratorError2 = undefined;

			try {
				for (var _iterator2 = input[Symbol.iterator](), _step2; !(_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done); _iteratorNormalCompletion2 = true) {
					var currentValue = _step2.value;

					if (currentValue >= n && currentValue < m) {
						m = currentValue;
					}
				}

				// Increase `delta` enough to advance the decoder's <n,i> state to <m,0>,
				// but guard against overflow.
			} catch (err) {
				_didIteratorError2 = true;
				_iteratorError2 = err;
			} finally {
				try {
					if (!_iteratorNormalCompletion2 && _iterator2.return) {
						_iterator2.return();
					}
				} finally {
					if (_didIteratorError2) {
						throw _iteratorError2;
					}
				}
			}

			var handledCPCountPlusOne = handledCPCount + 1;
			if (m - n > floor((maxInt - delta) / handledCPCountPlusOne)) {
				error$1('overflow');
			}

			delta += (m - n) * handledCPCountPlusOne;
			n = m;

			var _iteratorNormalCompletion3 = true;
			var _didIteratorError3 = false;
			var _iteratorError3 = undefined;

			try {
				for (var _iterator3 = input[Symbol.iterator](), _step3; !(_iteratorNormalCompletion3 = (_step3 = _iterator3.next()).done); _iteratorNormalCompletion3 = true) {
					var _currentValue = _step3.value;

					if (_currentValue < n && ++delta > maxInt) {
						error$1('overflow');
					}
					if (_currentValue == n) {
						// Represent delta as a generalized variable-length integer.
						var q = delta;
						for (var k = base;; /* no condition */k += base) {
							var t = k <= bias ? tMin : k >= bias + tMax ? tMax : k - bias;
							if (q < t) {
								break;
							}
							var qMinusT = q - t;
							var baseMinusT = base - t;
							output.push(stringFromCharCode(digitToBasic(t + qMinusT % baseMinusT, 0)));
							q = floor(qMinusT / baseMinusT);
						}

						output.push(stringFromCharCode(digitToBasic(q, 0)));
						bias = adapt(delta, handledCPCountPlusOne, handledCPCount == basicLength);
						delta = 0;
						++handledCPCount;
					}
				}
			} catch (err) {
				_didIteratorError3 = true;
				_iteratorError3 = err;
			} finally {
				try {
					if (!_iteratorNormalCompletion3 && _iterator3.return) {
						_iterator3.return();
					}
				} finally {
					if (_didIteratorError3) {
						throw _iteratorError3;
					}
				}
			}

			++delta;
			++n;
		}
		return output.join('');
	};

	/**
	 * Converts a Punycode string representing a domain name or an email address
	 * to Unicode. Only the Punycoded parts of the input will be converted, i.e.
	 * it doesn't matter if you call it on a string that has already been
	 * converted to Unicode.
	 * @memberOf punycode
	 * @param {String} input The Punycoded domain name or email address to
	 * convert to Unicode.
	 * @returns {String} The Unicode representation of the given Punycode
	 * string.
	 */
	var toUnicode = function toUnicode(input) {
		return mapDomain(input, function (string) {
			return regexPunycode.test(string) ? decode(string.slice(4).toLowerCase()) : string;
		});
	};

	/**
	 * Converts a Unicode string representing a domain name or an email address to
	 * Punycode. Only the non-ASCII parts of the domain name will be converted,
	 * i.e. it doesn't matter if you call it with a domain that's already in
	 * ASCII.
	 * @memberOf punycode
	 * @param {String} input The domain name or email address to convert, as a
	 * Unicode string.
	 * @returns {String} The Punycode representation of the given domain name or
	 * email address.
	 */
	var toASCII = function toASCII(input) {
		return mapDomain(input, function (string) {
			return regexNonASCII.test(string) ? 'xn--' + encode(string) : string;
		});
	};

	/*--------------------------------------------------------------------------*/

	/** Define the public API */
	var punycode = {
		/**
	  * A string representing the current Punycode.js version number.
	  * @memberOf punycode
	  * @type String
	  */
		'version': '2.1.0',
		/**
	  * An object of methods to convert from JavaScript's internal character
	  * representation (UCS-2) to Unicode code points, and back.
	  * @see <https://mathiasbynens.be/notes/javascript-encoding>
	  * @memberOf punycode
	  * @type Object
	  */
		'ucs2': {
			'decode': ucs2decode,
			'encode': ucs2encode
		},
		'decode': decode,
		'encode': encode,
		'toASCII': toASCII,
		'toUnicode': toUnicode
	};

	/**
	 * URI.js
	 *
	 * @fileoverview An RFC 3986 compliant, scheme extendable URI parsing/validating/resolving library for JavaScript.
	 * @author <a href="mailto:gary.court@gmail.com">Gary Court</a>
	 * @see http://github.com/garycourt/uri-js
	 */
	/**
	 * Copyright 2011 Gary Court. All rights reserved.
	 *
	 * Redistribution and use in source and binary forms, with or without modification, are
	 * permitted provided that the following conditions are met:
	 *
	 *    1. Redistributions of source code must retain the above copyright notice, this list of
	 *       conditions and the following disclaimer.
	 *
	 *    2. Redistributions in binary form must reproduce the above copyright notice, this list
	 *       of conditions and the following disclaimer in the documentation and/or other materials
	 *       provided with the distribution.
	 *
	 * THIS SOFTWARE IS PROVIDED BY GARY COURT ``AS IS'' AND ANY EXPRESS OR IMPLIED
	 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
	 * FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GARY COURT OR
	 * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
	 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
	 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
	 * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
	 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
	 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
	 *
	 * The views and conclusions contained in the software and documentation are those of the
	 * authors and should not be interpreted as representing official policies, either expressed
	 * or implied, of Gary Court.
	 */
	var SCHEMES = {};
	function pctEncChar(chr) {
	    var c = chr.charCodeAt(0);
	    var e = void 0;
	    if (c < 16) e = "%0" + c.toString(16).toUpperCase();else if (c < 128) e = "%" + c.toString(16).toUpperCase();else if (c < 2048) e = "%" + (c >> 6 | 192).toString(16).toUpperCase() + "%" + (c & 63 | 128).toString(16).toUpperCase();else e = "%" + (c >> 12 | 224).toString(16).toUpperCase() + "%" + (c >> 6 & 63 | 128).toString(16).toUpperCase() + "%" + (c & 63 | 128).toString(16).toUpperCase();
	    return e;
	}
	function pctDecChars(str) {
	    var newStr = "";
	    var i = 0;
	    var il = str.length;
	    while (i < il) {
	        var c = parseInt(str.substr(i + 1, 2), 16);
	        if (c < 128) {
	            newStr += String.fromCharCode(c);
	            i += 3;
	        } else if (c >= 194 && c < 224) {
	            if (il - i >= 6) {
	                var c2 = parseInt(str.substr(i + 4, 2), 16);
	                newStr += String.fromCharCode((c & 31) << 6 | c2 & 63);
	            } else {
	                newStr += str.substr(i, 6);
	            }
	            i += 6;
	        } else if (c >= 224) {
	            if (il - i >= 9) {
	                var _c = parseInt(str.substr(i + 4, 2), 16);
	                var c3 = parseInt(str.substr(i + 7, 2), 16);
	                newStr += String.fromCharCode((c & 15) << 12 | (_c & 63) << 6 | c3 & 63);
	            } else {
	                newStr += str.substr(i, 9);
	            }
	            i += 9;
	        } else {
	            newStr += str.substr(i, 3);
	            i += 3;
	        }
	    }
	    return newStr;
	}
	function _normalizeComponentEncoding(components, protocol) {
	    function decodeUnreserved(str) {
	        var decStr = pctDecChars(str);
	        return !decStr.match(protocol.UNRESERVED) ? str : decStr;
	    }
	    if (components.scheme) components.scheme = String(components.scheme).replace(protocol.PCT_ENCODED, decodeUnreserved).toLowerCase().replace(protocol.NOT_SCHEME, "");
	    if (components.userinfo !== undefined) components.userinfo = String(components.userinfo).replace(protocol.PCT_ENCODED, decodeUnreserved).replace(protocol.NOT_USERINFO, pctEncChar).replace(protocol.PCT_ENCODED, toUpperCase);
	    if (components.host !== undefined) components.host = String(components.host).replace(protocol.PCT_ENCODED, decodeUnreserved).toLowerCase().replace(protocol.NOT_HOST, pctEncChar).replace(protocol.PCT_ENCODED, toUpperCase);
	    if (components.path !== undefined) components.path = String(components.path).replace(protocol.PCT_ENCODED, decodeUnreserved).replace(components.scheme ? protocol.NOT_PATH : protocol.NOT_PATH_NOSCHEME, pctEncChar).replace(protocol.PCT_ENCODED, toUpperCase);
	    if (components.query !== undefined) components.query = String(components.query).replace(protocol.PCT_ENCODED, decodeUnreserved).replace(protocol.NOT_QUERY, pctEncChar).replace(protocol.PCT_ENCODED, toUpperCase);
	    if (components.fragment !== undefined) components.fragment = String(components.fragment).replace(protocol.PCT_ENCODED, decodeUnreserved).replace(protocol.NOT_FRAGMENT, pctEncChar).replace(protocol.PCT_ENCODED, toUpperCase);
	    return components;
	}

	function _stripLeadingZeros(str) {
	    return str.replace(/^0*(.*)/, "$1") || "0";
	}
	function _normalizeIPv4(host, protocol) {
	    var matches = host.match(protocol.IPV4ADDRESS) || [];

	    var _matches = slicedToArray(matches, 2),
	        address = _matches[1];

	    if (address) {
	        return address.split(".").map(_stripLeadingZeros).join(".");
	    } else {
	        return host;
	    }
	}
	function _normalizeIPv6(host, protocol) {
	    var matches = host.match(protocol.IPV6ADDRESS) || [];

	    var _matches2 = slicedToArray(matches, 3),
	        address = _matches2[1],
	        zone = _matches2[2];

	    if (address) {
	        var _address$toLowerCase$ = address.toLowerCase().split('::').reverse(),
	            _address$toLowerCase$2 = slicedToArray(_address$toLowerCase$, 2),
	            last = _address$toLowerCase$2[0],
	            first = _address$toLowerCase$2[1];

	        var firstFields = first ? first.split(":").map(_stripLeadingZeros) : [];
	        var lastFields = last.split(":").map(_stripLeadingZeros);
	        var isLastFieldIPv4Address = protocol.IPV4ADDRESS.test(lastFields[lastFields.length - 1]);
	        var fieldCount = isLastFieldIPv4Address ? 7 : 8;
	        var lastFieldsStart = lastFields.length - fieldCount;
	        var fields = Array(fieldCount);
	        for (var x = 0; x < fieldCount; ++x) {
	            fields[x] = firstFields[x] || lastFields[lastFieldsStart + x] || '';
	        }
	        if (isLastFieldIPv4Address) {
	            fields[fieldCount - 1] = _normalizeIPv4(fields[fieldCount - 1], protocol);
	        }
	        var allZeroFields = fields.reduce(function (acc, field, index) {
	            if (!field || field === "0") {
	                var lastLongest = acc[acc.length - 1];
	                if (lastLongest && lastLongest.index + lastLongest.length === index) {
	                    lastLongest.length++;
	                } else {
	                    acc.push({ index: index, length: 1 });
	                }
	            }
	            return acc;
	        }, []);
	        var longestZeroFields = allZeroFields.sort(function (a, b) {
	            return b.length - a.length;
	        })[0];
	        var newHost = void 0;
	        if (longestZeroFields && longestZeroFields.length > 1) {
	            var newFirst = fields.slice(0, longestZeroFields.index);
	            var newLast = fields.slice(longestZeroFields.index + longestZeroFields.length);
	            newHost = newFirst.join(":") + "::" + newLast.join(":");
	        } else {
	            newHost = fields.join(":");
	        }
	        if (zone) {
	            newHost += "%" + zone;
	        }
	        return newHost;
	    } else {
	        return host;
	    }
	}
	var URI_PARSE = /^(?:([^:\/?#]+):)?(?:\/\/((?:([^\/?#@]*)@)?(\[[^\/?#\]]+\]|[^\/?#:]*)(?:\:(\d*))?))?([^?#]*)(?:\?([^#]*))?(?:#((?:.|\n|\r)*))?/i;
	var NO_MATCH_IS_UNDEFINED = "".match(/(){0}/)[1] === undefined;
	function parse(uriString) {
	    var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};

	    var components = {};
	    var protocol = options.iri !== false ? IRI_PROTOCOL : URI_PROTOCOL;
	    if (options.reference === "suffix") uriString = (options.scheme ? options.scheme + ":" : "") + "//" + uriString;
	    var matches = uriString.match(URI_PARSE);
	    if (matches) {
	        if (NO_MATCH_IS_UNDEFINED) {
	            //store each component
	            components.scheme = matches[1];
	            components.userinfo = matches[3];
	            components.host = matches[4];
	            components.port = parseInt(matches[5], 10);
	            components.path = matches[6] || "";
	            components.query = matches[7];
	            components.fragment = matches[8];
	            //fix port number
	            if (isNaN(components.port)) {
	                components.port = matches[5];
	            }
	        } else {
	            //IE FIX for improper RegExp matching
	            //store each component
	            components.scheme = matches[1] || undefined;
	            components.userinfo = uriString.indexOf("@") !== -1 ? matches[3] : undefined;
	            components.host = uriString.indexOf("//") !== -1 ? matches[4] : undefined;
	            components.port = parseInt(matches[5], 10);
	            components.path = matches[6] || "";
	            components.query = uriString.indexOf("?") !== -1 ? matches[7] : undefined;
	            components.fragment = uriString.indexOf("#") !== -1 ? matches[8] : undefined;
	            //fix port number
	            if (isNaN(components.port)) {
	                components.port = uriString.match(/\/\/(?:.|\n)*\:(?:\/|\?|\#|$)/) ? matches[4] : undefined;
	            }
	        }
	        if (components.host) {
	            //normalize IP hosts
	            components.host = _normalizeIPv6(_normalizeIPv4(components.host, protocol), protocol);
	        }
	        //determine reference type
	        if (components.scheme === undefined && components.userinfo === undefined && components.host === undefined && components.port === undefined && !components.path && components.query === undefined) {
	            components.reference = "same-document";
	        } else if (components.scheme === undefined) {
	            components.reference = "relative";
	        } else if (components.fragment === undefined) {
	            components.reference = "absolute";
	        } else {
	            components.reference = "uri";
	        }
	        //check for reference errors
	        if (options.reference && options.reference !== "suffix" && options.reference !== components.reference) {
	            components.error = components.error || "URI is not a " + options.reference + " reference.";
	        }
	        //find scheme handler
	        var schemeHandler = SCHEMES[(options.scheme || components.scheme || "").toLowerCase()];
	        //check if scheme can't handle IRIs
	        if (!options.unicodeSupport && (!schemeHandler || !schemeHandler.unicodeSupport)) {
	            //if host component is a domain name
	            if (components.host && (options.domainHost || schemeHandler && schemeHandler.domainHost)) {
	                //convert Unicode IDN -> ASCII IDN
	                try {
	                    components.host = punycode.toASCII(components.host.replace(protocol.PCT_ENCODED, pctDecChars).toLowerCase());
	                } catch (e) {
	                    components.error = components.error || "Host's domain name can not be converted to ASCII via punycode: " + e;
	                }
	            }
	            //convert IRI -> URI
	            _normalizeComponentEncoding(components, URI_PROTOCOL);
	        } else {
	            //normalize encodings
	            _normalizeComponentEncoding(components, protocol);
	        }
	        //perform scheme specific parsing
	        if (schemeHandler && schemeHandler.parse) {
	            schemeHandler.parse(components, options);
	        }
	    } else {
	        components.error = components.error || "URI can not be parsed.";
	    }
	    return components;
	}

	function _recomposeAuthority(components, options) {
	    var protocol = options.iri !== false ? IRI_PROTOCOL : URI_PROTOCOL;
	    var uriTokens = [];
	    if (components.userinfo !== undefined) {
	        uriTokens.push(components.userinfo);
	        uriTokens.push("@");
	    }
	    if (components.host !== undefined) {
	        //normalize IP hosts, add brackets and escape zone separator for IPv6
	        uriTokens.push(_normalizeIPv6(_normalizeIPv4(String(components.host), protocol), protocol).replace(protocol.IPV6ADDRESS, function (_, $1, $2) {
	            return "[" + $1 + ($2 ? "%25" + $2 : "") + "]";
	        }));
	    }
	    if (typeof components.port === "number" || typeof components.port === "string") {
	        uriTokens.push(":");
	        uriTokens.push(String(components.port));
	    }
	    return uriTokens.length ? uriTokens.join("") : undefined;
	}

	var RDS1 = /^\.\.?\//;
	var RDS2 = /^\/\.(\/|$)/;
	var RDS3 = /^\/\.\.(\/|$)/;
	var RDS5 = /^\/?(?:.|\n)*?(?=\/|$)/;
	function removeDotSegments(input) {
	    var output = [];
	    while (input.length) {
	        if (input.match(RDS1)) {
	            input = input.replace(RDS1, "");
	        } else if (input.match(RDS2)) {
	            input = input.replace(RDS2, "/");
	        } else if (input.match(RDS3)) {
	            input = input.replace(RDS3, "/");
	            output.pop();
	        } else if (input === "." || input === "..") {
	            input = "";
	        } else {
	            var im = input.match(RDS5);
	            if (im) {
	                var s = im[0];
	                input = input.slice(s.length);
	                output.push(s);
	            } else {
	                throw new Error("Unexpected dot segment condition");
	            }
	        }
	    }
	    return output.join("");
	}

	function serialize(components) {
	    var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};

	    var protocol = options.iri ? IRI_PROTOCOL : URI_PROTOCOL;
	    var uriTokens = [];
	    //find scheme handler
	    var schemeHandler = SCHEMES[(options.scheme || components.scheme || "").toLowerCase()];
	    //perform scheme specific serialization
	    if (schemeHandler && schemeHandler.serialize) schemeHandler.serialize(components, options);
	    if (components.host) {
	        //if host component is an IPv6 address
	        if (protocol.IPV6ADDRESS.test(components.host)) ;
	        //TODO: normalize IPv6 address as per RFC 5952

	        //if host component is a domain name
	        else if (options.domainHost || schemeHandler && schemeHandler.domainHost) {
	                //convert IDN via punycode
	                try {
	                    components.host = !options.iri ? punycode.toASCII(components.host.replace(protocol.PCT_ENCODED, pctDecChars).toLowerCase()) : punycode.toUnicode(components.host);
	                } catch (e) {
	                    components.error = components.error || "Host's domain name can not be converted to " + (!options.iri ? "ASCII" : "Unicode") + " via punycode: " + e;
	                }
	            }
	    }
	    //normalize encoding
	    _normalizeComponentEncoding(components, protocol);
	    if (options.reference !== "suffix" && components.scheme) {
	        uriTokens.push(components.scheme);
	        uriTokens.push(":");
	    }
	    var authority = _recomposeAuthority(components, options);
	    if (authority !== undefined) {
	        if (options.reference !== "suffix") {
	            uriTokens.push("//");
	        }
	        uriTokens.push(authority);
	        if (components.path && components.path.charAt(0) !== "/") {
	            uriTokens.push("/");
	        }
	    }
	    if (components.path !== undefined) {
	        var s = components.path;
	        if (!options.absolutePath && (!schemeHandler || !schemeHandler.absolutePath)) {
	            s = removeDotSegments(s);
	        }
	        if (authority === undefined) {
	            s = s.replace(/^\/\//, "/%2F"); //don't allow the path to start with "//"
	        }
	        uriTokens.push(s);
	    }
	    if (components.query !== undefined) {
	        uriTokens.push("?");
	        uriTokens.push(components.query);
	    }
	    if (components.fragment !== undefined) {
	        uriTokens.push("#");
	        uriTokens.push(components.fragment);
	    }
	    return uriTokens.join(""); //merge tokens into a string
	}

	function resolveComponents(base, relative) {
	    var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
	    var skipNormalization = arguments[3];

	    var target = {};
	    if (!skipNormalization) {
	        base = parse(serialize(base, options), options); //normalize base components
	        relative = parse(serialize(relative, options), options); //normalize relative components
	    }
	    options = options || {};
	    if (!options.tolerant && relative.scheme) {
	        target.scheme = relative.scheme;
	        //target.authority = relative.authority;
	        target.userinfo = relative.userinfo;
	        target.host = relative.host;
	        target.port = relative.port;
	        target.path = removeDotSegments(relative.path || "");
	        target.query = relative.query;
	    } else {
	        if (relative.userinfo !== undefined || relative.host !== undefined || relative.port !== undefined) {
	            //target.authority = relative.authority;
	            target.userinfo = relative.userinfo;
	            target.host = relative.host;
	            target.port = relative.port;
	            target.path = removeDotSegments(relative.path || "");
	            target.query = relative.query;
	        } else {
	            if (!relative.path) {
	                target.path = base.path;
	                if (relative.query !== undefined) {
	                    target.query = relative.query;
	                } else {
	                    target.query = base.query;
	                }
	            } else {
	                if (relative.path.charAt(0) === "/") {
	                    target.path = removeDotSegments(relative.path);
	                } else {
	                    if ((base.userinfo !== undefined || base.host !== undefined || base.port !== undefined) && !base.path) {
	                        target.path = "/" + relative.path;
	                    } else if (!base.path) {
	                        target.path = relative.path;
	                    } else {
	                        target.path = base.path.slice(0, base.path.lastIndexOf("/") + 1) + relative.path;
	                    }
	                    target.path = removeDotSegments(target.path);
	                }
	                target.query = relative.query;
	            }
	            //target.authority = base.authority;
	            target.userinfo = base.userinfo;
	            target.host = base.host;
	            target.port = base.port;
	        }
	        target.scheme = base.scheme;
	    }
	    target.fragment = relative.fragment;
	    return target;
	}

	function resolve(baseURI, relativeURI, options) {
	    var schemelessOptions = assign({ scheme: 'null' }, options);
	    return serialize(resolveComponents(parse(baseURI, schemelessOptions), parse(relativeURI, schemelessOptions), schemelessOptions, true), schemelessOptions);
	}

	function normalize(uri, options) {
	    if (typeof uri === "string") {
	        uri = serialize(parse(uri, options), options);
	    } else if (typeOf(uri) === "object") {
	        uri = parse(serialize(uri, options), options);
	    }
	    return uri;
	}

	function equal(uriA, uriB, options) {
	    if (typeof uriA === "string") {
	        uriA = serialize(parse(uriA, options), options);
	    } else if (typeOf(uriA) === "object") {
	        uriA = serialize(uriA, options);
	    }
	    if (typeof uriB === "string") {
	        uriB = serialize(parse(uriB, options), options);
	    } else if (typeOf(uriB) === "object") {
	        uriB = serialize(uriB, options);
	    }
	    return uriA === uriB;
	}

	function escapeComponent(str, options) {
	    return str && str.toString().replace(!options || !options.iri ? URI_PROTOCOL.ESCAPE : IRI_PROTOCOL.ESCAPE, pctEncChar);
	}

	function unescapeComponent(str, options) {
	    return str && str.toString().replace(!options || !options.iri ? URI_PROTOCOL.PCT_ENCODED : IRI_PROTOCOL.PCT_ENCODED, pctDecChars);
	}

	var handler = {
	    scheme: "http",
	    domainHost: true,
	    parse: function parse(components, options) {
	        //report missing host
	        if (!components.host) {
	            components.error = components.error || "HTTP URIs must have a host.";
	        }
	        return components;
	    },
	    serialize: function serialize(components, options) {
	        var secure = String(components.scheme).toLowerCase() === "https";
	        //normalize the default port
	        if (components.port === (secure ? 443 : 80) || components.port === "") {
	            components.port = undefined;
	        }
	        //normalize the empty path
	        if (!components.path) {
	            components.path = "/";
	        }
	        //NOTE: We do not parse query strings for HTTP URIs
	        //as WWW Form Url Encoded query strings are part of the HTML4+ spec,
	        //and not the HTTP spec.
	        return components;
	    }
	};

	var handler$1 = {
	    scheme: "https",
	    domainHost: handler.domainHost,
	    parse: handler.parse,
	    serialize: handler.serialize
	};

	function isSecure(wsComponents) {
	    return typeof wsComponents.secure === 'boolean' ? wsComponents.secure : String(wsComponents.scheme).toLowerCase() === "wss";
	}
	//RFC 6455
	var handler$2 = {
	    scheme: "ws",
	    domainHost: true,
	    parse: function parse(components, options) {
	        var wsComponents = components;
	        //indicate if the secure flag is set
	        wsComponents.secure = isSecure(wsComponents);
	        //construct resouce name
	        wsComponents.resourceName = (wsComponents.path || '/') + (wsComponents.query ? '?' + wsComponents.query : '');
	        wsComponents.path = undefined;
	        wsComponents.query = undefined;
	        return wsComponents;
	    },
	    serialize: function serialize(wsComponents, options) {
	        //normalize the default port
	        if (wsComponents.port === (isSecure(wsComponents) ? 443 : 80) || wsComponents.port === "") {
	            wsComponents.port = undefined;
	        }
	        //ensure scheme matches secure flag
	        if (typeof wsComponents.secure === 'boolean') {
	            wsComponents.scheme = wsComponents.secure ? 'wss' : 'ws';
	            wsComponents.secure = undefined;
	        }
	        //reconstruct path from resource name
	        if (wsComponents.resourceName) {
	            var _wsComponents$resourc = wsComponents.resourceName.split('?'),
	                _wsComponents$resourc2 = slicedToArray(_wsComponents$resourc, 2),
	                path = _wsComponents$resourc2[0],
	                query = _wsComponents$resourc2[1];

	            wsComponents.path = path && path !== '/' ? path : undefined;
	            wsComponents.query = query;
	            wsComponents.resourceName = undefined;
	        }
	        //forbid fragment component
	        wsComponents.fragment = undefined;
	        return wsComponents;
	    }
	};

	var handler$3 = {
	    scheme: "wss",
	    domainHost: handler$2.domainHost,
	    parse: handler$2.parse,
	    serialize: handler$2.serialize
	};

	var O = {};
	//RFC 3986
	var UNRESERVED$$ = "[A-Za-z0-9\\-\\.\\_\\~" + ("\\xA0-\\u200D\\u2010-\\u2029\\u202F-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF" ) + "]";
	var HEXDIG$$ = "[0-9A-Fa-f]"; //case-insensitive
	var PCT_ENCODED$ = subexp(subexp("%[EFef]" + HEXDIG$$ + "%" + HEXDIG$$ + HEXDIG$$ + "%" + HEXDIG$$ + HEXDIG$$) + "|" + subexp("%[89A-Fa-f]" + HEXDIG$$ + "%" + HEXDIG$$ + HEXDIG$$) + "|" + subexp("%" + HEXDIG$$ + HEXDIG$$)); //expanded
	//RFC 5322, except these symbols as per RFC 6068: @ : / ? # [ ] & ; =
	//const ATEXT$$ = "[A-Za-z0-9\\!\\#\\$\\%\\&\\'\\*\\+\\-\\/\\=\\?\\^\\_\\`\\{\\|\\}\\~]";
	//const WSP$$ = "[\\x20\\x09]";
	//const OBS_QTEXT$$ = "[\\x01-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]";  //(%d1-8 / %d11-12 / %d14-31 / %d127)
	//const QTEXT$$ = merge("[\\x21\\x23-\\x5B\\x5D-\\x7E]", OBS_QTEXT$$);  //%d33 / %d35-91 / %d93-126 / obs-qtext
	//const VCHAR$$ = "[\\x21-\\x7E]";
	//const WSP$$ = "[\\x20\\x09]";
	//const OBS_QP$ = subexp("\\\\" + merge("[\\x00\\x0D\\x0A]", OBS_QTEXT$$));  //%d0 / CR / LF / obs-qtext
	//const FWS$ = subexp(subexp(WSP$$ + "*" + "\\x0D\\x0A") + "?" + WSP$$ + "+");
	//const QUOTED_PAIR$ = subexp(subexp("\\\\" + subexp(VCHAR$$ + "|" + WSP$$)) + "|" + OBS_QP$);
	//const QUOTED_STRING$ = subexp('\\"' + subexp(FWS$ + "?" + QCONTENT$) + "*" + FWS$ + "?" + '\\"');
	var ATEXT$$ = "[A-Za-z0-9\\!\\$\\%\\'\\*\\+\\-\\^\\_\\`\\{\\|\\}\\~]";
	var QTEXT$$ = "[\\!\\$\\%\\'\\(\\)\\*\\+\\,\\-\\.0-9\\<\\>A-Z\\x5E-\\x7E]";
	var VCHAR$$ = merge(QTEXT$$, "[\\\"\\\\]");
	var SOME_DELIMS$$ = "[\\!\\$\\'\\(\\)\\*\\+\\,\\;\\:\\@]";
	var UNRESERVED = new RegExp(UNRESERVED$$, "g");
	var PCT_ENCODED = new RegExp(PCT_ENCODED$, "g");
	var NOT_LOCAL_PART = new RegExp(merge("[^]", ATEXT$$, "[\\.]", '[\\"]', VCHAR$$), "g");
	var NOT_HFNAME = new RegExp(merge("[^]", UNRESERVED$$, SOME_DELIMS$$), "g");
	var NOT_HFVALUE = NOT_HFNAME;
	function decodeUnreserved(str) {
	    var decStr = pctDecChars(str);
	    return !decStr.match(UNRESERVED) ? str : decStr;
	}
	var handler$4 = {
	    scheme: "mailto",
	    parse: function parse$$1(components, options) {
	        var mailtoComponents = components;
	        var to = mailtoComponents.to = mailtoComponents.path ? mailtoComponents.path.split(",") : [];
	        mailtoComponents.path = undefined;
	        if (mailtoComponents.query) {
	            var unknownHeaders = false;
	            var headers = {};
	            var hfields = mailtoComponents.query.split("&");
	            for (var x = 0, xl = hfields.length; x < xl; ++x) {
	                var hfield = hfields[x].split("=");
	                switch (hfield[0]) {
	                    case "to":
	                        var toAddrs = hfield[1].split(",");
	                        for (var _x = 0, _xl = toAddrs.length; _x < _xl; ++_x) {
	                            to.push(toAddrs[_x]);
	                        }
	                        break;
	                    case "subject":
	                        mailtoComponents.subject = unescapeComponent(hfield[1], options);
	                        break;
	                    case "body":
	                        mailtoComponents.body = unescapeComponent(hfield[1], options);
	                        break;
	                    default:
	                        unknownHeaders = true;
	                        headers[unescapeComponent(hfield[0], options)] = unescapeComponent(hfield[1], options);
	                        break;
	                }
	            }
	            if (unknownHeaders) mailtoComponents.headers = headers;
	        }
	        mailtoComponents.query = undefined;
	        for (var _x2 = 0, _xl2 = to.length; _x2 < _xl2; ++_x2) {
	            var addr = to[_x2].split("@");
	            addr[0] = unescapeComponent(addr[0]);
	            if (!options.unicodeSupport) {
	                //convert Unicode IDN -> ASCII IDN
	                try {
	                    addr[1] = punycode.toASCII(unescapeComponent(addr[1], options).toLowerCase());
	                } catch (e) {
	                    mailtoComponents.error = mailtoComponents.error || "Email address's domain name can not be converted to ASCII via punycode: " + e;
	                }
	            } else {
	                addr[1] = unescapeComponent(addr[1], options).toLowerCase();
	            }
	            to[_x2] = addr.join("@");
	        }
	        return mailtoComponents;
	    },
	    serialize: function serialize$$1(mailtoComponents, options) {
	        var components = mailtoComponents;
	        var to = toArray(mailtoComponents.to);
	        if (to) {
	            for (var x = 0, xl = to.length; x < xl; ++x) {
	                var toAddr = String(to[x]);
	                var atIdx = toAddr.lastIndexOf("@");
	                var localPart = toAddr.slice(0, atIdx).replace(PCT_ENCODED, decodeUnreserved).replace(PCT_ENCODED, toUpperCase).replace(NOT_LOCAL_PART, pctEncChar);
	                var domain = toAddr.slice(atIdx + 1);
	                //convert IDN via punycode
	                try {
	                    domain = !options.iri ? punycode.toASCII(unescapeComponent(domain, options).toLowerCase()) : punycode.toUnicode(domain);
	                } catch (e) {
	                    components.error = components.error || "Email address's domain name can not be converted to " + (!options.iri ? "ASCII" : "Unicode") + " via punycode: " + e;
	                }
	                to[x] = localPart + "@" + domain;
	            }
	            components.path = to.join(",");
	        }
	        var headers = mailtoComponents.headers = mailtoComponents.headers || {};
	        if (mailtoComponents.subject) headers["subject"] = mailtoComponents.subject;
	        if (mailtoComponents.body) headers["body"] = mailtoComponents.body;
	        var fields = [];
	        for (var name in headers) {
	            if (headers[name] !== O[name]) {
	                fields.push(name.replace(PCT_ENCODED, decodeUnreserved).replace(PCT_ENCODED, toUpperCase).replace(NOT_HFNAME, pctEncChar) + "=" + headers[name].replace(PCT_ENCODED, decodeUnreserved).replace(PCT_ENCODED, toUpperCase).replace(NOT_HFVALUE, pctEncChar));
	            }
	        }
	        if (fields.length) {
	            components.query = fields.join("&");
	        }
	        return components;
	    }
	};

	var URN_PARSE = /^([^\:]+)\:(.*)/;
	//RFC 2141
	var handler$5 = {
	    scheme: "urn",
	    parse: function parse$$1(components, options) {
	        var matches = components.path && components.path.match(URN_PARSE);
	        var urnComponents = components;
	        if (matches) {
	            var scheme = options.scheme || urnComponents.scheme || "urn";
	            var nid = matches[1].toLowerCase();
	            var nss = matches[2];
	            var urnScheme = scheme + ":" + (options.nid || nid);
	            var schemeHandler = SCHEMES[urnScheme];
	            urnComponents.nid = nid;
	            urnComponents.nss = nss;
	            urnComponents.path = undefined;
	            if (schemeHandler) {
	                urnComponents = schemeHandler.parse(urnComponents, options);
	            }
	        } else {
	            urnComponents.error = urnComponents.error || "URN can not be parsed.";
	        }
	        return urnComponents;
	    },
	    serialize: function serialize$$1(urnComponents, options) {
	        var scheme = options.scheme || urnComponents.scheme || "urn";
	        var nid = urnComponents.nid;
	        var urnScheme = scheme + ":" + (options.nid || nid);
	        var schemeHandler = SCHEMES[urnScheme];
	        if (schemeHandler) {
	            urnComponents = schemeHandler.serialize(urnComponents, options);
	        }
	        var uriComponents = urnComponents;
	        var nss = urnComponents.nss;
	        uriComponents.path = (nid || options.nid) + ":" + nss;
	        return uriComponents;
	    }
	};

	var UUID = /^[0-9A-Fa-f]{8}(?:\-[0-9A-Fa-f]{4}){3}\-[0-9A-Fa-f]{12}$/;
	//RFC 4122
	var handler$6 = {
	    scheme: "urn:uuid",
	    parse: function parse(urnComponents, options) {
	        var uuidComponents = urnComponents;
	        uuidComponents.uuid = uuidComponents.nss;
	        uuidComponents.nss = undefined;
	        if (!options.tolerant && (!uuidComponents.uuid || !uuidComponents.uuid.match(UUID))) {
	            uuidComponents.error = uuidComponents.error || "UUID is not valid.";
	        }
	        return uuidComponents;
	    },
	    serialize: function serialize(uuidComponents, options) {
	        var urnComponents = uuidComponents;
	        //normalize UUID
	        urnComponents.nss = (uuidComponents.uuid || "").toLowerCase();
	        return urnComponents;
	    }
	};

	SCHEMES[handler.scheme] = handler;
	SCHEMES[handler$1.scheme] = handler$1;
	SCHEMES[handler$2.scheme] = handler$2;
	SCHEMES[handler$3.scheme] = handler$3;
	SCHEMES[handler$4.scheme] = handler$4;
	SCHEMES[handler$5.scheme] = handler$5;
	SCHEMES[handler$6.scheme] = handler$6;

	exports.SCHEMES = SCHEMES;
	exports.pctEncChar = pctEncChar;
	exports.pctDecChars = pctDecChars;
	exports.parse = parse;
	exports.removeDotSegments = removeDotSegments;
	exports.serialize = serialize;
	exports.resolveComponents = resolveComponents;
	exports.resolve = resolve;
	exports.normalize = normalize;
	exports.equal = equal;
	exports.escapeComponent = escapeComponent;
	exports.unescapeComponent = unescapeComponent;

	Object.defineProperty(exports, '__esModule', { value: true });

	})));
	
} (uri_all, uri_all.exports));

var uri_allExports = uri_all.exports;

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.validateHostedConfig = exports.powerSyncHostedConfig = exports.jwks = exports.jwk = exports.jwkHmac = exports.jwkRSA = exports.anyConnection = exports.hostedDemoConnection = exports.hostedPostgresConnection = exports.isHostedSecretValue = exports.hostedSecret = exports.hostedSecretRef = exports.hostedSecretValue = void 0;
	const t = __importStar(dist$4);
	const urijs = __importStar(uri_allExports);
	exports.hostedSecretValue = t.object({
	    secret: t.string
	});
	exports.hostedSecretRef = t.object({
	    secret_ref: t.string
	});
	exports.hostedSecret = exports.hostedSecretValue.or(exports.hostedSecretRef);
	function isHostedSecretValue(v) {
	    return typeof v.secret == 'string';
	}
	exports.isHostedSecretValue = isHostedSecretValue;
	exports.hostedPostgresConnection = t.object({
	    type: t.literal('postgresql'),
	    /** Descriptive name */
	    name: t.string.optional(),
	    /** Unique identifier for the connection - optional when a single connection is present. */
	    id: t.string.optional(),
	    /** Tag used as reference in sync rules. Defaults to "default". Does not have to be unique. */
	    tag: t.string.optional(),
	    uri: t.string.optional(),
	    hostname: t.string.optional(),
	    port: t.number.optional(),
	    username: t.string.optional(),
	    password: exports.hostedSecret.optional(),
	    database: t.string.optional(),
	    /** Defaults to verify-full */
	    sslmode: t.literal('verify-full').or(t.literal('verify-ca')).optional(),
	    /** Required for verify-ca, optional for verify-full */
	    cacert: t.string.optional(),
	    /** For mutual TLS */
	    client_certificate: t.string.optional(),
	    client_private_key: exports.hostedSecret.optional(),
	    /** Expose execute-sql */
	    debug_api: t.boolean.optional()
	});
	exports.hostedDemoConnection = t.object({
	    type: t.literal('postgresql-demo'),
	    tag: t.string.optional()
	});
	exports.anyConnection = exports.hostedPostgresConnection.or(exports.hostedDemoConnection);
	exports.jwkRSA = t.object({
	    kty: t.literal('RSA'),
	    kid: t.string,
	    n: t.string,
	    e: t.string,
	    alg: t.literal('RS256').or(t.literal('RS384')).or(t.literal('RS512')).optional(),
	    use: t.string.optional()
	});
	exports.jwkHmac = t.object({
	    kty: t.literal('oct'),
	    kid: t.string,
	    k: exports.hostedSecret,
	    alg: t.literal('HS256').or(t.literal('HS384')).or(t.literal('HS512')),
	    use: t.string.optional()
	});
	exports.jwk = t.union(exports.jwkRSA, exports.jwkHmac);
	exports.jwks = t.object({
	    keys: t.array(exports.jwk)
	});
	exports.powerSyncHostedConfig = t.object({
	    /** 'us' or 'eu' */
	    region: t.string,
	    replication: t
	        .object({
	        connections: t.array(exports.anyConnection).optional()
	    })
	        .optional(),
	    dev: t
	        .object({
	        demo_auth: t.boolean.optional(),
	        demo_password: exports.hostedSecret.optional(),
	        crud_api: t.boolean.optional(),
	        demo_client: t.boolean.optional()
	    })
	        .optional(),
	    client_auth: t
	        .object({
	        jwks_uri: t.string.optional(),
	        jwks: exports.jwks.optional(),
	        supabase: t.boolean.optional(),
	        additional_audiences: t.array(t.string).optional(),
	        allow_temporary_tokens: t.boolean.optional()
	    })
	        .optional(),
	    api: t
	        .object({
	        tokens: t.array(exports.hostedSecret).optional()
	    })
	        .optional()
	});
	/**
	 * Validate config.
	 *
	 * This assumes it already matches the PowerSyncHostedConfig schema,
	 * we just run some additional validations.
	 */
	function validateHostedConfig(config) {
	    const jwks_uri = config.client_auth?.jwks_uri;
	    if (jwks_uri != null) {
	        const uri = urijs.parse(jwks_uri);
	        if (uri.scheme != 'https') {
	            throw new Error(`Only https URLs are supported for JWKS`);
	        }
	    }
	}
	exports.validateHostedConfig = validateHostedConfig;
	
} (HostedConfig));

var dist$3 = {};

var PowerSyncConfig = {};

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.powerSyncConfig = exports.storageConfig = exports.strictJwks = exports.jwkHmac = exports.jwkRSA = exports.postgresConnection = exports.portParser = void 0;
	const t = __importStar(dist$4);
	/**
	 * Users might specify ports as strings if using YAML custom tag environment substitutions
	 */
	const portCodec = t.codec('Port', (value) => value, (value) => (typeof value == 'number' ? value : parseInt(value)));
	/**
	 * This gets used whenever generating a JSON schema
	 */
	exports.portParser = {
	    tag: portCodec._tag,
	    parse: () => ({
	        anyOf: [{ type: 'number' }, { type: 'string' }]
	    })
	};
	exports.postgresConnection = t.object({
	    type: t.literal('postgresql'),
	    /** Unique identifier for the connection - optional when a single connection is present. */
	    id: t.string.optional(),
	    /** Tag used as reference in sync rules. Defaults to "default". Does not have to be unique. */
	    tag: t.string.optional(),
	    uri: t.string.optional(),
	    hostname: t.string.optional(),
	    port: portCodec.optional(),
	    username: t.string.optional(),
	    password: t.string.optional(),
	    database: t.string.optional(),
	    /** Defaults to verify-full */
	    sslmode: t.literal('verify-full').or(t.literal('verify-ca')).or(t.literal('disable')).optional(),
	    /** Required for verify-ca, optional for verify-full */
	    cacert: t.string.optional(),
	    client_certificate: t.string.optional(),
	    client_private_key: t.string.optional(),
	    /** Expose database credentials */
	    demo_database: t.boolean.optional(),
	    /** Expose "execute-sql" */
	    debug_api: t.boolean.optional(),
	    /**
	     * Prefix for the slot name. Defaults to "powersync_"
	     */
	    slot_name_prefix: t.string.optional()
	});
	exports.jwkRSA = t.object({
	    kty: t.literal('RSA'),
	    kid: t.string,
	    n: t.string,
	    e: t.string,
	    alg: t.literal('RS256').or(t.literal('RS384')).or(t.literal('RS512')).optional(),
	    use: t.string.optional()
	});
	exports.jwkHmac = t.object({
	    kty: t.literal('oct'),
	    /**
	     * undefined kid indicates it can match any JWT, with or without a kid.
	     * Use a kid wherever possible.
	     */
	    kid: t.string.optional(),
	    k: t.string,
	    alg: t.literal('HS256').or(t.literal('HS384')).or(t.literal('HS512')),
	    use: t.string.optional()
	});
	const jwk = t.union(exports.jwkRSA, exports.jwkHmac);
	exports.strictJwks = t.object({
	    keys: t.array(jwk)
	});
	exports.storageConfig = t.object({
	    type: t.literal('mongodb'),
	    uri: t.string,
	    database: t.string.optional(),
	    username: t.string.optional(),
	    password: t.string.optional()
	});
	exports.powerSyncConfig = t.object({
	    replication: t
	        .object({
	        connections: t.array(exports.postgresConnection).optional()
	    })
	        .optional(),
	    dev: t
	        .object({
	        demo_auth: t.boolean.optional(),
	        demo_password: t.string.optional(),
	        crud_api: t.boolean.optional(),
	        demo_client: t.boolean.optional()
	    })
	        .optional(),
	    client_auth: t
	        .object({
	        jwks_uri: t.string.or(t.array(t.string)).optional(),
	        block_local_jwks: t.boolean.optional(),
	        jwks: exports.strictJwks.optional(),
	        supabase: t.boolean.optional(),
	        audience: t.array(t.string).optional()
	    })
	        .optional(),
	    api: t
	        .object({
	        tokens: t.array(t.string).optional()
	    })
	        .optional(),
	    storage: exports.storageConfig,
	    port: portCodec.optional(),
	    sync_rules: t
	        .object({
	        path: t.string.optional(),
	        content: t.string.optional()
	    })
	        .optional(),
	    metadata: t.record(t.string).optional(),
	    migrations: t
	        .object({
	        disable_auto_migration: t.boolean.optional()
	    })
	        .optional(),
	    telemetry: t.object({
	        disable_telemetry_sharing: t.boolean,
	        internal_service_endpoint: t.string.optional()
	    }).optional()
	});
	
} (PowerSyncConfig));

var definitions$3 = {};

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.InstanceSchema = exports.DatabaseSchema = exports.ConnectionStatus = exports.SyncRulesStatus = exports.TableInfo = exports.ReplicationError = void 0;
	const t = __importStar(dist$4);
	exports.ReplicationError = t.object({
	    /** Warning: Could indicate an issue. Fatal: Prevents replicating. */
	    level: t.literal('warning').or(t.literal('fatal')),
	    message: t.string
	});
	exports.TableInfo = t.object({
	    schema: t.string,
	    name: t.string,
	    /** Specified if this table is part of a wildcard pattern. */
	    pattern: t.string.optional(),
	    /** Usually just ['id'] */
	    replication_id: t.array(t.string),
	    /** Used in data replication */
	    data_queries: t.boolean,
	    /** Used for parameter query replication */
	    parameter_queries: t.boolean,
	    /** Also included in the global errors array. */
	    errors: t.array(exports.ReplicationError)
	});
	exports.SyncRulesStatus = t.object({
	    content: t.string.optional(),
	    connections: t.array(t.object({
	        id: t.string,
	        tag: t.string,
	        /**
	         * PostgreSQL logical replication slot name.
	         */
	        slot_name: t.string,
	        /**
	         * Once initial replication is done, this moves over to
	         * logical replication.
	         */
	        initial_replication_done: t.boolean,
	        /**
	         * The last LSN that has been replicated. This may be in the middle of a transaction.
	         */
	        last_lsn: t.string.optional(),
	        /**
	         * The last time any replication activity was recorded.
	         *
	         * This is typically (but not always) updated together with last_lsn
	         */
	        last_keepalive_ts: t.string.optional(),
	        /**
	         * The last time we created a new checkpoint. In other words, a transaction
	         * was successfully replicated.
	         */
	        last_checkpoint_ts: t.string.optional(),
	        /** Replication lag in bytes. undefined if we cannot calculate this. */
	        replication_lag_bytes: t.number.optional(),
	        tables: t.array(exports.TableInfo)
	    })),
	    /** Sync-rule-level errors */
	    errors: t.array(exports.ReplicationError)
	});
	exports.ConnectionStatus = t.object({
	    id: t.string,
	    postgres_uri: t.string,
	    connected: t.boolean,
	    /** Connection-level errors */
	    errors: t.array(exports.ReplicationError)
	});
	exports.DatabaseSchema = t.object({
	    name: t.string,
	    tables: t.array(t.object({
	        name: t.string,
	        columns: t.array(t.object({
	            name: t.string,
	            /**
	             * Full type name, e.g. "character varying(255)[]"
	             */
	            type: t.string,
	            /**
	             * Internal postgres type, e.g. "varchar[]".
	             */
	            pg_type: t.string
	        }))
	    }))
	});
	exports.InstanceSchema = t.object({
	    connections: t.array(t.object({
	        id: t.string.optional(),
	        tag: t.string,
	        schemas: t.array(exports.DatabaseSchema)
	    }))
	});
	
} (definitions$3));

var normalize = {};

var __createBinding$9 = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$9 = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$9 = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$9(result, mod, k);
    __setModuleDefault$9(result, mod);
    return result;
};
Object.defineProperty(normalize, "__esModule", { value: true });
normalize.baseUri = normalize.validatePort = normalize.normalizeConnection = void 0;
const urijs = __importStar$9(uri_allExports);
/**
 * Validate and normalize connection options.
 *
 * Returns destructured options.
 */
function normalizeConnection(options) {
    let uri;
    if (options.uri) {
        uri = urijs.parse(options.uri);
        if (uri.scheme != 'postgresql' && uri.scheme != 'postgres') {
            `Invalid URI - protocol must be postgresql, got ${uri.scheme}`;
        }
        else if (uri.scheme != 'postgresql') {
            uri.scheme = 'postgresql';
        }
    }
    else {
        uri = urijs.parse('postgresql:///');
    }
    const hostname = options.hostname ?? uri.host ?? '';
    const port = validatePort(options.port ?? uri.port ?? 5432);
    const database = options.database ?? uri.path?.substring(1) ?? '';
    const [uri_username, uri_password] = (uri.userinfo ?? '').split(':');
    const username = options.username ?? uri_username ?? '';
    const password = options.password ?? uri_password ?? '';
    const sslmode = options.sslmode ?? 'verify-full'; // Configuration not supported via URI
    const cacert = options.cacert;
    if (sslmode == 'verify-ca' && cacert == null) {
        throw new Error('Explicit cacert is required for sslmode=verify-ca');
    }
    if (hostname == '') {
        throw new Error(`hostname required`);
    }
    if (username == '') {
        throw new Error(`username required`);
    }
    if (password == '') {
        throw new Error(`password required`);
    }
    if (database == '') {
        throw new Error(`database required`);
    }
    return {
        id: options.id ?? 'default',
        tag: options.tag ?? 'default',
        hostname,
        port,
        database,
        username,
        password,
        sslmode,
        cacert,
        client_certificate: options.client_certificate ?? undefined,
        client_private_key: options.client_private_key ?? undefined
    };
}
normalize.normalizeConnection = normalizeConnection;
/**
 * Check whether the port is in a "safe" range.
 *
 * We do not support connecting to "privileged" ports.
 */
function validatePort(port) {
    if (typeof port == 'string') {
        port = parseInt(port);
    }
    if (port >= 1024 && port <= 49151) {
        return port;
    }
    else {
        throw new Error(`Port ${port} not supported`);
    }
}
normalize.validatePort = validatePort;
/**
 * Construct a postgres URI, without username, password or ssl options.
 *
 * Only contains hostname, port, database.
 */
function baseUri(options) {
    return `postgresql://${options.hostname}:${options.port}/${options.database}`;
}
normalize.baseUri = baseUri;

var routes$1 = {};

var __createBinding$8 = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$8 = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$8 = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$8(result, mod, k);
    __setModuleDefault$8(result, mod);
    return result;
};
Object.defineProperty(routes$1, "__esModule", { value: true });
routes$1.ValidateResponse = routes$1.ValidateRequest = routes$1.ReprocessResponse = routes$1.ReprocessRequest = routes$1.DiagnosticsResponse = routes$1.DiagnosticsRequest = routes$1.DemoCredentialsResponse = routes$1.DemoCredentialsRequest = routes$1.ExecuteSqlResponse = routes$1.ExecuteSqlRequest = routes$1.GetSchemaResponse = routes$1.GetSchemaRequest = void 0;
const t$7 = __importStar$8(dist$4);
const definitions_1 = definitions$3;
routes$1.GetSchemaRequest = t$7.object({});
routes$1.GetSchemaResponse = definitions_1.InstanceSchema;
routes$1.ExecuteSqlRequest = t$7.object({
    connection_id: t$7.string.optional(),
    sql: t$7.object({
        query: t$7.string,
        args: t$7.array(t$7.string.or(t$7.number).or(t$7.boolean))
    })
});
routes$1.ExecuteSqlResponse = t$7.object({
    success: t$7.boolean,
    results: t$7.object({
        columns: t$7.array(t$7.string),
        rows: t$7.array(t$7.array(t$7.string.or(t$7.number).or(t$7.boolean).or(t$7.Null)))
    }),
    /** Set if success = false */
    error: t$7.string.optional()
});
routes$1.DemoCredentialsRequest = t$7.object({
    connection_id: t$7.string.optional()
});
routes$1.DemoCredentialsResponse = t$7.object({
    /** If this instance has a demo database, this contains the credentials. */
    credentials: t$7
        .object({
        postgres_uri: t$7.string
    })
        .optional()
});
routes$1.DiagnosticsRequest = t$7.object({
    sync_rules_content: t$7.boolean.optional()
});
routes$1.DiagnosticsResponse = t$7.object({
    /**
     * Connection-level errors are listed here.
     */
    connections: t$7.array(definitions_1.ConnectionStatus),
    /**
     * Present if there are fully-deployed sync rules.
     *
     * Sync-rule-level errors are listed here.
     */
    active_sync_rules: definitions_1.SyncRulesStatus.optional(),
    /**
     * Present if there are sync rules in the process of being deployed / initial replication.
     *
     * Once initial replication is done, this will  be placed in `active_sync_rules`.
     *
     * Sync-rule-level errors are listed here.
     */
    deploying_sync_rules: definitions_1.SyncRulesStatus.optional()
});
routes$1.ReprocessRequest = t$7.object({});
routes$1.ReprocessResponse = t$7.object({
    connections: t$7.array(t$7.object({
        id: t$7.string.optional(),
        tag: t$7.string,
        slot_name: t$7.string
    }))
});
routes$1.ValidateRequest = t$7.object({
    sync_rules: t$7.string
});
routes$1.ValidateResponse = definitions_1.SyncRulesStatus;

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.internal_routes = exports.configFile = void 0;
	exports.configFile = __importStar(PowerSyncConfig);
	__exportStar(definitions$3, exports);
	__exportStar(normalize, exports);
	exports.internal_routes = __importStar(routes$1);
	
} (dist$3));

var routes = {};

var definitions$2 = {};

var __createBinding$7 = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$7 = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$7 = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$7(result, mod, k);
    __setModuleDefault$7(result, mod);
    return result;
};
Object.defineProperty(definitions$2, "__esModule", { value: true });
definitions$2.AppId = definitions$2.InstanceId = void 0;
const t$6 = __importStar$7(dist$4);
// Manage instances
definitions$2.InstanceId = t$6.object({
    org_id: t$6.string,
    app_id: t$6.string,
    id: t$6.string
});
definitions$2.AppId = t$6.object({
    org_id: t$6.string,
    app_id: t$6.string
});

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.GenerateDevTokenResponse = exports.GenerateDevTokenRequest = exports.ListRegionsResponse = exports.ListRegionsRequest = exports.InstanceDiagnosticsResponse = exports.InstanceDiagnosticsRequest = exports.ReprocessSyncRulesResponse = exports.ReprocessSyncRulesRequest = exports.ValidateSyncRulesResponse = exports.ValidateSyncRulesRequest = exports.ExecuteSqlResponse = exports.ExecuteSqlRequest = exports.GetSchemaResponse = exports.GetSchemaRequest = exports.TestPostgresConnectionResponse = exports.TestPostgresConnectionRequest = exports.DEV_ROUTES = exports.CompactInstanceResponse = exports.CompactInstanceRequest = exports.DeactivateInstanceResponse = exports.DeactivateInstanceRequest = exports.DestroyInstanceResponse = exports.DestroyInstanceRequest = exports.InstanceStatusResponse = exports.InstanceDeployOperation = exports.InstanceStatusRequest = exports.InstanceConfigResponse = exports.InstanceConfigRequest = exports.DeployInstanceResponse = exports.DeployInstanceRequest = exports.CreateInstanceResponse = exports.CreateInstanceRequest = exports.ListInstancesResponse = exports.ListInstancesRequest = exports.MANAGE_ROUTES = exports.GENERAL_ROUTES = void 0;
	const service_types_1 = dist$3;
	const t = __importStar(dist$4);
	const HostedConfig_1 = HostedConfig;
	const definitions_1 = definitions$2;
	(function (GENERAL_ROUTES) {
	    /** GET */
	    GENERAL_ROUTES["LIST_REGIONS"] = "/api/v1/regions";
	})(exports.GENERAL_ROUTES || (exports.GENERAL_ROUTES = {}));
	(function (MANAGE_ROUTES) {
	    MANAGE_ROUTES["LIST"] = "/api/v1/instances/list";
	    MANAGE_ROUTES["CREATE"] = "/api/v1/instances/create";
	    MANAGE_ROUTES["DEPLOY"] = "/api/v1/instances/deploy";
	    MANAGE_ROUTES["DESTROY"] = "/api/v1/instances/destroy";
	    MANAGE_ROUTES["DEACTIVATE"] = "/api/v1/instances/deactivate";
	    MANAGE_ROUTES["COMPACT"] = "/api/v1/instances/compact";
	    MANAGE_ROUTES["CONFIG"] = "/api/v1/instances/config";
	    MANAGE_ROUTES["STATUS"] = "/api/v1/instances/status";
	    MANAGE_ROUTES["DIAGNOSTICS"] = "/api/v1/instances/diagnostics";
	})(exports.MANAGE_ROUTES || (exports.MANAGE_ROUTES = {}));
	// POST /api/v1/instances/list
	exports.ListInstancesRequest = t.object({
	    org_id: t.string,
	    app_id: t.string
	});
	exports.ListInstancesResponse = t.object({
	    instances: t.array(t.object({
	        id: t.string,
	        name: t.string
	    }))
	});
	// POST /api/v1/instances/create
	exports.CreateInstanceRequest = t.object({
	    org_id: t.string,
	    app_id: t.string,
	    name: t.string
	});
	exports.CreateInstanceResponse = t.object({
	    id: t.string
	});
	// POST /api/instances/deploy
	exports.DeployInstanceRequest = definitions_1.InstanceId.and(t.object({
	    name: t.string.optional(),
	    config: HostedConfig_1.powerSyncHostedConfig,
	    sync_rules: t.string.optional()
	}));
	exports.DeployInstanceResponse = t.object({
	    id: t.string,
	    operation_id: t.string
	});
	// POST /api/v1/instances/config
	exports.InstanceConfigRequest = definitions_1.InstanceId;
	exports.InstanceConfigResponse = t.object({
	    id: t.string,
	    name: t.string,
	    config: HostedConfig_1.powerSyncHostedConfig.optional(),
	    sync_rules: t.string.optional()
	});
	// POST /api/v1/instances/status
	// Get provisioning status. Once provisioned, other requests can be used for additional
	// diagnostics.
	exports.InstanceStatusRequest = definitions_1.InstanceId;
	exports.InstanceDeployOperation = t.object({
	    id: t.string,
	    type: t.literal('up').or(t.literal('down')),
	    status: t.literal('pending').or(t.literal('running')).or(t.literal('failed')).or(t.literal('completed')),
	    created_at: t.string,
	    started_at: t.string.optional(),
	    finished_at: t.string.optional(),
	    system_upgrade: t.boolean.optional(),
	    teardown: t.boolean.optional(),
	    compact: t.boolean.optional(),
	    user_id: t.string.optional()
	});
	exports.InstanceStatusResponse = t.object({
	    id: t.string,
	    /** True if provisioned at least once, and should therefore be running. */
	    provisioned: t.boolean,
	    operations: t.array(exports.InstanceDeployOperation),
	    instance_url: t.string.optional()
	});
	// POST /api/v1/instances/destroy
	exports.DestroyInstanceRequest = definitions_1.InstanceId;
	exports.DestroyInstanceResponse = t.object({
	    id: t.string,
	    operation_id: t.string.optional()
	});
	// POST /api/v1/instances/deactivate
	exports.DeactivateInstanceRequest = definitions_1.InstanceId;
	exports.DeactivateInstanceResponse = t.object({
	    id: t.string,
	    operation_id: t.string.optional()
	});
	// POST /api/v1/instances/compact
	exports.CompactInstanceRequest = definitions_1.InstanceId;
	exports.CompactInstanceResponse = t.object({
	    id: t.string,
	    operation_id: t.string.optional()
	});
	(function (DEV_ROUTES) {
	    DEV_ROUTES["EXECUTE_SQL"] = "/api/v1/instances/dev/execute-sql";
	    DEV_ROUTES["GET_SCHEMA"] = "/api/v1/instances/dev/schema";
	    DEV_ROUTES["VALIDATE_SYNC_RULES"] = "/api/v1/instances/dev/validate-sync-rules";
	    DEV_ROUTES["REPROCESS_SYNC_RULES"] = "/api/v1/instances/dev/reprocess-sync-rules";
	    DEV_ROUTES["GENERATE_DEV_TOKEN"] = "/api/v1/instances/dev/generate-dev-token";
	    DEV_ROUTES["TEST_CONNECTION"] = "/api/v1/connections/test";
	})(exports.DEV_ROUTES || (exports.DEV_ROUTES = {}));
	// POST /api/v1/connections/test
	// Test a connection without deploying
	exports.TestPostgresConnectionRequest = t.object({
	    org_id: t.string,
	    app_id: t.string,
	    id: t.string.optional(),
	    connection: HostedConfig_1.hostedPostgresConnection
	});
	exports.TestPostgresConnectionResponse = t.object({
	    /** If false, check the fields below. */
	    success: t.boolean,
	    connection: t.object({
	        /** If false, check the fields below. */
	        success: t.boolean,
	        /** Can open a TCP connection. */
	        reachable: t.boolean,
	        /**
	         * Did TLS connection work? Only set if reachable.
	         */
	        tls_valid: t.boolean.optional(),
	        /** If TLS connection failed, use this CA list. */
	        suggested_cacert: t.string.optional(),
	        /** verify-full or verify-ca */
	        suggested_sslmode: t.string.optional(),
	        /** Only set if reachable and tls_valid */
	        authenticated: t.boolean.optional()
	    }),
	    /**
	     * Indicates potential configuration issues.
	     *
	     * Only present if the connection succeeded.
	     */
	    configuration: t
	        .object({
	        /** If false, check the fields below. */
	        success: t.boolean,
	        /** True if no issues detected. */
	        wal_valid: t.boolean.optional(),
	        /** True if publication is configured correctly. */
	        publication_valid: t.boolean.optional()
	    })
	        .optional(),
	    /**
	     * A human-readable error message, always set if success = false.
	     *
	     * Use as a fallback if the specific reason is not clear from other response fields.
	     */
	    error: t.string.optional()
	});
	// POST /api/instances/dev/schema
	// Only works if the instance is already provisioned.
	exports.GetSchemaRequest = definitions_1.InstanceId;
	exports.GetSchemaResponse = service_types_1.internal_routes.GetSchemaResponse;
	// POST /api/v1/instances/dev/execute-sql
	// Only works if the instance is already provisioned.
	exports.ExecuteSqlRequest = definitions_1.InstanceId.and(service_types_1.internal_routes.ExecuteSqlRequest);
	exports.ExecuteSqlResponse = service_types_1.internal_routes.ExecuteSqlResponse;
	// POST /api/v1/instances/dev/validate-sync-rules
	// Only works if the instance is already provisioned.
	exports.ValidateSyncRulesRequest = definitions_1.InstanceId.and(service_types_1.internal_routes.ValidateRequest);
	exports.ValidateSyncRulesResponse = service_types_1.internal_routes.ValidateResponse;
	// POST /api/v1/instances/dev/reprocess-sync-rules
	// Only works if the instance is already provisioned.
	exports.ReprocessSyncRulesRequest = definitions_1.InstanceId.and(service_types_1.internal_routes.ReprocessRequest);
	exports.ReprocessSyncRulesResponse = service_types_1.internal_routes.ReprocessResponse;
	// POST /api/v1/instances/diagnostics
	// Get instance diagnostics once provisioned.
	exports.InstanceDiagnosticsRequest = definitions_1.InstanceId.and(service_types_1.internal_routes.DiagnosticsRequest);
	exports.InstanceDiagnosticsResponse = service_types_1.internal_routes.DiagnosticsResponse;
	// GET /api/v1/regions
	// Returns list of regions to whitelist on the database.
	exports.ListRegionsRequest = t.object({});
	/**
	 * For IP whitelisting, we recommend just including IPs from all regions.
	 *
	 * An additional "dev" region is included, with IPs  used for development purposes,
	 * e.g. "test connection".
	 */
	exports.ListRegionsResponse = t.object({
	    regions: t.array(t.object({
	        name: t.string,
	        /** false for "dev" region */
	        deployable: t.boolean,
	        ips: t.array(t.string)
	    }))
	});
	exports.GenerateDevTokenRequest = definitions_1.InstanceId.and(t.object({
	    subject: t.string,
	    expiresInSeconds: t.number
	}));
	exports.GenerateDevTokenResponse = t.object({
	    token: t.string
	});
	
} (routes));

var events$1 = {};

var dist$2 = {};

var definitions$1 = {};

var stackOperations$1 = {};

var dist$1 = {};

var parsers$1 = {};

var codecs$4 = {};

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.FilterProperties = exports.makeQueryFilter = exports.QueryFilter = exports.Resource = exports.Timestamps = exports.ResourceId = exports.ObjectId = exports.date = exports.buffer = void 0;
	const t = __importStar(dist$4);
	const bson = __importStar(require$$1);
	exports.buffer = t.codec('Buffer', (buffer) => {
	    if (!Buffer.isBuffer(buffer)) {
	        throw new t.TransformError([`Expected buffer but got ${typeof buffer}`]);
	    }
	    return buffer.toString('base64');
	}, (buffer) => Buffer.from(buffer, 'base64'));
	exports.date = t.codec('Date', (date) => {
	    if (!(date instanceof Date)) {
	        throw new t.TransformError([`Expected Date but got ${typeof date}`]);
	    }
	    return date.toISOString();
	}, (date) => {
	    const parsed = new Date(date);
	    if (isNaN(parsed.getTime())) {
	        throw new t.TransformError([`Invalid date`]);
	    }
	    return parsed;
	});
	const assertObjectId = (value) => {
	    if (!bson.ObjectId.isValid(value)) {
	        throw new t.TransformError([`Expected an ObjectId but got ${typeof value}`]);
	    }
	};
	exports.ObjectId = t.codec('ObjectId', (id) => {
	    assertObjectId(id);
	    return id.toHexString();
	}, (id) => {
	    assertObjectId(id);
	    return new bson.ObjectId(id);
	});
	const assertObjectWithField = (field, data) => {
	    if (typeof data !== 'object') {
	        throw new t.TransformError([`Expected an object but got ${typeof data}`]);
	    }
	    if (!(field in data)) {
	        throw new t.TransformError([`Expected ${field} to be a member of object`]);
	    }
	};
	exports.ResourceId = t.codec('ResourceId', (data) => {
	    assertObjectWithField('_id', data);
	    return {
	        id: exports.ObjectId.encode(data._id)
	    };
	}, (data) => {
	    assertObjectWithField('id', data);
	    return {
	        _id: exports.ObjectId.decode(data.id)
	    };
	});
	exports.Timestamps = t.object({
	    created_at: exports.date,
	    updated_at: exports.date
	});
	exports.Resource = exports.ResourceId.and(exports.Timestamps);
	exports.QueryFilter = t.object({
	    exists: t.boolean
	});
	const makeQueryFilter = (type) => {
	    return type.or(t.array(type)).or(exports.QueryFilter).optional();
	};
	exports.makeQueryFilter = makeQueryFilter;
	const FilterProperties = (type) => {
	    let codecs = new Map();
	    const addCodecs = (codec) => {
	        if (codec.props?.shape) {
	            Object.keys(codec.props.shape).forEach((k) => {
	                codecs.set(k, codec.props.shape[k]);
	            });
	        }
	    };
	    if (type._tag === t.CodecType.Object) {
	        addCodecs(type);
	    }
	    else if (type._tag === t.CodecType.Intersection) {
	        type.props.codecs.forEach((c) => {
	            addCodecs(c);
	        });
	    }
	    t.object({
	        test: t.string
	    });
	    // @ts-ignore
	    return t.object(Array.from(codecs.keys()).reduce((prev, cur) => {
	        prev[cur] = (0, exports.makeQueryFilter)(codecs.get(cur));
	        return prev;
	    }, {}));
	};
	exports.FilterProperties = FilterProperties; 
} (codecs$4));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.parsers = exports.BufferParser = exports.DateParser = exports.ResourceIdParser = exports.ObjectIdParser = void 0;
	const codecs = __importStar(codecs$4);
	const t = __importStar(dist$4);
	exports.ObjectIdParser = t.createParser(codecs.ObjectId._tag, (_, { target }) => {
	    switch (target) {
	        case t.TransformTarget.Encoded: {
	            return { type: 'string' };
	        }
	        case t.TransformTarget.Decoded: {
	            return { bsonType: 'ObjectId' };
	        }
	    }
	});
	exports.ResourceIdParser = t.createParser(codecs.ResourceId._tag, (_, { target }) => {
	    switch (target) {
	        case t.TransformTarget.Encoded: {
	            return {
	                type: 'object',
	                properties: {
	                    id: { type: 'string' }
	                },
	                required: ['id']
	            };
	        }
	        case t.TransformTarget.Decoded: {
	            return {
	                type: 'object',
	                properties: {
	                    _id: { bsonType: 'ObjectId' }
	                },
	                required: ['_id']
	            };
	        }
	    }
	});
	exports.DateParser = t.createParser(codecs.date._tag, (_, { target }) => {
	    switch (target) {
	        case t.TransformTarget.Encoded: {
	            return { type: 'string' };
	        }
	        case t.TransformTarget.Decoded: {
	            return { nodeType: 'date' };
	        }
	    }
	});
	exports.BufferParser = t.createParser(codecs.buffer._tag, (_, { target }) => {
	    switch (target) {
	        case t.TransformTarget.Encoded: {
	            return { type: 'string' };
	        }
	        case t.TransformTarget.Decoded: {
	            return { nodeType: 'buffer' };
	        }
	    }
	});
	exports.parsers = [exports.ObjectIdParser, exports.ResourceIdParser, exports.DateParser, exports.BufferParser]; 
} (parsers$1));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(parsers$1, exports);
	__exportStar(codecs$4, exports); 
} (dist$1));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.StackOperationResource = exports.StackOperation = exports.StackOperationStatusEnum = exports.StackOperationStatus = exports.ExecutionType = void 0;
	const codecs = __importStar(dist$1);
	const t = __importStar(dist$4);
	var ExecutionType;
	(function (ExecutionType) {
	    ExecutionType["Up"] = "up";
	    ExecutionType["Down"] = "down";
	})(ExecutionType || (exports.ExecutionType = ExecutionType = {}));
	var StackOperationStatus;
	(function (StackOperationStatus) {
	    StackOperationStatus["Pending"] = "pending";
	    StackOperationStatus["Running"] = "running";
	    StackOperationStatus["Completed"] = "completed";
	    StackOperationStatus["Failed"] = "failed";
	})(StackOperationStatus || (exports.StackOperationStatus = StackOperationStatus = {}));
	exports.StackOperationStatusEnum = t.Enum(StackOperationStatus);
	exports.StackOperation = t.object({
	    status: exports.StackOperationStatusEnum,
	    stack_id: codecs.ObjectId,
	    type: t.Enum(ExecutionType),
	    /**
	     * This will be a snapshot of the context and resolved Stack config at the point in time this
	     * operation was created. This is to ensure that the correct data will be used when this
	     * Operation is executed regardless of any changes that may have been made to the Stack
	     * in the meantime.
	     */
	    snapshot: t.object({
	        program_id: codecs.ObjectId,
	        context: t.record(t.string).optional(),
	        config: t.any
	    }),
	    created_at: codecs.date,
	    started_at: codecs.date.optional(),
	    finished_at: codecs.date.optional(),
	    labels: t.record(t.string).optional()
	});
	exports.StackOperationResource = exports.StackOperation.and(codecs.ResourceId);
	
} (stackOperations$1));

var generics = {};

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.Labels = exports.ConfigVariable = exports.SecureValue = void 0;
	const t = __importStar(dist$4);
	exports.SecureValue = t.object({
	    secure: t.string
	});
	exports.ConfigVariable = t.string.or(exports.SecureValue);
	exports.Labels = t.record(t.string);
	
} (generics));

var contexts$1 = {};

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.ContextResource = exports.Context = void 0;
	const codecs = __importStar(dist$1);
	const t = __importStar(dist$4);
	exports.Context = t.object({
	    name: t.string,
	    /**
	     * Context values are encrypted using the configured crypto provider and the resulting
	     * cyphertext is stored as-is in the DB
	     */
	    values: t.record(t.string)
	});
	exports.ContextResource = exports.Context.and(codecs.Resource);
	
} (contexts$1));

var programs$1 = {};

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.ProgramResource = exports.Program = void 0;
	const codecs = __importStar(dist$1);
	const generics$1 = __importStar(generics);
	const t = __importStar(dist$4);
	exports.Program = t.object({
	    name: t.string,
	    version: t.string,
	    labels: generics$1.Labels,
	    schema: t.record(t.any)
	});
	exports.ProgramResource = exports.Program.and(codecs.Resource);
	
} (programs$1));

var stacks$1 = {};

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.StackResource = exports.Stack = exports.ProgramSelector = void 0;
	const codecs = __importStar(dist$1);
	const generics$1 = __importStar(generics);
	const t = __importStar(dist$4);
	exports.ProgramSelector = t.object({
	    name: t.string,
	    labels: generics$1.Labels.optional(),
	    version: t.string.optional()
	});
	exports.Stack = t.object({
	    name: t.string,
	    labels: generics$1.Labels,
	    /**
	     * Both `passphrase` and `secrets` will be encrypted in the database using the configured
	     * crypto provider. At the time of writing, in production, this will be AWS KMS.
	     *
	     * The encrypted cyphertext is stored as-is in the DB
	     */
	    passphrase: t.string,
	    secrets: t.record(t.string),
	    config: t.record(t.any),
	    program_selector: exports.ProgramSelector,
	    context_id: codecs.ObjectId.optional()
	});
	exports.StackResource = exports.Stack.and(codecs.Resource);
	
} (stacks$1));

var locks = {};

var __createBinding$6 = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$6 = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$6 = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$6(result, mod, k);
    __setModuleDefault$6(result, mod);
    return result;
};
Object.defineProperty(locks, "__esModule", { value: true });
locks.Lock = void 0;
const codecs$3 = __importStar$6(dist$1);
const t$5 = __importStar$6(dist$4);
locks.Lock = t$5.object({
    _id: codecs$3.ObjectId,
    name: t$5.string,
    active_lock: t$5
        .object({
        ts: codecs$3.date,
        lock_id: codecs$3.ObjectId
    })
        .optional()
});

var events = {};

var __createBinding$5 = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$5 = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$5 = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$5(result, mod, k);
    __setModuleDefault$5(result, mod);
    return result;
};
Object.defineProperty(events, "__esModule", { value: true });
events.StackOperationChangedEvent = events.StackOperationEventType = events.KronosKafkaTopic = events.KronosEventSchemaVersion = void 0;
const t$4 = __importStar$5(dist$4);
const stack_operations_1 = stackOperations$1;
const micro_codecs_1 = dist$1;
const generics_1 = generics;
var KronosEventSchemaVersion;
(function (KronosEventSchemaVersion) {
    KronosEventSchemaVersion["V1"] = "V1";
})(KronosEventSchemaVersion || (events.KronosEventSchemaVersion = KronosEventSchemaVersion = {}));
var KronosKafkaTopic;
(function (KronosKafkaTopic) {
    KronosKafkaTopic["STACK_OPERATION_EVENTS"] = "kronos-stack-operation-events";
})(KronosKafkaTopic || (events.KronosKafkaTopic = KronosKafkaTopic = {}));
//!---------- RESOURCE EVENTS -----------
var StackOperationEventType;
(function (StackOperationEventType) {
    StackOperationEventType["STACK_OPERATION_CHANGED"] = "STACK_OPERATION.CHANGED";
})(StackOperationEventType || (events.StackOperationEventType = StackOperationEventType = {}));
events.StackOperationChangedEvent = t$4.object({
    type: t$4.Enum(StackOperationEventType),
    payload: t$4.object({
        id: micro_codecs_1.ObjectId,
        stack_id: micro_codecs_1.ObjectId,
        stack_labels: generics_1.Labels,
        status: t$4.Enum(stack_operations_1.StackOperationStatus),
        type: t$4.Enum(stack_operations_1.ExecutionType),
        updated_at: micro_codecs_1.date,
        labels: t$4.record(t$4.string)
    })
});

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(stackOperations$1, exports);
	__exportStar(generics, exports);
	__exportStar(contexts$1, exports);
	__exportStar(programs$1, exports);
	__exportStar(stacks$1, exports);
	__exportStar(locks, exports);
	__exportStar(events, exports);
	
} (definitions$1));

var utils = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.transformSecretsInConfig = exports.isSecureValue = void 0;
	const isSecureValue = (data) => {
	    return 'secure' in data && typeof data.secure === 'string' && Object.keys(data).length === 1;
	};
	exports.isSecureValue = isSecureValue;
	const transformSecretsInConfig = (config, transformer) => {
	    const walk = async (data) => {
	        if (Array.isArray(data)) {
	            return await Promise.all(data.map(walk));
	        }
	        if (typeof data === 'object') {
	            if ((0, exports.isSecureValue)(data)) {
	                return await transformer(data);
	            }
	            const entries = await Promise.all(Object.entries(data).map(async ([key, value]) => {
	                return [key, await walk(value)];
	            }));
	            return Object.fromEntries(entries);
	        }
	        return data;
	    };
	    return walk(config);
	};
	exports.transformSecretsInConfig = transformSecretsInConfig;
	
} (utils));

var api = {};

var stackOperations = {};

var common = {};

var __createBinding$4 = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$4 = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$4 = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$4(result, mod, k);
    __setModuleDefault$4(result, mod);
    return result;
};
Object.defineProperty(common, "__esModule", { value: true });
common.ResourceIDParams = common.PaginationParams = void 0;
const t$3 = __importStar$4(dist$4);
common.PaginationParams = t$3.object({
    cursor: t$3.string.optional(),
    limit: t$3.number.optional()
});
common.ResourceIDParams = t$3.object({
    id: t$3.string
});

var __createBinding$3 = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$3 = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$3 = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$3(result, mod, k);
    __setModuleDefault$3(result, mod);
    return result;
};
Object.defineProperty(stackOperations, "__esModule", { value: true });
stackOperations.ListStackOperationParams = stackOperations.CreateStackOperationParams = void 0;
const common_1$2 = common;
const defs$2 = __importStar$3(definitions$1);
const t$2 = __importStar$3(dist$4);
const codecs$2 = __importStar$3(dist$1);
stackOperations.CreateStackOperationParams = t$2.object({
    stack_id: t$2.string,
    type: t$2.Enum(defs$2.ExecutionType).optional(),
    labels: t$2.record(t$2.string).optional()
});
stackOperations.ListStackOperationParams = common_1$2.PaginationParams.and(t$2.object({
    stack_id: t$2.string.optional(),
    since: codecs$2.date.optional()
}));

var contexts = {};

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.DeleteContextParams = exports.RemoveContextValuesParams = exports.SetContextValuesParams = exports.CreateContextParams = exports.ContextValues = void 0;
	const codecs = __importStar(dist$1);
	const t = __importStar(dist$4);
	exports.ContextValues = t.array(t.object({
	    key: t.string,
	    value: t.string
	}));
	exports.CreateContextParams = t.object({
	    name: t.string,
	    values: exports.ContextValues.optional()
	});
	exports.SetContextValuesParams = t.object({
	    context_id: t.string,
	    values: exports.ContextValues
	});
	exports.RemoveContextValuesParams = t.object({
	    context_id: t.string,
	    keys: t.array(t.string)
	});
	exports.DeleteContextParams = t.object({
	    context_id: codecs.ObjectId
	});
	
} (contexts));

var programs = {};

var __createBinding$2 = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$2 = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$2 = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$2(result, mod, k);
    __setModuleDefault$2(result, mod);
    return result;
};
Object.defineProperty(programs, "__esModule", { value: true });
programs.ListProgramsParams = void 0;
const common_1$1 = common;
const defs$1 = __importStar$2(definitions$1);
const t$1 = __importStar$2(dist$4);
programs.ListProgramsParams = common_1$1.PaginationParams.and(t$1.object({
    name: t$1.string.optional(),
    version: t$1.string.optional(),
    labels: defs$1.Labels.optional()
}));

var stacks = {};

var __createBinding$1 = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault$1 = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar$1 = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding$1(result, mod, k);
    __setModuleDefault$1(result, mod);
    return result;
};
Object.defineProperty(stacks, "__esModule", { value: true });
stacks.UpdateStackOperationStatusParams = stacks.ListStacksParams = stacks.UnsetStackSecretsParams = stacks.SetStackSecretsParams = stacks.UpdateStackParams = stacks.CreateStackParams = void 0;
const codecs$1 = __importStar$1(dist$1);
const common_1 = common;
const defs = __importStar$1(definitions$1);
const t = __importStar$1(dist$4);
stacks.CreateStackParams = t.omit(defs.Stack, ['passphrase']);
stacks.UpdateStackParams = t.omit(t.partial(defs.Stack), ['passphrase', 'secrets']).and(t.object({
    id: codecs$1.ObjectId
}));
stacks.SetStackSecretsParams = t
    .object({
    secrets: t.record(t.string)
})
    .and(codecs$1.ResourceId);
stacks.UnsetStackSecretsParams = t
    .object({
    keys: t.array(t.string)
})
    .and(codecs$1.ResourceId);
stacks.ListStacksParams = common_1.PaginationParams.and(t.object({
    name: t.string.optional(),
    labels: defs.Labels.optional()
}));
stacks.UpdateStackOperationStatusParams = t.object({
    stack_operation_id: t.string,
    status: defs.StackOperationStatusEnum
});

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(stackOperations, exports);
	__exportStar(contexts, exports);
	__exportStar(programs, exports);
	__exportStar(common, exports);
	__exportStar(stacks, exports);
	
} (api));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(definitions$1, exports);
	__exportStar(utils, exports);
	__exportStar(api, exports);
	
} (dist$2));

var dist = {};

var parsers = {};

var codecs = {};

var bson$1 = {};

function isAnyArrayBuffer(value) {
    return ['[object ArrayBuffer]', '[object SharedArrayBuffer]'].includes(Object.prototype.toString.call(value));
}
function isUint8Array(value) {
    return Object.prototype.toString.call(value) === '[object Uint8Array]';
}
function isRegExp(d) {
    return Object.prototype.toString.call(d) === '[object RegExp]';
}
function isMap$1(d) {
    return Object.prototype.toString.call(d) === '[object Map]';
}
function isDate(d) {
    return Object.prototype.toString.call(d) === '[object Date]';
}
function defaultInspect(x, _options) {
    return JSON.stringify(x, (k, v) => {
        if (typeof v === 'bigint') {
            return { $numberLong: `${v}` };
        }
        else if (isMap$1(v)) {
            return Object.fromEntries(v);
        }
        return v;
    });
}
function getStylizeFunction(options) {
    const stylizeExists = options != null &&
        typeof options === 'object' &&
        'stylize' in options &&
        typeof options.stylize === 'function';
    if (stylizeExists) {
        return options.stylize;
    }
}

const BSON_MAJOR_VERSION = 6;
const BSON_INT32_MAX = 0x7fffffff;
const BSON_INT32_MIN = -0x80000000;
const BSON_INT64_MAX = Math.pow(2, 63) - 1;
const BSON_INT64_MIN = -Math.pow(2, 63);
const JS_INT_MAX = Math.pow(2, 53);
const JS_INT_MIN = -Math.pow(2, 53);
const BSON_DATA_NUMBER = 1;
const BSON_DATA_STRING = 2;
const BSON_DATA_OBJECT = 3;
const BSON_DATA_ARRAY = 4;
const BSON_DATA_BINARY = 5;
const BSON_DATA_UNDEFINED = 6;
const BSON_DATA_OID = 7;
const BSON_DATA_BOOLEAN = 8;
const BSON_DATA_DATE = 9;
const BSON_DATA_NULL = 10;
const BSON_DATA_REGEXP = 11;
const BSON_DATA_DBPOINTER = 12;
const BSON_DATA_CODE = 13;
const BSON_DATA_SYMBOL = 14;
const BSON_DATA_CODE_W_SCOPE = 15;
const BSON_DATA_INT = 16;
const BSON_DATA_TIMESTAMP = 17;
const BSON_DATA_LONG = 18;
const BSON_DATA_DECIMAL128 = 19;
const BSON_DATA_MIN_KEY = 0xff;
const BSON_DATA_MAX_KEY = 0x7f;
const BSON_BINARY_SUBTYPE_DEFAULT = 0;
const BSON_BINARY_SUBTYPE_UUID_NEW = 4;
const BSONType = Object.freeze({
    double: 1,
    string: 2,
    object: 3,
    array: 4,
    binData: 5,
    undefined: 6,
    objectId: 7,
    bool: 8,
    date: 9,
    null: 10,
    regex: 11,
    dbPointer: 12,
    javascript: 13,
    symbol: 14,
    javascriptWithScope: 15,
    int: 16,
    timestamp: 17,
    long: 18,
    decimal: 19,
    minKey: -1,
    maxKey: 127
});

class BSONError extends Error {
    get bsonError() {
        return true;
    }
    get name() {
        return 'BSONError';
    }
    constructor(message, options) {
        super(message, options);
    }
    static isBSONError(value) {
        return (value != null &&
            typeof value === 'object' &&
            'bsonError' in value &&
            value.bsonError === true &&
            'name' in value &&
            'message' in value &&
            'stack' in value);
    }
}
class BSONVersionError extends BSONError {
    get name() {
        return 'BSONVersionError';
    }
    constructor() {
        super(`Unsupported BSON version, bson types must be from bson ${BSON_MAJOR_VERSION}.x.x`);
    }
}
class BSONRuntimeError extends BSONError {
    get name() {
        return 'BSONRuntimeError';
    }
    constructor(message) {
        super(message);
    }
}
class BSONOffsetError extends BSONError {
    get name() {
        return 'BSONOffsetError';
    }
    constructor(message, offset, options) {
        super(`${message}. offset: ${offset}`, options);
        this.offset = offset;
    }
}

let TextDecoderFatal;
let TextDecoderNonFatal;
function parseUtf8(buffer, start, end, fatal) {
    if (fatal) {
        TextDecoderFatal ??= new TextDecoder('utf8', { fatal: true });
        try {
            return TextDecoderFatal.decode(buffer.subarray(start, end));
        }
        catch (cause) {
            throw new BSONError('Invalid UTF-8 string in BSON document', { cause });
        }
    }
    TextDecoderNonFatal ??= new TextDecoder('utf8', { fatal: false });
    return TextDecoderNonFatal.decode(buffer.subarray(start, end));
}

function tryReadBasicLatin(uint8array, start, end) {
    if (uint8array.length === 0) {
        return '';
    }
    const stringByteLength = end - start;
    if (stringByteLength === 0) {
        return '';
    }
    if (stringByteLength > 20) {
        return null;
    }
    if (stringByteLength === 1 && uint8array[start] < 128) {
        return String.fromCharCode(uint8array[start]);
    }
    if (stringByteLength === 2 && uint8array[start] < 128 && uint8array[start + 1] < 128) {
        return String.fromCharCode(uint8array[start]) + String.fromCharCode(uint8array[start + 1]);
    }
    if (stringByteLength === 3 &&
        uint8array[start] < 128 &&
        uint8array[start + 1] < 128 &&
        uint8array[start + 2] < 128) {
        return (String.fromCharCode(uint8array[start]) +
            String.fromCharCode(uint8array[start + 1]) +
            String.fromCharCode(uint8array[start + 2]));
    }
    const latinBytes = [];
    for (let i = start; i < end; i++) {
        const byte = uint8array[i];
        if (byte > 127) {
            return null;
        }
        latinBytes.push(byte);
    }
    return String.fromCharCode(...latinBytes);
}
function tryWriteBasicLatin(destination, source, offset) {
    if (source.length === 0)
        return 0;
    if (source.length > 25)
        return null;
    if (destination.length - offset < source.length)
        return null;
    for (let charOffset = 0, destinationOffset = offset; charOffset < source.length; charOffset++, destinationOffset++) {
        const char = source.charCodeAt(charOffset);
        if (char > 127)
            return null;
        destination[destinationOffset] = char;
    }
    return source.length;
}

function nodejsMathRandomBytes(byteLength) {
    return nodeJsByteUtils.fromNumberArray(Array.from({ length: byteLength }, () => Math.floor(Math.random() * 256)));
}
const nodejsRandomBytes = (() => {
    try {
        return require('crypto').randomBytes;
    }
    catch {
        return nodejsMathRandomBytes;
    }
})();
const nodeJsByteUtils = {
    toLocalBufferType(potentialBuffer) {
        if (Buffer.isBuffer(potentialBuffer)) {
            return potentialBuffer;
        }
        if (ArrayBuffer.isView(potentialBuffer)) {
            return Buffer.from(potentialBuffer.buffer, potentialBuffer.byteOffset, potentialBuffer.byteLength);
        }
        const stringTag = potentialBuffer?.[Symbol.toStringTag] ?? Object.prototype.toString.call(potentialBuffer);
        if (stringTag === 'ArrayBuffer' ||
            stringTag === 'SharedArrayBuffer' ||
            stringTag === '[object ArrayBuffer]' ||
            stringTag === '[object SharedArrayBuffer]') {
            return Buffer.from(potentialBuffer);
        }
        throw new BSONError(`Cannot create Buffer from ${String(potentialBuffer)}`);
    },
    allocate(size) {
        return Buffer.alloc(size);
    },
    allocateUnsafe(size) {
        return Buffer.allocUnsafe(size);
    },
    equals(a, b) {
        return nodeJsByteUtils.toLocalBufferType(a).equals(b);
    },
    fromNumberArray(array) {
        return Buffer.from(array);
    },
    fromBase64(base64) {
        return Buffer.from(base64, 'base64');
    },
    toBase64(buffer) {
        return nodeJsByteUtils.toLocalBufferType(buffer).toString('base64');
    },
    fromISO88591(codePoints) {
        return Buffer.from(codePoints, 'binary');
    },
    toISO88591(buffer) {
        return nodeJsByteUtils.toLocalBufferType(buffer).toString('binary');
    },
    fromHex(hex) {
        return Buffer.from(hex, 'hex');
    },
    toHex(buffer) {
        return nodeJsByteUtils.toLocalBufferType(buffer).toString('hex');
    },
    toUTF8(buffer, start, end, fatal) {
        const basicLatin = end - start <= 20 ? tryReadBasicLatin(buffer, start, end) : null;
        if (basicLatin != null) {
            return basicLatin;
        }
        const string = nodeJsByteUtils.toLocalBufferType(buffer).toString('utf8', start, end);
        if (fatal) {
            for (let i = 0; i < string.length; i++) {
                if (string.charCodeAt(i) === 0xfffd) {
                    parseUtf8(buffer, start, end, true);
                    break;
                }
            }
        }
        return string;
    },
    utf8ByteLength(input) {
        return Buffer.byteLength(input, 'utf8');
    },
    encodeUTF8Into(buffer, source, byteOffset) {
        const latinBytesWritten = tryWriteBasicLatin(buffer, source, byteOffset);
        if (latinBytesWritten != null) {
            return latinBytesWritten;
        }
        return nodeJsByteUtils.toLocalBufferType(buffer).write(source, byteOffset, undefined, 'utf8');
    },
    randomBytes: nodejsRandomBytes
};

function isReactNative() {
    const { navigator } = globalThis;
    return typeof navigator === 'object' && navigator.product === 'ReactNative';
}
function webMathRandomBytes(byteLength) {
    if (byteLength < 0) {
        throw new RangeError(`The argument 'byteLength' is invalid. Received ${byteLength}`);
    }
    return webByteUtils.fromNumberArray(Array.from({ length: byteLength }, () => Math.floor(Math.random() * 256)));
}
const webRandomBytes = (() => {
    const { crypto } = globalThis;
    if (crypto != null && typeof crypto.getRandomValues === 'function') {
        return (byteLength) => {
            return crypto.getRandomValues(webByteUtils.allocate(byteLength));
        };
    }
    else {
        if (isReactNative()) {
            const { console } = globalThis;
            console?.warn?.('BSON: For React Native please polyfill crypto.getRandomValues, e.g. using: https://www.npmjs.com/package/react-native-get-random-values.');
        }
        return webMathRandomBytes;
    }
})();
const HEX_DIGIT = /(\d|[a-f])/i;
const webByteUtils = {
    toLocalBufferType(potentialUint8array) {
        const stringTag = potentialUint8array?.[Symbol.toStringTag] ??
            Object.prototype.toString.call(potentialUint8array);
        if (stringTag === 'Uint8Array') {
            return potentialUint8array;
        }
        if (ArrayBuffer.isView(potentialUint8array)) {
            return new Uint8Array(potentialUint8array.buffer.slice(potentialUint8array.byteOffset, potentialUint8array.byteOffset + potentialUint8array.byteLength));
        }
        if (stringTag === 'ArrayBuffer' ||
            stringTag === 'SharedArrayBuffer' ||
            stringTag === '[object ArrayBuffer]' ||
            stringTag === '[object SharedArrayBuffer]') {
            return new Uint8Array(potentialUint8array);
        }
        throw new BSONError(`Cannot make a Uint8Array from ${String(potentialUint8array)}`);
    },
    allocate(size) {
        if (typeof size !== 'number') {
            throw new TypeError(`The "size" argument must be of type number. Received ${String(size)}`);
        }
        return new Uint8Array(size);
    },
    allocateUnsafe(size) {
        return webByteUtils.allocate(size);
    },
    equals(a, b) {
        if (a.byteLength !== b.byteLength) {
            return false;
        }
        for (let i = 0; i < a.byteLength; i++) {
            if (a[i] !== b[i]) {
                return false;
            }
        }
        return true;
    },
    fromNumberArray(array) {
        return Uint8Array.from(array);
    },
    fromBase64(base64) {
        return Uint8Array.from(atob(base64), c => c.charCodeAt(0));
    },
    toBase64(uint8array) {
        return btoa(webByteUtils.toISO88591(uint8array));
    },
    fromISO88591(codePoints) {
        return Uint8Array.from(codePoints, c => c.charCodeAt(0) & 0xff);
    },
    toISO88591(uint8array) {
        return Array.from(Uint16Array.from(uint8array), b => String.fromCharCode(b)).join('');
    },
    fromHex(hex) {
        const evenLengthHex = hex.length % 2 === 0 ? hex : hex.slice(0, hex.length - 1);
        const buffer = [];
        for (let i = 0; i < evenLengthHex.length; i += 2) {
            const firstDigit = evenLengthHex[i];
            const secondDigit = evenLengthHex[i + 1];
            if (!HEX_DIGIT.test(firstDigit)) {
                break;
            }
            if (!HEX_DIGIT.test(secondDigit)) {
                break;
            }
            const hexDigit = Number.parseInt(`${firstDigit}${secondDigit}`, 16);
            buffer.push(hexDigit);
        }
        return Uint8Array.from(buffer);
    },
    toHex(uint8array) {
        return Array.from(uint8array, byte => byte.toString(16).padStart(2, '0')).join('');
    },
    toUTF8(uint8array, start, end, fatal) {
        const basicLatin = end - start <= 20 ? tryReadBasicLatin(uint8array, start, end) : null;
        if (basicLatin != null) {
            return basicLatin;
        }
        return parseUtf8(uint8array, start, end, fatal);
    },
    utf8ByteLength(input) {
        return new TextEncoder().encode(input).byteLength;
    },
    encodeUTF8Into(uint8array, source, byteOffset) {
        const bytes = new TextEncoder().encode(source);
        uint8array.set(bytes, byteOffset);
        return bytes.byteLength;
    },
    randomBytes: webRandomBytes
};

const hasGlobalBuffer = typeof Buffer === 'function' && Buffer.prototype?._isBuffer !== true;
const ByteUtils = hasGlobalBuffer ? nodeJsByteUtils : webByteUtils;

class BSONValue {
    get [Symbol.for('@@mdb.bson.version')]() {
        return BSON_MAJOR_VERSION;
    }
    [Symbol.for('nodejs.util.inspect.custom')](depth, options, inspect) {
        return this.inspect(depth, options, inspect);
    }
}

class Binary extends BSONValue {
    get _bsontype() {
        return 'Binary';
    }
    constructor(buffer, subType) {
        super();
        if (!(buffer == null) &&
            typeof buffer === 'string' &&
            !ArrayBuffer.isView(buffer) &&
            !isAnyArrayBuffer(buffer) &&
            !Array.isArray(buffer)) {
            throw new BSONError('Binary can only be constructed from Uint8Array or number[]');
        }
        this.sub_type = subType ?? Binary.BSON_BINARY_SUBTYPE_DEFAULT;
        if (buffer == null) {
            this.buffer = ByteUtils.allocate(Binary.BUFFER_SIZE);
            this.position = 0;
        }
        else {
            this.buffer = Array.isArray(buffer)
                ? ByteUtils.fromNumberArray(buffer)
                : ByteUtils.toLocalBufferType(buffer);
            this.position = this.buffer.byteLength;
        }
    }
    put(byteValue) {
        if (typeof byteValue === 'string' && byteValue.length !== 1) {
            throw new BSONError('only accepts single character String');
        }
        else if (typeof byteValue !== 'number' && byteValue.length !== 1)
            throw new BSONError('only accepts single character Uint8Array or Array');
        let decodedByte;
        if (typeof byteValue === 'string') {
            decodedByte = byteValue.charCodeAt(0);
        }
        else if (typeof byteValue === 'number') {
            decodedByte = byteValue;
        }
        else {
            decodedByte = byteValue[0];
        }
        if (decodedByte < 0 || decodedByte > 255) {
            throw new BSONError('only accepts number in a valid unsigned byte range 0-255');
        }
        if (this.buffer.byteLength > this.position) {
            this.buffer[this.position++] = decodedByte;
        }
        else {
            const newSpace = ByteUtils.allocate(Binary.BUFFER_SIZE + this.buffer.length);
            newSpace.set(this.buffer, 0);
            this.buffer = newSpace;
            this.buffer[this.position++] = decodedByte;
        }
    }
    write(sequence, offset) {
        offset = typeof offset === 'number' ? offset : this.position;
        if (this.buffer.byteLength < offset + sequence.length) {
            const newSpace = ByteUtils.allocate(this.buffer.byteLength + sequence.length);
            newSpace.set(this.buffer, 0);
            this.buffer = newSpace;
        }
        if (ArrayBuffer.isView(sequence)) {
            this.buffer.set(ByteUtils.toLocalBufferType(sequence), offset);
            this.position =
                offset + sequence.byteLength > this.position ? offset + sequence.length : this.position;
        }
        else if (typeof sequence === 'string') {
            throw new BSONError('input cannot be string');
        }
    }
    read(position, length) {
        length = length && length > 0 ? length : this.position;
        return this.buffer.slice(position, position + length);
    }
    value() {
        return this.buffer.length === this.position
            ? this.buffer
            : this.buffer.subarray(0, this.position);
    }
    length() {
        return this.position;
    }
    toJSON() {
        return ByteUtils.toBase64(this.buffer.subarray(0, this.position));
    }
    toString(encoding) {
        if (encoding === 'hex')
            return ByteUtils.toHex(this.buffer.subarray(0, this.position));
        if (encoding === 'base64')
            return ByteUtils.toBase64(this.buffer.subarray(0, this.position));
        if (encoding === 'utf8' || encoding === 'utf-8')
            return ByteUtils.toUTF8(this.buffer, 0, this.position, false);
        return ByteUtils.toUTF8(this.buffer, 0, this.position, false);
    }
    toExtendedJSON(options) {
        options = options || {};
        const base64String = ByteUtils.toBase64(this.buffer);
        const subType = Number(this.sub_type).toString(16);
        if (options.legacy) {
            return {
                $binary: base64String,
                $type: subType.length === 1 ? '0' + subType : subType
            };
        }
        return {
            $binary: {
                base64: base64String,
                subType: subType.length === 1 ? '0' + subType : subType
            }
        };
    }
    toUUID() {
        if (this.sub_type === Binary.SUBTYPE_UUID) {
            return new UUID(this.buffer.slice(0, this.position));
        }
        throw new BSONError(`Binary sub_type "${this.sub_type}" is not supported for converting to UUID. Only "${Binary.SUBTYPE_UUID}" is currently supported.`);
    }
    static createFromHexString(hex, subType) {
        return new Binary(ByteUtils.fromHex(hex), subType);
    }
    static createFromBase64(base64, subType) {
        return new Binary(ByteUtils.fromBase64(base64), subType);
    }
    static fromExtendedJSON(doc, options) {
        options = options || {};
        let data;
        let type;
        if ('$binary' in doc) {
            if (options.legacy && typeof doc.$binary === 'string' && '$type' in doc) {
                type = doc.$type ? parseInt(doc.$type, 16) : 0;
                data = ByteUtils.fromBase64(doc.$binary);
            }
            else {
                if (typeof doc.$binary !== 'string') {
                    type = doc.$binary.subType ? parseInt(doc.$binary.subType, 16) : 0;
                    data = ByteUtils.fromBase64(doc.$binary.base64);
                }
            }
        }
        else if ('$uuid' in doc) {
            type = 4;
            data = UUID.bytesFromString(doc.$uuid);
        }
        if (!data) {
            throw new BSONError(`Unexpected Binary Extended JSON format ${JSON.stringify(doc)}`);
        }
        return type === BSON_BINARY_SUBTYPE_UUID_NEW ? new UUID(data) : new Binary(data, type);
    }
    inspect(depth, options, inspect) {
        inspect ??= defaultInspect;
        const base64 = ByteUtils.toBase64(this.buffer.subarray(0, this.position));
        const base64Arg = inspect(base64, options);
        const subTypeArg = inspect(this.sub_type, options);
        return `Binary.createFromBase64(${base64Arg}, ${subTypeArg})`;
    }
}
Binary.BSON_BINARY_SUBTYPE_DEFAULT = 0;
Binary.BUFFER_SIZE = 256;
Binary.SUBTYPE_DEFAULT = 0;
Binary.SUBTYPE_FUNCTION = 1;
Binary.SUBTYPE_BYTE_ARRAY = 2;
Binary.SUBTYPE_UUID_OLD = 3;
Binary.SUBTYPE_UUID = 4;
Binary.SUBTYPE_MD5 = 5;
Binary.SUBTYPE_ENCRYPTED = 6;
Binary.SUBTYPE_COLUMN = 7;
Binary.SUBTYPE_SENSITIVE = 8;
Binary.SUBTYPE_USER_DEFINED = 128;
const UUID_BYTE_LENGTH = 16;
const UUID_WITHOUT_DASHES = /^[0-9A-F]{32}$/i;
const UUID_WITH_DASHES = /^[0-9A-F]{8}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{12}$/i;
class UUID extends Binary {
    constructor(input) {
        let bytes;
        if (input == null) {
            bytes = UUID.generate();
        }
        else if (input instanceof UUID) {
            bytes = ByteUtils.toLocalBufferType(new Uint8Array(input.buffer));
        }
        else if (ArrayBuffer.isView(input) && input.byteLength === UUID_BYTE_LENGTH) {
            bytes = ByteUtils.toLocalBufferType(input);
        }
        else if (typeof input === 'string') {
            bytes = UUID.bytesFromString(input);
        }
        else {
            throw new BSONError('Argument passed in UUID constructor must be a UUID, a 16 byte Buffer or a 32/36 character hex string (dashes excluded/included, format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx).');
        }
        super(bytes, BSON_BINARY_SUBTYPE_UUID_NEW);
    }
    get id() {
        return this.buffer;
    }
    set id(value) {
        this.buffer = value;
    }
    toHexString(includeDashes = true) {
        if (includeDashes) {
            return [
                ByteUtils.toHex(this.buffer.subarray(0, 4)),
                ByteUtils.toHex(this.buffer.subarray(4, 6)),
                ByteUtils.toHex(this.buffer.subarray(6, 8)),
                ByteUtils.toHex(this.buffer.subarray(8, 10)),
                ByteUtils.toHex(this.buffer.subarray(10, 16))
            ].join('-');
        }
        return ByteUtils.toHex(this.buffer);
    }
    toString(encoding) {
        if (encoding === 'hex')
            return ByteUtils.toHex(this.id);
        if (encoding === 'base64')
            return ByteUtils.toBase64(this.id);
        return this.toHexString();
    }
    toJSON() {
        return this.toHexString();
    }
    equals(otherId) {
        if (!otherId) {
            return false;
        }
        if (otherId instanceof UUID) {
            return ByteUtils.equals(otherId.id, this.id);
        }
        try {
            return ByteUtils.equals(new UUID(otherId).id, this.id);
        }
        catch {
            return false;
        }
    }
    toBinary() {
        return new Binary(this.id, Binary.SUBTYPE_UUID);
    }
    static generate() {
        const bytes = ByteUtils.randomBytes(UUID_BYTE_LENGTH);
        bytes[6] = (bytes[6] & 0x0f) | 0x40;
        bytes[8] = (bytes[8] & 0x3f) | 0x80;
        return bytes;
    }
    static isValid(input) {
        if (!input) {
            return false;
        }
        if (typeof input === 'string') {
            return UUID.isValidUUIDString(input);
        }
        if (isUint8Array(input)) {
            return input.byteLength === UUID_BYTE_LENGTH;
        }
        return (input._bsontype === 'Binary' &&
            input.sub_type === this.SUBTYPE_UUID &&
            input.buffer.byteLength === 16);
    }
    static createFromHexString(hexString) {
        const buffer = UUID.bytesFromString(hexString);
        return new UUID(buffer);
    }
    static createFromBase64(base64) {
        return new UUID(ByteUtils.fromBase64(base64));
    }
    static bytesFromString(representation) {
        if (!UUID.isValidUUIDString(representation)) {
            throw new BSONError('UUID string representation must be 32 hex digits or canonical hyphenated representation');
        }
        return ByteUtils.fromHex(representation.replace(/-/g, ''));
    }
    static isValidUUIDString(representation) {
        return UUID_WITHOUT_DASHES.test(representation) || UUID_WITH_DASHES.test(representation);
    }
    inspect(depth, options, inspect) {
        inspect ??= defaultInspect;
        return `new UUID(${inspect(this.toHexString(), options)})`;
    }
}

class Code extends BSONValue {
    get _bsontype() {
        return 'Code';
    }
    constructor(code, scope) {
        super();
        this.code = code.toString();
        this.scope = scope ?? null;
    }
    toJSON() {
        if (this.scope != null) {
            return { code: this.code, scope: this.scope };
        }
        return { code: this.code };
    }
    toExtendedJSON() {
        if (this.scope) {
            return { $code: this.code, $scope: this.scope };
        }
        return { $code: this.code };
    }
    static fromExtendedJSON(doc) {
        return new Code(doc.$code, doc.$scope);
    }
    inspect(depth, options, inspect) {
        inspect ??= defaultInspect;
        let parametersString = inspect(this.code, options);
        const multiLineFn = parametersString.includes('\n');
        if (this.scope != null) {
            parametersString += `,${multiLineFn ? '\n' : ' '}${inspect(this.scope, options)}`;
        }
        const endingNewline = multiLineFn && this.scope === null;
        return `new Code(${multiLineFn ? '\n' : ''}${parametersString}${endingNewline ? '\n' : ''})`;
    }
}

function isDBRefLike(value) {
    return (value != null &&
        typeof value === 'object' &&
        '$id' in value &&
        value.$id != null &&
        '$ref' in value &&
        typeof value.$ref === 'string' &&
        (!('$db' in value) || ('$db' in value && typeof value.$db === 'string')));
}
class DBRef extends BSONValue {
    get _bsontype() {
        return 'DBRef';
    }
    constructor(collection, oid, db, fields) {
        super();
        const parts = collection.split('.');
        if (parts.length === 2) {
            db = parts.shift();
            collection = parts.shift();
        }
        this.collection = collection;
        this.oid = oid;
        this.db = db;
        this.fields = fields || {};
    }
    get namespace() {
        return this.collection;
    }
    set namespace(value) {
        this.collection = value;
    }
    toJSON() {
        const o = Object.assign({
            $ref: this.collection,
            $id: this.oid
        }, this.fields);
        if (this.db != null)
            o.$db = this.db;
        return o;
    }
    toExtendedJSON(options) {
        options = options || {};
        let o = {
            $ref: this.collection,
            $id: this.oid
        };
        if (options.legacy) {
            return o;
        }
        if (this.db)
            o.$db = this.db;
        o = Object.assign(o, this.fields);
        return o;
    }
    static fromExtendedJSON(doc) {
        const copy = Object.assign({}, doc);
        delete copy.$ref;
        delete copy.$id;
        delete copy.$db;
        return new DBRef(doc.$ref, doc.$id, doc.$db, copy);
    }
    inspect(depth, options, inspect) {
        inspect ??= defaultInspect;
        const args = [
            inspect(this.namespace, options),
            inspect(this.oid, options),
            ...(this.db ? [inspect(this.db, options)] : []),
            ...(Object.keys(this.fields).length > 0 ? [inspect(this.fields, options)] : [])
        ];
        args[1] = inspect === defaultInspect ? `new ObjectId(${args[1]})` : args[1];
        return `new DBRef(${args.join(', ')})`;
    }
}

function removeLeadingZerosAndExplicitPlus(str) {
    if (str === '') {
        return str;
    }
    let startIndex = 0;
    const isNegative = str[startIndex] === '-';
    const isExplicitlyPositive = str[startIndex] === '+';
    if (isExplicitlyPositive || isNegative) {
        startIndex += 1;
    }
    let foundInsignificantZero = false;
    for (; startIndex < str.length && str[startIndex] === '0'; ++startIndex) {
        foundInsignificantZero = true;
    }
    if (!foundInsignificantZero) {
        return isExplicitlyPositive ? str.slice(1) : str;
    }
    return `${isNegative ? '-' : ''}${str.length === startIndex ? '0' : str.slice(startIndex)}`;
}
function validateStringCharacters(str, radix) {
    radix = radix ?? 10;
    const validCharacters = '0123456789abcdefghijklmnopqrstuvwxyz'.slice(0, radix);
    const regex = new RegExp(`[^-+${validCharacters}]`, 'i');
    return regex.test(str) ? false : str;
}

let wasm = undefined;
try {
    wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;
}
catch {
}
const TWO_PWR_16_DBL = 1 << 16;
const TWO_PWR_24_DBL = 1 << 24;
const TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;
const TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;
const TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;
const INT_CACHE = {};
const UINT_CACHE = {};
const MAX_INT64_STRING_LENGTH = 20;
const DECIMAL_REG_EX = /^(\+?0|(\+|-)?[1-9][0-9]*)$/;
class Long extends BSONValue {
    get _bsontype() {
        return 'Long';
    }
    get __isLong__() {
        return true;
    }
    constructor(lowOrValue = 0, highOrUnsigned, unsigned) {
        super();
        const unsignedBool = typeof highOrUnsigned === 'boolean' ? highOrUnsigned : Boolean(unsigned);
        const high = typeof highOrUnsigned === 'number' ? highOrUnsigned : 0;
        const res = typeof lowOrValue === 'string'
            ? Long.fromString(lowOrValue, unsignedBool)
            : typeof lowOrValue === 'bigint'
                ? Long.fromBigInt(lowOrValue, unsignedBool)
                : { low: lowOrValue | 0, high: high | 0, unsigned: unsignedBool };
        this.low = res.low;
        this.high = res.high;
        this.unsigned = res.unsigned;
    }
    static fromBits(lowBits, highBits, unsigned) {
        return new Long(lowBits, highBits, unsigned);
    }
    static fromInt(value, unsigned) {
        let obj, cachedObj, cache;
        if (unsigned) {
            value >>>= 0;
            if ((cache = 0 <= value && value < 256)) {
                cachedObj = UINT_CACHE[value];
                if (cachedObj)
                    return cachedObj;
            }
            obj = Long.fromBits(value, (value | 0) < 0 ? -1 : 0, true);
            if (cache)
                UINT_CACHE[value] = obj;
            return obj;
        }
        else {
            value |= 0;
            if ((cache = -128 <= value && value < 128)) {
                cachedObj = INT_CACHE[value];
                if (cachedObj)
                    return cachedObj;
            }
            obj = Long.fromBits(value, value < 0 ? -1 : 0, false);
            if (cache)
                INT_CACHE[value] = obj;
            return obj;
        }
    }
    static fromNumber(value, unsigned) {
        if (isNaN(value))
            return unsigned ? Long.UZERO : Long.ZERO;
        if (unsigned) {
            if (value < 0)
                return Long.UZERO;
            if (value >= TWO_PWR_64_DBL)
                return Long.MAX_UNSIGNED_VALUE;
        }
        else {
            if (value <= -TWO_PWR_63_DBL)
                return Long.MIN_VALUE;
            if (value + 1 >= TWO_PWR_63_DBL)
                return Long.MAX_VALUE;
        }
        if (value < 0)
            return Long.fromNumber(-value, unsigned).neg();
        return Long.fromBits(value % TWO_PWR_32_DBL | 0, (value / TWO_PWR_32_DBL) | 0, unsigned);
    }
    static fromBigInt(value, unsigned) {
        const FROM_BIGINT_BIT_MASK = BigInt(0xffffffff);
        const FROM_BIGINT_BIT_SHIFT = BigInt(32);
        return new Long(Number(value & FROM_BIGINT_BIT_MASK), Number((value >> FROM_BIGINT_BIT_SHIFT) & FROM_BIGINT_BIT_MASK), unsigned);
    }
    static _fromString(str, unsigned, radix) {
        if (str.length === 0)
            throw new BSONError('empty string');
        if (radix < 2 || 36 < radix)
            throw new BSONError('radix');
        let p;
        if ((p = str.indexOf('-')) > 0)
            throw new BSONError('interior hyphen');
        else if (p === 0) {
            return Long._fromString(str.substring(1), unsigned, radix).neg();
        }
        const radixToPower = Long.fromNumber(Math.pow(radix, 8));
        let result = Long.ZERO;
        for (let i = 0; i < str.length; i += 8) {
            const size = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size), radix);
            if (size < 8) {
                const power = Long.fromNumber(Math.pow(radix, size));
                result = result.mul(power).add(Long.fromNumber(value));
            }
            else {
                result = result.mul(radixToPower);
                result = result.add(Long.fromNumber(value));
            }
        }
        result.unsigned = unsigned;
        return result;
    }
    static fromStringStrict(str, unsignedOrRadix, radix) {
        let unsigned = false;
        if (typeof unsignedOrRadix === 'number') {
            (radix = unsignedOrRadix), (unsignedOrRadix = false);
        }
        else {
            unsigned = !!unsignedOrRadix;
        }
        radix ??= 10;
        if (str.trim() !== str) {
            throw new BSONError(`Input: '${str}' contains leading and/or trailing whitespace`);
        }
        if (!validateStringCharacters(str, radix)) {
            throw new BSONError(`Input: '${str}' contains invalid characters for radix: ${radix}`);
        }
        const cleanedStr = removeLeadingZerosAndExplicitPlus(str);
        const result = Long._fromString(cleanedStr, unsigned, radix);
        if (result.toString(radix).toLowerCase() !== cleanedStr.toLowerCase()) {
            throw new BSONError(`Input: ${str} is not representable as ${result.unsigned ? 'an unsigned' : 'a signed'} 64-bit Long ${radix != null ? `with radix: ${radix}` : ''}`);
        }
        return result;
    }
    static fromString(str, unsignedOrRadix, radix) {
        let unsigned = false;
        if (typeof unsignedOrRadix === 'number') {
            (radix = unsignedOrRadix), (unsignedOrRadix = false);
        }
        else {
            unsigned = !!unsignedOrRadix;
        }
        radix ??= 10;
        if (str === 'NaN' && radix < 24) {
            return Long.ZERO;
        }
        else if ((str === 'Infinity' || str === '+Infinity' || str === '-Infinity') && radix < 35) {
            return Long.ZERO;
        }
        return Long._fromString(str, unsigned, radix);
    }
    static fromBytes(bytes, unsigned, le) {
        return le ? Long.fromBytesLE(bytes, unsigned) : Long.fromBytesBE(bytes, unsigned);
    }
    static fromBytesLE(bytes, unsigned) {
        return new Long(bytes[0] | (bytes[1] << 8) | (bytes[2] << 16) | (bytes[3] << 24), bytes[4] | (bytes[5] << 8) | (bytes[6] << 16) | (bytes[7] << 24), unsigned);
    }
    static fromBytesBE(bytes, unsigned) {
        return new Long((bytes[4] << 24) | (bytes[5] << 16) | (bytes[6] << 8) | bytes[7], (bytes[0] << 24) | (bytes[1] << 16) | (bytes[2] << 8) | bytes[3], unsigned);
    }
    static isLong(value) {
        return (value != null &&
            typeof value === 'object' &&
            '__isLong__' in value &&
            value.__isLong__ === true);
    }
    static fromValue(val, unsigned) {
        if (typeof val === 'number')
            return Long.fromNumber(val, unsigned);
        if (typeof val === 'string')
            return Long.fromString(val, unsigned);
        return Long.fromBits(val.low, val.high, typeof unsigned === 'boolean' ? unsigned : val.unsigned);
    }
    add(addend) {
        if (!Long.isLong(addend))
            addend = Long.fromValue(addend);
        const a48 = this.high >>> 16;
        const a32 = this.high & 0xffff;
        const a16 = this.low >>> 16;
        const a00 = this.low & 0xffff;
        const b48 = addend.high >>> 16;
        const b32 = addend.high & 0xffff;
        const b16 = addend.low >>> 16;
        const b00 = addend.low & 0xffff;
        let c48 = 0, c32 = 0, c16 = 0, c00 = 0;
        c00 += a00 + b00;
        c16 += c00 >>> 16;
        c00 &= 0xffff;
        c16 += a16 + b16;
        c32 += c16 >>> 16;
        c16 &= 0xffff;
        c32 += a32 + b32;
        c48 += c32 >>> 16;
        c32 &= 0xffff;
        c48 += a48 + b48;
        c48 &= 0xffff;
        return Long.fromBits((c16 << 16) | c00, (c48 << 16) | c32, this.unsigned);
    }
    and(other) {
        if (!Long.isLong(other))
            other = Long.fromValue(other);
        return Long.fromBits(this.low & other.low, this.high & other.high, this.unsigned);
    }
    compare(other) {
        if (!Long.isLong(other))
            other = Long.fromValue(other);
        if (this.eq(other))
            return 0;
        const thisNeg = this.isNegative(), otherNeg = other.isNegative();
        if (thisNeg && !otherNeg)
            return -1;
        if (!thisNeg && otherNeg)
            return 1;
        if (!this.unsigned)
            return this.sub(other).isNegative() ? -1 : 1;
        return other.high >>> 0 > this.high >>> 0 ||
            (other.high === this.high && other.low >>> 0 > this.low >>> 0)
            ? -1
            : 1;
    }
    comp(other) {
        return this.compare(other);
    }
    divide(divisor) {
        if (!Long.isLong(divisor))
            divisor = Long.fromValue(divisor);
        if (divisor.isZero())
            throw new BSONError('division by zero');
        if (wasm) {
            if (!this.unsigned &&
                this.high === -0x80000000 &&
                divisor.low === -1 &&
                divisor.high === -1) {
                return this;
            }
            const low = (this.unsigned ? wasm.div_u : wasm.div_s)(this.low, this.high, divisor.low, divisor.high);
            return Long.fromBits(low, wasm.get_high(), this.unsigned);
        }
        if (this.isZero())
            return this.unsigned ? Long.UZERO : Long.ZERO;
        let approx, rem, res;
        if (!this.unsigned) {
            if (this.eq(Long.MIN_VALUE)) {
                if (divisor.eq(Long.ONE) || divisor.eq(Long.NEG_ONE))
                    return Long.MIN_VALUE;
                else if (divisor.eq(Long.MIN_VALUE))
                    return Long.ONE;
                else {
                    const halfThis = this.shr(1);
                    approx = halfThis.div(divisor).shl(1);
                    if (approx.eq(Long.ZERO)) {
                        return divisor.isNegative() ? Long.ONE : Long.NEG_ONE;
                    }
                    else {
                        rem = this.sub(divisor.mul(approx));
                        res = approx.add(rem.div(divisor));
                        return res;
                    }
                }
            }
            else if (divisor.eq(Long.MIN_VALUE))
                return this.unsigned ? Long.UZERO : Long.ZERO;
            if (this.isNegative()) {
                if (divisor.isNegative())
                    return this.neg().div(divisor.neg());
                return this.neg().div(divisor).neg();
            }
            else if (divisor.isNegative())
                return this.div(divisor.neg()).neg();
            res = Long.ZERO;
        }
        else {
            if (!divisor.unsigned)
                divisor = divisor.toUnsigned();
            if (divisor.gt(this))
                return Long.UZERO;
            if (divisor.gt(this.shru(1)))
                return Long.UONE;
            res = Long.UZERO;
        }
        rem = this;
        while (rem.gte(divisor)) {
            approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));
            const log2 = Math.ceil(Math.log(approx) / Math.LN2);
            const delta = log2 <= 48 ? 1 : Math.pow(2, log2 - 48);
            let approxRes = Long.fromNumber(approx);
            let approxRem = approxRes.mul(divisor);
            while (approxRem.isNegative() || approxRem.gt(rem)) {
                approx -= delta;
                approxRes = Long.fromNumber(approx, this.unsigned);
                approxRem = approxRes.mul(divisor);
            }
            if (approxRes.isZero())
                approxRes = Long.ONE;
            res = res.add(approxRes);
            rem = rem.sub(approxRem);
        }
        return res;
    }
    div(divisor) {
        return this.divide(divisor);
    }
    equals(other) {
        if (!Long.isLong(other))
            other = Long.fromValue(other);
        if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)
            return false;
        return this.high === other.high && this.low === other.low;
    }
    eq(other) {
        return this.equals(other);
    }
    getHighBits() {
        return this.high;
    }
    getHighBitsUnsigned() {
        return this.high >>> 0;
    }
    getLowBits() {
        return this.low;
    }
    getLowBitsUnsigned() {
        return this.low >>> 0;
    }
    getNumBitsAbs() {
        if (this.isNegative()) {
            return this.eq(Long.MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();
        }
        const val = this.high !== 0 ? this.high : this.low;
        let bit;
        for (bit = 31; bit > 0; bit--)
            if ((val & (1 << bit)) !== 0)
                break;
        return this.high !== 0 ? bit + 33 : bit + 1;
    }
    greaterThan(other) {
        return this.comp(other) > 0;
    }
    gt(other) {
        return this.greaterThan(other);
    }
    greaterThanOrEqual(other) {
        return this.comp(other) >= 0;
    }
    gte(other) {
        return this.greaterThanOrEqual(other);
    }
    ge(other) {
        return this.greaterThanOrEqual(other);
    }
    isEven() {
        return (this.low & 1) === 0;
    }
    isNegative() {
        return !this.unsigned && this.high < 0;
    }
    isOdd() {
        return (this.low & 1) === 1;
    }
    isPositive() {
        return this.unsigned || this.high >= 0;
    }
    isZero() {
        return this.high === 0 && this.low === 0;
    }
    lessThan(other) {
        return this.comp(other) < 0;
    }
    lt(other) {
        return this.lessThan(other);
    }
    lessThanOrEqual(other) {
        return this.comp(other) <= 0;
    }
    lte(other) {
        return this.lessThanOrEqual(other);
    }
    modulo(divisor) {
        if (!Long.isLong(divisor))
            divisor = Long.fromValue(divisor);
        if (wasm) {
            const low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(this.low, this.high, divisor.low, divisor.high);
            return Long.fromBits(low, wasm.get_high(), this.unsigned);
        }
        return this.sub(this.div(divisor).mul(divisor));
    }
    mod(divisor) {
        return this.modulo(divisor);
    }
    rem(divisor) {
        return this.modulo(divisor);
    }
    multiply(multiplier) {
        if (this.isZero())
            return Long.ZERO;
        if (!Long.isLong(multiplier))
            multiplier = Long.fromValue(multiplier);
        if (wasm) {
            const low = wasm.mul(this.low, this.high, multiplier.low, multiplier.high);
            return Long.fromBits(low, wasm.get_high(), this.unsigned);
        }
        if (multiplier.isZero())
            return Long.ZERO;
        if (this.eq(Long.MIN_VALUE))
            return multiplier.isOdd() ? Long.MIN_VALUE : Long.ZERO;
        if (multiplier.eq(Long.MIN_VALUE))
            return this.isOdd() ? Long.MIN_VALUE : Long.ZERO;
        if (this.isNegative()) {
            if (multiplier.isNegative())
                return this.neg().mul(multiplier.neg());
            else
                return this.neg().mul(multiplier).neg();
        }
        else if (multiplier.isNegative())
            return this.mul(multiplier.neg()).neg();
        if (this.lt(Long.TWO_PWR_24) && multiplier.lt(Long.TWO_PWR_24))
            return Long.fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);
        const a48 = this.high >>> 16;
        const a32 = this.high & 0xffff;
        const a16 = this.low >>> 16;
        const a00 = this.low & 0xffff;
        const b48 = multiplier.high >>> 16;
        const b32 = multiplier.high & 0xffff;
        const b16 = multiplier.low >>> 16;
        const b00 = multiplier.low & 0xffff;
        let c48 = 0, c32 = 0, c16 = 0, c00 = 0;
        c00 += a00 * b00;
        c16 += c00 >>> 16;
        c00 &= 0xffff;
        c16 += a16 * b00;
        c32 += c16 >>> 16;
        c16 &= 0xffff;
        c16 += a00 * b16;
        c32 += c16 >>> 16;
        c16 &= 0xffff;
        c32 += a32 * b00;
        c48 += c32 >>> 16;
        c32 &= 0xffff;
        c32 += a16 * b16;
        c48 += c32 >>> 16;
        c32 &= 0xffff;
        c32 += a00 * b32;
        c48 += c32 >>> 16;
        c32 &= 0xffff;
        c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;
        c48 &= 0xffff;
        return Long.fromBits((c16 << 16) | c00, (c48 << 16) | c32, this.unsigned);
    }
    mul(multiplier) {
        return this.multiply(multiplier);
    }
    negate() {
        if (!this.unsigned && this.eq(Long.MIN_VALUE))
            return Long.MIN_VALUE;
        return this.not().add(Long.ONE);
    }
    neg() {
        return this.negate();
    }
    not() {
        return Long.fromBits(~this.low, ~this.high, this.unsigned);
    }
    notEquals(other) {
        return !this.equals(other);
    }
    neq(other) {
        return this.notEquals(other);
    }
    ne(other) {
        return this.notEquals(other);
    }
    or(other) {
        if (!Long.isLong(other))
            other = Long.fromValue(other);
        return Long.fromBits(this.low | other.low, this.high | other.high, this.unsigned);
    }
    shiftLeft(numBits) {
        if (Long.isLong(numBits))
            numBits = numBits.toInt();
        if ((numBits &= 63) === 0)
            return this;
        else if (numBits < 32)
            return Long.fromBits(this.low << numBits, (this.high << numBits) | (this.low >>> (32 - numBits)), this.unsigned);
        else
            return Long.fromBits(0, this.low << (numBits - 32), this.unsigned);
    }
    shl(numBits) {
        return this.shiftLeft(numBits);
    }
    shiftRight(numBits) {
        if (Long.isLong(numBits))
            numBits = numBits.toInt();
        if ((numBits &= 63) === 0)
            return this;
        else if (numBits < 32)
            return Long.fromBits((this.low >>> numBits) | (this.high << (32 - numBits)), this.high >> numBits, this.unsigned);
        else
            return Long.fromBits(this.high >> (numBits - 32), this.high >= 0 ? 0 : -1, this.unsigned);
    }
    shr(numBits) {
        return this.shiftRight(numBits);
    }
    shiftRightUnsigned(numBits) {
        if (Long.isLong(numBits))
            numBits = numBits.toInt();
        numBits &= 63;
        if (numBits === 0)
            return this;
        else {
            const high = this.high;
            if (numBits < 32) {
                const low = this.low;
                return Long.fromBits((low >>> numBits) | (high << (32 - numBits)), high >>> numBits, this.unsigned);
            }
            else if (numBits === 32)
                return Long.fromBits(high, 0, this.unsigned);
            else
                return Long.fromBits(high >>> (numBits - 32), 0, this.unsigned);
        }
    }
    shr_u(numBits) {
        return this.shiftRightUnsigned(numBits);
    }
    shru(numBits) {
        return this.shiftRightUnsigned(numBits);
    }
    subtract(subtrahend) {
        if (!Long.isLong(subtrahend))
            subtrahend = Long.fromValue(subtrahend);
        return this.add(subtrahend.neg());
    }
    sub(subtrahend) {
        return this.subtract(subtrahend);
    }
    toInt() {
        return this.unsigned ? this.low >>> 0 : this.low;
    }
    toNumber() {
        if (this.unsigned)
            return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);
        return this.high * TWO_PWR_32_DBL + (this.low >>> 0);
    }
    toBigInt() {
        return BigInt(this.toString());
    }
    toBytes(le) {
        return le ? this.toBytesLE() : this.toBytesBE();
    }
    toBytesLE() {
        const hi = this.high, lo = this.low;
        return [
            lo & 0xff,
            (lo >>> 8) & 0xff,
            (lo >>> 16) & 0xff,
            lo >>> 24,
            hi & 0xff,
            (hi >>> 8) & 0xff,
            (hi >>> 16) & 0xff,
            hi >>> 24
        ];
    }
    toBytesBE() {
        const hi = this.high, lo = this.low;
        return [
            hi >>> 24,
            (hi >>> 16) & 0xff,
            (hi >>> 8) & 0xff,
            hi & 0xff,
            lo >>> 24,
            (lo >>> 16) & 0xff,
            (lo >>> 8) & 0xff,
            lo & 0xff
        ];
    }
    toSigned() {
        if (!this.unsigned)
            return this;
        return Long.fromBits(this.low, this.high, false);
    }
    toString(radix) {
        radix = radix || 10;
        if (radix < 2 || 36 < radix)
            throw new BSONError('radix');
        if (this.isZero())
            return '0';
        if (this.isNegative()) {
            if (this.eq(Long.MIN_VALUE)) {
                const radixLong = Long.fromNumber(radix), div = this.div(radixLong), rem1 = div.mul(radixLong).sub(this);
                return div.toString(radix) + rem1.toInt().toString(radix);
            }
            else
                return '-' + this.neg().toString(radix);
        }
        const radixToPower = Long.fromNumber(Math.pow(radix, 6), this.unsigned);
        let rem = this;
        let result = '';
        while (true) {
            const remDiv = rem.div(radixToPower);
            const intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0;
            let digits = intval.toString(radix);
            rem = remDiv;
            if (rem.isZero()) {
                return digits + result;
            }
            else {
                while (digits.length < 6)
                    digits = '0' + digits;
                result = '' + digits + result;
            }
        }
    }
    toUnsigned() {
        if (this.unsigned)
            return this;
        return Long.fromBits(this.low, this.high, true);
    }
    xor(other) {
        if (!Long.isLong(other))
            other = Long.fromValue(other);
        return Long.fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);
    }
    eqz() {
        return this.isZero();
    }
    le(other) {
        return this.lessThanOrEqual(other);
    }
    toExtendedJSON(options) {
        if (options && options.relaxed)
            return this.toNumber();
        return { $numberLong: this.toString() };
    }
    static fromExtendedJSON(doc, options) {
        const { useBigInt64 = false, relaxed = true } = { ...options };
        if (doc.$numberLong.length > MAX_INT64_STRING_LENGTH) {
            throw new BSONError('$numberLong string is too long');
        }
        if (!DECIMAL_REG_EX.test(doc.$numberLong)) {
            throw new BSONError(`$numberLong string "${doc.$numberLong}" is in an invalid format`);
        }
        if (useBigInt64) {
            const bigIntResult = BigInt(doc.$numberLong);
            return BigInt.asIntN(64, bigIntResult);
        }
        const longResult = Long.fromString(doc.$numberLong);
        if (relaxed) {
            return longResult.toNumber();
        }
        return longResult;
    }
    inspect(depth, options, inspect) {
        inspect ??= defaultInspect;
        const longVal = inspect(this.toString(), options);
        const unsignedVal = this.unsigned ? `, ${inspect(this.unsigned, options)}` : '';
        return `new Long(${longVal}${unsignedVal})`;
    }
}
Long.TWO_PWR_24 = Long.fromInt(TWO_PWR_24_DBL);
Long.MAX_UNSIGNED_VALUE = Long.fromBits(0xffffffff | 0, 0xffffffff | 0, true);
Long.ZERO = Long.fromInt(0);
Long.UZERO = Long.fromInt(0, true);
Long.ONE = Long.fromInt(1);
Long.UONE = Long.fromInt(1, true);
Long.NEG_ONE = Long.fromInt(-1);
Long.MAX_VALUE = Long.fromBits(0xffffffff | 0, 0x7fffffff | 0, false);
Long.MIN_VALUE = Long.fromBits(0, 0x80000000 | 0, false);

const PARSE_STRING_REGEXP = /^(\+|-)?(\d+|(\d*\.\d*))?(E|e)?([-+])?(\d+)?$/;
const PARSE_INF_REGEXP = /^(\+|-)?(Infinity|inf)$/i;
const PARSE_NAN_REGEXP = /^(\+|-)?NaN$/i;
const EXPONENT_MAX = 6111;
const EXPONENT_MIN = -6176;
const EXPONENT_BIAS = 6176;
const MAX_DIGITS = 34;
const NAN_BUFFER = ByteUtils.fromNumberArray([
    0x7c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
].reverse());
const INF_NEGATIVE_BUFFER = ByteUtils.fromNumberArray([
    0xf8, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
].reverse());
const INF_POSITIVE_BUFFER = ByteUtils.fromNumberArray([
    0x78, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
].reverse());
const EXPONENT_REGEX = /^([-+])?(\d+)?$/;
const COMBINATION_MASK = 0x1f;
const EXPONENT_MASK = 0x3fff;
const COMBINATION_INFINITY = 30;
const COMBINATION_NAN = 31;
function isDigit$1(value) {
    return !isNaN(parseInt(value, 10));
}
function divideu128(value) {
    const DIVISOR = Long.fromNumber(1000 * 1000 * 1000);
    let _rem = Long.fromNumber(0);
    if (!value.parts[0] && !value.parts[1] && !value.parts[2] && !value.parts[3]) {
        return { quotient: value, rem: _rem };
    }
    for (let i = 0; i <= 3; i++) {
        _rem = _rem.shiftLeft(32);
        _rem = _rem.add(new Long(value.parts[i], 0));
        value.parts[i] = _rem.div(DIVISOR).low;
        _rem = _rem.modulo(DIVISOR);
    }
    return { quotient: value, rem: _rem };
}
function multiply64x2(left, right) {
    if (!left && !right) {
        return { high: Long.fromNumber(0), low: Long.fromNumber(0) };
    }
    const leftHigh = left.shiftRightUnsigned(32);
    const leftLow = new Long(left.getLowBits(), 0);
    const rightHigh = right.shiftRightUnsigned(32);
    const rightLow = new Long(right.getLowBits(), 0);
    let productHigh = leftHigh.multiply(rightHigh);
    let productMid = leftHigh.multiply(rightLow);
    const productMid2 = leftLow.multiply(rightHigh);
    let productLow = leftLow.multiply(rightLow);
    productHigh = productHigh.add(productMid.shiftRightUnsigned(32));
    productMid = new Long(productMid.getLowBits(), 0)
        .add(productMid2)
        .add(productLow.shiftRightUnsigned(32));
    productHigh = productHigh.add(productMid.shiftRightUnsigned(32));
    productLow = productMid.shiftLeft(32).add(new Long(productLow.getLowBits(), 0));
    return { high: productHigh, low: productLow };
}
function lessThan(left, right) {
    const uhleft = left.high >>> 0;
    const uhright = right.high >>> 0;
    if (uhleft < uhright) {
        return true;
    }
    else if (uhleft === uhright) {
        const ulleft = left.low >>> 0;
        const ulright = right.low >>> 0;
        if (ulleft < ulright)
            return true;
    }
    return false;
}
function invalidErr(string, message) {
    throw new BSONError(`"${string}" is not a valid Decimal128 string - ${message}`);
}
class Decimal128 extends BSONValue {
    get _bsontype() {
        return 'Decimal128';
    }
    constructor(bytes) {
        super();
        if (typeof bytes === 'string') {
            this.bytes = Decimal128.fromString(bytes).bytes;
        }
        else if (isUint8Array(bytes)) {
            if (bytes.byteLength !== 16) {
                throw new BSONError('Decimal128 must take a Buffer of 16 bytes');
            }
            this.bytes = bytes;
        }
        else {
            throw new BSONError('Decimal128 must take a Buffer or string');
        }
    }
    static fromString(representation) {
        return Decimal128._fromString(representation, { allowRounding: false });
    }
    static fromStringWithRounding(representation) {
        return Decimal128._fromString(representation, { allowRounding: true });
    }
    static _fromString(representation, options) {
        let isNegative = false;
        let sawSign = false;
        let sawRadix = false;
        let foundNonZero = false;
        let significantDigits = 0;
        let nDigitsRead = 0;
        let nDigits = 0;
        let radixPosition = 0;
        let firstNonZero = 0;
        const digits = [0];
        let nDigitsStored = 0;
        let digitsInsert = 0;
        let lastDigit = 0;
        let exponent = 0;
        let significandHigh = new Long(0, 0);
        let significandLow = new Long(0, 0);
        let biasedExponent = 0;
        let index = 0;
        if (representation.length >= 7000) {
            throw new BSONError('' + representation + ' not a valid Decimal128 string');
        }
        const stringMatch = representation.match(PARSE_STRING_REGEXP);
        const infMatch = representation.match(PARSE_INF_REGEXP);
        const nanMatch = representation.match(PARSE_NAN_REGEXP);
        if ((!stringMatch && !infMatch && !nanMatch) || representation.length === 0) {
            throw new BSONError('' + representation + ' not a valid Decimal128 string');
        }
        if (stringMatch) {
            const unsignedNumber = stringMatch[2];
            const e = stringMatch[4];
            const expSign = stringMatch[5];
            const expNumber = stringMatch[6];
            if (e && expNumber === undefined)
                invalidErr(representation, 'missing exponent power');
            if (e && unsignedNumber === undefined)
                invalidErr(representation, 'missing exponent base');
            if (e === undefined && (expSign || expNumber)) {
                invalidErr(representation, 'missing e before exponent');
            }
        }
        if (representation[index] === '+' || representation[index] === '-') {
            sawSign = true;
            isNegative = representation[index++] === '-';
        }
        if (!isDigit$1(representation[index]) && representation[index] !== '.') {
            if (representation[index] === 'i' || representation[index] === 'I') {
                return new Decimal128(isNegative ? INF_NEGATIVE_BUFFER : INF_POSITIVE_BUFFER);
            }
            else if (representation[index] === 'N') {
                return new Decimal128(NAN_BUFFER);
            }
        }
        while (isDigit$1(representation[index]) || representation[index] === '.') {
            if (representation[index] === '.') {
                if (sawRadix)
                    invalidErr(representation, 'contains multiple periods');
                sawRadix = true;
                index = index + 1;
                continue;
            }
            if (nDigitsStored < MAX_DIGITS) {
                if (representation[index] !== '0' || foundNonZero) {
                    if (!foundNonZero) {
                        firstNonZero = nDigitsRead;
                    }
                    foundNonZero = true;
                    digits[digitsInsert++] = parseInt(representation[index], 10);
                    nDigitsStored = nDigitsStored + 1;
                }
            }
            if (foundNonZero)
                nDigits = nDigits + 1;
            if (sawRadix)
                radixPosition = radixPosition + 1;
            nDigitsRead = nDigitsRead + 1;
            index = index + 1;
        }
        if (sawRadix && !nDigitsRead)
            throw new BSONError('' + representation + ' not a valid Decimal128 string');
        if (representation[index] === 'e' || representation[index] === 'E') {
            const match = representation.substr(++index).match(EXPONENT_REGEX);
            if (!match || !match[2])
                return new Decimal128(NAN_BUFFER);
            exponent = parseInt(match[0], 10);
            index = index + match[0].length;
        }
        if (representation[index])
            return new Decimal128(NAN_BUFFER);
        if (!nDigitsStored) {
            digits[0] = 0;
            nDigits = 1;
            nDigitsStored = 1;
            significantDigits = 0;
        }
        else {
            lastDigit = nDigitsStored - 1;
            significantDigits = nDigits;
            if (significantDigits !== 1) {
                while (representation[firstNonZero + significantDigits - 1 + Number(sawSign) + Number(sawRadix)] === '0') {
                    significantDigits = significantDigits - 1;
                }
            }
        }
        if (exponent <= radixPosition && radixPosition > exponent + (1 << 14)) {
            exponent = EXPONENT_MIN;
        }
        else {
            exponent = exponent - radixPosition;
        }
        while (exponent > EXPONENT_MAX) {
            lastDigit = lastDigit + 1;
            if (lastDigit >= MAX_DIGITS) {
                if (significantDigits === 0) {
                    exponent = EXPONENT_MAX;
                    break;
                }
                invalidErr(representation, 'overflow');
            }
            exponent = exponent - 1;
        }
        if (options.allowRounding) {
            while (exponent < EXPONENT_MIN || nDigitsStored < nDigits) {
                if (lastDigit === 0 && significantDigits < nDigitsStored) {
                    exponent = EXPONENT_MIN;
                    significantDigits = 0;
                    break;
                }
                if (nDigitsStored < nDigits) {
                    nDigits = nDigits - 1;
                }
                else {
                    lastDigit = lastDigit - 1;
                }
                if (exponent < EXPONENT_MAX) {
                    exponent = exponent + 1;
                }
                else {
                    const digitsString = digits.join('');
                    if (digitsString.match(/^0+$/)) {
                        exponent = EXPONENT_MAX;
                        break;
                    }
                    invalidErr(representation, 'overflow');
                }
            }
            if (lastDigit + 1 < significantDigits) {
                let endOfString = nDigitsRead;
                if (sawRadix) {
                    firstNonZero = firstNonZero + 1;
                    endOfString = endOfString + 1;
                }
                if (sawSign) {
                    firstNonZero = firstNonZero + 1;
                    endOfString = endOfString + 1;
                }
                const roundDigit = parseInt(representation[firstNonZero + lastDigit + 1], 10);
                let roundBit = 0;
                if (roundDigit >= 5) {
                    roundBit = 1;
                    if (roundDigit === 5) {
                        roundBit = digits[lastDigit] % 2 === 1 ? 1 : 0;
                        for (let i = firstNonZero + lastDigit + 2; i < endOfString; i++) {
                            if (parseInt(representation[i], 10)) {
                                roundBit = 1;
                                break;
                            }
                        }
                    }
                }
                if (roundBit) {
                    let dIdx = lastDigit;
                    for (; dIdx >= 0; dIdx--) {
                        if (++digits[dIdx] > 9) {
                            digits[dIdx] = 0;
                            if (dIdx === 0) {
                                if (exponent < EXPONENT_MAX) {
                                    exponent = exponent + 1;
                                    digits[dIdx] = 1;
                                }
                                else {
                                    return new Decimal128(isNegative ? INF_NEGATIVE_BUFFER : INF_POSITIVE_BUFFER);
                                }
                            }
                        }
                        else {
                            break;
                        }
                    }
                }
            }
        }
        else {
            while (exponent < EXPONENT_MIN || nDigitsStored < nDigits) {
                if (lastDigit === 0) {
                    if (significantDigits === 0) {
                        exponent = EXPONENT_MIN;
                        break;
                    }
                    invalidErr(representation, 'exponent underflow');
                }
                if (nDigitsStored < nDigits) {
                    if (representation[nDigits - 1 + Number(sawSign) + Number(sawRadix)] !== '0' &&
                        significantDigits !== 0) {
                        invalidErr(representation, 'inexact rounding');
                    }
                    nDigits = nDigits - 1;
                }
                else {
                    if (digits[lastDigit] !== 0) {
                        invalidErr(representation, 'inexact rounding');
                    }
                    lastDigit = lastDigit - 1;
                }
                if (exponent < EXPONENT_MAX) {
                    exponent = exponent + 1;
                }
                else {
                    invalidErr(representation, 'overflow');
                }
            }
            if (lastDigit + 1 < significantDigits) {
                if (sawRadix) {
                    firstNonZero = firstNonZero + 1;
                }
                if (sawSign) {
                    firstNonZero = firstNonZero + 1;
                }
                const roundDigit = parseInt(representation[firstNonZero + lastDigit + 1], 10);
                if (roundDigit !== 0) {
                    invalidErr(representation, 'inexact rounding');
                }
            }
        }
        significandHigh = Long.fromNumber(0);
        significandLow = Long.fromNumber(0);
        if (significantDigits === 0) {
            significandHigh = Long.fromNumber(0);
            significandLow = Long.fromNumber(0);
        }
        else if (lastDigit < 17) {
            let dIdx = 0;
            significandLow = Long.fromNumber(digits[dIdx++]);
            significandHigh = new Long(0, 0);
            for (; dIdx <= lastDigit; dIdx++) {
                significandLow = significandLow.multiply(Long.fromNumber(10));
                significandLow = significandLow.add(Long.fromNumber(digits[dIdx]));
            }
        }
        else {
            let dIdx = 0;
            significandHigh = Long.fromNumber(digits[dIdx++]);
            for (; dIdx <= lastDigit - 17; dIdx++) {
                significandHigh = significandHigh.multiply(Long.fromNumber(10));
                significandHigh = significandHigh.add(Long.fromNumber(digits[dIdx]));
            }
            significandLow = Long.fromNumber(digits[dIdx++]);
            for (; dIdx <= lastDigit; dIdx++) {
                significandLow = significandLow.multiply(Long.fromNumber(10));
                significandLow = significandLow.add(Long.fromNumber(digits[dIdx]));
            }
        }
        const significand = multiply64x2(significandHigh, Long.fromString('100000000000000000'));
        significand.low = significand.low.add(significandLow);
        if (lessThan(significand.low, significandLow)) {
            significand.high = significand.high.add(Long.fromNumber(1));
        }
        biasedExponent = exponent + EXPONENT_BIAS;
        const dec = { low: Long.fromNumber(0), high: Long.fromNumber(0) };
        if (significand.high.shiftRightUnsigned(49).and(Long.fromNumber(1)).equals(Long.fromNumber(1))) {
            dec.high = dec.high.or(Long.fromNumber(0x3).shiftLeft(61));
            dec.high = dec.high.or(Long.fromNumber(biasedExponent).and(Long.fromNumber(0x3fff).shiftLeft(47)));
            dec.high = dec.high.or(significand.high.and(Long.fromNumber(0x7fffffffffff)));
        }
        else {
            dec.high = dec.high.or(Long.fromNumber(biasedExponent & 0x3fff).shiftLeft(49));
            dec.high = dec.high.or(significand.high.and(Long.fromNumber(0x1ffffffffffff)));
        }
        dec.low = significand.low;
        if (isNegative) {
            dec.high = dec.high.or(Long.fromString('9223372036854775808'));
        }
        const buffer = ByteUtils.allocateUnsafe(16);
        index = 0;
        buffer[index++] = dec.low.low & 0xff;
        buffer[index++] = (dec.low.low >> 8) & 0xff;
        buffer[index++] = (dec.low.low >> 16) & 0xff;
        buffer[index++] = (dec.low.low >> 24) & 0xff;
        buffer[index++] = dec.low.high & 0xff;
        buffer[index++] = (dec.low.high >> 8) & 0xff;
        buffer[index++] = (dec.low.high >> 16) & 0xff;
        buffer[index++] = (dec.low.high >> 24) & 0xff;
        buffer[index++] = dec.high.low & 0xff;
        buffer[index++] = (dec.high.low >> 8) & 0xff;
        buffer[index++] = (dec.high.low >> 16) & 0xff;
        buffer[index++] = (dec.high.low >> 24) & 0xff;
        buffer[index++] = dec.high.high & 0xff;
        buffer[index++] = (dec.high.high >> 8) & 0xff;
        buffer[index++] = (dec.high.high >> 16) & 0xff;
        buffer[index++] = (dec.high.high >> 24) & 0xff;
        return new Decimal128(buffer);
    }
    toString() {
        let biased_exponent;
        let significand_digits = 0;
        const significand = new Array(36);
        for (let i = 0; i < significand.length; i++)
            significand[i] = 0;
        let index = 0;
        let is_zero = false;
        let significand_msb;
        let significand128 = { parts: [0, 0, 0, 0] };
        let j, k;
        const string = [];
        index = 0;
        const buffer = this.bytes;
        const low = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);
        const midl = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);
        const midh = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);
        const high = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);
        index = 0;
        const dec = {
            low: new Long(low, midl),
            high: new Long(midh, high)
        };
        if (dec.high.lessThan(Long.ZERO)) {
            string.push('-');
        }
        const combination = (high >> 26) & COMBINATION_MASK;
        if (combination >> 3 === 3) {
            if (combination === COMBINATION_INFINITY) {
                return string.join('') + 'Infinity';
            }
            else if (combination === COMBINATION_NAN) {
                return 'NaN';
            }
            else {
                biased_exponent = (high >> 15) & EXPONENT_MASK;
                significand_msb = 0x08 + ((high >> 14) & 0x01);
            }
        }
        else {
            significand_msb = (high >> 14) & 0x07;
            biased_exponent = (high >> 17) & EXPONENT_MASK;
        }
        const exponent = biased_exponent - EXPONENT_BIAS;
        significand128.parts[0] = (high & 0x3fff) + ((significand_msb & 0xf) << 14);
        significand128.parts[1] = midh;
        significand128.parts[2] = midl;
        significand128.parts[3] = low;
        if (significand128.parts[0] === 0 &&
            significand128.parts[1] === 0 &&
            significand128.parts[2] === 0 &&
            significand128.parts[3] === 0) {
            is_zero = true;
        }
        else {
            for (k = 3; k >= 0; k--) {
                let least_digits = 0;
                const result = divideu128(significand128);
                significand128 = result.quotient;
                least_digits = result.rem.low;
                if (!least_digits)
                    continue;
                for (j = 8; j >= 0; j--) {
                    significand[k * 9 + j] = least_digits % 10;
                    least_digits = Math.floor(least_digits / 10);
                }
            }
        }
        if (is_zero) {
            significand_digits = 1;
            significand[index] = 0;
        }
        else {
            significand_digits = 36;
            while (!significand[index]) {
                significand_digits = significand_digits - 1;
                index = index + 1;
            }
        }
        const scientific_exponent = significand_digits - 1 + exponent;
        if (scientific_exponent >= 34 || scientific_exponent <= -7 || exponent > 0) {
            if (significand_digits > 34) {
                string.push(`${0}`);
                if (exponent > 0)
                    string.push(`E+${exponent}`);
                else if (exponent < 0)
                    string.push(`E${exponent}`);
                return string.join('');
            }
            string.push(`${significand[index++]}`);
            significand_digits = significand_digits - 1;
            if (significand_digits) {
                string.push('.');
            }
            for (let i = 0; i < significand_digits; i++) {
                string.push(`${significand[index++]}`);
            }
            string.push('E');
            if (scientific_exponent > 0) {
                string.push(`+${scientific_exponent}`);
            }
            else {
                string.push(`${scientific_exponent}`);
            }
        }
        else {
            if (exponent >= 0) {
                for (let i = 0; i < significand_digits; i++) {
                    string.push(`${significand[index++]}`);
                }
            }
            else {
                let radix_position = significand_digits + exponent;
                if (radix_position > 0) {
                    for (let i = 0; i < radix_position; i++) {
                        string.push(`${significand[index++]}`);
                    }
                }
                else {
                    string.push('0');
                }
                string.push('.');
                while (radix_position++ < 0) {
                    string.push('0');
                }
                for (let i = 0; i < significand_digits - Math.max(radix_position - 1, 0); i++) {
                    string.push(`${significand[index++]}`);
                }
            }
        }
        return string.join('');
    }
    toJSON() {
        return { $numberDecimal: this.toString() };
    }
    toExtendedJSON() {
        return { $numberDecimal: this.toString() };
    }
    static fromExtendedJSON(doc) {
        return Decimal128.fromString(doc.$numberDecimal);
    }
    inspect(depth, options, inspect) {
        inspect ??= defaultInspect;
        const d128string = inspect(this.toString(), options);
        return `new Decimal128(${d128string})`;
    }
}

class Double extends BSONValue {
    get _bsontype() {
        return 'Double';
    }
    constructor(value) {
        super();
        if (value instanceof Number) {
            value = value.valueOf();
        }
        this.value = +value;
    }
    static fromString(value) {
        const coercedValue = Number(value);
        if (value === 'NaN')
            return new Double(NaN);
        if (value === 'Infinity')
            return new Double(Infinity);
        if (value === '-Infinity')
            return new Double(-Infinity);
        if (!Number.isFinite(coercedValue)) {
            throw new BSONError(`Input: ${value} is not representable as a Double`);
        }
        if (value.trim() !== value) {
            throw new BSONError(`Input: '${value}' contains whitespace`);
        }
        if (value === '') {
            throw new BSONError(`Input is an empty string`);
        }
        if (/[^-0-9.+eE]/.test(value)) {
            throw new BSONError(`Input: '${value}' is not in decimal or exponential notation`);
        }
        return new Double(coercedValue);
    }
    valueOf() {
        return this.value;
    }
    toJSON() {
        return this.value;
    }
    toString(radix) {
        return this.value.toString(radix);
    }
    toExtendedJSON(options) {
        if (options && (options.legacy || (options.relaxed && isFinite(this.value)))) {
            return this.value;
        }
        if (Object.is(Math.sign(this.value), -0)) {
            return { $numberDouble: '-0.0' };
        }
        return {
            $numberDouble: Number.isInteger(this.value) ? this.value.toFixed(1) : this.value.toString()
        };
    }
    static fromExtendedJSON(doc, options) {
        const doubleValue = parseFloat(doc.$numberDouble);
        return options && options.relaxed ? doubleValue : new Double(doubleValue);
    }
    inspect(depth, options, inspect) {
        inspect ??= defaultInspect;
        return `new Double(${inspect(this.value, options)})`;
    }
}

class Int32 extends BSONValue {
    get _bsontype() {
        return 'Int32';
    }
    constructor(value) {
        super();
        if (value instanceof Number) {
            value = value.valueOf();
        }
        this.value = +value | 0;
    }
    static fromString(value) {
        const cleanedValue = removeLeadingZerosAndExplicitPlus(value);
        const coercedValue = Number(value);
        if (BSON_INT32_MAX < coercedValue) {
            throw new BSONError(`Input: '${value}' is larger than the maximum value for Int32`);
        }
        else if (BSON_INT32_MIN > coercedValue) {
            throw new BSONError(`Input: '${value}' is smaller than the minimum value for Int32`);
        }
        else if (!Number.isSafeInteger(coercedValue)) {
            throw new BSONError(`Input: '${value}' is not a safe integer`);
        }
        else if (coercedValue.toString() !== cleanedValue) {
            throw new BSONError(`Input: '${value}' is not a valid Int32 string`);
        }
        return new Int32(coercedValue);
    }
    valueOf() {
        return this.value;
    }
    toString(radix) {
        return this.value.toString(radix);
    }
    toJSON() {
        return this.value;
    }
    toExtendedJSON(options) {
        if (options && (options.relaxed || options.legacy))
            return this.value;
        return { $numberInt: this.value.toString() };
    }
    static fromExtendedJSON(doc, options) {
        return options && options.relaxed ? parseInt(doc.$numberInt, 10) : new Int32(doc.$numberInt);
    }
    inspect(depth, options, inspect) {
        inspect ??= defaultInspect;
        return `new Int32(${inspect(this.value, options)})`;
    }
}

class MaxKey extends BSONValue {
    get _bsontype() {
        return 'MaxKey';
    }
    toExtendedJSON() {
        return { $maxKey: 1 };
    }
    static fromExtendedJSON() {
        return new MaxKey();
    }
    inspect() {
        return 'new MaxKey()';
    }
}

class MinKey extends BSONValue {
    get _bsontype() {
        return 'MinKey';
    }
    toExtendedJSON() {
        return { $minKey: 1 };
    }
    static fromExtendedJSON() {
        return new MinKey();
    }
    inspect() {
        return 'new MinKey()';
    }
}

const FLOAT = new Float64Array(1);
const FLOAT_BYTES = new Uint8Array(FLOAT.buffer, 0, 8);
FLOAT[0] = -1;
const isBigEndian = FLOAT_BYTES[7] === 0;
const NumberUtils = {
    getNonnegativeInt32LE(source, offset) {
        if (source[offset + 3] > 127) {
            throw new RangeError(`Size cannot be negative at offset: ${offset}`);
        }
        return (source[offset] |
            (source[offset + 1] << 8) |
            (source[offset + 2] << 16) |
            (source[offset + 3] << 24));
    },
    getInt32LE(source, offset) {
        return (source[offset] |
            (source[offset + 1] << 8) |
            (source[offset + 2] << 16) |
            (source[offset + 3] << 24));
    },
    getUint32LE(source, offset) {
        return (source[offset] +
            source[offset + 1] * 256 +
            source[offset + 2] * 65536 +
            source[offset + 3] * 16777216);
    },
    getUint32BE(source, offset) {
        return (source[offset + 3] +
            source[offset + 2] * 256 +
            source[offset + 1] * 65536 +
            source[offset] * 16777216);
    },
    getBigInt64LE(source, offset) {
        const lo = NumberUtils.getUint32LE(source, offset);
        const hi = NumberUtils.getUint32LE(source, offset + 4);
        return (BigInt(hi) << BigInt(32)) + BigInt(lo);
    },
    getFloat64LE: isBigEndian
        ? (source, offset) => {
            FLOAT_BYTES[7] = source[offset];
            FLOAT_BYTES[6] = source[offset + 1];
            FLOAT_BYTES[5] = source[offset + 2];
            FLOAT_BYTES[4] = source[offset + 3];
            FLOAT_BYTES[3] = source[offset + 4];
            FLOAT_BYTES[2] = source[offset + 5];
            FLOAT_BYTES[1] = source[offset + 6];
            FLOAT_BYTES[0] = source[offset + 7];
            return FLOAT[0];
        }
        : (source, offset) => {
            FLOAT_BYTES[0] = source[offset];
            FLOAT_BYTES[1] = source[offset + 1];
            FLOAT_BYTES[2] = source[offset + 2];
            FLOAT_BYTES[3] = source[offset + 3];
            FLOAT_BYTES[4] = source[offset + 4];
            FLOAT_BYTES[5] = source[offset + 5];
            FLOAT_BYTES[6] = source[offset + 6];
            FLOAT_BYTES[7] = source[offset + 7];
            return FLOAT[0];
        },
    setInt32BE(destination, offset, value) {
        destination[offset + 3] = value;
        value >>>= 8;
        destination[offset + 2] = value;
        value >>>= 8;
        destination[offset + 1] = value;
        value >>>= 8;
        destination[offset] = value;
        return 4;
    },
    setInt32LE(destination, offset, value) {
        destination[offset] = value;
        value >>>= 8;
        destination[offset + 1] = value;
        value >>>= 8;
        destination[offset + 2] = value;
        value >>>= 8;
        destination[offset + 3] = value;
        return 4;
    },
    setBigInt64LE(destination, offset, value) {
        const mask32bits = BigInt(4294967295);
        let lo = Number(value & mask32bits);
        destination[offset] = lo;
        lo >>= 8;
        destination[offset + 1] = lo;
        lo >>= 8;
        destination[offset + 2] = lo;
        lo >>= 8;
        destination[offset + 3] = lo;
        let hi = Number((value >> BigInt(32)) & mask32bits);
        destination[offset + 4] = hi;
        hi >>= 8;
        destination[offset + 5] = hi;
        hi >>= 8;
        destination[offset + 6] = hi;
        hi >>= 8;
        destination[offset + 7] = hi;
        return 8;
    },
    setFloat64LE: isBigEndian
        ? (destination, offset, value) => {
            FLOAT[0] = value;
            destination[offset] = FLOAT_BYTES[7];
            destination[offset + 1] = FLOAT_BYTES[6];
            destination[offset + 2] = FLOAT_BYTES[5];
            destination[offset + 3] = FLOAT_BYTES[4];
            destination[offset + 4] = FLOAT_BYTES[3];
            destination[offset + 5] = FLOAT_BYTES[2];
            destination[offset + 6] = FLOAT_BYTES[1];
            destination[offset + 7] = FLOAT_BYTES[0];
            return 8;
        }
        : (destination, offset, value) => {
            FLOAT[0] = value;
            destination[offset] = FLOAT_BYTES[0];
            destination[offset + 1] = FLOAT_BYTES[1];
            destination[offset + 2] = FLOAT_BYTES[2];
            destination[offset + 3] = FLOAT_BYTES[3];
            destination[offset + 4] = FLOAT_BYTES[4];
            destination[offset + 5] = FLOAT_BYTES[5];
            destination[offset + 6] = FLOAT_BYTES[6];
            destination[offset + 7] = FLOAT_BYTES[7];
            return 8;
        }
};

const checkForHexRegExp = new RegExp('^[0-9a-fA-F]{24}$');
let PROCESS_UNIQUE = null;
class ObjectId extends BSONValue {
    get _bsontype() {
        return 'ObjectId';
    }
    constructor(inputId) {
        super();
        let workingId;
        if (typeof inputId === 'object' && inputId && 'id' in inputId) {
            if (typeof inputId.id !== 'string' && !ArrayBuffer.isView(inputId.id)) {
                throw new BSONError('Argument passed in must have an id that is of type string or Buffer');
            }
            if ('toHexString' in inputId && typeof inputId.toHexString === 'function') {
                workingId = ByteUtils.fromHex(inputId.toHexString());
            }
            else {
                workingId = inputId.id;
            }
        }
        else {
            workingId = inputId;
        }
        if (workingId == null || typeof workingId === 'number') {
            this.buffer = ObjectId.generate(typeof workingId === 'number' ? workingId : undefined);
        }
        else if (ArrayBuffer.isView(workingId) && workingId.byteLength === 12) {
            this.buffer = ByteUtils.toLocalBufferType(workingId);
        }
        else if (typeof workingId === 'string') {
            if (workingId.length === 24 && checkForHexRegExp.test(workingId)) {
                this.buffer = ByteUtils.fromHex(workingId);
            }
            else {
                throw new BSONError('input must be a 24 character hex string, 12 byte Uint8Array, or an integer');
            }
        }
        else {
            throw new BSONError('Argument passed in does not match the accepted types');
        }
        if (ObjectId.cacheHexString) {
            this.__id = ByteUtils.toHex(this.id);
        }
    }
    get id() {
        return this.buffer;
    }
    set id(value) {
        this.buffer = value;
        if (ObjectId.cacheHexString) {
            this.__id = ByteUtils.toHex(value);
        }
    }
    toHexString() {
        if (ObjectId.cacheHexString && this.__id) {
            return this.__id;
        }
        const hexString = ByteUtils.toHex(this.id);
        if (ObjectId.cacheHexString && !this.__id) {
            this.__id = hexString;
        }
        return hexString;
    }
    static getInc() {
        return (ObjectId.index = (ObjectId.index + 1) % 0xffffff);
    }
    static generate(time) {
        if ('number' !== typeof time) {
            time = Math.floor(Date.now() / 1000);
        }
        const inc = ObjectId.getInc();
        const buffer = ByteUtils.allocateUnsafe(12);
        NumberUtils.setInt32BE(buffer, 0, time);
        if (PROCESS_UNIQUE === null) {
            PROCESS_UNIQUE = ByteUtils.randomBytes(5);
        }
        buffer[4] = PROCESS_UNIQUE[0];
        buffer[5] = PROCESS_UNIQUE[1];
        buffer[6] = PROCESS_UNIQUE[2];
        buffer[7] = PROCESS_UNIQUE[3];
        buffer[8] = PROCESS_UNIQUE[4];
        buffer[11] = inc & 0xff;
        buffer[10] = (inc >> 8) & 0xff;
        buffer[9] = (inc >> 16) & 0xff;
        return buffer;
    }
    toString(encoding) {
        if (encoding === 'base64')
            return ByteUtils.toBase64(this.id);
        if (encoding === 'hex')
            return this.toHexString();
        return this.toHexString();
    }
    toJSON() {
        return this.toHexString();
    }
    static is(variable) {
        return (variable != null &&
            typeof variable === 'object' &&
            '_bsontype' in variable &&
            variable._bsontype === 'ObjectId');
    }
    equals(otherId) {
        if (otherId === undefined || otherId === null) {
            return false;
        }
        if (ObjectId.is(otherId)) {
            return (this.buffer[11] === otherId.buffer[11] && ByteUtils.equals(this.buffer, otherId.buffer));
        }
        if (typeof otherId === 'string') {
            return otherId.toLowerCase() === this.toHexString();
        }
        if (typeof otherId === 'object' && typeof otherId.toHexString === 'function') {
            const otherIdString = otherId.toHexString();
            const thisIdString = this.toHexString();
            return typeof otherIdString === 'string' && otherIdString.toLowerCase() === thisIdString;
        }
        return false;
    }
    getTimestamp() {
        const timestamp = new Date();
        const time = NumberUtils.getUint32BE(this.buffer, 0);
        timestamp.setTime(Math.floor(time) * 1000);
        return timestamp;
    }
    static createPk() {
        return new ObjectId();
    }
    serializeInto(uint8array, index) {
        uint8array[index] = this.buffer[0];
        uint8array[index + 1] = this.buffer[1];
        uint8array[index + 2] = this.buffer[2];
        uint8array[index + 3] = this.buffer[3];
        uint8array[index + 4] = this.buffer[4];
        uint8array[index + 5] = this.buffer[5];
        uint8array[index + 6] = this.buffer[6];
        uint8array[index + 7] = this.buffer[7];
        uint8array[index + 8] = this.buffer[8];
        uint8array[index + 9] = this.buffer[9];
        uint8array[index + 10] = this.buffer[10];
        uint8array[index + 11] = this.buffer[11];
        return 12;
    }
    static createFromTime(time) {
        const buffer = ByteUtils.allocate(12);
        for (let i = 11; i >= 4; i--)
            buffer[i] = 0;
        NumberUtils.setInt32BE(buffer, 0, time);
        return new ObjectId(buffer);
    }
    static createFromHexString(hexString) {
        if (hexString?.length !== 24) {
            throw new BSONError('hex string must be 24 characters');
        }
        return new ObjectId(ByteUtils.fromHex(hexString));
    }
    static createFromBase64(base64) {
        if (base64?.length !== 16) {
            throw new BSONError('base64 string must be 16 characters');
        }
        return new ObjectId(ByteUtils.fromBase64(base64));
    }
    static isValid(id) {
        if (id == null)
            return false;
        try {
            new ObjectId(id);
            return true;
        }
        catch {
            return false;
        }
    }
    toExtendedJSON() {
        if (this.toHexString)
            return { $oid: this.toHexString() };
        return { $oid: this.toString('hex') };
    }
    static fromExtendedJSON(doc) {
        return new ObjectId(doc.$oid);
    }
    inspect(depth, options, inspect) {
        inspect ??= defaultInspect;
        return `new ObjectId(${inspect(this.toHexString(), options)})`;
    }
}
ObjectId.index = Math.floor(Math.random() * 0xffffff);

function internalCalculateObjectSize(object, serializeFunctions, ignoreUndefined) {
    let totalLength = 4 + 1;
    if (Array.isArray(object)) {
        for (let i = 0; i < object.length; i++) {
            totalLength += calculateElement(i.toString(), object[i], serializeFunctions, true, ignoreUndefined);
        }
    }
    else {
        if (typeof object?.toBSON === 'function') {
            object = object.toBSON();
        }
        for (const key of Object.keys(object)) {
            totalLength += calculateElement(key, object[key], serializeFunctions, false, ignoreUndefined);
        }
    }
    return totalLength;
}
function calculateElement(name, value, serializeFunctions = false, isArray = false, ignoreUndefined = false) {
    if (typeof value?.toBSON === 'function') {
        value = value.toBSON();
    }
    switch (typeof value) {
        case 'string':
            return 1 + ByteUtils.utf8ByteLength(name) + 1 + 4 + ByteUtils.utf8ByteLength(value) + 1;
        case 'number':
            if (Math.floor(value) === value &&
                value >= JS_INT_MIN &&
                value <= JS_INT_MAX) {
                if (value >= BSON_INT32_MIN && value <= BSON_INT32_MAX) {
                    return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (4 + 1);
                }
                else {
                    return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);
                }
            }
            else {
                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);
            }
        case 'undefined':
            if (isArray || !ignoreUndefined)
                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + 1;
            return 0;
        case 'boolean':
            return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (1 + 1);
        case 'object':
            if (value != null &&
                typeof value._bsontype === 'string' &&
                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {
                throw new BSONVersionError();
            }
            else if (value == null || value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {
                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + 1;
            }
            else if (value._bsontype === 'ObjectId') {
                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (12 + 1);
            }
            else if (value instanceof Date || isDate(value)) {
                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);
            }
            else if (ArrayBuffer.isView(value) ||
                value instanceof ArrayBuffer ||
                isAnyArrayBuffer(value)) {
                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (1 + 4 + 1) + value.byteLength);
            }
            else if (value._bsontype === 'Long' ||
                value._bsontype === 'Double' ||
                value._bsontype === 'Timestamp') {
                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);
            }
            else if (value._bsontype === 'Decimal128') {
                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (16 + 1);
            }
            else if (value._bsontype === 'Code') {
                if (value.scope != null && Object.keys(value.scope).length > 0) {
                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
                        1 +
                        4 +
                        4 +
                        ByteUtils.utf8ByteLength(value.code.toString()) +
                        1 +
                        internalCalculateObjectSize(value.scope, serializeFunctions, ignoreUndefined));
                }
                else {
                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
                        1 +
                        4 +
                        ByteUtils.utf8ByteLength(value.code.toString()) +
                        1);
                }
            }
            else if (value._bsontype === 'Binary') {
                const binary = value;
                if (binary.sub_type === Binary.SUBTYPE_BYTE_ARRAY) {
                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
                        (binary.position + 1 + 4 + 1 + 4));
                }
                else {
                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (binary.position + 1 + 4 + 1));
                }
            }
            else if (value._bsontype === 'Symbol') {
                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
                    ByteUtils.utf8ByteLength(value.value) +
                    4 +
                    1 +
                    1);
            }
            else if (value._bsontype === 'DBRef') {
                const ordered_values = Object.assign({
                    $ref: value.collection,
                    $id: value.oid
                }, value.fields);
                if (value.db != null) {
                    ordered_values['$db'] = value.db;
                }
                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
                    1 +
                    internalCalculateObjectSize(ordered_values, serializeFunctions, ignoreUndefined));
            }
            else if (value instanceof RegExp || isRegExp(value)) {
                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
                    1 +
                    ByteUtils.utf8ByteLength(value.source) +
                    1 +
                    (value.global ? 1 : 0) +
                    (value.ignoreCase ? 1 : 0) +
                    (value.multiline ? 1 : 0) +
                    1);
            }
            else if (value._bsontype === 'BSONRegExp') {
                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
                    1 +
                    ByteUtils.utf8ByteLength(value.pattern) +
                    1 +
                    ByteUtils.utf8ByteLength(value.options) +
                    1);
            }
            else {
                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
                    internalCalculateObjectSize(value, serializeFunctions, ignoreUndefined) +
                    1);
            }
        case 'function':
            if (serializeFunctions) {
                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +
                    1 +
                    4 +
                    ByteUtils.utf8ByteLength(value.toString()) +
                    1);
            }
    }
    return 0;
}

function alphabetize(str) {
    return str.split('').sort().join('');
}
class BSONRegExp extends BSONValue {
    get _bsontype() {
        return 'BSONRegExp';
    }
    constructor(pattern, options) {
        super();
        this.pattern = pattern;
        this.options = alphabetize(options ?? '');
        if (this.pattern.indexOf('\x00') !== -1) {
            throw new BSONError(`BSON Regex patterns cannot contain null bytes, found: ${JSON.stringify(this.pattern)}`);
        }
        if (this.options.indexOf('\x00') !== -1) {
            throw new BSONError(`BSON Regex options cannot contain null bytes, found: ${JSON.stringify(this.options)}`);
        }
        for (let i = 0; i < this.options.length; i++) {
            if (!(this.options[i] === 'i' ||
                this.options[i] === 'm' ||
                this.options[i] === 'x' ||
                this.options[i] === 'l' ||
                this.options[i] === 's' ||
                this.options[i] === 'u')) {
                throw new BSONError(`The regular expression option [${this.options[i]}] is not supported`);
            }
        }
    }
    static parseOptions(options) {
        return options ? options.split('').sort().join('') : '';
    }
    toExtendedJSON(options) {
        options = options || {};
        if (options.legacy) {
            return { $regex: this.pattern, $options: this.options };
        }
        return { $regularExpression: { pattern: this.pattern, options: this.options } };
    }
    static fromExtendedJSON(doc) {
        if ('$regex' in doc) {
            if (typeof doc.$regex !== 'string') {
                if (doc.$regex._bsontype === 'BSONRegExp') {
                    return doc;
                }
            }
            else {
                return new BSONRegExp(doc.$regex, BSONRegExp.parseOptions(doc.$options));
            }
        }
        if ('$regularExpression' in doc) {
            return new BSONRegExp(doc.$regularExpression.pattern, BSONRegExp.parseOptions(doc.$regularExpression.options));
        }
        throw new BSONError(`Unexpected BSONRegExp EJSON object form: ${JSON.stringify(doc)}`);
    }
    inspect(depth, options, inspect) {
        const stylize = getStylizeFunction(options) ?? (v => v);
        inspect ??= defaultInspect;
        const pattern = stylize(inspect(this.pattern), 'regexp');
        const flags = stylize(inspect(this.options), 'regexp');
        return `new BSONRegExp(${pattern}, ${flags})`;
    }
}

class BSONSymbol extends BSONValue {
    get _bsontype() {
        return 'BSONSymbol';
    }
    constructor(value) {
        super();
        this.value = value;
    }
    valueOf() {
        return this.value;
    }
    toString() {
        return this.value;
    }
    toJSON() {
        return this.value;
    }
    toExtendedJSON() {
        return { $symbol: this.value };
    }
    static fromExtendedJSON(doc) {
        return new BSONSymbol(doc.$symbol);
    }
    inspect(depth, options, inspect) {
        inspect ??= defaultInspect;
        return `new BSONSymbol(${inspect(this.value, options)})`;
    }
}

const LongWithoutOverridesClass = Long;
class Timestamp extends LongWithoutOverridesClass {
    get _bsontype() {
        return 'Timestamp';
    }
    constructor(low) {
        if (low == null) {
            super(0, 0, true);
        }
        else if (typeof low === 'bigint') {
            super(low, true);
        }
        else if (Long.isLong(low)) {
            super(low.low, low.high, true);
        }
        else if (typeof low === 'object' && 't' in low && 'i' in low) {
            if (typeof low.t !== 'number' && (typeof low.t !== 'object' || low.t._bsontype !== 'Int32')) {
                throw new BSONError('Timestamp constructed from { t, i } must provide t as a number');
            }
            if (typeof low.i !== 'number' && (typeof low.i !== 'object' || low.i._bsontype !== 'Int32')) {
                throw new BSONError('Timestamp constructed from { t, i } must provide i as a number');
            }
            const t = Number(low.t);
            const i = Number(low.i);
            if (t < 0 || Number.isNaN(t)) {
                throw new BSONError('Timestamp constructed from { t, i } must provide a positive t');
            }
            if (i < 0 || Number.isNaN(i)) {
                throw new BSONError('Timestamp constructed from { t, i } must provide a positive i');
            }
            if (t > 4294967295) {
                throw new BSONError('Timestamp constructed from { t, i } must provide t equal or less than uint32 max');
            }
            if (i > 4294967295) {
                throw new BSONError('Timestamp constructed from { t, i } must provide i equal or less than uint32 max');
            }
            super(i, t, true);
        }
        else {
            throw new BSONError('A Timestamp can only be constructed with: bigint, Long, or { t: number; i: number }');
        }
    }
    toJSON() {
        return {
            $timestamp: this.toString()
        };
    }
    static fromInt(value) {
        return new Timestamp(Long.fromInt(value, true));
    }
    static fromNumber(value) {
        return new Timestamp(Long.fromNumber(value, true));
    }
    static fromBits(lowBits, highBits) {
        return new Timestamp({ i: lowBits, t: highBits });
    }
    static fromString(str, optRadix) {
        return new Timestamp(Long.fromString(str, true, optRadix));
    }
    toExtendedJSON() {
        return { $timestamp: { t: this.high >>> 0, i: this.low >>> 0 } };
    }
    static fromExtendedJSON(doc) {
        const i = Long.isLong(doc.$timestamp.i)
            ? doc.$timestamp.i.getLowBitsUnsigned()
            : doc.$timestamp.i;
        const t = Long.isLong(doc.$timestamp.t)
            ? doc.$timestamp.t.getLowBitsUnsigned()
            : doc.$timestamp.t;
        return new Timestamp({ t, i });
    }
    inspect(depth, options, inspect) {
        inspect ??= defaultInspect;
        const t = inspect(this.high >>> 0, options);
        const i = inspect(this.low >>> 0, options);
        return `new Timestamp({ t: ${t}, i: ${i} })`;
    }
}
Timestamp.MAX_VALUE = Long.MAX_UNSIGNED_VALUE;

const JS_INT_MAX_LONG = Long.fromNumber(JS_INT_MAX);
const JS_INT_MIN_LONG = Long.fromNumber(JS_INT_MIN);
function internalDeserialize(buffer, options, isArray) {
    options = options == null ? {} : options;
    const index = options && options.index ? options.index : 0;
    const size = NumberUtils.getInt32LE(buffer, index);
    if (size < 5) {
        throw new BSONError(`bson size must be >= 5, is ${size}`);
    }
    if (options.allowObjectSmallerThanBufferSize && buffer.length < size) {
        throw new BSONError(`buffer length ${buffer.length} must be >= bson size ${size}`);
    }
    if (!options.allowObjectSmallerThanBufferSize && buffer.length !== size) {
        throw new BSONError(`buffer length ${buffer.length} must === bson size ${size}`);
    }
    if (size + index > buffer.byteLength) {
        throw new BSONError(`(bson size ${size} + options.index ${index} must be <= buffer length ${buffer.byteLength})`);
    }
    if (buffer[index + size - 1] !== 0) {
        throw new BSONError("One object, sized correctly, with a spot for an EOO, but the EOO isn't 0x00");
    }
    return deserializeObject(buffer, index, options, isArray);
}
const allowedDBRefKeys = /^\$ref$|^\$id$|^\$db$/;
function deserializeObject(buffer, index, options, isArray = false) {
    const fieldsAsRaw = options['fieldsAsRaw'] == null ? null : options['fieldsAsRaw'];
    const raw = options['raw'] == null ? false : options['raw'];
    const bsonRegExp = typeof options['bsonRegExp'] === 'boolean' ? options['bsonRegExp'] : false;
    const promoteBuffers = options.promoteBuffers ?? false;
    const promoteLongs = options.promoteLongs ?? true;
    const promoteValues = options.promoteValues ?? true;
    const useBigInt64 = options.useBigInt64 ?? false;
    if (useBigInt64 && !promoteValues) {
        throw new BSONError('Must either request bigint or Long for int64 deserialization');
    }
    if (useBigInt64 && !promoteLongs) {
        throw new BSONError('Must either request bigint or Long for int64 deserialization');
    }
    const validation = options.validation == null ? { utf8: true } : options.validation;
    let globalUTFValidation = true;
    let validationSetting;
    let utf8KeysSet;
    const utf8ValidatedKeys = validation.utf8;
    if (typeof utf8ValidatedKeys === 'boolean') {
        validationSetting = utf8ValidatedKeys;
    }
    else {
        globalUTFValidation = false;
        const utf8ValidationValues = Object.keys(utf8ValidatedKeys).map(function (key) {
            return utf8ValidatedKeys[key];
        });
        if (utf8ValidationValues.length === 0) {
            throw new BSONError('UTF-8 validation setting cannot be empty');
        }
        if (typeof utf8ValidationValues[0] !== 'boolean') {
            throw new BSONError('Invalid UTF-8 validation option, must specify boolean values');
        }
        validationSetting = utf8ValidationValues[0];
        if (!utf8ValidationValues.every(item => item === validationSetting)) {
            throw new BSONError('Invalid UTF-8 validation option - keys must be all true or all false');
        }
    }
    if (!globalUTFValidation) {
        utf8KeysSet = new Set();
        for (const key of Object.keys(utf8ValidatedKeys)) {
            utf8KeysSet.add(key);
        }
    }
    const startIndex = index;
    if (buffer.length < 5)
        throw new BSONError('corrupt bson message < 5 bytes long');
    const size = NumberUtils.getInt32LE(buffer, index);
    index += 4;
    if (size < 5 || size > buffer.length)
        throw new BSONError('corrupt bson message');
    const object = isArray ? [] : {};
    let arrayIndex = 0;
    const done = false;
    let isPossibleDBRef = isArray ? false : null;
    while (!done) {
        const elementType = buffer[index++];
        if (elementType === 0)
            break;
        let i = index;
        while (buffer[i] !== 0x00 && i < buffer.length) {
            i++;
        }
        if (i >= buffer.byteLength)
            throw new BSONError('Bad BSON Document: illegal CString');
        const name = isArray ? arrayIndex++ : ByteUtils.toUTF8(buffer, index, i, false);
        let shouldValidateKey = true;
        if (globalUTFValidation || utf8KeysSet?.has(name)) {
            shouldValidateKey = validationSetting;
        }
        else {
            shouldValidateKey = !validationSetting;
        }
        if (isPossibleDBRef !== false && name[0] === '$') {
            isPossibleDBRef = allowedDBRefKeys.test(name);
        }
        let value;
        index = i + 1;
        if (elementType === BSON_DATA_STRING) {
            const stringSize = NumberUtils.getInt32LE(buffer, index);
            index += 4;
            if (stringSize <= 0 ||
                stringSize > buffer.length - index ||
                buffer[index + stringSize - 1] !== 0) {
                throw new BSONError('bad string length in bson');
            }
            value = ByteUtils.toUTF8(buffer, index, index + stringSize - 1, shouldValidateKey);
            index = index + stringSize;
        }
        else if (elementType === BSON_DATA_OID) {
            const oid = ByteUtils.allocateUnsafe(12);
            for (let i = 0; i < 12; i++)
                oid[i] = buffer[index + i];
            value = new ObjectId(oid);
            index = index + 12;
        }
        else if (elementType === BSON_DATA_INT && promoteValues === false) {
            value = new Int32(NumberUtils.getInt32LE(buffer, index));
            index += 4;
        }
        else if (elementType === BSON_DATA_INT) {
            value = NumberUtils.getInt32LE(buffer, index);
            index += 4;
        }
        else if (elementType === BSON_DATA_NUMBER) {
            value = NumberUtils.getFloat64LE(buffer, index);
            index += 8;
            if (promoteValues === false)
                value = new Double(value);
        }
        else if (elementType === BSON_DATA_DATE) {
            const lowBits = NumberUtils.getInt32LE(buffer, index);
            const highBits = NumberUtils.getInt32LE(buffer, index + 4);
            index += 8;
            value = new Date(new Long(lowBits, highBits).toNumber());
        }
        else if (elementType === BSON_DATA_BOOLEAN) {
            if (buffer[index] !== 0 && buffer[index] !== 1)
                throw new BSONError('illegal boolean type value');
            value = buffer[index++] === 1;
        }
        else if (elementType === BSON_DATA_OBJECT) {
            const _index = index;
            const objectSize = NumberUtils.getInt32LE(buffer, index);
            if (objectSize <= 0 || objectSize > buffer.length - index)
                throw new BSONError('bad embedded document length in bson');
            if (raw) {
                value = buffer.slice(index, index + objectSize);
            }
            else {
                let objectOptions = options;
                if (!globalUTFValidation) {
                    objectOptions = { ...options, validation: { utf8: shouldValidateKey } };
                }
                value = deserializeObject(buffer, _index, objectOptions, false);
            }
            index = index + objectSize;
        }
        else if (elementType === BSON_DATA_ARRAY) {
            const _index = index;
            const objectSize = NumberUtils.getInt32LE(buffer, index);
            let arrayOptions = options;
            const stopIndex = index + objectSize;
            if (fieldsAsRaw && fieldsAsRaw[name]) {
                arrayOptions = { ...options, raw: true };
            }
            if (!globalUTFValidation) {
                arrayOptions = { ...arrayOptions, validation: { utf8: shouldValidateKey } };
            }
            value = deserializeObject(buffer, _index, arrayOptions, true);
            index = index + objectSize;
            if (buffer[index - 1] !== 0)
                throw new BSONError('invalid array terminator byte');
            if (index !== stopIndex)
                throw new BSONError('corrupted array bson');
        }
        else if (elementType === BSON_DATA_UNDEFINED) {
            value = undefined;
        }
        else if (elementType === BSON_DATA_NULL) {
            value = null;
        }
        else if (elementType === BSON_DATA_LONG) {
            if (useBigInt64) {
                value = NumberUtils.getBigInt64LE(buffer, index);
                index += 8;
            }
            else {
                const lowBits = NumberUtils.getInt32LE(buffer, index);
                const highBits = NumberUtils.getInt32LE(buffer, index + 4);
                index += 8;
                const long = new Long(lowBits, highBits);
                if (promoteLongs && promoteValues === true) {
                    value =
                        long.lessThanOrEqual(JS_INT_MAX_LONG) && long.greaterThanOrEqual(JS_INT_MIN_LONG)
                            ? long.toNumber()
                            : long;
                }
                else {
                    value = long;
                }
            }
        }
        else if (elementType === BSON_DATA_DECIMAL128) {
            const bytes = ByteUtils.allocateUnsafe(16);
            for (let i = 0; i < 16; i++)
                bytes[i] = buffer[index + i];
            index = index + 16;
            value = new Decimal128(bytes);
        }
        else if (elementType === BSON_DATA_BINARY) {
            let binarySize = NumberUtils.getInt32LE(buffer, index);
            index += 4;
            const totalBinarySize = binarySize;
            const subType = buffer[index++];
            if (binarySize < 0)
                throw new BSONError('Negative binary type element size found');
            if (binarySize > buffer.byteLength)
                throw new BSONError('Binary type size larger than document size');
            if (buffer['slice'] != null) {
                if (subType === Binary.SUBTYPE_BYTE_ARRAY) {
                    binarySize = NumberUtils.getInt32LE(buffer, index);
                    index += 4;
                    if (binarySize < 0)
                        throw new BSONError('Negative binary type element size found for subtype 0x02');
                    if (binarySize > totalBinarySize - 4)
                        throw new BSONError('Binary type with subtype 0x02 contains too long binary size');
                    if (binarySize < totalBinarySize - 4)
                        throw new BSONError('Binary type with subtype 0x02 contains too short binary size');
                }
                if (promoteBuffers && promoteValues) {
                    value = ByteUtils.toLocalBufferType(buffer.slice(index, index + binarySize));
                }
                else {
                    value = new Binary(buffer.slice(index, index + binarySize), subType);
                    if (subType === BSON_BINARY_SUBTYPE_UUID_NEW && UUID.isValid(value)) {
                        value = value.toUUID();
                    }
                }
            }
            else {
                if (subType === Binary.SUBTYPE_BYTE_ARRAY) {
                    binarySize = NumberUtils.getInt32LE(buffer, index);
                    index += 4;
                    if (binarySize < 0)
                        throw new BSONError('Negative binary type element size found for subtype 0x02');
                    if (binarySize > totalBinarySize - 4)
                        throw new BSONError('Binary type with subtype 0x02 contains too long binary size');
                    if (binarySize < totalBinarySize - 4)
                        throw new BSONError('Binary type with subtype 0x02 contains too short binary size');
                }
                if (promoteBuffers && promoteValues) {
                    value = ByteUtils.allocateUnsafe(binarySize);
                    for (i = 0; i < binarySize; i++) {
                        value[i] = buffer[index + i];
                    }
                }
                else {
                    value = new Binary(buffer.slice(index, index + binarySize), subType);
                    if (subType === BSON_BINARY_SUBTYPE_UUID_NEW && UUID.isValid(value)) {
                        value = value.toUUID();
                    }
                }
            }
            index = index + binarySize;
        }
        else if (elementType === BSON_DATA_REGEXP && bsonRegExp === false) {
            i = index;
            while (buffer[i] !== 0x00 && i < buffer.length) {
                i++;
            }
            if (i >= buffer.length)
                throw new BSONError('Bad BSON Document: illegal CString');
            const source = ByteUtils.toUTF8(buffer, index, i, false);
            index = i + 1;
            i = index;
            while (buffer[i] !== 0x00 && i < buffer.length) {
                i++;
            }
            if (i >= buffer.length)
                throw new BSONError('Bad BSON Document: illegal CString');
            const regExpOptions = ByteUtils.toUTF8(buffer, index, i, false);
            index = i + 1;
            const optionsArray = new Array(regExpOptions.length);
            for (i = 0; i < regExpOptions.length; i++) {
                switch (regExpOptions[i]) {
                    case 'm':
                        optionsArray[i] = 'm';
                        break;
                    case 's':
                        optionsArray[i] = 'g';
                        break;
                    case 'i':
                        optionsArray[i] = 'i';
                        break;
                }
            }
            value = new RegExp(source, optionsArray.join(''));
        }
        else if (elementType === BSON_DATA_REGEXP && bsonRegExp === true) {
            i = index;
            while (buffer[i] !== 0x00 && i < buffer.length) {
                i++;
            }
            if (i >= buffer.length)
                throw new BSONError('Bad BSON Document: illegal CString');
            const source = ByteUtils.toUTF8(buffer, index, i, false);
            index = i + 1;
            i = index;
            while (buffer[i] !== 0x00 && i < buffer.length) {
                i++;
            }
            if (i >= buffer.length)
                throw new BSONError('Bad BSON Document: illegal CString');
            const regExpOptions = ByteUtils.toUTF8(buffer, index, i, false);
            index = i + 1;
            value = new BSONRegExp(source, regExpOptions);
        }
        else if (elementType === BSON_DATA_SYMBOL) {
            const stringSize = NumberUtils.getInt32LE(buffer, index);
            index += 4;
            if (stringSize <= 0 ||
                stringSize > buffer.length - index ||
                buffer[index + stringSize - 1] !== 0) {
                throw new BSONError('bad string length in bson');
            }
            const symbol = ByteUtils.toUTF8(buffer, index, index + stringSize - 1, shouldValidateKey);
            value = promoteValues ? symbol : new BSONSymbol(symbol);
            index = index + stringSize;
        }
        else if (elementType === BSON_DATA_TIMESTAMP) {
            value = new Timestamp({
                i: NumberUtils.getUint32LE(buffer, index),
                t: NumberUtils.getUint32LE(buffer, index + 4)
            });
            index += 8;
        }
        else if (elementType === BSON_DATA_MIN_KEY) {
            value = new MinKey();
        }
        else if (elementType === BSON_DATA_MAX_KEY) {
            value = new MaxKey();
        }
        else if (elementType === BSON_DATA_CODE) {
            const stringSize = NumberUtils.getInt32LE(buffer, index);
            index += 4;
            if (stringSize <= 0 ||
                stringSize > buffer.length - index ||
                buffer[index + stringSize - 1] !== 0) {
                throw new BSONError('bad string length in bson');
            }
            const functionString = ByteUtils.toUTF8(buffer, index, index + stringSize - 1, shouldValidateKey);
            value = new Code(functionString);
            index = index + stringSize;
        }
        else if (elementType === BSON_DATA_CODE_W_SCOPE) {
            const totalSize = NumberUtils.getInt32LE(buffer, index);
            index += 4;
            if (totalSize < 4 + 4 + 4 + 1) {
                throw new BSONError('code_w_scope total size shorter minimum expected length');
            }
            const stringSize = NumberUtils.getInt32LE(buffer, index);
            index += 4;
            if (stringSize <= 0 ||
                stringSize > buffer.length - index ||
                buffer[index + stringSize - 1] !== 0) {
                throw new BSONError('bad string length in bson');
            }
            const functionString = ByteUtils.toUTF8(buffer, index, index + stringSize - 1, shouldValidateKey);
            index = index + stringSize;
            const _index = index;
            const objectSize = NumberUtils.getInt32LE(buffer, index);
            const scopeObject = deserializeObject(buffer, _index, options, false);
            index = index + objectSize;
            if (totalSize < 4 + 4 + objectSize + stringSize) {
                throw new BSONError('code_w_scope total size is too short, truncating scope');
            }
            if (totalSize > 4 + 4 + objectSize + stringSize) {
                throw new BSONError('code_w_scope total size is too long, clips outer document');
            }
            value = new Code(functionString, scopeObject);
        }
        else if (elementType === BSON_DATA_DBPOINTER) {
            const stringSize = NumberUtils.getInt32LE(buffer, index);
            index += 4;
            if (stringSize <= 0 ||
                stringSize > buffer.length - index ||
                buffer[index + stringSize - 1] !== 0)
                throw new BSONError('bad string length in bson');
            const namespace = ByteUtils.toUTF8(buffer, index, index + stringSize - 1, shouldValidateKey);
            index = index + stringSize;
            const oidBuffer = ByteUtils.allocateUnsafe(12);
            for (let i = 0; i < 12; i++)
                oidBuffer[i] = buffer[index + i];
            const oid = new ObjectId(oidBuffer);
            index = index + 12;
            value = new DBRef(namespace, oid);
        }
        else {
            throw new BSONError(`Detected unknown BSON type ${elementType.toString(16)} for fieldname "${name}"`);
        }
        if (name === '__proto__') {
            Object.defineProperty(object, name, {
                value,
                writable: true,
                enumerable: true,
                configurable: true
            });
        }
        else {
            object[name] = value;
        }
    }
    if (size !== index - startIndex) {
        if (isArray)
            throw new BSONError('corrupt array bson');
        throw new BSONError('corrupt object bson');
    }
    if (!isPossibleDBRef)
        return object;
    if (isDBRefLike(object)) {
        const copy = Object.assign({}, object);
        delete copy.$ref;
        delete copy.$id;
        delete copy.$db;
        return new DBRef(object.$ref, object.$id, object.$db, copy);
    }
    return object;
}

const regexp = /\x00/;
const ignoreKeys = new Set(['$db', '$ref', '$id', '$clusterTime']);
function serializeString(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_STRING;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes + 1;
    buffer[index - 1] = 0;
    const size = ByteUtils.encodeUTF8Into(buffer, value, index + 4);
    NumberUtils.setInt32LE(buffer, index, size + 1);
    index = index + 4 + size;
    buffer[index++] = 0;
    return index;
}
function serializeNumber(buffer, key, value, index) {
    const isNegativeZero = Object.is(value, -0);
    const type = !isNegativeZero &&
        Number.isSafeInteger(value) &&
        value <= BSON_INT32_MAX &&
        value >= BSON_INT32_MIN
        ? BSON_DATA_INT
        : BSON_DATA_NUMBER;
    buffer[index++] = type;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0x00;
    if (type === BSON_DATA_INT) {
        index += NumberUtils.setInt32LE(buffer, index, value);
    }
    else {
        index += NumberUtils.setFloat64LE(buffer, index, value);
    }
    return index;
}
function serializeBigInt(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_LONG;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index += numberOfWrittenBytes;
    buffer[index++] = 0;
    index += NumberUtils.setBigInt64LE(buffer, index, value);
    return index;
}
function serializeNull(buffer, key, _, index) {
    buffer[index++] = BSON_DATA_NULL;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    return index;
}
function serializeBoolean(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_BOOLEAN;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    buffer[index++] = value ? 1 : 0;
    return index;
}
function serializeDate(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_DATE;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    const dateInMilis = Long.fromNumber(value.getTime());
    const lowBits = dateInMilis.getLowBits();
    const highBits = dateInMilis.getHighBits();
    index += NumberUtils.setInt32LE(buffer, index, lowBits);
    index += NumberUtils.setInt32LE(buffer, index, highBits);
    return index;
}
function serializeRegExp(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_REGEXP;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    if (value.source && value.source.match(regexp) != null) {
        throw new BSONError('value ' + value.source + ' must not contain null bytes');
    }
    index = index + ByteUtils.encodeUTF8Into(buffer, value.source, index);
    buffer[index++] = 0x00;
    if (value.ignoreCase)
        buffer[index++] = 0x69;
    if (value.global)
        buffer[index++] = 0x73;
    if (value.multiline)
        buffer[index++] = 0x6d;
    buffer[index++] = 0x00;
    return index;
}
function serializeBSONRegExp(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_REGEXP;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    if (value.pattern.match(regexp) != null) {
        throw new BSONError('pattern ' + value.pattern + ' must not contain null bytes');
    }
    index = index + ByteUtils.encodeUTF8Into(buffer, value.pattern, index);
    buffer[index++] = 0x00;
    const sortedOptions = value.options.split('').sort().join('');
    index = index + ByteUtils.encodeUTF8Into(buffer, sortedOptions, index);
    buffer[index++] = 0x00;
    return index;
}
function serializeMinMax(buffer, key, value, index) {
    if (value === null) {
        buffer[index++] = BSON_DATA_NULL;
    }
    else if (value._bsontype === 'MinKey') {
        buffer[index++] = BSON_DATA_MIN_KEY;
    }
    else {
        buffer[index++] = BSON_DATA_MAX_KEY;
    }
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    return index;
}
function serializeObjectId(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_OID;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    index += value.serializeInto(buffer, index);
    return index;
}
function serializeBuffer(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_BINARY;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    const size = value.length;
    index += NumberUtils.setInt32LE(buffer, index, size);
    buffer[index++] = BSON_BINARY_SUBTYPE_DEFAULT;
    if (size <= 16) {
        for (let i = 0; i < size; i++)
            buffer[index + i] = value[i];
    }
    else {
        buffer.set(value, index);
    }
    index = index + size;
    return index;
}
function serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path) {
    if (path.has(value)) {
        throw new BSONError('Cannot convert circular structure to BSON');
    }
    path.add(value);
    buffer[index++] = Array.isArray(value) ? BSON_DATA_ARRAY : BSON_DATA_OBJECT;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    const endIndex = serializeInto(buffer, value, checkKeys, index, depth + 1, serializeFunctions, ignoreUndefined, path);
    path.delete(value);
    return endIndex;
}
function serializeDecimal128(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_DECIMAL128;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    for (let i = 0; i < 16; i++)
        buffer[index + i] = value.bytes[i];
    return index + 16;
}
function serializeLong(buffer, key, value, index) {
    buffer[index++] =
        value._bsontype === 'Long' ? BSON_DATA_LONG : BSON_DATA_TIMESTAMP;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    const lowBits = value.getLowBits();
    const highBits = value.getHighBits();
    index += NumberUtils.setInt32LE(buffer, index, lowBits);
    index += NumberUtils.setInt32LE(buffer, index, highBits);
    return index;
}
function serializeInt32(buffer, key, value, index) {
    value = value.valueOf();
    buffer[index++] = BSON_DATA_INT;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    index += NumberUtils.setInt32LE(buffer, index, value);
    return index;
}
function serializeDouble(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_NUMBER;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    index += NumberUtils.setFloat64LE(buffer, index, value.value);
    return index;
}
function serializeFunction(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_CODE;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    const functionString = value.toString();
    const size = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;
    NumberUtils.setInt32LE(buffer, index, size);
    index = index + 4 + size - 1;
    buffer[index++] = 0;
    return index;
}
function serializeCode(buffer, key, value, index, checkKeys = false, depth = 0, serializeFunctions = false, ignoreUndefined = true, path) {
    if (value.scope && typeof value.scope === 'object') {
        buffer[index++] = BSON_DATA_CODE_W_SCOPE;
        const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
        index = index + numberOfWrittenBytes;
        buffer[index++] = 0;
        let startIndex = index;
        const functionString = value.code;
        index = index + 4;
        const codeSize = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;
        NumberUtils.setInt32LE(buffer, index, codeSize);
        buffer[index + 4 + codeSize - 1] = 0;
        index = index + codeSize + 4;
        const endIndex = serializeInto(buffer, value.scope, checkKeys, index, depth + 1, serializeFunctions, ignoreUndefined, path);
        index = endIndex - 1;
        const totalSize = endIndex - startIndex;
        startIndex += NumberUtils.setInt32LE(buffer, startIndex, totalSize);
        buffer[index++] = 0;
    }
    else {
        buffer[index++] = BSON_DATA_CODE;
        const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
        index = index + numberOfWrittenBytes;
        buffer[index++] = 0;
        const functionString = value.code.toString();
        const size = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;
        NumberUtils.setInt32LE(buffer, index, size);
        index = index + 4 + size - 1;
        buffer[index++] = 0;
    }
    return index;
}
function serializeBinary(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_BINARY;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    const data = value.buffer;
    let size = value.position;
    if (value.sub_type === Binary.SUBTYPE_BYTE_ARRAY)
        size = size + 4;
    index += NumberUtils.setInt32LE(buffer, index, size);
    buffer[index++] = value.sub_type;
    if (value.sub_type === Binary.SUBTYPE_BYTE_ARRAY) {
        size = size - 4;
        index += NumberUtils.setInt32LE(buffer, index, size);
    }
    if (size <= 16) {
        for (let i = 0; i < size; i++)
            buffer[index + i] = data[i];
    }
    else {
        buffer.set(data, index);
    }
    index = index + value.position;
    return index;
}
function serializeSymbol(buffer, key, value, index) {
    buffer[index++] = BSON_DATA_SYMBOL;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    const size = ByteUtils.encodeUTF8Into(buffer, value.value, index + 4) + 1;
    NumberUtils.setInt32LE(buffer, index, size);
    index = index + 4 + size - 1;
    buffer[index++] = 0;
    return index;
}
function serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path) {
    buffer[index++] = BSON_DATA_OBJECT;
    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);
    index = index + numberOfWrittenBytes;
    buffer[index++] = 0;
    let startIndex = index;
    let output = {
        $ref: value.collection || value.namespace,
        $id: value.oid
    };
    if (value.db != null) {
        output.$db = value.db;
    }
    output = Object.assign(output, value.fields);
    const endIndex = serializeInto(buffer, output, false, index, depth + 1, serializeFunctions, true, path);
    const size = endIndex - startIndex;
    startIndex += NumberUtils.setInt32LE(buffer, index, size);
    return endIndex;
}
function serializeInto(buffer, object, checkKeys, startingIndex, depth, serializeFunctions, ignoreUndefined, path) {
    if (path == null) {
        if (object == null) {
            buffer[0] = 0x05;
            buffer[1] = 0x00;
            buffer[2] = 0x00;
            buffer[3] = 0x00;
            buffer[4] = 0x00;
            return 5;
        }
        if (Array.isArray(object)) {
            throw new BSONError('serialize does not support an array as the root input');
        }
        if (typeof object !== 'object') {
            throw new BSONError('serialize does not support non-object as the root input');
        }
        else if ('_bsontype' in object && typeof object._bsontype === 'string') {
            throw new BSONError(`BSON types cannot be serialized as a document`);
        }
        else if (isDate(object) ||
            isRegExp(object) ||
            isUint8Array(object) ||
            isAnyArrayBuffer(object)) {
            throw new BSONError(`date, regexp, typedarray, and arraybuffer cannot be BSON documents`);
        }
        path = new Set();
    }
    path.add(object);
    let index = startingIndex + 4;
    if (Array.isArray(object)) {
        for (let i = 0; i < object.length; i++) {
            const key = `${i}`;
            let value = object[i];
            if (typeof value?.toBSON === 'function') {
                value = value.toBSON();
            }
            if (typeof value === 'string') {
                index = serializeString(buffer, key, value, index);
            }
            else if (typeof value === 'number') {
                index = serializeNumber(buffer, key, value, index);
            }
            else if (typeof value === 'bigint') {
                index = serializeBigInt(buffer, key, value, index);
            }
            else if (typeof value === 'boolean') {
                index = serializeBoolean(buffer, key, value, index);
            }
            else if (value instanceof Date || isDate(value)) {
                index = serializeDate(buffer, key, value, index);
            }
            else if (value === undefined) {
                index = serializeNull(buffer, key, value, index);
            }
            else if (value === null) {
                index = serializeNull(buffer, key, value, index);
            }
            else if (isUint8Array(value)) {
                index = serializeBuffer(buffer, key, value, index);
            }
            else if (value instanceof RegExp || isRegExp(value)) {
                index = serializeRegExp(buffer, key, value, index);
            }
            else if (typeof value === 'object' && value._bsontype == null) {
                index = serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);
            }
            else if (typeof value === 'object' &&
                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {
                throw new BSONVersionError();
            }
            else if (value._bsontype === 'ObjectId') {
                index = serializeObjectId(buffer, key, value, index);
            }
            else if (value._bsontype === 'Decimal128') {
                index = serializeDecimal128(buffer, key, value, index);
            }
            else if (value._bsontype === 'Long' || value._bsontype === 'Timestamp') {
                index = serializeLong(buffer, key, value, index);
            }
            else if (value._bsontype === 'Double') {
                index = serializeDouble(buffer, key, value, index);
            }
            else if (typeof value === 'function' && serializeFunctions) {
                index = serializeFunction(buffer, key, value, index);
            }
            else if (value._bsontype === 'Code') {
                index = serializeCode(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);
            }
            else if (value._bsontype === 'Binary') {
                index = serializeBinary(buffer, key, value, index);
            }
            else if (value._bsontype === 'BSONSymbol') {
                index = serializeSymbol(buffer, key, value, index);
            }
            else if (value._bsontype === 'DBRef') {
                index = serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path);
            }
            else if (value._bsontype === 'BSONRegExp') {
                index = serializeBSONRegExp(buffer, key, value, index);
            }
            else if (value._bsontype === 'Int32') {
                index = serializeInt32(buffer, key, value, index);
            }
            else if (value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {
                index = serializeMinMax(buffer, key, value, index);
            }
            else if (typeof value._bsontype !== 'undefined') {
                throw new BSONError(`Unrecognized or invalid _bsontype: ${String(value._bsontype)}`);
            }
        }
    }
    else if (object instanceof Map || isMap$1(object)) {
        const iterator = object.entries();
        let done = false;
        while (!done) {
            const entry = iterator.next();
            done = !!entry.done;
            if (done)
                continue;
            const key = entry.value[0];
            let value = entry.value[1];
            if (typeof value?.toBSON === 'function') {
                value = value.toBSON();
            }
            const type = typeof value;
            if (typeof key === 'string' && !ignoreKeys.has(key)) {
                if (key.match(regexp) != null) {
                    throw new BSONError('key ' + key + ' must not contain null bytes');
                }
                if (checkKeys) {
                    if ('$' === key[0]) {
                        throw new BSONError('key ' + key + " must not start with '$'");
                    }
                    else if (key.includes('.')) {
                        throw new BSONError('key ' + key + " must not contain '.'");
                    }
                }
            }
            if (type === 'string') {
                index = serializeString(buffer, key, value, index);
            }
            else if (type === 'number') {
                index = serializeNumber(buffer, key, value, index);
            }
            else if (type === 'bigint') {
                index = serializeBigInt(buffer, key, value, index);
            }
            else if (type === 'boolean') {
                index = serializeBoolean(buffer, key, value, index);
            }
            else if (value instanceof Date || isDate(value)) {
                index = serializeDate(buffer, key, value, index);
            }
            else if (value === null || (value === undefined && ignoreUndefined === false)) {
                index = serializeNull(buffer, key, value, index);
            }
            else if (isUint8Array(value)) {
                index = serializeBuffer(buffer, key, value, index);
            }
            else if (value instanceof RegExp || isRegExp(value)) {
                index = serializeRegExp(buffer, key, value, index);
            }
            else if (type === 'object' && value._bsontype == null) {
                index = serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);
            }
            else if (typeof value === 'object' &&
                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {
                throw new BSONVersionError();
            }
            else if (value._bsontype === 'ObjectId') {
                index = serializeObjectId(buffer, key, value, index);
            }
            else if (type === 'object' && value._bsontype === 'Decimal128') {
                index = serializeDecimal128(buffer, key, value, index);
            }
            else if (value._bsontype === 'Long' || value._bsontype === 'Timestamp') {
                index = serializeLong(buffer, key, value, index);
            }
            else if (value._bsontype === 'Double') {
                index = serializeDouble(buffer, key, value, index);
            }
            else if (value._bsontype === 'Code') {
                index = serializeCode(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);
            }
            else if (typeof value === 'function' && serializeFunctions) {
                index = serializeFunction(buffer, key, value, index);
            }
            else if (value._bsontype === 'Binary') {
                index = serializeBinary(buffer, key, value, index);
            }
            else if (value._bsontype === 'BSONSymbol') {
                index = serializeSymbol(buffer, key, value, index);
            }
            else if (value._bsontype === 'DBRef') {
                index = serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path);
            }
            else if (value._bsontype === 'BSONRegExp') {
                index = serializeBSONRegExp(buffer, key, value, index);
            }
            else if (value._bsontype === 'Int32') {
                index = serializeInt32(buffer, key, value, index);
            }
            else if (value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {
                index = serializeMinMax(buffer, key, value, index);
            }
            else if (typeof value._bsontype !== 'undefined') {
                throw new BSONError(`Unrecognized or invalid _bsontype: ${String(value._bsontype)}`);
            }
        }
    }
    else {
        if (typeof object?.toBSON === 'function') {
            object = object.toBSON();
            if (object != null && typeof object !== 'object') {
                throw new BSONError('toBSON function did not return an object');
            }
        }
        for (const key of Object.keys(object)) {
            let value = object[key];
            if (typeof value?.toBSON === 'function') {
                value = value.toBSON();
            }
            const type = typeof value;
            if (typeof key === 'string' && !ignoreKeys.has(key)) {
                if (key.match(regexp) != null) {
                    throw new BSONError('key ' + key + ' must not contain null bytes');
                }
                if (checkKeys) {
                    if ('$' === key[0]) {
                        throw new BSONError('key ' + key + " must not start with '$'");
                    }
                    else if (key.includes('.')) {
                        throw new BSONError('key ' + key + " must not contain '.'");
                    }
                }
            }
            if (type === 'string') {
                index = serializeString(buffer, key, value, index);
            }
            else if (type === 'number') {
                index = serializeNumber(buffer, key, value, index);
            }
            else if (type === 'bigint') {
                index = serializeBigInt(buffer, key, value, index);
            }
            else if (type === 'boolean') {
                index = serializeBoolean(buffer, key, value, index);
            }
            else if (value instanceof Date || isDate(value)) {
                index = serializeDate(buffer, key, value, index);
            }
            else if (value === undefined) {
                if (ignoreUndefined === false)
                    index = serializeNull(buffer, key, value, index);
            }
            else if (value === null) {
                index = serializeNull(buffer, key, value, index);
            }
            else if (isUint8Array(value)) {
                index = serializeBuffer(buffer, key, value, index);
            }
            else if (value instanceof RegExp || isRegExp(value)) {
                index = serializeRegExp(buffer, key, value, index);
            }
            else if (type === 'object' && value._bsontype == null) {
                index = serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);
            }
            else if (typeof value === 'object' &&
                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {
                throw new BSONVersionError();
            }
            else if (value._bsontype === 'ObjectId') {
                index = serializeObjectId(buffer, key, value, index);
            }
            else if (type === 'object' && value._bsontype === 'Decimal128') {
                index = serializeDecimal128(buffer, key, value, index);
            }
            else if (value._bsontype === 'Long' || value._bsontype === 'Timestamp') {
                index = serializeLong(buffer, key, value, index);
            }
            else if (value._bsontype === 'Double') {
                index = serializeDouble(buffer, key, value, index);
            }
            else if (value._bsontype === 'Code') {
                index = serializeCode(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);
            }
            else if (typeof value === 'function' && serializeFunctions) {
                index = serializeFunction(buffer, key, value, index);
            }
            else if (value._bsontype === 'Binary') {
                index = serializeBinary(buffer, key, value, index);
            }
            else if (value._bsontype === 'BSONSymbol') {
                index = serializeSymbol(buffer, key, value, index);
            }
            else if (value._bsontype === 'DBRef') {
                index = serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path);
            }
            else if (value._bsontype === 'BSONRegExp') {
                index = serializeBSONRegExp(buffer, key, value, index);
            }
            else if (value._bsontype === 'Int32') {
                index = serializeInt32(buffer, key, value, index);
            }
            else if (value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {
                index = serializeMinMax(buffer, key, value, index);
            }
            else if (typeof value._bsontype !== 'undefined') {
                throw new BSONError(`Unrecognized or invalid _bsontype: ${String(value._bsontype)}`);
            }
        }
    }
    path.delete(object);
    buffer[index++] = 0x00;
    const size = index - startingIndex;
    startingIndex += NumberUtils.setInt32LE(buffer, startingIndex, size);
    return index;
}

function isBSONType(value) {
    return (value != null &&
        typeof value === 'object' &&
        '_bsontype' in value &&
        typeof value._bsontype === 'string');
}
const keysToCodecs = {
    $oid: ObjectId,
    $binary: Binary,
    $uuid: Binary,
    $symbol: BSONSymbol,
    $numberInt: Int32,
    $numberDecimal: Decimal128,
    $numberDouble: Double,
    $numberLong: Long,
    $minKey: MinKey,
    $maxKey: MaxKey,
    $regex: BSONRegExp,
    $regularExpression: BSONRegExp,
    $timestamp: Timestamp
};
function deserializeValue(value, options = {}) {
    if (typeof value === 'number') {
        const in32BitRange = value <= BSON_INT32_MAX && value >= BSON_INT32_MIN;
        const in64BitRange = value <= BSON_INT64_MAX && value >= BSON_INT64_MIN;
        if (options.relaxed || options.legacy) {
            return value;
        }
        if (Number.isInteger(value) && !Object.is(value, -0)) {
            if (in32BitRange) {
                return new Int32(value);
            }
            if (in64BitRange) {
                if (options.useBigInt64) {
                    return BigInt(value);
                }
                return Long.fromNumber(value);
            }
        }
        return new Double(value);
    }
    if (value == null || typeof value !== 'object')
        return value;
    if (value.$undefined)
        return null;
    const keys = Object.keys(value).filter(k => k.startsWith('$') && value[k] != null);
    for (let i = 0; i < keys.length; i++) {
        const c = keysToCodecs[keys[i]];
        if (c)
            return c.fromExtendedJSON(value, options);
    }
    if (value.$date != null) {
        const d = value.$date;
        const date = new Date();
        if (options.legacy) {
            if (typeof d === 'number')
                date.setTime(d);
            else if (typeof d === 'string')
                date.setTime(Date.parse(d));
            else if (typeof d === 'bigint')
                date.setTime(Number(d));
            else
                throw new BSONRuntimeError(`Unrecognized type for EJSON date: ${typeof d}`);
        }
        else {
            if (typeof d === 'string')
                date.setTime(Date.parse(d));
            else if (Long.isLong(d))
                date.setTime(d.toNumber());
            else if (typeof d === 'number' && options.relaxed)
                date.setTime(d);
            else if (typeof d === 'bigint')
                date.setTime(Number(d));
            else
                throw new BSONRuntimeError(`Unrecognized type for EJSON date: ${typeof d}`);
        }
        return date;
    }
    if (value.$code != null) {
        const copy = Object.assign({}, value);
        if (value.$scope) {
            copy.$scope = deserializeValue(value.$scope);
        }
        return Code.fromExtendedJSON(value);
    }
    if (isDBRefLike(value) || value.$dbPointer) {
        const v = value.$ref ? value : value.$dbPointer;
        if (v instanceof DBRef)
            return v;
        const dollarKeys = Object.keys(v).filter(k => k.startsWith('$'));
        let valid = true;
        dollarKeys.forEach(k => {
            if (['$ref', '$id', '$db'].indexOf(k) === -1)
                valid = false;
        });
        if (valid)
            return DBRef.fromExtendedJSON(v);
    }
    return value;
}
function serializeArray(array, options) {
    return array.map((v, index) => {
        options.seenObjects.push({ propertyName: `index ${index}`, obj: null });
        try {
            return serializeValue(v, options);
        }
        finally {
            options.seenObjects.pop();
        }
    });
}
function getISOString(date) {
    const isoStr = date.toISOString();
    return date.getUTCMilliseconds() !== 0 ? isoStr : isoStr.slice(0, -5) + 'Z';
}
function serializeValue(value, options) {
    if (value instanceof Map || isMap$1(value)) {
        const obj = Object.create(null);
        for (const [k, v] of value) {
            if (typeof k !== 'string') {
                throw new BSONError('Can only serialize maps with string keys');
            }
            obj[k] = v;
        }
        return serializeValue(obj, options);
    }
    if ((typeof value === 'object' || typeof value === 'function') && value !== null) {
        const index = options.seenObjects.findIndex(entry => entry.obj === value);
        if (index !== -1) {
            const props = options.seenObjects.map(entry => entry.propertyName);
            const leadingPart = props
                .slice(0, index)
                .map(prop => `${prop} -> `)
                .join('');
            const alreadySeen = props[index];
            const circularPart = ' -> ' +
                props
                    .slice(index + 1, props.length - 1)
                    .map(prop => `${prop} -> `)
                    .join('');
            const current = props[props.length - 1];
            const leadingSpace = ' '.repeat(leadingPart.length + alreadySeen.length / 2);
            const dashes = '-'.repeat(circularPart.length + (alreadySeen.length + current.length) / 2 - 1);
            throw new BSONError('Converting circular structure to EJSON:\n' +
                `    ${leadingPart}${alreadySeen}${circularPart}${current}\n` +
                `    ${leadingSpace}\\${dashes}/`);
        }
        options.seenObjects[options.seenObjects.length - 1].obj = value;
    }
    if (Array.isArray(value))
        return serializeArray(value, options);
    if (value === undefined)
        return null;
    if (value instanceof Date || isDate(value)) {
        const dateNum = value.getTime(), inRange = dateNum > -1 && dateNum < 253402318800000;
        if (options.legacy) {
            return options.relaxed && inRange
                ? { $date: value.getTime() }
                : { $date: getISOString(value) };
        }
        return options.relaxed && inRange
            ? { $date: getISOString(value) }
            : { $date: { $numberLong: value.getTime().toString() } };
    }
    if (typeof value === 'number' && (!options.relaxed || !isFinite(value))) {
        if (Number.isInteger(value) && !Object.is(value, -0)) {
            if (value >= BSON_INT32_MIN && value <= BSON_INT32_MAX) {
                return { $numberInt: value.toString() };
            }
            if (value >= BSON_INT64_MIN && value <= BSON_INT64_MAX) {
                return { $numberLong: value.toString() };
            }
        }
        return { $numberDouble: Object.is(value, -0) ? '-0.0' : value.toString() };
    }
    if (typeof value === 'bigint') {
        if (!options.relaxed) {
            return { $numberLong: BigInt.asIntN(64, value).toString() };
        }
        return Number(BigInt.asIntN(64, value));
    }
    if (value instanceof RegExp || isRegExp(value)) {
        let flags = value.flags;
        if (flags === undefined) {
            const match = value.toString().match(/[gimuy]*$/);
            if (match) {
                flags = match[0];
            }
        }
        const rx = new BSONRegExp(value.source, flags);
        return rx.toExtendedJSON(options);
    }
    if (value != null && typeof value === 'object')
        return serializeDocument(value, options);
    return value;
}
const BSON_TYPE_MAPPINGS = {
    Binary: (o) => new Binary(o.value(), o.sub_type),
    Code: (o) => new Code(o.code, o.scope),
    DBRef: (o) => new DBRef(o.collection || o.namespace, o.oid, o.db, o.fields),
    Decimal128: (o) => new Decimal128(o.bytes),
    Double: (o) => new Double(o.value),
    Int32: (o) => new Int32(o.value),
    Long: (o) => Long.fromBits(o.low != null ? o.low : o.low_, o.low != null ? o.high : o.high_, o.low != null ? o.unsigned : o.unsigned_),
    MaxKey: () => new MaxKey(),
    MinKey: () => new MinKey(),
    ObjectId: (o) => new ObjectId(o),
    BSONRegExp: (o) => new BSONRegExp(o.pattern, o.options),
    BSONSymbol: (o) => new BSONSymbol(o.value),
    Timestamp: (o) => Timestamp.fromBits(o.low, o.high)
};
function serializeDocument(doc, options) {
    if (doc == null || typeof doc !== 'object')
        throw new BSONError('not an object instance');
    const bsontype = doc._bsontype;
    if (typeof bsontype === 'undefined') {
        const _doc = {};
        for (const name of Object.keys(doc)) {
            options.seenObjects.push({ propertyName: name, obj: null });
            try {
                const value = serializeValue(doc[name], options);
                if (name === '__proto__') {
                    Object.defineProperty(_doc, name, {
                        value,
                        writable: true,
                        enumerable: true,
                        configurable: true
                    });
                }
                else {
                    _doc[name] = value;
                }
            }
            finally {
                options.seenObjects.pop();
            }
        }
        return _doc;
    }
    else if (doc != null &&
        typeof doc === 'object' &&
        typeof doc._bsontype === 'string' &&
        doc[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {
        throw new BSONVersionError();
    }
    else if (isBSONType(doc)) {
        let outDoc = doc;
        if (typeof outDoc.toExtendedJSON !== 'function') {
            const mapper = BSON_TYPE_MAPPINGS[doc._bsontype];
            if (!mapper) {
                throw new BSONError('Unrecognized or invalid _bsontype: ' + doc._bsontype);
            }
            outDoc = mapper(outDoc);
        }
        if (bsontype === 'Code' && outDoc.scope) {
            outDoc = new Code(outDoc.code, serializeValue(outDoc.scope, options));
        }
        else if (bsontype === 'DBRef' && outDoc.oid) {
            outDoc = new DBRef(serializeValue(outDoc.collection, options), serializeValue(outDoc.oid, options), serializeValue(outDoc.db, options), serializeValue(outDoc.fields, options));
        }
        return outDoc.toExtendedJSON(options);
    }
    else {
        throw new BSONError('_bsontype must be a string, but was: ' + typeof bsontype);
    }
}
function parse$2(text, options) {
    const ejsonOptions = {
        useBigInt64: options?.useBigInt64 ?? false,
        relaxed: options?.relaxed ?? true,
        legacy: options?.legacy ?? false
    };
    return JSON.parse(text, (key, value) => {
        if (key.indexOf('\x00') !== -1) {
            throw new BSONError(`BSON Document field names cannot contain null bytes, found: ${JSON.stringify(key)}`);
        }
        return deserializeValue(value, ejsonOptions);
    });
}
function stringify$2(value, replacer, space, options) {
    if (space != null && typeof space === 'object') {
        options = space;
        space = 0;
    }
    if (replacer != null && typeof replacer === 'object' && !Array.isArray(replacer)) {
        options = replacer;
        replacer = undefined;
        space = 0;
    }
    const serializeOptions = Object.assign({ relaxed: true, legacy: false }, options, {
        seenObjects: [{ propertyName: '(root)', obj: null }]
    });
    const doc = serializeValue(value, serializeOptions);
    return JSON.stringify(doc, replacer, space);
}
function EJSONserialize(value, options) {
    options = options || {};
    return JSON.parse(stringify$2(value, options));
}
function EJSONdeserialize(ejson, options) {
    options = options || {};
    return parse$2(JSON.stringify(ejson), options);
}
const EJSON = Object.create(null);
EJSON.parse = parse$2;
EJSON.stringify = stringify$2;
EJSON.serialize = EJSONserialize;
EJSON.deserialize = EJSONdeserialize;
Object.freeze(EJSON);

function getSize(source, offset) {
    try {
        return NumberUtils.getNonnegativeInt32LE(source, offset);
    }
    catch (cause) {
        throw new BSONOffsetError('BSON size cannot be negative', offset, { cause });
    }
}
function findNull(bytes, offset) {
    let nullTerminatorOffset = offset;
    for (; bytes[nullTerminatorOffset] !== 0x00; nullTerminatorOffset++)
        ;
    if (nullTerminatorOffset === bytes.length - 1) {
        throw new BSONOffsetError('Null terminator not found', offset);
    }
    return nullTerminatorOffset;
}
function parseToElements(bytes, startOffset = 0) {
    startOffset ??= 0;
    if (bytes.length < 5) {
        throw new BSONOffsetError(`Input must be at least 5 bytes, got ${bytes.length} bytes`, startOffset);
    }
    const documentSize = getSize(bytes, startOffset);
    if (documentSize > bytes.length - startOffset) {
        throw new BSONOffsetError(`Parsed documentSize (${documentSize} bytes) does not match input length (${bytes.length} bytes)`, startOffset);
    }
    if (bytes[startOffset + documentSize - 1] !== 0x00) {
        throw new BSONOffsetError('BSON documents must end in 0x00', startOffset + documentSize);
    }
    const elements = [];
    let offset = startOffset + 4;
    while (offset <= documentSize + startOffset) {
        const type = bytes[offset];
        offset += 1;
        if (type === 0) {
            if (offset - startOffset !== documentSize) {
                throw new BSONOffsetError(`Invalid 0x00 type byte`, offset);
            }
            break;
        }
        const nameOffset = offset;
        const nameLength = findNull(bytes, offset) - nameOffset;
        offset += nameLength + 1;
        let length;
        if (type === 1 ||
            type === 18 ||
            type === 9 ||
            type === 17) {
            length = 8;
        }
        else if (type === 16) {
            length = 4;
        }
        else if (type === 7) {
            length = 12;
        }
        else if (type === 19) {
            length = 16;
        }
        else if (type === 8) {
            length = 1;
        }
        else if (type === 10 ||
            type === 6 ||
            type === 127 ||
            type === 255) {
            length = 0;
        }
        else if (type === 11) {
            length = findNull(bytes, findNull(bytes, offset) + 1) + 1 - offset;
        }
        else if (type === 3 ||
            type === 4 ||
            type === 15) {
            length = getSize(bytes, offset);
        }
        else if (type === 2 ||
            type === 5 ||
            type === 12 ||
            type === 13 ||
            type === 14) {
            length = getSize(bytes, offset) + 4;
            if (type === 5) {
                length += 1;
            }
            if (type === 12) {
                length += 12;
            }
        }
        else {
            throw new BSONOffsetError(`Invalid 0x${type.toString(16).padStart(2, '0')} type byte`, offset);
        }
        if (length > documentSize) {
            throw new BSONOffsetError('value reports length larger than document', offset);
        }
        elements.push([type, nameOffset, nameLength, offset, length]);
        offset += length;
    }
    return elements;
}

const onDemand = Object.create(null);
onDemand.parseToElements = parseToElements;
onDemand.ByteUtils = ByteUtils;
onDemand.NumberUtils = NumberUtils;
Object.freeze(onDemand);

const MAXSIZE = 1024 * 1024 * 17;
let buffer = ByteUtils.allocate(MAXSIZE);
function setInternalBufferSize(size) {
    if (buffer.length < size) {
        buffer = ByteUtils.allocate(size);
    }
}
function serialize(object, options = {}) {
    const checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;
    const serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;
    const ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;
    const minInternalBufferSize = typeof options.minInternalBufferSize === 'number' ? options.minInternalBufferSize : MAXSIZE;
    if (buffer.length < minInternalBufferSize) {
        buffer = ByteUtils.allocate(minInternalBufferSize);
    }
    const serializationIndex = serializeInto(buffer, object, checkKeys, 0, 0, serializeFunctions, ignoreUndefined, null);
    const finishedBuffer = ByteUtils.allocateUnsafe(serializationIndex);
    finishedBuffer.set(buffer.subarray(0, serializationIndex), 0);
    return finishedBuffer;
}
function serializeWithBufferAndIndex(object, finalBuffer, options = {}) {
    const checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;
    const serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;
    const ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;
    const startIndex = typeof options.index === 'number' ? options.index : 0;
    const serializationIndex = serializeInto(buffer, object, checkKeys, 0, 0, serializeFunctions, ignoreUndefined, null);
    finalBuffer.set(buffer.subarray(0, serializationIndex), startIndex);
    return startIndex + serializationIndex - 1;
}
function deserialize(buffer, options = {}) {
    return internalDeserialize(ByteUtils.toLocalBufferType(buffer), options);
}
function calculateObjectSize(object, options = {}) {
    options = options || {};
    const serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;
    const ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;
    return internalCalculateObjectSize(object, serializeFunctions, ignoreUndefined);
}
function deserializeStream(data, startIndex, numberOfDocuments, documents, docStartIndex, options) {
    const internalOptions = Object.assign({ allowObjectSmallerThanBufferSize: true, index: 0 }, options);
    const bufferData = ByteUtils.toLocalBufferType(data);
    let index = startIndex;
    for (let i = 0; i < numberOfDocuments; i++) {
        const size = NumberUtils.getInt32LE(bufferData, index);
        internalOptions.index = index;
        documents[docStartIndex + i] = internalDeserialize(bufferData, internalOptions);
        index = index + size;
    }
    return index;
}

var bson = /*#__PURE__*/Object.freeze({
    __proto__: null,
    BSONError: BSONError,
    BSONOffsetError: BSONOffsetError,
    BSONRegExp: BSONRegExp,
    BSONRuntimeError: BSONRuntimeError,
    BSONSymbol: BSONSymbol,
    BSONType: BSONType,
    BSONValue: BSONValue,
    BSONVersionError: BSONVersionError,
    Binary: Binary,
    Code: Code,
    DBRef: DBRef,
    Decimal128: Decimal128,
    Double: Double,
    EJSON: EJSON,
    Int32: Int32,
    Long: Long,
    MaxKey: MaxKey,
    MinKey: MinKey,
    ObjectId: ObjectId,
    Timestamp: Timestamp,
    UUID: UUID,
    calculateObjectSize: calculateObjectSize,
    deserialize: deserialize,
    deserializeStream: deserializeStream,
    onDemand: onDemand,
    serialize: serialize,
    serializeWithBufferAndIndex: serializeWithBufferAndIndex,
    setInternalBufferSize: setInternalBufferSize
});

bson$1.BSON = bson;
bson$1.BSONError = BSONError;
bson$1.BSONOffsetError = BSONOffsetError;
bson$1.BSONRegExp = BSONRegExp;
bson$1.BSONRuntimeError = BSONRuntimeError;
bson$1.BSONSymbol = BSONSymbol;
bson$1.BSONType = BSONType;
bson$1.BSONValue = BSONValue;
bson$1.BSONVersionError = BSONVersionError;
bson$1.Binary = Binary;
bson$1.Code = Code;
bson$1.DBRef = DBRef;
bson$1.Decimal128 = Decimal128;
bson$1.Double = Double;
bson$1.EJSON = EJSON;
bson$1.Int32 = Int32;
bson$1.Long = Long;
bson$1.MaxKey = MaxKey;
bson$1.MinKey = MinKey;
bson$1.ObjectId = ObjectId;
bson$1.Timestamp = Timestamp;
bson$1.UUID = UUID;
bson$1.calculateObjectSize = calculateObjectSize;
bson$1.deserialize = deserialize;
bson$1.deserializeStream = deserializeStream;
bson$1.onDemand = onDemand;
bson$1.serialize = serialize;
bson$1.serializeWithBufferAndIndex = serializeWithBufferAndIndex;
bson$1.setInternalBufferSize = setInternalBufferSize;

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.FilterProperties = exports.makeQueryFilter = exports.QueryFilter = exports.Resource = exports.Timestamps = exports.ResourceId = exports.ObjectId = exports.date = exports.buffer = void 0;
	const t = __importStar(dist$4);
	const bson = __importStar(bson$1);
	exports.buffer = t.codec('Buffer', (buffer) => {
	    if (!Buffer.isBuffer(buffer)) {
	        throw new t.TransformError([`Expected buffer but got ${typeof buffer}`]);
	    }
	    return buffer.toString('base64');
	}, (buffer) => Buffer.from(buffer, 'base64'));
	exports.date = t.codec('Date', (date) => {
	    if (!(date instanceof Date)) {
	        throw new t.TransformError([`Expected Date but got ${typeof date}`]);
	    }
	    return date.toISOString();
	}, (date) => {
	    const parsed = new Date(date);
	    if (isNaN(parsed.getTime())) {
	        throw new t.TransformError([`Invalid date`]);
	    }
	    return parsed;
	});
	const assertObjectId = (value) => {
	    if (!bson.ObjectId.isValid(value)) {
	        throw new t.TransformError([`Expected an ObjectId but got ${typeof value}`]);
	    }
	};
	exports.ObjectId = t.codec('ObjectId', (id) => {
	    assertObjectId(id);
	    return id.toHexString();
	}, (id) => {
	    assertObjectId(id);
	    return new bson.ObjectId(id);
	});
	const assertObjectWithField = (field, data) => {
	    if (typeof data !== 'object') {
	        throw new t.TransformError([`Expected an object but got ${typeof data}`]);
	    }
	    if (!(field in data)) {
	        throw new t.TransformError([`Expected ${field} to be a member of object`]);
	    }
	};
	exports.ResourceId = t.codec('ResourceId', (data) => {
	    assertObjectWithField('_id', data);
	    return {
	        id: exports.ObjectId.encode(data._id)
	    };
	}, (data) => {
	    assertObjectWithField('id', data);
	    return {
	        _id: exports.ObjectId.decode(data.id)
	    };
	});
	exports.Timestamps = t.object({
	    created_at: exports.date,
	    updated_at: exports.date
	});
	exports.Resource = exports.ResourceId.and(exports.Timestamps);
	exports.QueryFilter = t.object({
	    exists: t.boolean
	});
	const makeQueryFilter = (type) => {
	    return type.or(t.array(type)).or(exports.QueryFilter).optional();
	};
	exports.makeQueryFilter = makeQueryFilter;
	const FilterProperties = (type) => {
	    let codecs = new Map();
	    const addCodecs = (codec) => {
	        if (codec.props?.shape) {
	            Object.keys(codec.props.shape).forEach((k) => {
	                codecs.set(k, codec.props.shape[k]);
	            });
	        }
	    };
	    if (type._tag === t.CodecType.Object) {
	        addCodecs(type);
	    }
	    else if (type._tag === t.CodecType.Intersection) {
	        type.props.codecs.forEach((c) => {
	            addCodecs(c);
	        });
	    }
	    t.object({
	        test: t.string
	    });
	    // @ts-ignore
	    return t.object(Array.from(codecs.keys()).reduce((prev, cur) => {
	        prev[cur] = (0, exports.makeQueryFilter)(codecs.get(cur));
	        return prev;
	    }, {}));
	};
	exports.FilterProperties = FilterProperties; 
} (codecs));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.parsers = exports.BufferParser = exports.DateParser = exports.ResourceIdParser = exports.ObjectIdParser = void 0;
	const codecs$1 = __importStar(codecs);
	const t = __importStar(dist$4);
	exports.ObjectIdParser = t.createParser(codecs$1.ObjectId._tag, (_, { target }) => {
	    switch (target) {
	        case t.TransformTarget.Encoded: {
	            return { type: 'string' };
	        }
	        case t.TransformTarget.Decoded: {
	            return { bsonType: 'ObjectId' };
	        }
	    }
	});
	exports.ResourceIdParser = t.createParser(codecs$1.ResourceId._tag, (_, { target }) => {
	    switch (target) {
	        case t.TransformTarget.Encoded: {
	            return {
	                type: 'object',
	                properties: {
	                    id: { type: 'string' }
	                },
	                required: ['id']
	            };
	        }
	        case t.TransformTarget.Decoded: {
	            return {
	                type: 'object',
	                properties: {
	                    _id: { bsonType: 'ObjectId' }
	                },
	                required: ['_id']
	            };
	        }
	    }
	});
	exports.DateParser = t.createParser(codecs$1.date._tag, (_, { target }) => {
	    switch (target) {
	        case t.TransformTarget.Encoded: {
	            return { type: 'string' };
	        }
	        case t.TransformTarget.Decoded: {
	            return { nodeType: 'date' };
	        }
	    }
	});
	exports.BufferParser = t.createParser(codecs$1.buffer._tag, (_, { target }) => {
	    switch (target) {
	        case t.TransformTarget.Encoded: {
	            return { type: 'string' };
	        }
	        case t.TransformTarget.Decoded: {
	            return { nodeType: 'buffer' };
	        }
	    }
	});
	exports.parsers = [exports.ObjectIdParser, exports.ResourceIdParser, exports.DateParser, exports.BufferParser]; 
} (parsers));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	__exportStar(parsers, exports);
	__exportStar(codecs, exports); 
} (dist));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.InstanceDeployStatusEvent = exports.InstanceDeployEventType = exports.InstanceDeployOperationType = exports.InstanceResourceChangedEvent = exports.InstanceResourceEventType = exports.KafkaTopic = exports.InstanceEventSchemaVersion = void 0;
	const t = __importStar(dist$4);
	const types_kronos_1 = dist$2;
	const micro_codecs_1 = dist;
	(function (InstanceEventSchemaVersion) {
	    InstanceEventSchemaVersion["V1"] = "V1";
	})(exports.InstanceEventSchemaVersion || (exports.InstanceEventSchemaVersion = {}));
	(function (KafkaTopic) {
	    KafkaTopic["INSTANCE_RESOURCE_EVENTS"] = "instance-resource-events";
	    KafkaTopic["INSTANCE_DEPLOY_EVENTS"] = "instance-deploy-events";
	})(exports.KafkaTopic || (exports.KafkaTopic = {}));
	//!---------- RESOURCE EVENTS -----------
	var InstanceResourceEventType;
	(function (InstanceResourceEventType) {
	    InstanceResourceEventType["INSTANCE_CREATED"] = "INSTANCE.CREATED";
	    InstanceResourceEventType["INSTANCE_DELETED"] = "INSTANCE.DELETED";
	})(InstanceResourceEventType = exports.InstanceResourceEventType || (exports.InstanceResourceEventType = {}));
	exports.InstanceResourceChangedEvent = t.object({
	    type: t.Enum(InstanceResourceEventType),
	    payload: t.object({
	        id: t.string,
	        org_id: t.string,
	        app_id: t.string
	    })
	});
	//!---------- DEPLOY EVENTS -----------
	var InstanceDeployOperationType;
	(function (InstanceDeployOperationType) {
	    InstanceDeployOperationType["PROVISIONING"] = "provisioning";
	    InstanceDeployOperationType["DESTROYING"] = "destroying";
	    InstanceDeployOperationType["DEACTIVATING"] = "deactivating";
	})(InstanceDeployOperationType = exports.InstanceDeployOperationType || (exports.InstanceDeployOperationType = {}));
	var InstanceDeployEventType;
	(function (InstanceDeployEventType) {
	    InstanceDeployEventType["DEPLOY_STATUS_UPDATE"] = "DEPLOY.STATUS_UPDATE";
	})(InstanceDeployEventType = exports.InstanceDeployEventType || (exports.InstanceDeployEventType = {}));
	exports.InstanceDeployStatusEvent = t.object({
	    type: t.Enum(InstanceDeployEventType),
	    payload: t.object({
	        id: t.string,
	        org_id: t.string,
	        app_id: t.string,
	        operation: t.Enum(InstanceDeployOperationType),
	        status: t.Enum(types_kronos_1.StackOperationStatus),
	        updated_at: micro_codecs_1.date,
	        system_upgrade: t.boolean,
	        user_id: t.string.optional()
	    })
	});
	
} (events$1));

var errors$1 = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.PowerSyncErrorCodes = void 0;
	(function (PowerSyncErrorCodes) {
	    PowerSyncErrorCodes["REGION_CHANGED"] = "REGION_CHANGED";
	    PowerSyncErrorCodes["PLAN_LIMIT_REACHED"] = "PLAN_LIMIT_REACHED";
	    PowerSyncErrorCodes["SECRET_NOT_FOUND"] = "SECRET_NOT_FOUND";
	    PowerSyncErrorCodes["INVALID_REGION"] = "INVALID_REGION";
	    PowerSyncErrorCodes["INVALID_CONFIG"] = "INVALID_CONFIG";
	})(exports.PowerSyncErrorCodes || (exports.PowerSyncErrorCodes = {}));
	
} (errors$1));

(function (exports) {
	var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
	    Object.defineProperty(o, "default", { enumerable: true, value: v });
	}) : function(o, v) {
	    o["default"] = v;
	});
	var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
	    if (mod && mod.__esModule) return mod;
	    var result = {};
	    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
	    __setModuleDefault(result, mod);
	    return result;
	};
	var __exportStar = (commonjsGlobal && commonjsGlobal.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.validateHostedConfig = exports.isHostedSecretValue = exports.powerSyncHostedConfig = exports.events = exports.routes = exports.baseUri = exports.validatePort = exports.normalizeConnection = exports.internal_routes = exports.configFile = exports.hostedConfig = void 0;
	exports.hostedConfig = __importStar(HostedConfig);
	// Exports to maintain API compatibility
	var service_types_1 = dist$3;
	Object.defineProperty(exports, "configFile", { enumerable: true, get: function () { return service_types_1.configFile; } });
	Object.defineProperty(exports, "internal_routes", { enumerable: true, get: function () { return service_types_1.internal_routes; } });
	Object.defineProperty(exports, "normalizeConnection", { enumerable: true, get: function () { return service_types_1.normalizeConnection; } });
	Object.defineProperty(exports, "validatePort", { enumerable: true, get: function () { return service_types_1.validatePort; } });
	Object.defineProperty(exports, "baseUri", { enumerable: true, get: function () { return service_types_1.baseUri; } });
	exports.routes = __importStar(routes);
	exports.events = __importStar(events$1);
	var HostedConfig_js_1 = HostedConfig;
	Object.defineProperty(exports, "powerSyncHostedConfig", { enumerable: true, get: function () { return HostedConfig_js_1.powerSyncHostedConfig; } });
	Object.defineProperty(exports, "isHostedSecretValue", { enumerable: true, get: function () { return HostedConfig_js_1.isHostedSecretValue; } });
	Object.defineProperty(exports, "validateHostedConfig", { enumerable: true, get: function () { return HostedConfig_js_1.validateHostedConfig; } });
	__exportStar(errors$1, exports);
	__exportStar(definitions$2, exports);
	
} (dist$5));

var __createBinding = (commonjsGlobal && commonjsGlobal.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (commonjsGlobal && commonjsGlobal.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (commonjsGlobal && commonjsGlobal.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(dist$6, "__esModule", { value: true });
var Client_1 = dist$6.Client = void 0;
const powersync_types_1 = dist$5;
const sdk = __importStar(dist$8);
const dev = powersync_types_1.routes.DEV_ROUTES;
const manage = powersync_types_1.routes.MANAGE_ROUTES;
const general = powersync_types_1.routes.GENERAL_ROUTES;
class Client extends sdk.SDKClient {
    constructor() {
        super(...arguments);
        this.listInstances = this.createEndpoint({
            path: manage.LIST
        });
        this.createInstance = this.createEndpoint({
            path: manage.CREATE
        });
        this.destroyInstance = this.createEndpoint({
            path: manage.DESTROY
        });
        this.deactivateInstance = this.createEndpoint({
            path: manage.DEACTIVATE
        });
        this.deployInstance = this.createEndpoint({
            path: manage.DEPLOY
        });
        this.getInstanceConfig = this.createEndpoint({
            path: manage.CONFIG
        });
        this.getInstanceStatus = this.createEndpoint({
            path: manage.STATUS
        });
        this.getInstanceDiagnostics = this.createEndpoint({
            path: manage.DIAGNOSTICS
        });
        this.compact = this.createEndpoint({
            path: manage.COMPACT
        });
        this.testConnection = this.createEndpoint({
            path: dev.TEST_CONNECTION
        });
        this.getInstanceSchema = this.createEndpoint({
            path: dev.GET_SCHEMA
        });
        this.executeSql = this.createEndpoint({
            path: dev.EXECUTE_SQL
        });
        this.validateSyncRules = this.createEndpoint({
            path: dev.VALIDATE_SYNC_RULES
        });
        this.reprocessSyncRules = this.createEndpoint({
            path: dev.REPROCESS_SYNC_RULES
        });
        this.generateDevToken = this.createEndpoint({
            path: dev.GENERATE_DEV_TOKEN
        });
        this.listRegions = this.createEndpoint({
            path: general.LIST_REGIONS,
            method: 'get'
        });
    }
}
Client_1 = dist$6.Client = Client;

var main$1 = {exports: {}};

var name$1 = "dotenv";
var version$2 = "16.4.5";
var description$2 = "Loads environment variables from .env file";
var main = "lib/main.js";
var types$3 = "lib/main.d.ts";
var exports$1 = {
	".": {
		types: "./lib/main.d.ts",
		require: "./lib/main.js",
		"default": "./lib/main.js"
	},
	"./config": "./config.js",
	"./config.js": "./config.js",
	"./lib/env-options": "./lib/env-options.js",
	"./lib/env-options.js": "./lib/env-options.js",
	"./lib/cli-options": "./lib/cli-options.js",
	"./lib/cli-options.js": "./lib/cli-options.js",
	"./package.json": "./package.json"
};
var scripts$1 = {
	"dts-check": "tsc --project tests/types/tsconfig.json",
	lint: "standard",
	"lint-readme": "standard-markdown",
	pretest: "npm run lint && npm run dts-check",
	test: "tap tests/*.js --100 -Rspec",
	"test:coverage": "tap --coverage-report=lcov",
	prerelease: "npm test",
	release: "standard-version"
};
var repository$1 = {
	type: "git",
	url: "git://github.com/motdotla/dotenv.git"
};
var funding = "https://dotenvx.com";
var keywords = [
	"dotenv",
	"env",
	".env",
	"environment",
	"variables",
	"config",
	"settings"
];
var readmeFilename = "README.md";
var license$1 = "BSD-2-Clause";
var devDependencies$1 = {
	"@definitelytyped/dtslint": "^0.0.133",
	"@types/node": "^18.11.3",
	decache: "^4.6.1",
	sinon: "^14.0.1",
	standard: "^17.0.0",
	"standard-markdown": "^7.1.0",
	"standard-version": "^9.5.0",
	tap: "^16.3.0",
	tar: "^6.1.11",
	typescript: "^4.8.4"
};
var engines$1 = {
	node: ">=12"
};
var browser = {
	fs: false
};
var require$$4 = {
	name: name$1,
	version: version$2,
	description: description$2,
	main: main,
	types: types$3,
	exports: exports$1,
	scripts: scripts$1,
	repository: repository$1,
	funding: funding,
	keywords: keywords,
	readmeFilename: readmeFilename,
	license: license$1,
	devDependencies: devDependencies$1,
	engines: engines$1,
	browser: browser
};

const fs = require$$0$5;
const path = require$$1$1;
const os = require$$2;
const crypto = require$$3$1;
const packageJson = require$$4;

const version$1 = packageJson.version;

const LINE = /(?:^|^)\s*(?:export\s+)?([\w.-]+)(?:\s*=\s*?|:\s+?)(\s*'(?:\\'|[^'])*'|\s*"(?:\\"|[^"])*"|\s*`(?:\\`|[^`])*`|[^#\r\n]+)?\s*(?:#.*)?(?:$|$)/mg;

// Parse src into an Object
function parse$1 (src) {
  const obj = {};

  // Convert buffer to string
  let lines = src.toString();

  // Convert line breaks to same format
  lines = lines.replace(/\r\n?/mg, '\n');

  let match;
  while ((match = LINE.exec(lines)) != null) {
    const key = match[1];

    // Default undefined or null to empty string
    let value = (match[2] || '');

    // Remove whitespace
    value = value.trim();

    // Check if double quoted
    const maybeQuote = value[0];

    // Remove surrounding quotes
    value = value.replace(/^(['"`])([\s\S]*)\1$/mg, '$2');

    // Expand newlines if double quoted
    if (maybeQuote === '"') {
      value = value.replace(/\\n/g, '\n');
      value = value.replace(/\\r/g, '\r');
    }

    // Add to object
    obj[key] = value;
  }

  return obj
}

function _parseVault (options) {
  const vaultPath = _vaultPath(options);

  // Parse .env.vault
  const result = DotenvModule.configDotenv({ path: vaultPath });
  if (!result.parsed) {
    const err = new Error(`MISSING_DATA: Cannot parse ${vaultPath} for an unknown reason`);
    err.code = 'MISSING_DATA';
    throw err
  }

  // handle scenario for comma separated keys - for use with key rotation
  // example: DOTENV_KEY="dotenv://:key_1234@dotenvx.com/vault/.env.vault?environment=prod,dotenv://:key_7890@dotenvx.com/vault/.env.vault?environment=prod"
  const keys = _dotenvKey(options).split(',');
  const length = keys.length;

  let decrypted;
  for (let i = 0; i < length; i++) {
    try {
      // Get full key
      const key = keys[i].trim();

      // Get instructions for decrypt
      const attrs = _instructions(result, key);

      // Decrypt
      decrypted = DotenvModule.decrypt(attrs.ciphertext, attrs.key);

      break
    } catch (error) {
      // last key
      if (i + 1 >= length) {
        throw error
      }
      // try next key
    }
  }

  // Parse decrypted .env string
  return DotenvModule.parse(decrypted)
}

function _log (message) {
  console.log(`[dotenv@${version$1}][INFO] ${message}`);
}

function _warn (message) {
  console.log(`[dotenv@${version$1}][WARN] ${message}`);
}

function _debug (message) {
  console.log(`[dotenv@${version$1}][DEBUG] ${message}`);
}

function _dotenvKey (options) {
  // prioritize developer directly setting options.DOTENV_KEY
  if (options && options.DOTENV_KEY && options.DOTENV_KEY.length > 0) {
    return options.DOTENV_KEY
  }

  // secondary infra already contains a DOTENV_KEY environment variable
  if (process.env.DOTENV_KEY && process.env.DOTENV_KEY.length > 0) {
    return process.env.DOTENV_KEY
  }

  // fallback to empty string
  return ''
}

function _instructions (result, dotenvKey) {
  // Parse DOTENV_KEY. Format is a URI
  let uri;
  try {
    uri = new URL(dotenvKey);
  } catch (error) {
    if (error.code === 'ERR_INVALID_URL') {
      const err = new Error('INVALID_DOTENV_KEY: Wrong format. Must be in valid uri format like dotenv://:key_1234@dotenvx.com/vault/.env.vault?environment=development');
      err.code = 'INVALID_DOTENV_KEY';
      throw err
    }

    throw error
  }

  // Get decrypt key
  const key = uri.password;
  if (!key) {
    const err = new Error('INVALID_DOTENV_KEY: Missing key part');
    err.code = 'INVALID_DOTENV_KEY';
    throw err
  }

  // Get environment
  const environment = uri.searchParams.get('environment');
  if (!environment) {
    const err = new Error('INVALID_DOTENV_KEY: Missing environment part');
    err.code = 'INVALID_DOTENV_KEY';
    throw err
  }

  // Get ciphertext payload
  const environmentKey = `DOTENV_VAULT_${environment.toUpperCase()}`;
  const ciphertext = result.parsed[environmentKey]; // DOTENV_VAULT_PRODUCTION
  if (!ciphertext) {
    const err = new Error(`NOT_FOUND_DOTENV_ENVIRONMENT: Cannot locate environment ${environmentKey} in your .env.vault file.`);
    err.code = 'NOT_FOUND_DOTENV_ENVIRONMENT';
    throw err
  }

  return { ciphertext, key }
}

function _vaultPath (options) {
  let possibleVaultPath = null;

  if (options && options.path && options.path.length > 0) {
    if (Array.isArray(options.path)) {
      for (const filepath of options.path) {
        if (fs.existsSync(filepath)) {
          possibleVaultPath = filepath.endsWith('.vault') ? filepath : `${filepath}.vault`;
        }
      }
    } else {
      possibleVaultPath = options.path.endsWith('.vault') ? options.path : `${options.path}.vault`;
    }
  } else {
    possibleVaultPath = path.resolve(process.cwd(), '.env.vault');
  }

  if (fs.existsSync(possibleVaultPath)) {
    return possibleVaultPath
  }

  return null
}

function _resolveHome (envPath) {
  return envPath[0] === '~' ? path.join(os.homedir(), envPath.slice(1)) : envPath
}

function _configVault (options) {
  _log('Loading env from encrypted .env.vault');

  const parsed = DotenvModule._parseVault(options);

  let processEnv = process.env;
  if (options && options.processEnv != null) {
    processEnv = options.processEnv;
  }

  DotenvModule.populate(processEnv, parsed, options);

  return { parsed }
}

function configDotenv (options) {
  const dotenvPath = path.resolve(process.cwd(), '.env');
  let encoding = 'utf8';
  const debug = Boolean(options && options.debug);

  if (options && options.encoding) {
    encoding = options.encoding;
  } else {
    if (debug) {
      _debug('No encoding is specified. UTF-8 is used by default');
    }
  }

  let optionPaths = [dotenvPath]; // default, look for .env
  if (options && options.path) {
    if (!Array.isArray(options.path)) {
      optionPaths = [_resolveHome(options.path)];
    } else {
      optionPaths = []; // reset default
      for (const filepath of options.path) {
        optionPaths.push(_resolveHome(filepath));
      }
    }
  }

  // Build the parsed data in a temporary object (because we need to return it).  Once we have the final
  // parsed data, we will combine it with process.env (or options.processEnv if provided).
  let lastError;
  const parsedAll = {};
  for (const path of optionPaths) {
    try {
      // Specifying an encoding returns a string instead of a buffer
      const parsed = DotenvModule.parse(fs.readFileSync(path, { encoding }));

      DotenvModule.populate(parsedAll, parsed, options);
    } catch (e) {
      if (debug) {
        _debug(`Failed to load ${path} ${e.message}`);
      }
      lastError = e;
    }
  }

  let processEnv = process.env;
  if (options && options.processEnv != null) {
    processEnv = options.processEnv;
  }

  DotenvModule.populate(processEnv, parsedAll, options);

  if (lastError) {
    return { parsed: parsedAll, error: lastError }
  } else {
    return { parsed: parsedAll }
  }
}

// Populates process.env from .env file
function config (options) {
  // fallback to original dotenv if DOTENV_KEY is not set
  if (_dotenvKey(options).length === 0) {
    return DotenvModule.configDotenv(options)
  }

  const vaultPath = _vaultPath(options);

  // dotenvKey exists but .env.vault file does not exist
  if (!vaultPath) {
    _warn(`You set DOTENV_KEY but you are missing a .env.vault file at ${vaultPath}. Did you forget to build it?`);

    return DotenvModule.configDotenv(options)
  }

  return DotenvModule._configVault(options)
}

function decrypt (encrypted, keyStr) {
  const key = Buffer.from(keyStr.slice(-64), 'hex');
  let ciphertext = Buffer.from(encrypted, 'base64');

  const nonce = ciphertext.subarray(0, 12);
  const authTag = ciphertext.subarray(-16);
  ciphertext = ciphertext.subarray(12, -16);

  try {
    const aesgcm = crypto.createDecipheriv('aes-256-gcm', key, nonce);
    aesgcm.setAuthTag(authTag);
    return `${aesgcm.update(ciphertext)}${aesgcm.final()}`
  } catch (error) {
    const isRange = error instanceof RangeError;
    const invalidKeyLength = error.message === 'Invalid key length';
    const decryptionFailed = error.message === 'Unsupported state or unable to authenticate data';

    if (isRange || invalidKeyLength) {
      const err = new Error('INVALID_DOTENV_KEY: It must be 64 characters long (or more)');
      err.code = 'INVALID_DOTENV_KEY';
      throw err
    } else if (decryptionFailed) {
      const err = new Error('DECRYPTION_FAILED: Please check your DOTENV_KEY');
      err.code = 'DECRYPTION_FAILED';
      throw err
    } else {
      throw error
    }
  }
}

// Populate process.env with parsed values
function populate (processEnv, parsed, options = {}) {
  const debug = Boolean(options && options.debug);
  const override = Boolean(options && options.override);

  if (typeof parsed !== 'object') {
    const err = new Error('OBJECT_REQUIRED: Please check the processEnv argument being passed to populate');
    err.code = 'OBJECT_REQUIRED';
    throw err
  }

  // Set process.env
  for (const key of Object.keys(parsed)) {
    if (Object.prototype.hasOwnProperty.call(processEnv, key)) {
      if (override === true) {
        processEnv[key] = parsed[key];
      }

      if (debug) {
        if (override === true) {
          _debug(`"${key}" is already defined and WAS overwritten`);
        } else {
          _debug(`"${key}" is already defined and was NOT overwritten`);
        }
      }
    } else {
      processEnv[key] = parsed[key];
    }
  }
}

const DotenvModule = {
  configDotenv,
  _configVault,
  _parseVault,
  config,
  decrypt,
  parse: parse$1,
  populate
};

main$1.exports.configDotenv = DotenvModule.configDotenv;
main$1.exports._configVault = DotenvModule._configVault;
main$1.exports._parseVault = DotenvModule._parseVault;
var config_1 = main$1.exports.config = DotenvModule.config;
main$1.exports.decrypt = DotenvModule.decrypt;
main$1.exports.parse = DotenvModule.parse;
main$1.exports.populate = DotenvModule.populate;

main$1.exports = DotenvModule;

const APP_NAME = "POWERSYNC_CLI";
const POWERSYNC_DIRECTORY = path$1.join(homedir(), "/.powersync");
const ENV_FILE_PATH = `${POWERSYNC_DIRECTORY}/.env.powersync`;
const ENDPOINTS = {
  ACCOUNTS_URL: "https://accounts.journeyapps.com",
  POWERSYNC_URL: "https://powersync-api.journeyapps.com"
};

var author = "JourneyApps";
var bin = {
	powersync: "./bin/run.js"
};
var publishConfig = {
	registry: "https://registry.npmjs.org/",
	access: "public"
};
var description$1 = "PowerSync CLI";
var engines = {
	node: ">=20.0.0"
};
var files = [
	"/bin",
	"/dist",
	"/oclif.manifest.json"
];
var version = "0.6.1";
var bugs = "https://github.com/powersync-ja/cli/issues";
var types$2 = "dist/index.d.ts";
var exports = "./lib/index.js";
var type$2 = "module";
var homepage = "https://github.com/powersync-ja/cli";
var license = "UNLICENSED";
var name = "powersync";
var oclif = {
	bin: "powersync",
	dirname: "powersync",
	commands: "./dist/commands",
	plugins: [
		"@oclif/plugin-help",
		"@oclif/plugin-not-found",
		"@oclif/plugin-warn-if-update-available"
	],
	topics: {
		"instance:sync-rules": {
			description: "run \"powersync instance sync-rules\" to see a list of subcommands"
		},
		instance: {
			description: "run \"powersync instance\" to see a list of subcommands"
		}
	},
	topicSeparator: " "
};
var repository = "powersync-ja/cli";
var scripts = {
	build: "pnpm build:oclif-commands && pnpm bundle:powersync-deps && ./combine-bundle-and-build.sh && pnpm readme",
	"build:oclif-commands": "shx rm -rf dist && tsc -b",
	"bundle:powersync-deps": "shx rm -rf lib && rollup -c rollup.config.mjs",
	lint: "eslint . --ext .ts",
	postpack: "shx rm -f oclif.manifest.json",
	posttest: "pnpm run lint",
	prepack: "pnpm run build && oclif manifest && oclif readme",
	readme: "oclif readme && ./update-readme.sh",
	prepare: "pnpm run build",
	test: "vitest",
	release: "pnpm build && pnpm changeset publish",
	prettier: "prettier --write \"**/*.ts\"",
	version: "pnpm run readme && git add README.md",
	"pack:tarballs": "oclif pack tarballs --parallel",
	"changeset:version": "pnpm changeset version && pnpm readme"
};
var dependencies$1 = {
	"@oclif/core": "^3.27.0",
	"@oclif/plugin-help": "^6.2.8",
	"@oclif/plugin-not-found": "^3.1.4",
	"@oclif/plugin-warn-if-update-available": "^3.1.11",
	"@rollup/plugin-typescript": "^11.1.6",
	clipboardy: "^4.0.0",
	dotenv: "^16.4.5",
	inquirer: "^9.3.6",
	ora: "^8.0.1"
};
var devDependencies = {
	"@changesets/cli": "^2.27.7",
	"@journeyapps-platform/powersync-types": "^0.22.0",
	"@journeyapps-platform/sdk-accounts-hub": "^7.0.1",
	"@journeyapps-platform/sdk-common": "^5.5.0",
	"@journeyapps-platform/sdk-powersync": "^0.22.1",
	"@journeyapps-platform/types-accounts-hub": "^7.0.1",
	"@powersync/service-sync-rules": "^0.18.2",
	"@rollup/plugin-commonjs": "^26.0.1",
	"@rollup/plugin-json": "^6.1.0",
	"@rollup/plugin-node-resolve": "^15.2.3",
	"@types/inquirer": "^9.0.7",
	"@types/node": "^20.16.1",
	esbuild: "^0.23.1",
	eslint: "^8.57.0",
	"eslint-config-oclif": "^5",
	"eslint-config-oclif-typescript": "^3.1.9",
	"eslint-config-prettier": "^9.1.0",
	"eslint-plugin-prettier": "^5.2.1",
	glob: "^11.0.0",
	oclif: "^4.14.29",
	prettier: "^3.3.3",
	rollup: "^4.21.2",
	"rollup-plugin-esbuild": "^6.1.1",
	shx: "^0.3.4",
	"strip-ansi": "^7.1.0",
	"ts-node": "^10.9.2",
	typescript: "^5.5.4",
	vitest: "^2.0.5"
};
var packageJSON = {
	author: author,
	bin: bin,
	publishConfig: publishConfig,
	description: description$1,
	engines: engines,
	files: files,
	version: version,
	bugs: bugs,
	types: types$2,
	exports: exports,
	type: type$2,
	homepage: homepage,
	license: license,
	name: name,
	oclif: oclif,
	repository: repository,
	scripts: scripts,
	dependencies: dependencies$1,
	devDependencies: devDependencies
};

const generateHeader = (bearerToken) => {
  return {
    Accept: "application/json",
    Authorization: `Bearer ${bearerToken}`,
    ContentType: "application/json",
    "user-agent": `${APP_NAME}/${packageJSON.version}`
  };
};
const checkProjectId = (projectId) => {
  if (!projectId)
    throw new Error("No project id found");
};
const checkOrgId = (orgId) => {
  if (!orgId)
    throw new Error("No org id found");
};
const checkInstanceId = (instanceId) => {
  if (!instanceId)
    throw new Error("No instance id found");
};

const ALIAS = Symbol.for('yaml.alias');
const DOC = Symbol.for('yaml.document');
const MAP = Symbol.for('yaml.map');
const PAIR = Symbol.for('yaml.pair');
const SCALAR$1 = Symbol.for('yaml.scalar');
const SEQ = Symbol.for('yaml.seq');
const NODE_TYPE = Symbol.for('yaml.node.type');
const isAlias = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === ALIAS;
const isDocument = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === DOC;
const isMap = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === MAP;
const isPair = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === PAIR;
const isScalar = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === SCALAR$1;
const isSeq = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === SEQ;
function isCollection(node) {
    if (node && typeof node === 'object')
        switch (node[NODE_TYPE]) {
            case MAP:
            case SEQ:
                return true;
        }
    return false;
}
function isNode(node) {
    if (node && typeof node === 'object')
        switch (node[NODE_TYPE]) {
            case ALIAS:
            case MAP:
            case SCALAR$1:
            case SEQ:
                return true;
        }
    return false;
}
const hasAnchor = (node) => (isScalar(node) || isCollection(node)) && !!node.anchor;

const BREAK = Symbol('break visit');
const SKIP = Symbol('skip children');
const REMOVE = Symbol('remove node');
/**
 * Apply a visitor to an AST node or document.
 *
 * Walks through the tree (depth-first) starting from `node`, calling a
 * `visitor` function with three arguments:
 *   - `key`: For sequence values and map `Pair`, the node's index in the
 *     collection. Within a `Pair`, `'key'` or `'value'`, correspondingly.
 *     `null` for the root node.
 *   - `node`: The current node.
 *   - `path`: The ancestry of the current node.
 *
 * The return value of the visitor may be used to control the traversal:
 *   - `undefined` (default): Do nothing and continue
 *   - `visit.SKIP`: Do not visit the children of this node, continue with next
 *     sibling
 *   - `visit.BREAK`: Terminate traversal completely
 *   - `visit.REMOVE`: Remove the current node, then continue with the next one
 *   - `Node`: Replace the current node, then continue by visiting it
 *   - `number`: While iterating the items of a sequence or map, set the index
 *     of the next step. This is useful especially if the index of the current
 *     node has changed.
 *
 * If `visitor` is a single function, it will be called with all values
 * encountered in the tree, including e.g. `null` values. Alternatively,
 * separate visitor functions may be defined for each `Map`, `Pair`, `Seq`,
 * `Alias` and `Scalar` node. To define the same visitor function for more than
 * one node type, use the `Collection` (map and seq), `Value` (map, seq & scalar)
 * and `Node` (alias, map, seq & scalar) targets. Of all these, only the most
 * specific defined one will be used for each node.
 */
function visit(node, visitor) {
    const visitor_ = initVisitor(visitor);
    if (isDocument(node)) {
        const cd = visit_(null, node.contents, visitor_, Object.freeze([node]));
        if (cd === REMOVE)
            node.contents = null;
    }
    else
        visit_(null, node, visitor_, Object.freeze([]));
}
// Without the `as symbol` casts, TS declares these in the `visit`
// namespace using `var`, but then complains about that because
// `unique symbol` must be `const`.
/** Terminate visit traversal completely */
visit.BREAK = BREAK;
/** Do not visit the children of the current node */
visit.SKIP = SKIP;
/** Remove the current node */
visit.REMOVE = REMOVE;
function visit_(key, node, visitor, path) {
    const ctrl = callVisitor(key, node, visitor, path);
    if (isNode(ctrl) || isPair(ctrl)) {
        replaceNode(key, path, ctrl);
        return visit_(key, ctrl, visitor, path);
    }
    if (typeof ctrl !== 'symbol') {
        if (isCollection(node)) {
            path = Object.freeze(path.concat(node));
            for (let i = 0; i < node.items.length; ++i) {
                const ci = visit_(i, node.items[i], visitor, path);
                if (typeof ci === 'number')
                    i = ci - 1;
                else if (ci === BREAK)
                    return BREAK;
                else if (ci === REMOVE) {
                    node.items.splice(i, 1);
                    i -= 1;
                }
            }
        }
        else if (isPair(node)) {
            path = Object.freeze(path.concat(node));
            const ck = visit_('key', node.key, visitor, path);
            if (ck === BREAK)
                return BREAK;
            else if (ck === REMOVE)
                node.key = null;
            const cv = visit_('value', node.value, visitor, path);
            if (cv === BREAK)
                return BREAK;
            else if (cv === REMOVE)
                node.value = null;
        }
    }
    return ctrl;
}
function initVisitor(visitor) {
    if (typeof visitor === 'object' &&
        (visitor.Collection || visitor.Node || visitor.Value)) {
        return Object.assign({
            Alias: visitor.Node,
            Map: visitor.Node,
            Scalar: visitor.Node,
            Seq: visitor.Node
        }, visitor.Value && {
            Map: visitor.Value,
            Scalar: visitor.Value,
            Seq: visitor.Value
        }, visitor.Collection && {
            Map: visitor.Collection,
            Seq: visitor.Collection
        }, visitor);
    }
    return visitor;
}
function callVisitor(key, node, visitor, path) {
    if (typeof visitor === 'function')
        return visitor(key, node, path);
    if (isMap(node))
        return visitor.Map?.(key, node, path);
    if (isSeq(node))
        return visitor.Seq?.(key, node, path);
    if (isPair(node))
        return visitor.Pair?.(key, node, path);
    if (isScalar(node))
        return visitor.Scalar?.(key, node, path);
    if (isAlias(node))
        return visitor.Alias?.(key, node, path);
    return undefined;
}
function replaceNode(key, path, node) {
    const parent = path[path.length - 1];
    if (isCollection(parent)) {
        parent.items[key] = node;
    }
    else if (isPair(parent)) {
        if (key === 'key')
            parent.key = node;
        else
            parent.value = node;
    }
    else if (isDocument(parent)) {
        parent.contents = node;
    }
    else {
        const pt = isAlias(parent) ? 'alias' : 'scalar';
        throw new Error(`Cannot replace node with ${pt} parent`);
    }
}

const escapeChars = {
    '!': '%21',
    ',': '%2C',
    '[': '%5B',
    ']': '%5D',
    '{': '%7B',
    '}': '%7D'
};
const escapeTagName = (tn) => tn.replace(/[!,[\]{}]/g, ch => escapeChars[ch]);
class Directives {
    constructor(yaml, tags) {
        /**
         * The directives-end/doc-start marker `---`. If `null`, a marker may still be
         * included in the document's stringified representation.
         */
        this.docStart = null;
        /** The doc-end marker `...`.  */
        this.docEnd = false;
        this.yaml = Object.assign({}, Directives.defaultYaml, yaml);
        this.tags = Object.assign({}, Directives.defaultTags, tags);
    }
    clone() {
        const copy = new Directives(this.yaml, this.tags);
        copy.docStart = this.docStart;
        return copy;
    }
    /**
     * During parsing, get a Directives instance for the current document and
     * update the stream state according to the current version's spec.
     */
    atDocument() {
        const res = new Directives(this.yaml, this.tags);
        switch (this.yaml.version) {
            case '1.1':
                this.atNextDocument = true;
                break;
            case '1.2':
                this.atNextDocument = false;
                this.yaml = {
                    explicit: Directives.defaultYaml.explicit,
                    version: '1.2'
                };
                this.tags = Object.assign({}, Directives.defaultTags);
                break;
        }
        return res;
    }
    /**
     * @param onError - May be called even if the action was successful
     * @returns `true` on success
     */
    add(line, onError) {
        if (this.atNextDocument) {
            this.yaml = { explicit: Directives.defaultYaml.explicit, version: '1.1' };
            this.tags = Object.assign({}, Directives.defaultTags);
            this.atNextDocument = false;
        }
        const parts = line.trim().split(/[ \t]+/);
        const name = parts.shift();
        switch (name) {
            case '%TAG': {
                if (parts.length !== 2) {
                    onError(0, '%TAG directive should contain exactly two parts');
                    if (parts.length < 2)
                        return false;
                }
                const [handle, prefix] = parts;
                this.tags[handle] = prefix;
                return true;
            }
            case '%YAML': {
                this.yaml.explicit = true;
                if (parts.length !== 1) {
                    onError(0, '%YAML directive should contain exactly one part');
                    return false;
                }
                const [version] = parts;
                if (version === '1.1' || version === '1.2') {
                    this.yaml.version = version;
                    return true;
                }
                else {
                    const isValid = /^\d+\.\d+$/.test(version);
                    onError(6, `Unsupported YAML version ${version}`, isValid);
                    return false;
                }
            }
            default:
                onError(0, `Unknown directive ${name}`, true);
                return false;
        }
    }
    /**
     * Resolves a tag, matching handles to those defined in %TAG directives.
     *
     * @returns Resolved tag, which may also be the non-specific tag `'!'` or a
     *   `'!local'` tag, or `null` if unresolvable.
     */
    tagName(source, onError) {
        if (source === '!')
            return '!'; // non-specific tag
        if (source[0] !== '!') {
            onError(`Not a valid tag: ${source}`);
            return null;
        }
        if (source[1] === '<') {
            const verbatim = source.slice(2, -1);
            if (verbatim === '!' || verbatim === '!!') {
                onError(`Verbatim tags aren't resolved, so ${source} is invalid.`);
                return null;
            }
            if (source[source.length - 1] !== '>')
                onError('Verbatim tags must end with a >');
            return verbatim;
        }
        const [, handle, suffix] = source.match(/^(.*!)([^!]*)$/s);
        if (!suffix)
            onError(`The ${source} tag has no suffix`);
        const prefix = this.tags[handle];
        if (prefix) {
            try {
                return prefix + decodeURIComponent(suffix);
            }
            catch (error) {
                onError(String(error));
                return null;
            }
        }
        if (handle === '!')
            return source; // local tag
        onError(`Could not resolve tag: ${source}`);
        return null;
    }
    /**
     * Given a fully resolved tag, returns its printable string form,
     * taking into account current tag prefixes and defaults.
     */
    tagString(tag) {
        for (const [handle, prefix] of Object.entries(this.tags)) {
            if (tag.startsWith(prefix))
                return handle + escapeTagName(tag.substring(prefix.length));
        }
        return tag[0] === '!' ? tag : `!<${tag}>`;
    }
    toString(doc) {
        const lines = this.yaml.explicit
            ? [`%YAML ${this.yaml.version || '1.2'}`]
            : [];
        const tagEntries = Object.entries(this.tags);
        let tagNames;
        if (doc && tagEntries.length > 0 && isNode(doc.contents)) {
            const tags = {};
            visit(doc.contents, (_key, node) => {
                if (isNode(node) && node.tag)
                    tags[node.tag] = true;
            });
            tagNames = Object.keys(tags);
        }
        else
            tagNames = [];
        for (const [handle, prefix] of tagEntries) {
            if (handle === '!!' && prefix === 'tag:yaml.org,2002:')
                continue;
            if (!doc || tagNames.some(tn => tn.startsWith(prefix)))
                lines.push(`%TAG ${handle} ${prefix}`);
        }
        return lines.join('\n');
    }
}
Directives.defaultYaml = { explicit: false, version: '1.2' };
Directives.defaultTags = { '!!': 'tag:yaml.org,2002:' };

/**
 * Verify that the input string is a valid anchor.
 *
 * Will throw on errors.
 */
function anchorIsValid(anchor) {
    if (/[\x00-\x19\s,[\]{}]/.test(anchor)) {
        const sa = JSON.stringify(anchor);
        const msg = `Anchor must not contain whitespace or control characters: ${sa}`;
        throw new Error(msg);
    }
    return true;
}
function anchorNames(root) {
    const anchors = new Set();
    visit(root, {
        Value(_key, node) {
            if (node.anchor)
                anchors.add(node.anchor);
        }
    });
    return anchors;
}
/** Find a new anchor name with the given `prefix` and a one-indexed suffix. */
function findNewAnchor(prefix, exclude) {
    for (let i = 1; true; ++i) {
        const name = `${prefix}${i}`;
        if (!exclude.has(name))
            return name;
    }
}
function createNodeAnchors(doc, prefix) {
    const aliasObjects = [];
    const sourceObjects = new Map();
    let prevAnchors = null;
    return {
        onAnchor: (source) => {
            aliasObjects.push(source);
            if (!prevAnchors)
                prevAnchors = anchorNames(doc);
            const anchor = findNewAnchor(prefix, prevAnchors);
            prevAnchors.add(anchor);
            return anchor;
        },
        /**
         * With circular references, the source node is only resolved after all
         * of its child nodes are. This is why anchors are set only after all of
         * the nodes have been created.
         */
        setAnchors: () => {
            for (const source of aliasObjects) {
                const ref = sourceObjects.get(source);
                if (typeof ref === 'object' &&
                    ref.anchor &&
                    (isScalar(ref.node) || isCollection(ref.node))) {
                    ref.node.anchor = ref.anchor;
                }
                else {
                    const error = new Error('Failed to resolve repeated object (this should not happen)');
                    error.source = source;
                    throw error;
                }
            }
        },
        sourceObjects
    };
}

/**
 * Applies the JSON.parse reviver algorithm as defined in the ECMA-262 spec,
 * in section 24.5.1.1 "Runtime Semantics: InternalizeJSONProperty" of the
 * 2021 edition: https://tc39.es/ecma262/#sec-json.parse
 *
 * Includes extensions for handling Map and Set objects.
 */
function applyReviver(reviver, obj, key, val) {
    if (val && typeof val === 'object') {
        if (Array.isArray(val)) {
            for (let i = 0, len = val.length; i < len; ++i) {
                const v0 = val[i];
                const v1 = applyReviver(reviver, val, String(i), v0);
                if (v1 === undefined)
                    delete val[i];
                else if (v1 !== v0)
                    val[i] = v1;
            }
        }
        else if (val instanceof Map) {
            for (const k of Array.from(val.keys())) {
                const v0 = val.get(k);
                const v1 = applyReviver(reviver, val, k, v0);
                if (v1 === undefined)
                    val.delete(k);
                else if (v1 !== v0)
                    val.set(k, v1);
            }
        }
        else if (val instanceof Set) {
            for (const v0 of Array.from(val)) {
                const v1 = applyReviver(reviver, val, v0, v0);
                if (v1 === undefined)
                    val.delete(v0);
                else if (v1 !== v0) {
                    val.delete(v0);
                    val.add(v1);
                }
            }
        }
        else {
            for (const [k, v0] of Object.entries(val)) {
                const v1 = applyReviver(reviver, val, k, v0);
                if (v1 === undefined)
                    delete val[k];
                else if (v1 !== v0)
                    val[k] = v1;
            }
        }
    }
    return reviver.call(obj, key, val);
}

/**
 * Recursively convert any node or its contents to native JavaScript
 *
 * @param value - The input value
 * @param arg - If `value` defines a `toJSON()` method, use this
 *   as its first argument
 * @param ctx - Conversion context, originally set in Document#toJS(). If
 *   `{ keep: true }` is not set, output should be suitable for JSON
 *   stringification.
 */
function toJS(value, arg, ctx) {
    // eslint-disable-next-line @typescript-eslint/no-unsafe-return
    if (Array.isArray(value))
        return value.map((v, i) => toJS(v, String(i), ctx));
    if (value && typeof value.toJSON === 'function') {
        // eslint-disable-next-line @typescript-eslint/no-unsafe-call
        if (!ctx || !hasAnchor(value))
            return value.toJSON(arg, ctx);
        const data = { aliasCount: 0, count: 1, res: undefined };
        ctx.anchors.set(value, data);
        ctx.onCreate = res => {
            data.res = res;
            delete ctx.onCreate;
        };
        const res = value.toJSON(arg, ctx);
        if (ctx.onCreate)
            ctx.onCreate(res);
        return res;
    }
    if (typeof value === 'bigint' && !ctx?.keep)
        return Number(value);
    return value;
}

class NodeBase {
    constructor(type) {
        Object.defineProperty(this, NODE_TYPE, { value: type });
    }
    /** Create a copy of this node.  */
    clone() {
        const copy = Object.create(Object.getPrototypeOf(this), Object.getOwnPropertyDescriptors(this));
        if (this.range)
            copy.range = this.range.slice();
        return copy;
    }
    /** A plain JavaScript representation of this node. */
    toJS(doc, { mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {
        if (!isDocument(doc))
            throw new TypeError('A document argument is required');
        const ctx = {
            anchors: new Map(),
            doc,
            keep: true,
            mapAsMap: mapAsMap === true,
            mapKeyWarned: false,
            maxAliasCount: typeof maxAliasCount === 'number' ? maxAliasCount : 100
        };
        const res = toJS(this, '', ctx);
        if (typeof onAnchor === 'function')
            for (const { count, res } of ctx.anchors.values())
                onAnchor(res, count);
        return typeof reviver === 'function'
            ? applyReviver(reviver, { '': res }, '', res)
            : res;
    }
}

class Alias extends NodeBase {
    constructor(source) {
        super(ALIAS);
        this.source = source;
        Object.defineProperty(this, 'tag', {
            set() {
                throw new Error('Alias nodes cannot have tags');
            }
        });
    }
    /**
     * Resolve the value of this alias within `doc`, finding the last
     * instance of the `source` anchor before this node.
     */
    resolve(doc) {
        let found = undefined;
        visit(doc, {
            Node: (_key, node) => {
                if (node === this)
                    return visit.BREAK;
                if (node.anchor === this.source)
                    found = node;
            }
        });
        return found;
    }
    toJSON(_arg, ctx) {
        if (!ctx)
            return { source: this.source };
        const { anchors, doc, maxAliasCount } = ctx;
        const source = this.resolve(doc);
        if (!source) {
            const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`;
            throw new ReferenceError(msg);
        }
        let data = anchors.get(source);
        if (!data) {
            // Resolve anchors for Node.prototype.toJS()
            toJS(source, null, ctx);
            data = anchors.get(source);
        }
        /* istanbul ignore if */
        if (!data || data.res === undefined) {
            const msg = 'This should not happen: Alias anchor was not resolved?';
            throw new ReferenceError(msg);
        }
        if (maxAliasCount >= 0) {
            data.count += 1;
            if (data.aliasCount === 0)
                data.aliasCount = getAliasCount(doc, source, anchors);
            if (data.count * data.aliasCount > maxAliasCount) {
                const msg = 'Excessive alias count indicates a resource exhaustion attack';
                throw new ReferenceError(msg);
            }
        }
        return data.res;
    }
    toString(ctx, _onComment, _onChompKeep) {
        const src = `*${this.source}`;
        if (ctx) {
            anchorIsValid(this.source);
            if (ctx.options.verifyAliasOrder && !ctx.anchors.has(this.source)) {
                const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`;
                throw new Error(msg);
            }
            if (ctx.implicitKey)
                return `${src} `;
        }
        return src;
    }
}
function getAliasCount(doc, node, anchors) {
    if (isAlias(node)) {
        const source = node.resolve(doc);
        const anchor = anchors && source && anchors.get(source);
        return anchor ? anchor.count * anchor.aliasCount : 0;
    }
    else if (isCollection(node)) {
        let count = 0;
        for (const item of node.items) {
            const c = getAliasCount(doc, item, anchors);
            if (c > count)
                count = c;
        }
        return count;
    }
    else if (isPair(node)) {
        const kc = getAliasCount(doc, node.key, anchors);
        const vc = getAliasCount(doc, node.value, anchors);
        return Math.max(kc, vc);
    }
    return 1;
}

const isScalarValue = (value) => !value || (typeof value !== 'function' && typeof value !== 'object');
class Scalar extends NodeBase {
    constructor(value) {
        super(SCALAR$1);
        this.value = value;
    }
    toJSON(arg, ctx) {
        return ctx?.keep ? this.value : toJS(this.value, arg, ctx);
    }
    toString() {
        return String(this.value);
    }
}
Scalar.BLOCK_FOLDED = 'BLOCK_FOLDED';
Scalar.BLOCK_LITERAL = 'BLOCK_LITERAL';
Scalar.PLAIN = 'PLAIN';
Scalar.QUOTE_DOUBLE = 'QUOTE_DOUBLE';
Scalar.QUOTE_SINGLE = 'QUOTE_SINGLE';

const defaultTagPrefix = 'tag:yaml.org,2002:';
function findTagObject(value, tagName, tags) {
    if (tagName) {
        const match = tags.filter(t => t.tag === tagName);
        const tagObj = match.find(t => !t.format) ?? match[0];
        if (!tagObj)
            throw new Error(`Tag ${tagName} not found`);
        return tagObj;
    }
    return tags.find(t => t.identify?.(value) && !t.format);
}
function createNode(value, tagName, ctx) {
    if (isDocument(value))
        value = value.contents;
    if (isNode(value))
        return value;
    if (isPair(value)) {
        const map = ctx.schema[MAP].createNode?.(ctx.schema, null, ctx);
        map.items.push(value);
        return map;
    }
    if (value instanceof String ||
        value instanceof Number ||
        value instanceof Boolean ||
        (typeof BigInt !== 'undefined' && value instanceof BigInt) // not supported everywhere
    ) {
        // https://tc39.es/ecma262/#sec-serializejsonproperty
        value = value.valueOf();
    }
    const { aliasDuplicateObjects, onAnchor, onTagObj, schema, sourceObjects } = ctx;
    // Detect duplicate references to the same object & use Alias nodes for all
    // after first. The `ref` wrapper allows for circular references to resolve.
    let ref = undefined;
    if (aliasDuplicateObjects && value && typeof value === 'object') {
        ref = sourceObjects.get(value);
        if (ref) {
            if (!ref.anchor)
                ref.anchor = onAnchor(value);
            return new Alias(ref.anchor);
        }
        else {
            ref = { anchor: null, node: null };
            sourceObjects.set(value, ref);
        }
    }
    if (tagName?.startsWith('!!'))
        tagName = defaultTagPrefix + tagName.slice(2);
    let tagObj = findTagObject(value, tagName, schema.tags);
    if (!tagObj) {
        if (value && typeof value.toJSON === 'function') {
            // eslint-disable-next-line @typescript-eslint/no-unsafe-call
            value = value.toJSON();
        }
        if (!value || typeof value !== 'object') {
            const node = new Scalar(value);
            if (ref)
                ref.node = node;
            return node;
        }
        tagObj =
            value instanceof Map
                ? schema[MAP]
                : Symbol.iterator in Object(value)
                    ? schema[SEQ]
                    : schema[MAP];
    }
    if (onTagObj) {
        onTagObj(tagObj);
        delete ctx.onTagObj;
    }
    const node = tagObj?.createNode
        ? tagObj.createNode(ctx.schema, value, ctx)
        : typeof tagObj?.nodeClass?.from === 'function'
            ? tagObj.nodeClass.from(ctx.schema, value, ctx)
            : new Scalar(value);
    if (tagName)
        node.tag = tagName;
    else if (!tagObj.default)
        node.tag = tagObj.tag;
    if (ref)
        ref.node = node;
    return node;
}

function collectionFromPath(schema, path, value) {
    let v = value;
    for (let i = path.length - 1; i >= 0; --i) {
        const k = path[i];
        if (typeof k === 'number' && Number.isInteger(k) && k >= 0) {
            const a = [];
            a[k] = v;
            v = a;
        }
        else {
            v = new Map([[k, v]]);
        }
    }
    return createNode(v, undefined, {
        aliasDuplicateObjects: false,
        keepUndefined: false,
        onAnchor: () => {
            throw new Error('This should not happen, please report a bug.');
        },
        schema,
        sourceObjects: new Map()
    });
}
// Type guard is intentionally a little wrong so as to be more useful,
// as it does not cover untypable empty non-string iterables (e.g. []).
const isEmptyPath = (path) => path == null ||
    (typeof path === 'object' && !!path[Symbol.iterator]().next().done);
class Collection extends NodeBase {
    constructor(type, schema) {
        super(type);
        Object.defineProperty(this, 'schema', {
            value: schema,
            configurable: true,
            enumerable: false,
            writable: true
        });
    }
    /**
     * Create a copy of this collection.
     *
     * @param schema - If defined, overwrites the original's schema
     */
    clone(schema) {
        const copy = Object.create(Object.getPrototypeOf(this), Object.getOwnPropertyDescriptors(this));
        if (schema)
            copy.schema = schema;
        copy.items = copy.items.map(it => isNode(it) || isPair(it) ? it.clone(schema) : it);
        if (this.range)
            copy.range = this.range.slice();
        return copy;
    }
    /**
     * Adds a value to the collection. For `!!map` and `!!omap` the value must
     * be a Pair instance or a `{ key, value }` object, which may not have a key
     * that already exists in the map.
     */
    addIn(path, value) {
        if (isEmptyPath(path))
            this.add(value);
        else {
            const [key, ...rest] = path;
            const node = this.get(key, true);
            if (isCollection(node))
                node.addIn(rest, value);
            else if (node === undefined && this.schema)
                this.set(key, collectionFromPath(this.schema, rest, value));
            else
                throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);
        }
    }
    /**
     * Removes a value from the collection.
     * @returns `true` if the item was found and removed.
     */
    deleteIn(path) {
        const [key, ...rest] = path;
        if (rest.length === 0)
            return this.delete(key);
        const node = this.get(key, true);
        if (isCollection(node))
            return node.deleteIn(rest);
        else
            throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);
    }
    /**
     * Returns item at `key`, or `undefined` if not found. By default unwraps
     * scalar values from their surrounding node; to disable set `keepScalar` to
     * `true` (collections are always returned intact).
     */
    getIn(path, keepScalar) {
        const [key, ...rest] = path;
        const node = this.get(key, true);
        if (rest.length === 0)
            return !keepScalar && isScalar(node) ? node.value : node;
        else
            return isCollection(node) ? node.getIn(rest, keepScalar) : undefined;
    }
    hasAllNullValues(allowScalar) {
        return this.items.every(node => {
            if (!isPair(node))
                return false;
            const n = node.value;
            return (n == null ||
                (allowScalar &&
                    isScalar(n) &&
                    n.value == null &&
                    !n.commentBefore &&
                    !n.comment &&
                    !n.tag));
        });
    }
    /**
     * Checks if the collection includes a value with the key `key`.
     */
    hasIn(path) {
        const [key, ...rest] = path;
        if (rest.length === 0)
            return this.has(key);
        const node = this.get(key, true);
        return isCollection(node) ? node.hasIn(rest) : false;
    }
    /**
     * Sets a value in this collection. For `!!set`, `value` needs to be a
     * boolean to add/remove the item from the set.
     */
    setIn(path, value) {
        const [key, ...rest] = path;
        if (rest.length === 0) {
            this.set(key, value);
        }
        else {
            const node = this.get(key, true);
            if (isCollection(node))
                node.setIn(rest, value);
            else if (node === undefined && this.schema)
                this.set(key, collectionFromPath(this.schema, rest, value));
            else
                throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);
        }
    }
}
Collection.maxFlowStringSingleLineLength = 60;

/**
 * Stringifies a comment.
 *
 * Empty comment lines are left empty,
 * lines consisting of a single space are replaced by `#`,
 * and all other lines are prefixed with a `#`.
 */
const stringifyComment = (str) => str.replace(/^(?!$)(?: $)?/gm, '#');
function indentComment(comment, indent) {
    if (/^\n+$/.test(comment))
        return comment.substring(1);
    return indent ? comment.replace(/^(?! *$)/gm, indent) : comment;
}
const lineComment = (str, indent, comment) => str.endsWith('\n')
    ? indentComment(comment, indent)
    : comment.includes('\n')
        ? '\n' + indentComment(comment, indent)
        : (str.endsWith(' ') ? '' : ' ') + comment;

const FOLD_FLOW = 'flow';
const FOLD_BLOCK = 'block';
const FOLD_QUOTED = 'quoted';
/**
 * Tries to keep input at up to `lineWidth` characters, splitting only on spaces
 * not followed by newlines or spaces unless `mode` is `'quoted'`. Lines are
 * terminated with `\n` and started with `indent`.
 */
function foldFlowLines(text, indent, mode = 'flow', { indentAtStart, lineWidth = 80, minContentWidth = 20, onFold, onOverflow } = {}) {
    if (!lineWidth || lineWidth < 0)
        return text;
    const endStep = Math.max(1 + minContentWidth, 1 + lineWidth - indent.length);
    if (text.length <= endStep)
        return text;
    const folds = [];
    const escapedFolds = {};
    let end = lineWidth - indent.length;
    if (typeof indentAtStart === 'number') {
        if (indentAtStart > lineWidth - Math.max(2, minContentWidth))
            folds.push(0);
        else
            end = lineWidth - indentAtStart;
    }
    let split = undefined;
    let prev = undefined;
    let overflow = false;
    let i = -1;
    let escStart = -1;
    let escEnd = -1;
    if (mode === FOLD_BLOCK) {
        i = consumeMoreIndentedLines(text, i);
        if (i !== -1)
            end = i + endStep;
    }
    for (let ch; (ch = text[(i += 1)]);) {
        if (mode === FOLD_QUOTED && ch === '\\') {
            escStart = i;
            switch (text[i + 1]) {
                case 'x':
                    i += 3;
                    break;
                case 'u':
                    i += 5;
                    break;
                case 'U':
                    i += 9;
                    break;
                default:
                    i += 1;
            }
            escEnd = i;
        }
        if (ch === '\n') {
            if (mode === FOLD_BLOCK)
                i = consumeMoreIndentedLines(text, i);
            end = i + endStep;
            split = undefined;
        }
        else {
            if (ch === ' ' &&
                prev &&
                prev !== ' ' &&
                prev !== '\n' &&
                prev !== '\t') {
                // space surrounded by non-space can be replaced with newline + indent
                const next = text[i + 1];
                if (next && next !== ' ' && next !== '\n' && next !== '\t')
                    split = i;
            }
            if (i >= end) {
                if (split) {
                    folds.push(split);
                    end = split + endStep;
                    split = undefined;
                }
                else if (mode === FOLD_QUOTED) {
                    // white-space collected at end may stretch past lineWidth
                    while (prev === ' ' || prev === '\t') {
                        prev = ch;
                        ch = text[(i += 1)];
                        overflow = true;
                    }
                    // Account for newline escape, but don't break preceding escape
                    const j = i > escEnd + 1 ? i - 2 : escStart - 1;
                    // Bail out if lineWidth & minContentWidth are shorter than an escape string
                    if (escapedFolds[j])
                        return text;
                    folds.push(j);
                    escapedFolds[j] = true;
                    end = j + endStep;
                    split = undefined;
                }
                else {
                    overflow = true;
                }
            }
        }
        prev = ch;
    }
    if (overflow && onOverflow)
        onOverflow();
    if (folds.length === 0)
        return text;
    if (onFold)
        onFold();
    let res = text.slice(0, folds[0]);
    for (let i = 0; i < folds.length; ++i) {
        const fold = folds[i];
        const end = folds[i + 1] || text.length;
        if (fold === 0)
            res = `\n${indent}${text.slice(0, end)}`;
        else {
            if (mode === FOLD_QUOTED && escapedFolds[fold])
                res += `${text[fold]}\\`;
            res += `\n${indent}${text.slice(fold + 1, end)}`;
        }
    }
    return res;
}
/**
 * Presumes `i + 1` is at the start of a line
 * @returns index of last newline in more-indented block
 */
function consumeMoreIndentedLines(text, i) {
    let ch = text[i + 1];
    while (ch === ' ' || ch === '\t') {
        do {
            ch = text[(i += 1)];
        } while (ch && ch !== '\n');
        ch = text[i + 1];
    }
    return i;
}

const getFoldOptions = (ctx, isBlock) => ({
    indentAtStart: isBlock ? ctx.indent.length : ctx.indentAtStart,
    lineWidth: ctx.options.lineWidth,
    minContentWidth: ctx.options.minContentWidth
});
// Also checks for lines starting with %, as parsing the output as YAML 1.1 will
// presume that's starting a new document.
const containsDocumentMarker = (str) => /^(%|---|\.\.\.)/m.test(str);
function lineLengthOverLimit(str, lineWidth, indentLength) {
    if (!lineWidth || lineWidth < 0)
        return false;
    const limit = lineWidth - indentLength;
    const strLen = str.length;
    if (strLen <= limit)
        return false;
    for (let i = 0, start = 0; i < strLen; ++i) {
        if (str[i] === '\n') {
            if (i - start > limit)
                return true;
            start = i + 1;
            if (strLen - start <= limit)
                return false;
        }
    }
    return true;
}
function doubleQuotedString(value, ctx) {
    const json = JSON.stringify(value);
    if (ctx.options.doubleQuotedAsJSON)
        return json;
    const { implicitKey } = ctx;
    const minMultiLineLength = ctx.options.doubleQuotedMinMultiLineLength;
    const indent = ctx.indent || (containsDocumentMarker(value) ? '  ' : '');
    let str = '';
    let start = 0;
    for (let i = 0, ch = json[i]; ch; ch = json[++i]) {
        if (ch === ' ' && json[i + 1] === '\\' && json[i + 2] === 'n') {
            // space before newline needs to be escaped to not be folded
            str += json.slice(start, i) + '\\ ';
            i += 1;
            start = i;
            ch = '\\';
        }
        if (ch === '\\')
            switch (json[i + 1]) {
                case 'u':
                    {
                        str += json.slice(start, i);
                        const code = json.substr(i + 2, 4);
                        switch (code) {
                            case '0000':
                                str += '\\0';
                                break;
                            case '0007':
                                str += '\\a';
                                break;
                            case '000b':
                                str += '\\v';
                                break;
                            case '001b':
                                str += '\\e';
                                break;
                            case '0085':
                                str += '\\N';
                                break;
                            case '00a0':
                                str += '\\_';
                                break;
                            case '2028':
                                str += '\\L';
                                break;
                            case '2029':
                                str += '\\P';
                                break;
                            default:
                                if (code.substr(0, 2) === '00')
                                    str += '\\x' + code.substr(2);
                                else
                                    str += json.substr(i, 6);
                        }
                        i += 5;
                        start = i + 1;
                    }
                    break;
                case 'n':
                    if (implicitKey ||
                        json[i + 2] === '"' ||
                        json.length < minMultiLineLength) {
                        i += 1;
                    }
                    else {
                        // folding will eat first newline
                        str += json.slice(start, i) + '\n\n';
                        while (json[i + 2] === '\\' &&
                            json[i + 3] === 'n' &&
                            json[i + 4] !== '"') {
                            str += '\n';
                            i += 2;
                        }
                        str += indent;
                        // space after newline needs to be escaped to not be folded
                        if (json[i + 2] === ' ')
                            str += '\\';
                        i += 1;
                        start = i + 1;
                    }
                    break;
                default:
                    i += 1;
            }
    }
    str = start ? str + json.slice(start) : json;
    return implicitKey
        ? str
        : foldFlowLines(str, indent, FOLD_QUOTED, getFoldOptions(ctx, false));
}
function singleQuotedString(value, ctx) {
    if (ctx.options.singleQuote === false ||
        (ctx.implicitKey && value.includes('\n')) ||
        /[ \t]\n|\n[ \t]/.test(value) // single quoted string can't have leading or trailing whitespace around newline
    )
        return doubleQuotedString(value, ctx);
    const indent = ctx.indent || (containsDocumentMarker(value) ? '  ' : '');
    const res = "'" + value.replace(/'/g, "''").replace(/\n+/g, `$&\n${indent}`) + "'";
    return ctx.implicitKey
        ? res
        : foldFlowLines(res, indent, FOLD_FLOW, getFoldOptions(ctx, false));
}
function quotedString(value, ctx) {
    const { singleQuote } = ctx.options;
    let qs;
    if (singleQuote === false)
        qs = doubleQuotedString;
    else {
        const hasDouble = value.includes('"');
        const hasSingle = value.includes("'");
        if (hasDouble && !hasSingle)
            qs = singleQuotedString;
        else if (hasSingle && !hasDouble)
            qs = doubleQuotedString;
        else
            qs = singleQuote ? singleQuotedString : doubleQuotedString;
    }
    return qs(value, ctx);
}
// The negative lookbehind avoids a polynomial search,
// but isn't supported yet on Safari: https://caniuse.com/js-regexp-lookbehind
let blockEndNewlines;
try {
    blockEndNewlines = new RegExp('(^|(?<!\n))\n+(?!\n|$)', 'g');
}
catch {
    blockEndNewlines = /\n+(?!\n|$)/g;
}
function blockString({ comment, type, value }, ctx, onComment, onChompKeep) {
    const { blockQuote, commentString, lineWidth } = ctx.options;
    // 1. Block can't end in whitespace unless the last line is non-empty.
    // 2. Strings consisting of only whitespace are best rendered explicitly.
    if (!blockQuote || /\n[\t ]+$/.test(value) || /^\s*$/.test(value)) {
        return quotedString(value, ctx);
    }
    const indent = ctx.indent ||
        (ctx.forceBlockIndent || containsDocumentMarker(value) ? '  ' : '');
    const literal = blockQuote === 'literal'
        ? true
        : blockQuote === 'folded' || type === Scalar.BLOCK_FOLDED
            ? false
            : type === Scalar.BLOCK_LITERAL
                ? true
                : !lineLengthOverLimit(value, lineWidth, indent.length);
    if (!value)
        return literal ? '|\n' : '>\n';
    // determine chomping from whitespace at value end
    let chomp;
    let endStart;
    for (endStart = value.length; endStart > 0; --endStart) {
        const ch = value[endStart - 1];
        if (ch !== '\n' && ch !== '\t' && ch !== ' ')
            break;
    }
    let end = value.substring(endStart);
    const endNlPos = end.indexOf('\n');
    if (endNlPos === -1) {
        chomp = '-'; // strip
    }
    else if (value === end || endNlPos !== end.length - 1) {
        chomp = '+'; // keep
        if (onChompKeep)
            onChompKeep();
    }
    else {
        chomp = ''; // clip
    }
    if (end) {
        value = value.slice(0, -end.length);
        if (end[end.length - 1] === '\n')
            end = end.slice(0, -1);
        end = end.replace(blockEndNewlines, `$&${indent}`);
    }
    // determine indent indicator from whitespace at value start
    let startWithSpace = false;
    let startEnd;
    let startNlPos = -1;
    for (startEnd = 0; startEnd < value.length; ++startEnd) {
        const ch = value[startEnd];
        if (ch === ' ')
            startWithSpace = true;
        else if (ch === '\n')
            startNlPos = startEnd;
        else
            break;
    }
    let start = value.substring(0, startNlPos < startEnd ? startNlPos + 1 : startEnd);
    if (start) {
        value = value.substring(start.length);
        start = start.replace(/\n+/g, `$&${indent}`);
    }
    const indentSize = indent ? '2' : '1'; // root is at -1
    let header = (literal ? '|' : '>') + (startWithSpace ? indentSize : '') + chomp;
    if (comment) {
        header += ' ' + commentString(comment.replace(/ ?[\r\n]+/g, ' '));
        if (onComment)
            onComment();
    }
    if (literal) {
        value = value.replace(/\n+/g, `$&${indent}`);
        return `${header}\n${indent}${start}${value}${end}`;
    }
    value = value
        .replace(/\n+/g, '\n$&')
        .replace(/(?:^|\n)([\t ].*)(?:([\n\t ]*)\n(?![\n\t ]))?/g, '$1$2') // more-indented lines aren't folded
        //                ^ more-ind. ^ empty     ^ capture next empty lines only at end of indent
        .replace(/\n+/g, `$&${indent}`);
    const body = foldFlowLines(`${start}${value}${end}`, indent, FOLD_BLOCK, getFoldOptions(ctx, true));
    return `${header}\n${indent}${body}`;
}
function plainString(item, ctx, onComment, onChompKeep) {
    const { type, value } = item;
    const { actualString, implicitKey, indent, indentStep, inFlow } = ctx;
    if ((implicitKey && value.includes('\n')) ||
        (inFlow && /[[\]{},]/.test(value))) {
        return quotedString(value, ctx);
    }
    if (!value ||
        /^[\n\t ,[\]{}#&*!|>'"%@`]|^[?-]$|^[?-][ \t]|[\n:][ \t]|[ \t]\n|[\n\t ]#|[\n\t :]$/.test(value)) {
        // not allowed:
        // - empty string, '-' or '?'
        // - start with an indicator character (except [?:-]) or /[?-] /
        // - '\n ', ': ' or ' \n' anywhere
        // - '#' not preceded by a non-space char
        // - end with ' ' or ':'
        return implicitKey || inFlow || !value.includes('\n')
            ? quotedString(value, ctx)
            : blockString(item, ctx, onComment, onChompKeep);
    }
    if (!implicitKey &&
        !inFlow &&
        type !== Scalar.PLAIN &&
        value.includes('\n')) {
        // Where allowed & type not set explicitly, prefer block style for multiline strings
        return blockString(item, ctx, onComment, onChompKeep);
    }
    if (containsDocumentMarker(value)) {
        if (indent === '') {
            ctx.forceBlockIndent = true;
            return blockString(item, ctx, onComment, onChompKeep);
        }
        else if (implicitKey && indent === indentStep) {
            return quotedString(value, ctx);
        }
    }
    const str = value.replace(/\n+/g, `$&\n${indent}`);
    // Verify that output will be parsed as a string, as e.g. plain numbers and
    // booleans get parsed with those types in v1.2 (e.g. '42', 'true' & '0.9e-3'),
    // and others in v1.1.
    if (actualString) {
        const test = (tag) => tag.default && tag.tag !== 'tag:yaml.org,2002:str' && tag.test?.test(str);
        const { compat, tags } = ctx.doc.schema;
        if (tags.some(test) || compat?.some(test))
            return quotedString(value, ctx);
    }
    return implicitKey
        ? str
        : foldFlowLines(str, indent, FOLD_FLOW, getFoldOptions(ctx, false));
}
function stringifyString(item, ctx, onComment, onChompKeep) {
    const { implicitKey, inFlow } = ctx;
    const ss = typeof item.value === 'string'
        ? item
        : Object.assign({}, item, { value: String(item.value) });
    let { type } = item;
    if (type !== Scalar.QUOTE_DOUBLE) {
        // force double quotes on control characters & unpaired surrogates
        if (/[\x00-\x08\x0b-\x1f\x7f-\x9f\u{D800}-\u{DFFF}]/u.test(ss.value))
            type = Scalar.QUOTE_DOUBLE;
    }
    const _stringify = (_type) => {
        switch (_type) {
            case Scalar.BLOCK_FOLDED:
            case Scalar.BLOCK_LITERAL:
                return implicitKey || inFlow
                    ? quotedString(ss.value, ctx) // blocks are not valid inside flow containers
                    : blockString(ss, ctx, onComment, onChompKeep);
            case Scalar.QUOTE_DOUBLE:
                return doubleQuotedString(ss.value, ctx);
            case Scalar.QUOTE_SINGLE:
                return singleQuotedString(ss.value, ctx);
            case Scalar.PLAIN:
                return plainString(ss, ctx, onComment, onChompKeep);
            default:
                return null;
        }
    };
    let res = _stringify(type);
    if (res === null) {
        const { defaultKeyType, defaultStringType } = ctx.options;
        const t = (implicitKey && defaultKeyType) || defaultStringType;
        res = _stringify(t);
        if (res === null)
            throw new Error(`Unsupported default string type ${t}`);
    }
    return res;
}

function createStringifyContext(doc, options) {
    const opt = Object.assign({
        blockQuote: true,
        commentString: stringifyComment,
        defaultKeyType: null,
        defaultStringType: 'PLAIN',
        directives: null,
        doubleQuotedAsJSON: false,
        doubleQuotedMinMultiLineLength: 40,
        falseStr: 'false',
        flowCollectionPadding: true,
        indentSeq: true,
        lineWidth: 80,
        minContentWidth: 20,
        nullStr: 'null',
        simpleKeys: false,
        singleQuote: null,
        trueStr: 'true',
        verifyAliasOrder: true
    }, doc.schema.toStringOptions, options);
    let inFlow;
    switch (opt.collectionStyle) {
        case 'block':
            inFlow = false;
            break;
        case 'flow':
            inFlow = true;
            break;
        default:
            inFlow = null;
    }
    return {
        anchors: new Set(),
        doc,
        flowCollectionPadding: opt.flowCollectionPadding ? ' ' : '',
        indent: '',
        indentStep: typeof opt.indent === 'number' ? ' '.repeat(opt.indent) : '  ',
        inFlow,
        options: opt
    };
}
function getTagObject(tags, item) {
    if (item.tag) {
        const match = tags.filter(t => t.tag === item.tag);
        if (match.length > 0)
            return match.find(t => t.format === item.format) ?? match[0];
    }
    let tagObj = undefined;
    let obj;
    if (isScalar(item)) {
        obj = item.value;
        const match = tags.filter(t => t.identify?.(obj));
        tagObj =
            match.find(t => t.format === item.format) ?? match.find(t => !t.format);
    }
    else {
        obj = item;
        tagObj = tags.find(t => t.nodeClass && obj instanceof t.nodeClass);
    }
    if (!tagObj) {
        const name = obj?.constructor?.name ?? typeof obj;
        throw new Error(`Tag not resolved for ${name} value`);
    }
    return tagObj;
}
// needs to be called before value stringifier to allow for circular anchor refs
function stringifyProps(node, tagObj, { anchors, doc }) {
    if (!doc.directives)
        return '';
    const props = [];
    const anchor = (isScalar(node) || isCollection(node)) && node.anchor;
    if (anchor && anchorIsValid(anchor)) {
        anchors.add(anchor);
        props.push(`&${anchor}`);
    }
    const tag = node.tag ? node.tag : tagObj.default ? null : tagObj.tag;
    if (tag)
        props.push(doc.directives.tagString(tag));
    return props.join(' ');
}
function stringify$1(item, ctx, onComment, onChompKeep) {
    if (isPair(item))
        return item.toString(ctx, onComment, onChompKeep);
    if (isAlias(item)) {
        if (ctx.doc.directives)
            return item.toString(ctx);
        if (ctx.resolvedAliases?.has(item)) {
            throw new TypeError(`Cannot stringify circular structure without alias nodes`);
        }
        else {
            if (ctx.resolvedAliases)
                ctx.resolvedAliases.add(item);
            else
                ctx.resolvedAliases = new Set([item]);
            item = item.resolve(ctx.doc);
        }
    }
    let tagObj = undefined;
    const node = isNode(item)
        ? item
        : ctx.doc.createNode(item, { onTagObj: o => (tagObj = o) });
    if (!tagObj)
        tagObj = getTagObject(ctx.doc.schema.tags, node);
    const props = stringifyProps(node, tagObj, ctx);
    if (props.length > 0)
        ctx.indentAtStart = (ctx.indentAtStart ?? 0) + props.length + 1;
    const str = typeof tagObj.stringify === 'function'
        ? tagObj.stringify(node, ctx, onComment, onChompKeep)
        : isScalar(node)
            ? stringifyString(node, ctx, onComment, onChompKeep)
            : node.toString(ctx, onComment, onChompKeep);
    if (!props)
        return str;
    return isScalar(node) || str[0] === '{' || str[0] === '['
        ? `${props} ${str}`
        : `${props}\n${ctx.indent}${str}`;
}

function stringifyPair({ key, value }, ctx, onComment, onChompKeep) {
    const { allNullValues, doc, indent, indentStep, options: { commentString, indentSeq, simpleKeys } } = ctx;
    let keyComment = (isNode(key) && key.comment) || null;
    if (simpleKeys) {
        if (keyComment) {
            throw new Error('With simple keys, key nodes cannot have comments');
        }
        if (isCollection(key)) {
            const msg = 'With simple keys, collection cannot be used as a key value';
            throw new Error(msg);
        }
    }
    let explicitKey = !simpleKeys &&
        (!key ||
            (keyComment && value == null && !ctx.inFlow) ||
            isCollection(key) ||
            (isScalar(key)
                ? key.type === Scalar.BLOCK_FOLDED || key.type === Scalar.BLOCK_LITERAL
                : typeof key === 'object'));
    ctx = Object.assign({}, ctx, {
        allNullValues: false,
        implicitKey: !explicitKey && (simpleKeys || !allNullValues),
        indent: indent + indentStep
    });
    let keyCommentDone = false;
    let chompKeep = false;
    let str = stringify$1(key, ctx, () => (keyCommentDone = true), () => (chompKeep = true));
    if (!explicitKey && !ctx.inFlow && str.length > 1024) {
        if (simpleKeys)
            throw new Error('With simple keys, single line scalar must not span more than 1024 characters');
        explicitKey = true;
    }
    if (ctx.inFlow) {
        if (allNullValues || value == null) {
            if (keyCommentDone && onComment)
                onComment();
            return str === '' ? '?' : explicitKey ? `? ${str}` : str;
        }
    }
    else if ((allNullValues && !simpleKeys) || (value == null && explicitKey)) {
        str = `? ${str}`;
        if (keyComment && !keyCommentDone) {
            str += lineComment(str, ctx.indent, commentString(keyComment));
        }
        else if (chompKeep && onChompKeep)
            onChompKeep();
        return str;
    }
    if (keyCommentDone)
        keyComment = null;
    if (explicitKey) {
        if (keyComment)
            str += lineComment(str, ctx.indent, commentString(keyComment));
        str = `? ${str}\n${indent}:`;
    }
    else {
        str = `${str}:`;
        if (keyComment)
            str += lineComment(str, ctx.indent, commentString(keyComment));
    }
    let vsb, vcb, valueComment;
    if (isNode(value)) {
        vsb = !!value.spaceBefore;
        vcb = value.commentBefore;
        valueComment = value.comment;
    }
    else {
        vsb = false;
        vcb = null;
        valueComment = null;
        if (value && typeof value === 'object')
            value = doc.createNode(value);
    }
    ctx.implicitKey = false;
    if (!explicitKey && !keyComment && isScalar(value))
        ctx.indentAtStart = str.length + 1;
    chompKeep = false;
    if (!indentSeq &&
        indentStep.length >= 2 &&
        !ctx.inFlow &&
        !explicitKey &&
        isSeq(value) &&
        !value.flow &&
        !value.tag &&
        !value.anchor) {
        // If indentSeq === false, consider '- ' as part of indentation where possible
        ctx.indent = ctx.indent.substring(2);
    }
    let valueCommentDone = false;
    const valueStr = stringify$1(value, ctx, () => (valueCommentDone = true), () => (chompKeep = true));
    let ws = ' ';
    if (keyComment || vsb || vcb) {
        ws = vsb ? '\n' : '';
        if (vcb) {
            const cs = commentString(vcb);
            ws += `\n${indentComment(cs, ctx.indent)}`;
        }
        if (valueStr === '' && !ctx.inFlow) {
            if (ws === '\n')
                ws = '\n\n';
        }
        else {
            ws += `\n${ctx.indent}`;
        }
    }
    else if (!explicitKey && isCollection(value)) {
        const vs0 = valueStr[0];
        const nl0 = valueStr.indexOf('\n');
        const hasNewline = nl0 !== -1;
        const flow = ctx.inFlow ?? value.flow ?? value.items.length === 0;
        if (hasNewline || !flow) {
            let hasPropsLine = false;
            if (hasNewline && (vs0 === '&' || vs0 === '!')) {
                let sp0 = valueStr.indexOf(' ');
                if (vs0 === '&' &&
                    sp0 !== -1 &&
                    sp0 < nl0 &&
                    valueStr[sp0 + 1] === '!') {
                    sp0 = valueStr.indexOf(' ', sp0 + 1);
                }
                if (sp0 === -1 || nl0 < sp0)
                    hasPropsLine = true;
            }
            if (!hasPropsLine)
                ws = `\n${ctx.indent}`;
        }
    }
    else if (valueStr === '' || valueStr[0] === '\n') {
        ws = '';
    }
    str += ws + valueStr;
    if (ctx.inFlow) {
        if (valueCommentDone && onComment)
            onComment();
    }
    else if (valueComment && !valueCommentDone) {
        str += lineComment(str, ctx.indent, commentString(valueComment));
    }
    else if (chompKeep && onChompKeep) {
        onChompKeep();
    }
    return str;
}

function warn(logLevel, warning) {
    if (logLevel === 'debug' || logLevel === 'warn') {
        // https://github.com/typescript-eslint/typescript-eslint/issues/7478
        // eslint-disable-next-line @typescript-eslint/prefer-optional-chain
        if (typeof process !== 'undefined' && process.emitWarning)
            process.emitWarning(warning);
        else
            console.warn(warning);
    }
}

const MERGE_KEY = '<<';
function addPairToJSMap(ctx, map, { key, value }) {
    if (ctx?.doc.schema.merge && isMergeKey(key)) {
        value = isAlias(value) ? value.resolve(ctx.doc) : value;
        if (isSeq(value))
            for (const it of value.items)
                mergeToJSMap(ctx, map, it);
        else if (Array.isArray(value))
            for (const it of value)
                mergeToJSMap(ctx, map, it);
        else
            mergeToJSMap(ctx, map, value);
    }
    else {
        const jsKey = toJS(key, '', ctx);
        if (map instanceof Map) {
            map.set(jsKey, toJS(value, jsKey, ctx));
        }
        else if (map instanceof Set) {
            map.add(jsKey);
        }
        else {
            const stringKey = stringifyKey(key, jsKey, ctx);
            const jsValue = toJS(value, stringKey, ctx);
            if (stringKey in map)
                Object.defineProperty(map, stringKey, {
                    value: jsValue,
                    writable: true,
                    enumerable: true,
                    configurable: true
                });
            else
                map[stringKey] = jsValue;
        }
    }
    return map;
}
const isMergeKey = (key) => key === MERGE_KEY ||
    (isScalar(key) &&
        key.value === MERGE_KEY &&
        (!key.type || key.type === Scalar.PLAIN));
// If the value associated with a merge key is a single mapping node, each of
// its key/value pairs is inserted into the current mapping, unless the key
// already exists in it. If the value associated with the merge key is a
// sequence, then this sequence is expected to contain mapping nodes and each
// of these nodes is merged in turn according to its order in the sequence.
// Keys in mapping nodes earlier in the sequence override keys specified in
// later mapping nodes. -- http://yaml.org/type/merge.html
function mergeToJSMap(ctx, map, value) {
    const source = ctx && isAlias(value) ? value.resolve(ctx.doc) : value;
    if (!isMap(source))
        throw new Error('Merge sources must be maps or map aliases');
    const srcMap = source.toJSON(null, ctx, Map);
    for (const [key, value] of srcMap) {
        if (map instanceof Map) {
            if (!map.has(key))
                map.set(key, value);
        }
        else if (map instanceof Set) {
            map.add(key);
        }
        else if (!Object.prototype.hasOwnProperty.call(map, key)) {
            Object.defineProperty(map, key, {
                value,
                writable: true,
                enumerable: true,
                configurable: true
            });
        }
    }
    return map;
}
function stringifyKey(key, jsKey, ctx) {
    if (jsKey === null)
        return '';
    if (typeof jsKey !== 'object')
        return String(jsKey);
    if (isNode(key) && ctx?.doc) {
        const strCtx = createStringifyContext(ctx.doc, {});
        strCtx.anchors = new Set();
        for (const node of ctx.anchors.keys())
            strCtx.anchors.add(node.anchor);
        strCtx.inFlow = true;
        strCtx.inStringifyKey = true;
        const strKey = key.toString(strCtx);
        if (!ctx.mapKeyWarned) {
            let jsonStr = JSON.stringify(strKey);
            if (jsonStr.length > 40)
                jsonStr = jsonStr.substring(0, 36) + '..."';
            warn(ctx.doc.options.logLevel, `Keys with collection values will be stringified due to JS Object restrictions: ${jsonStr}. Set mapAsMap: true to use object keys.`);
            ctx.mapKeyWarned = true;
        }
        return strKey;
    }
    return JSON.stringify(jsKey);
}

function createPair(key, value, ctx) {
    const k = createNode(key, undefined, ctx);
    const v = createNode(value, undefined, ctx);
    return new Pair(k, v);
}
class Pair {
    constructor(key, value = null) {
        Object.defineProperty(this, NODE_TYPE, { value: PAIR });
        this.key = key;
        this.value = value;
    }
    clone(schema) {
        let { key, value } = this;
        if (isNode(key))
            key = key.clone(schema);
        if (isNode(value))
            value = value.clone(schema);
        return new Pair(key, value);
    }
    toJSON(_, ctx) {
        const pair = ctx?.mapAsMap ? new Map() : {};
        return addPairToJSMap(ctx, pair, this);
    }
    toString(ctx, onComment, onChompKeep) {
        return ctx?.doc
            ? stringifyPair(this, ctx, onComment, onChompKeep)
            : JSON.stringify(this);
    }
}

function stringifyCollection(collection, ctx, options) {
    const flow = ctx.inFlow ?? collection.flow;
    const stringify = flow ? stringifyFlowCollection : stringifyBlockCollection;
    return stringify(collection, ctx, options);
}
function stringifyBlockCollection({ comment, items }, ctx, { blockItemPrefix, flowChars, itemIndent, onChompKeep, onComment }) {
    const { indent, options: { commentString } } = ctx;
    const itemCtx = Object.assign({}, ctx, { indent: itemIndent, type: null });
    let chompKeep = false; // flag for the preceding node's status
    const lines = [];
    for (let i = 0; i < items.length; ++i) {
        const item = items[i];
        let comment = null;
        if (isNode(item)) {
            if (!chompKeep && item.spaceBefore)
                lines.push('');
            addCommentBefore(ctx, lines, item.commentBefore, chompKeep);
            if (item.comment)
                comment = item.comment;
        }
        else if (isPair(item)) {
            const ik = isNode(item.key) ? item.key : null;
            if (ik) {
                if (!chompKeep && ik.spaceBefore)
                    lines.push('');
                addCommentBefore(ctx, lines, ik.commentBefore, chompKeep);
            }
        }
        chompKeep = false;
        let str = stringify$1(item, itemCtx, () => (comment = null), () => (chompKeep = true));
        if (comment)
            str += lineComment(str, itemIndent, commentString(comment));
        if (chompKeep && comment)
            chompKeep = false;
        lines.push(blockItemPrefix + str);
    }
    let str;
    if (lines.length === 0) {
        str = flowChars.start + flowChars.end;
    }
    else {
        str = lines[0];
        for (let i = 1; i < lines.length; ++i) {
            const line = lines[i];
            str += line ? `\n${indent}${line}` : '\n';
        }
    }
    if (comment) {
        str += '\n' + indentComment(commentString(comment), indent);
        if (onComment)
            onComment();
    }
    else if (chompKeep && onChompKeep)
        onChompKeep();
    return str;
}
function stringifyFlowCollection({ comment, items }, ctx, { flowChars, itemIndent, onComment }) {
    const { indent, indentStep, flowCollectionPadding: fcPadding, options: { commentString } } = ctx;
    itemIndent += indentStep;
    const itemCtx = Object.assign({}, ctx, {
        indent: itemIndent,
        inFlow: true,
        type: null
    });
    let reqNewline = false;
    let linesAtValue = 0;
    const lines = [];
    for (let i = 0; i < items.length; ++i) {
        const item = items[i];
        let comment = null;
        if (isNode(item)) {
            if (item.spaceBefore)
                lines.push('');
            addCommentBefore(ctx, lines, item.commentBefore, false);
            if (item.comment)
                comment = item.comment;
        }
        else if (isPair(item)) {
            const ik = isNode(item.key) ? item.key : null;
            if (ik) {
                if (ik.spaceBefore)
                    lines.push('');
                addCommentBefore(ctx, lines, ik.commentBefore, false);
                if (ik.comment)
                    reqNewline = true;
            }
            const iv = isNode(item.value) ? item.value : null;
            if (iv) {
                if (iv.comment)
                    comment = iv.comment;
                if (iv.commentBefore)
                    reqNewline = true;
            }
            else if (item.value == null && ik?.comment) {
                comment = ik.comment;
            }
        }
        if (comment)
            reqNewline = true;
        let str = stringify$1(item, itemCtx, () => (comment = null));
        if (i < items.length - 1)
            str += ',';
        if (comment)
            str += lineComment(str, itemIndent, commentString(comment));
        if (!reqNewline && (lines.length > linesAtValue || str.includes('\n')))
            reqNewline = true;
        lines.push(str);
        linesAtValue = lines.length;
    }
    let str;
    const { start, end } = flowChars;
    if (lines.length === 0) {
        str = start + end;
    }
    else {
        if (!reqNewline) {
            const len = lines.reduce((sum, line) => sum + line.length + 2, 2);
            reqNewline = len > Collection.maxFlowStringSingleLineLength;
        }
        if (reqNewline) {
            str = start;
            for (const line of lines)
                str += line ? `\n${indentStep}${indent}${line}` : '\n';
            str += `\n${indent}${end}`;
        }
        else {
            str = `${start}${fcPadding}${lines.join(' ')}${fcPadding}${end}`;
        }
    }
    if (comment) {
        str += lineComment(str, indent, commentString(comment));
        if (onComment)
            onComment();
    }
    return str;
}
function addCommentBefore({ indent, options: { commentString } }, lines, comment, chompKeep) {
    if (comment && chompKeep)
        comment = comment.replace(/^\n+/, '');
    if (comment) {
        const ic = indentComment(commentString(comment), indent);
        lines.push(ic.trimStart()); // Avoid double indent on first line
    }
}

function findPair(items, key) {
    const k = isScalar(key) ? key.value : key;
    for (const it of items) {
        if (isPair(it)) {
            if (it.key === key || it.key === k)
                return it;
            if (isScalar(it.key) && it.key.value === k)
                return it;
        }
    }
    return undefined;
}
class YAMLMap extends Collection {
    static get tagName() {
        return 'tag:yaml.org,2002:map';
    }
    constructor(schema) {
        super(MAP, schema);
        this.items = [];
    }
    /**
     * A generic collection parsing method that can be extended
     * to other node classes that inherit from YAMLMap
     */
    static from(schema, obj, ctx) {
        const { keepUndefined, replacer } = ctx;
        const map = new this(schema);
        const add = (key, value) => {
            if (typeof replacer === 'function')
                value = replacer.call(obj, key, value);
            else if (Array.isArray(replacer) && !replacer.includes(key))
                return;
            if (value !== undefined || keepUndefined)
                map.items.push(createPair(key, value, ctx));
        };
        if (obj instanceof Map) {
            for (const [key, value] of obj)
                add(key, value);
        }
        else if (obj && typeof obj === 'object') {
            for (const key of Object.keys(obj))
                add(key, obj[key]);
        }
        if (typeof schema.sortMapEntries === 'function') {
            map.items.sort(schema.sortMapEntries);
        }
        return map;
    }
    /**
     * Adds a value to the collection.
     *
     * @param overwrite - If not set `true`, using a key that is already in the
     *   collection will throw. Otherwise, overwrites the previous value.
     */
    add(pair, overwrite) {
        let _pair;
        if (isPair(pair))
            _pair = pair;
        else if (!pair || typeof pair !== 'object' || !('key' in pair)) {
            // In TypeScript, this never happens.
            _pair = new Pair(pair, pair?.value);
        }
        else
            _pair = new Pair(pair.key, pair.value);
        const prev = findPair(this.items, _pair.key);
        const sortEntries = this.schema?.sortMapEntries;
        if (prev) {
            if (!overwrite)
                throw new Error(`Key ${_pair.key} already set`);
            // For scalars, keep the old node & its comments and anchors
            if (isScalar(prev.value) && isScalarValue(_pair.value))
                prev.value.value = _pair.value;
            else
                prev.value = _pair.value;
        }
        else if (sortEntries) {
            const i = this.items.findIndex(item => sortEntries(_pair, item) < 0);
            if (i === -1)
                this.items.push(_pair);
            else
                this.items.splice(i, 0, _pair);
        }
        else {
            this.items.push(_pair);
        }
    }
    delete(key) {
        const it = findPair(this.items, key);
        if (!it)
            return false;
        const del = this.items.splice(this.items.indexOf(it), 1);
        return del.length > 0;
    }
    get(key, keepScalar) {
        const it = findPair(this.items, key);
        const node = it?.value;
        return (!keepScalar && isScalar(node) ? node.value : node) ?? undefined;
    }
    has(key) {
        return !!findPair(this.items, key);
    }
    set(key, value) {
        this.add(new Pair(key, value), true);
    }
    /**
     * @param ctx - Conversion context, originally set in Document#toJS()
     * @param {Class} Type - If set, forces the returned collection type
     * @returns Instance of Type, Map, or Object
     */
    toJSON(_, ctx, Type) {
        const map = Type ? new Type() : ctx?.mapAsMap ? new Map() : {};
        if (ctx?.onCreate)
            ctx.onCreate(map);
        for (const item of this.items)
            addPairToJSMap(ctx, map, item);
        return map;
    }
    toString(ctx, onComment, onChompKeep) {
        if (!ctx)
            return JSON.stringify(this);
        for (const item of this.items) {
            if (!isPair(item))
                throw new Error(`Map items must all be pairs; found ${JSON.stringify(item)} instead`);
        }
        if (!ctx.allNullValues && this.hasAllNullValues(false))
            ctx = Object.assign({}, ctx, { allNullValues: true });
        return stringifyCollection(this, ctx, {
            blockItemPrefix: '',
            flowChars: { start: '{', end: '}' },
            itemIndent: ctx.indent || '',
            onChompKeep,
            onComment
        });
    }
}

const map = {
    collection: 'map',
    default: true,
    nodeClass: YAMLMap,
    tag: 'tag:yaml.org,2002:map',
    resolve(map, onError) {
        if (!isMap(map))
            onError('Expected a mapping for this tag');
        return map;
    },
    createNode: (schema, obj, ctx) => YAMLMap.from(schema, obj, ctx)
};

class YAMLSeq extends Collection {
    static get tagName() {
        return 'tag:yaml.org,2002:seq';
    }
    constructor(schema) {
        super(SEQ, schema);
        this.items = [];
    }
    add(value) {
        this.items.push(value);
    }
    /**
     * Removes a value from the collection.
     *
     * `key` must contain a representation of an integer for this to succeed.
     * It may be wrapped in a `Scalar`.
     *
     * @returns `true` if the item was found and removed.
     */
    delete(key) {
        const idx = asItemIndex(key);
        if (typeof idx !== 'number')
            return false;
        const del = this.items.splice(idx, 1);
        return del.length > 0;
    }
    get(key, keepScalar) {
        const idx = asItemIndex(key);
        if (typeof idx !== 'number')
            return undefined;
        const it = this.items[idx];
        return !keepScalar && isScalar(it) ? it.value : it;
    }
    /**
     * Checks if the collection includes a value with the key `key`.
     *
     * `key` must contain a representation of an integer for this to succeed.
     * It may be wrapped in a `Scalar`.
     */
    has(key) {
        const idx = asItemIndex(key);
        return typeof idx === 'number' && idx < this.items.length;
    }
    /**
     * Sets a value in this collection. For `!!set`, `value` needs to be a
     * boolean to add/remove the item from the set.
     *
     * If `key` does not contain a representation of an integer, this will throw.
     * It may be wrapped in a `Scalar`.
     */
    set(key, value) {
        const idx = asItemIndex(key);
        if (typeof idx !== 'number')
            throw new Error(`Expected a valid index, not ${key}.`);
        const prev = this.items[idx];
        if (isScalar(prev) && isScalarValue(value))
            prev.value = value;
        else
            this.items[idx] = value;
    }
    toJSON(_, ctx) {
        const seq = [];
        if (ctx?.onCreate)
            ctx.onCreate(seq);
        let i = 0;
        for (const item of this.items)
            seq.push(toJS(item, String(i++), ctx));
        return seq;
    }
    toString(ctx, onComment, onChompKeep) {
        if (!ctx)
            return JSON.stringify(this);
        return stringifyCollection(this, ctx, {
            blockItemPrefix: '- ',
            flowChars: { start: '[', end: ']' },
            itemIndent: (ctx.indent || '') + '  ',
            onChompKeep,
            onComment
        });
    }
    static from(schema, obj, ctx) {
        const { replacer } = ctx;
        const seq = new this(schema);
        if (obj && Symbol.iterator in Object(obj)) {
            let i = 0;
            for (let it of obj) {
                if (typeof replacer === 'function') {
                    const key = obj instanceof Set ? it : String(i++);
                    it = replacer.call(obj, key, it);
                }
                seq.items.push(createNode(it, undefined, ctx));
            }
        }
        return seq;
    }
}
function asItemIndex(key) {
    let idx = isScalar(key) ? key.value : key;
    if (idx && typeof idx === 'string')
        idx = Number(idx);
    return typeof idx === 'number' && Number.isInteger(idx) && idx >= 0
        ? idx
        : null;
}

const seq = {
    collection: 'seq',
    default: true,
    nodeClass: YAMLSeq,
    tag: 'tag:yaml.org,2002:seq',
    resolve(seq, onError) {
        if (!isSeq(seq))
            onError('Expected a sequence for this tag');
        return seq;
    },
    createNode: (schema, obj, ctx) => YAMLSeq.from(schema, obj, ctx)
};

const string$1 = {
    identify: value => typeof value === 'string',
    default: true,
    tag: 'tag:yaml.org,2002:str',
    resolve: str => str,
    stringify(item, ctx, onComment, onChompKeep) {
        ctx = Object.assign({ actualString: true }, ctx);
        return stringifyString(item, ctx, onComment, onChompKeep);
    }
};

const nullTag = {
    identify: value => value == null,
    createNode: () => new Scalar(null),
    default: true,
    tag: 'tag:yaml.org,2002:null',
    test: /^(?:~|[Nn]ull|NULL)?$/,
    resolve: () => new Scalar(null),
    stringify: ({ source }, ctx) => typeof source === 'string' && nullTag.test.test(source)
        ? source
        : ctx.options.nullStr
};

const boolTag = {
    identify: value => typeof value === 'boolean',
    default: true,
    tag: 'tag:yaml.org,2002:bool',
    test: /^(?:[Tt]rue|TRUE|[Ff]alse|FALSE)$/,
    resolve: str => new Scalar(str[0] === 't' || str[0] === 'T'),
    stringify({ source, value }, ctx) {
        if (source && boolTag.test.test(source)) {
            const sv = source[0] === 't' || source[0] === 'T';
            if (value === sv)
                return source;
        }
        return value ? ctx.options.trueStr : ctx.options.falseStr;
    }
};

function stringifyNumber({ format, minFractionDigits, tag, value }) {
    if (typeof value === 'bigint')
        return String(value);
    const num = typeof value === 'number' ? value : Number(value);
    if (!isFinite(num))
        return isNaN(num) ? '.nan' : num < 0 ? '-.inf' : '.inf';
    let n = JSON.stringify(value);
    if (!format &&
        minFractionDigits &&
        (!tag || tag === 'tag:yaml.org,2002:float') &&
        /^\d/.test(n)) {
        let i = n.indexOf('.');
        if (i < 0) {
            i = n.length;
            n += '.';
        }
        let d = minFractionDigits - (n.length - i - 1);
        while (d-- > 0)
            n += '0';
    }
    return n;
}

const floatNaN$1 = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    test: /^(?:[-+]?\.(?:inf|Inf|INF|nan|NaN|NAN))$/,
    resolve: str => str.slice(-3).toLowerCase() === 'nan'
        ? NaN
        : str[0] === '-'
            ? Number.NEGATIVE_INFINITY
            : Number.POSITIVE_INFINITY,
    stringify: stringifyNumber
};
const floatExp$1 = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    format: 'EXP',
    test: /^[-+]?(?:\.[0-9]+|[0-9]+(?:\.[0-9]*)?)[eE][-+]?[0-9]+$/,
    resolve: str => parseFloat(str),
    stringify(node) {
        const num = Number(node.value);
        return isFinite(num) ? num.toExponential() : stringifyNumber(node);
    }
};
const float$2 = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    test: /^[-+]?(?:\.[0-9]+|[0-9]+\.[0-9]*)$/,
    resolve(str) {
        const node = new Scalar(parseFloat(str));
        const dot = str.indexOf('.');
        if (dot !== -1 && str[str.length - 1] === '0')
            node.minFractionDigits = str.length - dot - 1;
        return node;
    },
    stringify: stringifyNumber
};

const intIdentify$2 = (value) => typeof value === 'bigint' || Number.isInteger(value);
const intResolve$1 = (str, offset, radix, { intAsBigInt }) => (intAsBigInt ? BigInt(str) : parseInt(str.substring(offset), radix));
function intStringify$1(node, radix, prefix) {
    const { value } = node;
    if (intIdentify$2(value) && value >= 0)
        return prefix + value.toString(radix);
    return stringifyNumber(node);
}
const intOct$1 = {
    identify: value => intIdentify$2(value) && value >= 0,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    format: 'OCT',
    test: /^0o[0-7]+$/,
    resolve: (str, _onError, opt) => intResolve$1(str, 2, 8, opt),
    stringify: node => intStringify$1(node, 8, '0o')
};
const int$2 = {
    identify: intIdentify$2,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    test: /^[-+]?[0-9]+$/,
    resolve: (str, _onError, opt) => intResolve$1(str, 0, 10, opt),
    stringify: stringifyNumber
};
const intHex$1 = {
    identify: value => intIdentify$2(value) && value >= 0,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    format: 'HEX',
    test: /^0x[0-9a-fA-F]+$/,
    resolve: (str, _onError, opt) => intResolve$1(str, 2, 16, opt),
    stringify: node => intStringify$1(node, 16, '0x')
};

const schema$2 = [
    map,
    seq,
    string$1,
    nullTag,
    boolTag,
    intOct$1,
    int$2,
    intHex$1,
    floatNaN$1,
    floatExp$1,
    float$2
];

function intIdentify$1(value) {
    return typeof value === 'bigint' || Number.isInteger(value);
}
const stringifyJSON = ({ value }) => JSON.stringify(value);
const jsonScalars = [
    {
        identify: value => typeof value === 'string',
        default: true,
        tag: 'tag:yaml.org,2002:str',
        resolve: str => str,
        stringify: stringifyJSON
    },
    {
        identify: value => value == null,
        createNode: () => new Scalar(null),
        default: true,
        tag: 'tag:yaml.org,2002:null',
        test: /^null$/,
        resolve: () => null,
        stringify: stringifyJSON
    },
    {
        identify: value => typeof value === 'boolean',
        default: true,
        tag: 'tag:yaml.org,2002:bool',
        test: /^true|false$/,
        resolve: str => str === 'true',
        stringify: stringifyJSON
    },
    {
        identify: intIdentify$1,
        default: true,
        tag: 'tag:yaml.org,2002:int',
        test: /^-?(?:0|[1-9][0-9]*)$/,
        resolve: (str, _onError, { intAsBigInt }) => intAsBigInt ? BigInt(str) : parseInt(str, 10),
        stringify: ({ value }) => intIdentify$1(value) ? value.toString() : JSON.stringify(value)
    },
    {
        identify: value => typeof value === 'number',
        default: true,
        tag: 'tag:yaml.org,2002:float',
        test: /^-?(?:0|[1-9][0-9]*)(?:\.[0-9]*)?(?:[eE][-+]?[0-9]+)?$/,
        resolve: str => parseFloat(str),
        stringify: stringifyJSON
    }
];
const jsonError = {
    default: true,
    tag: '',
    test: /^/,
    resolve(str, onError) {
        onError(`Unresolved plain scalar ${JSON.stringify(str)}`);
        return str;
    }
};
const schema$1 = [map, seq].concat(jsonScalars, jsonError);

const binary = {
    identify: value => value instanceof Uint8Array,
    default: false,
    tag: 'tag:yaml.org,2002:binary',
    /**
     * Returns a Buffer in node and an Uint8Array in browsers
     *
     * To use the resulting buffer as an image, you'll want to do something like:
     *
     *   const blob = new Blob([buffer], { type: 'image/jpeg' })
     *   document.querySelector('#photo').src = URL.createObjectURL(blob)
     */
    resolve(src, onError) {
        if (typeof Buffer === 'function') {
            return Buffer.from(src, 'base64');
        }
        else if (typeof atob === 'function') {
            // On IE 11, atob() can't handle newlines
            const str = atob(src.replace(/[\n\r]/g, ''));
            const buffer = new Uint8Array(str.length);
            for (let i = 0; i < str.length; ++i)
                buffer[i] = str.charCodeAt(i);
            return buffer;
        }
        else {
            onError('This environment does not support reading binary tags; either Buffer or atob is required');
            return src;
        }
    },
    stringify({ comment, type, value }, ctx, onComment, onChompKeep) {
        const buf = value; // checked earlier by binary.identify()
        let str;
        if (typeof Buffer === 'function') {
            str =
                buf instanceof Buffer
                    ? buf.toString('base64')
                    : Buffer.from(buf.buffer).toString('base64');
        }
        else if (typeof btoa === 'function') {
            let s = '';
            for (let i = 0; i < buf.length; ++i)
                s += String.fromCharCode(buf[i]);
            str = btoa(s);
        }
        else {
            throw new Error('This environment does not support writing binary tags; either Buffer or btoa is required');
        }
        if (!type)
            type = Scalar.BLOCK_LITERAL;
        if (type !== Scalar.QUOTE_DOUBLE) {
            const lineWidth = Math.max(ctx.options.lineWidth - ctx.indent.length, ctx.options.minContentWidth);
            const n = Math.ceil(str.length / lineWidth);
            const lines = new Array(n);
            for (let i = 0, o = 0; i < n; ++i, o += lineWidth) {
                lines[i] = str.substr(o, lineWidth);
            }
            str = lines.join(type === Scalar.BLOCK_LITERAL ? '\n' : ' ');
        }
        return stringifyString({ comment, type, value: str }, ctx, onComment, onChompKeep);
    }
};

function resolvePairs(seq, onError) {
    if (isSeq(seq)) {
        for (let i = 0; i < seq.items.length; ++i) {
            let item = seq.items[i];
            if (isPair(item))
                continue;
            else if (isMap(item)) {
                if (item.items.length > 1)
                    onError('Each pair must have its own sequence indicator');
                const pair = item.items[0] || new Pair(new Scalar(null));
                if (item.commentBefore)
                    pair.key.commentBefore = pair.key.commentBefore
                        ? `${item.commentBefore}\n${pair.key.commentBefore}`
                        : item.commentBefore;
                if (item.comment) {
                    const cn = pair.value ?? pair.key;
                    cn.comment = cn.comment
                        ? `${item.comment}\n${cn.comment}`
                        : item.comment;
                }
                item = pair;
            }
            seq.items[i] = isPair(item) ? item : new Pair(item);
        }
    }
    else
        onError('Expected a sequence for this tag');
    return seq;
}
function createPairs(schema, iterable, ctx) {
    const { replacer } = ctx;
    const pairs = new YAMLSeq(schema);
    pairs.tag = 'tag:yaml.org,2002:pairs';
    let i = 0;
    if (iterable && Symbol.iterator in Object(iterable))
        for (let it of iterable) {
            if (typeof replacer === 'function')
                it = replacer.call(iterable, String(i++), it);
            let key, value;
            if (Array.isArray(it)) {
                if (it.length === 2) {
                    key = it[0];
                    value = it[1];
                }
                else
                    throw new TypeError(`Expected [key, value] tuple: ${it}`);
            }
            else if (it && it instanceof Object) {
                const keys = Object.keys(it);
                if (keys.length === 1) {
                    key = keys[0];
                    value = it[key];
                }
                else {
                    throw new TypeError(`Expected tuple with one key, not ${keys.length} keys`);
                }
            }
            else {
                key = it;
            }
            pairs.items.push(createPair(key, value, ctx));
        }
    return pairs;
}
const pairs = {
    collection: 'seq',
    default: false,
    tag: 'tag:yaml.org,2002:pairs',
    resolve: resolvePairs,
    createNode: createPairs
};

class YAMLOMap extends YAMLSeq {
    constructor() {
        super();
        this.add = YAMLMap.prototype.add.bind(this);
        this.delete = YAMLMap.prototype.delete.bind(this);
        this.get = YAMLMap.prototype.get.bind(this);
        this.has = YAMLMap.prototype.has.bind(this);
        this.set = YAMLMap.prototype.set.bind(this);
        this.tag = YAMLOMap.tag;
    }
    /**
     * If `ctx` is given, the return type is actually `Map<unknown, unknown>`,
     * but TypeScript won't allow widening the signature of a child method.
     */
    toJSON(_, ctx) {
        if (!ctx)
            return super.toJSON(_);
        const map = new Map();
        if (ctx?.onCreate)
            ctx.onCreate(map);
        for (const pair of this.items) {
            let key, value;
            if (isPair(pair)) {
                key = toJS(pair.key, '', ctx);
                value = toJS(pair.value, key, ctx);
            }
            else {
                key = toJS(pair, '', ctx);
            }
            if (map.has(key))
                throw new Error('Ordered maps must not include duplicate keys');
            map.set(key, value);
        }
        return map;
    }
    static from(schema, iterable, ctx) {
        const pairs = createPairs(schema, iterable, ctx);
        const omap = new this();
        omap.items = pairs.items;
        return omap;
    }
}
YAMLOMap.tag = 'tag:yaml.org,2002:omap';
const omap = {
    collection: 'seq',
    identify: value => value instanceof Map,
    nodeClass: YAMLOMap,
    default: false,
    tag: 'tag:yaml.org,2002:omap',
    resolve(seq, onError) {
        const pairs = resolvePairs(seq, onError);
        const seenKeys = [];
        for (const { key } of pairs.items) {
            if (isScalar(key)) {
                if (seenKeys.includes(key.value)) {
                    onError(`Ordered maps must not include duplicate keys: ${key.value}`);
                }
                else {
                    seenKeys.push(key.value);
                }
            }
        }
        return Object.assign(new YAMLOMap(), pairs);
    },
    createNode: (schema, iterable, ctx) => YAMLOMap.from(schema, iterable, ctx)
};

function boolStringify({ value, source }, ctx) {
    const boolObj = value ? trueTag : falseTag;
    if (source && boolObj.test.test(source))
        return source;
    return value ? ctx.options.trueStr : ctx.options.falseStr;
}
const trueTag = {
    identify: value => value === true,
    default: true,
    tag: 'tag:yaml.org,2002:bool',
    test: /^(?:Y|y|[Yy]es|YES|[Tt]rue|TRUE|[Oo]n|ON)$/,
    resolve: () => new Scalar(true),
    stringify: boolStringify
};
const falseTag = {
    identify: value => value === false,
    default: true,
    tag: 'tag:yaml.org,2002:bool',
    test: /^(?:N|n|[Nn]o|NO|[Ff]alse|FALSE|[Oo]ff|OFF)$/i,
    resolve: () => new Scalar(false),
    stringify: boolStringify
};

const floatNaN = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    test: /^[-+]?\.(?:inf|Inf|INF|nan|NaN|NAN)$/,
    resolve: (str) => str.slice(-3).toLowerCase() === 'nan'
        ? NaN
        : str[0] === '-'
            ? Number.NEGATIVE_INFINITY
            : Number.POSITIVE_INFINITY,
    stringify: stringifyNumber
};
const floatExp = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    format: 'EXP',
    test: /^[-+]?(?:[0-9][0-9_]*)?(?:\.[0-9_]*)?[eE][-+]?[0-9]+$/,
    resolve: (str) => parseFloat(str.replace(/_/g, '')),
    stringify(node) {
        const num = Number(node.value);
        return isFinite(num) ? num.toExponential() : stringifyNumber(node);
    }
};
const float$1 = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    test: /^[-+]?(?:[0-9][0-9_]*)?\.[0-9_]*$/,
    resolve(str) {
        const node = new Scalar(parseFloat(str.replace(/_/g, '')));
        const dot = str.indexOf('.');
        if (dot !== -1) {
            const f = str.substring(dot + 1).replace(/_/g, '');
            if (f[f.length - 1] === '0')
                node.minFractionDigits = f.length;
        }
        return node;
    },
    stringify: stringifyNumber
};

const intIdentify = (value) => typeof value === 'bigint' || Number.isInteger(value);
function intResolve(str, offset, radix, { intAsBigInt }) {
    const sign = str[0];
    if (sign === '-' || sign === '+')
        offset += 1;
    str = str.substring(offset).replace(/_/g, '');
    if (intAsBigInt) {
        switch (radix) {
            case 2:
                str = `0b${str}`;
                break;
            case 8:
                str = `0o${str}`;
                break;
            case 16:
                str = `0x${str}`;
                break;
        }
        const n = BigInt(str);
        return sign === '-' ? BigInt(-1) * n : n;
    }
    const n = parseInt(str, radix);
    return sign === '-' ? -1 * n : n;
}
function intStringify(node, radix, prefix) {
    const { value } = node;
    if (intIdentify(value)) {
        const str = value.toString(radix);
        return value < 0 ? '-' + prefix + str.substr(1) : prefix + str;
    }
    return stringifyNumber(node);
}
const intBin = {
    identify: intIdentify,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    format: 'BIN',
    test: /^[-+]?0b[0-1_]+$/,
    resolve: (str, _onError, opt) => intResolve(str, 2, 2, opt),
    stringify: node => intStringify(node, 2, '0b')
};
const intOct = {
    identify: intIdentify,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    format: 'OCT',
    test: /^[-+]?0[0-7_]+$/,
    resolve: (str, _onError, opt) => intResolve(str, 1, 8, opt),
    stringify: node => intStringify(node, 8, '0')
};
const int$1 = {
    identify: intIdentify,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    test: /^[-+]?[0-9][0-9_]*$/,
    resolve: (str, _onError, opt) => intResolve(str, 0, 10, opt),
    stringify: stringifyNumber
};
const intHex = {
    identify: intIdentify,
    default: true,
    tag: 'tag:yaml.org,2002:int',
    format: 'HEX',
    test: /^[-+]?0x[0-9a-fA-F_]+$/,
    resolve: (str, _onError, opt) => intResolve(str, 2, 16, opt),
    stringify: node => intStringify(node, 16, '0x')
};

class YAMLSet extends YAMLMap {
    constructor(schema) {
        super(schema);
        this.tag = YAMLSet.tag;
    }
    add(key) {
        let pair;
        if (isPair(key))
            pair = key;
        else if (key &&
            typeof key === 'object' &&
            'key' in key &&
            'value' in key &&
            key.value === null)
            pair = new Pair(key.key, null);
        else
            pair = new Pair(key, null);
        const prev = findPair(this.items, pair.key);
        if (!prev)
            this.items.push(pair);
    }
    /**
     * If `keepPair` is `true`, returns the Pair matching `key`.
     * Otherwise, returns the value of that Pair's key.
     */
    get(key, keepPair) {
        const pair = findPair(this.items, key);
        return !keepPair && isPair(pair)
            ? isScalar(pair.key)
                ? pair.key.value
                : pair.key
            : pair;
    }
    set(key, value) {
        if (typeof value !== 'boolean')
            throw new Error(`Expected boolean value for set(key, value) in a YAML set, not ${typeof value}`);
        const prev = findPair(this.items, key);
        if (prev && !value) {
            this.items.splice(this.items.indexOf(prev), 1);
        }
        else if (!prev && value) {
            this.items.push(new Pair(key));
        }
    }
    toJSON(_, ctx) {
        return super.toJSON(_, ctx, Set);
    }
    toString(ctx, onComment, onChompKeep) {
        if (!ctx)
            return JSON.stringify(this);
        if (this.hasAllNullValues(true))
            return super.toString(Object.assign({}, ctx, { allNullValues: true }), onComment, onChompKeep);
        else
            throw new Error('Set items must all have null values');
    }
    static from(schema, iterable, ctx) {
        const { replacer } = ctx;
        const set = new this(schema);
        if (iterable && Symbol.iterator in Object(iterable))
            for (let value of iterable) {
                if (typeof replacer === 'function')
                    value = replacer.call(iterable, value, value);
                set.items.push(createPair(value, null, ctx));
            }
        return set;
    }
}
YAMLSet.tag = 'tag:yaml.org,2002:set';
const set = {
    collection: 'map',
    identify: value => value instanceof Set,
    nodeClass: YAMLSet,
    default: false,
    tag: 'tag:yaml.org,2002:set',
    createNode: (schema, iterable, ctx) => YAMLSet.from(schema, iterable, ctx),
    resolve(map, onError) {
        if (isMap(map)) {
            if (map.hasAllNullValues(true))
                return Object.assign(new YAMLSet(), map);
            else
                onError('Set items must all have null values');
        }
        else
            onError('Expected a mapping for this tag');
        return map;
    }
};

/** Internal types handle bigint as number, because TS can't figure it out. */
function parseSexagesimal(str, asBigInt) {
    const sign = str[0];
    const parts = sign === '-' || sign === '+' ? str.substring(1) : str;
    const num = (n) => asBigInt ? BigInt(n) : Number(n);
    const res = parts
        .replace(/_/g, '')
        .split(':')
        .reduce((res, p) => res * num(60) + num(p), num(0));
    return (sign === '-' ? num(-1) * res : res);
}
/**
 * hhhh:mm:ss.sss
 *
 * Internal types handle bigint as number, because TS can't figure it out.
 */
function stringifySexagesimal(node) {
    let { value } = node;
    let num = (n) => n;
    if (typeof value === 'bigint')
        num = n => BigInt(n);
    else if (isNaN(value) || !isFinite(value))
        return stringifyNumber(node);
    let sign = '';
    if (value < 0) {
        sign = '-';
        value *= num(-1);
    }
    const _60 = num(60);
    const parts = [value % _60]; // seconds, including ms
    if (value < 60) {
        parts.unshift(0); // at least one : is required
    }
    else {
        value = (value - parts[0]) / _60;
        parts.unshift(value % _60); // minutes
        if (value >= 60) {
            value = (value - parts[0]) / _60;
            parts.unshift(value); // hours
        }
    }
    return (sign +
        parts
            .map(n => String(n).padStart(2, '0'))
            .join(':')
            .replace(/000000\d*$/, '') // % 60 may introduce error
    );
}
const intTime = {
    identify: value => typeof value === 'bigint' || Number.isInteger(value),
    default: true,
    tag: 'tag:yaml.org,2002:int',
    format: 'TIME',
    test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+$/,
    resolve: (str, _onError, { intAsBigInt }) => parseSexagesimal(str, intAsBigInt),
    stringify: stringifySexagesimal
};
const floatTime = {
    identify: value => typeof value === 'number',
    default: true,
    tag: 'tag:yaml.org,2002:float',
    format: 'TIME',
    test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\.[0-9_]*$/,
    resolve: str => parseSexagesimal(str, false),
    stringify: stringifySexagesimal
};
const timestamp = {
    identify: value => value instanceof Date,
    default: true,
    tag: 'tag:yaml.org,2002:timestamp',
    // If the time zone is omitted, the timestamp is assumed to be specified in UTC. The time part
    // may be omitted altogether, resulting in a date format. In such a case, the time part is
    // assumed to be 00:00:00Z (start of day, UTC).
    test: RegExp('^([0-9]{4})-([0-9]{1,2})-([0-9]{1,2})' + // YYYY-Mm-Dd
        '(?:' + // time is optional
        '(?:t|T|[ \\t]+)' + // t | T | whitespace
        '([0-9]{1,2}):([0-9]{1,2}):([0-9]{1,2}(\\.[0-9]+)?)' + // Hh:Mm:Ss(.ss)?
        '(?:[ \\t]*(Z|[-+][012]?[0-9](?::[0-9]{2})?))?' + // Z | +5 | -03:30
        ')?$'),
    resolve(str) {
        const match = str.match(timestamp.test);
        if (!match)
            throw new Error('!!timestamp expects a date, starting with yyyy-mm-dd');
        const [, year, month, day, hour, minute, second] = match.map(Number);
        const millisec = match[7] ? Number((match[7] + '00').substr(1, 3)) : 0;
        let date = Date.UTC(year, month - 1, day, hour || 0, minute || 0, second || 0, millisec);
        const tz = match[8];
        if (tz && tz !== 'Z') {
            let d = parseSexagesimal(tz, false);
            if (Math.abs(d) < 30)
                d *= 60;
            date -= 60000 * d;
        }
        return new Date(date);
    },
    stringify: ({ value }) => value.toISOString().replace(/((T00:00)?:00)?\.000Z$/, '')
};

const schema = [
    map,
    seq,
    string$1,
    nullTag,
    trueTag,
    falseTag,
    intBin,
    intOct,
    int$1,
    intHex,
    floatNaN,
    floatExp,
    float$1,
    binary,
    omap,
    pairs,
    set,
    intTime,
    floatTime,
    timestamp
];

const schemas = new Map([
    ['core', schema$2],
    ['failsafe', [map, seq, string$1]],
    ['json', schema$1],
    ['yaml11', schema],
    ['yaml-1.1', schema]
]);
const tagsByName = {
    binary,
    bool: boolTag,
    float: float$2,
    floatExp: floatExp$1,
    floatNaN: floatNaN$1,
    floatTime,
    int: int$2,
    intHex: intHex$1,
    intOct: intOct$1,
    intTime,
    map,
    null: nullTag,
    omap,
    pairs,
    seq,
    set,
    timestamp
};
const coreKnownTags = {
    'tag:yaml.org,2002:binary': binary,
    'tag:yaml.org,2002:omap': omap,
    'tag:yaml.org,2002:pairs': pairs,
    'tag:yaml.org,2002:set': set,
    'tag:yaml.org,2002:timestamp': timestamp
};
function getTags(customTags, schemaName) {
    let tags = schemas.get(schemaName);
    if (!tags) {
        if (Array.isArray(customTags))
            tags = [];
        else {
            const keys = Array.from(schemas.keys())
                .filter(key => key !== 'yaml11')
                .map(key => JSON.stringify(key))
                .join(', ');
            throw new Error(`Unknown schema "${schemaName}"; use one of ${keys} or define customTags array`);
        }
    }
    if (Array.isArray(customTags)) {
        for (const tag of customTags)
            tags = tags.concat(tag);
    }
    else if (typeof customTags === 'function') {
        tags = customTags(tags.slice());
    }
    return tags.map(tag => {
        if (typeof tag !== 'string')
            return tag;
        const tagObj = tagsByName[tag];
        if (tagObj)
            return tagObj;
        const keys = Object.keys(tagsByName)
            .map(key => JSON.stringify(key))
            .join(', ');
        throw new Error(`Unknown custom tag "${tag}"; use one of ${keys}`);
    });
}

const sortMapEntriesByKey = (a, b) => a.key < b.key ? -1 : a.key > b.key ? 1 : 0;
class Schema {
    constructor({ compat, customTags, merge, resolveKnownTags, schema, sortMapEntries, toStringDefaults }) {
        this.compat = Array.isArray(compat)
            ? getTags(compat, 'compat')
            : compat
                ? getTags(null, compat)
                : null;
        this.merge = !!merge;
        this.name = (typeof schema === 'string' && schema) || 'core';
        this.knownTags = resolveKnownTags ? coreKnownTags : {};
        this.tags = getTags(customTags, this.name);
        this.toStringOptions = toStringDefaults ?? null;
        Object.defineProperty(this, MAP, { value: map });
        Object.defineProperty(this, SCALAR$1, { value: string$1 });
        Object.defineProperty(this, SEQ, { value: seq });
        // Used by createMap()
        this.sortMapEntries =
            typeof sortMapEntries === 'function'
                ? sortMapEntries
                : sortMapEntries === true
                    ? sortMapEntriesByKey
                    : null;
    }
    clone() {
        const copy = Object.create(Schema.prototype, Object.getOwnPropertyDescriptors(this));
        copy.tags = this.tags.slice();
        return copy;
    }
}

function stringifyDocument(doc, options) {
    const lines = [];
    let hasDirectives = options.directives === true;
    if (options.directives !== false && doc.directives) {
        const dir = doc.directives.toString(doc);
        if (dir) {
            lines.push(dir);
            hasDirectives = true;
        }
        else if (doc.directives.docStart)
            hasDirectives = true;
    }
    if (hasDirectives)
        lines.push('---');
    const ctx = createStringifyContext(doc, options);
    const { commentString } = ctx.options;
    if (doc.commentBefore) {
        if (lines.length !== 1)
            lines.unshift('');
        const cs = commentString(doc.commentBefore);
        lines.unshift(indentComment(cs, ''));
    }
    let chompKeep = false;
    let contentComment = null;
    if (doc.contents) {
        if (isNode(doc.contents)) {
            if (doc.contents.spaceBefore && hasDirectives)
                lines.push('');
            if (doc.contents.commentBefore) {
                const cs = commentString(doc.contents.commentBefore);
                lines.push(indentComment(cs, ''));
            }
            // top-level block scalars need to be indented if followed by a comment
            ctx.forceBlockIndent = !!doc.comment;
            contentComment = doc.contents.comment;
        }
        const onChompKeep = contentComment ? undefined : () => (chompKeep = true);
        let body = stringify$1(doc.contents, ctx, () => (contentComment = null), onChompKeep);
        if (contentComment)
            body += lineComment(body, '', commentString(contentComment));
        if ((body[0] === '|' || body[0] === '>') &&
            lines[lines.length - 1] === '---') {
            // Top-level block scalars with a preceding doc marker ought to use the
            // same line for their header.
            lines[lines.length - 1] = `--- ${body}`;
        }
        else
            lines.push(body);
    }
    else {
        lines.push(stringify$1(doc.contents, ctx));
    }
    if (doc.directives?.docEnd) {
        if (doc.comment) {
            const cs = commentString(doc.comment);
            if (cs.includes('\n')) {
                lines.push('...');
                lines.push(indentComment(cs, ''));
            }
            else {
                lines.push(`... ${cs}`);
            }
        }
        else {
            lines.push('...');
        }
    }
    else {
        let dc = doc.comment;
        if (dc && chompKeep)
            dc = dc.replace(/^\n+/, '');
        if (dc) {
            if ((!chompKeep || contentComment) && lines[lines.length - 1] !== '')
                lines.push('');
            lines.push(indentComment(commentString(dc), ''));
        }
    }
    return lines.join('\n') + '\n';
}

class Document {
    constructor(value, replacer, options) {
        /** A comment before this Document */
        this.commentBefore = null;
        /** A comment immediately after this Document */
        this.comment = null;
        /** Errors encountered during parsing. */
        this.errors = [];
        /** Warnings encountered during parsing. */
        this.warnings = [];
        Object.defineProperty(this, NODE_TYPE, { value: DOC });
        let _replacer = null;
        if (typeof replacer === 'function' || Array.isArray(replacer)) {
            _replacer = replacer;
        }
        else if (options === undefined && replacer) {
            options = replacer;
            replacer = undefined;
        }
        const opt = Object.assign({
            intAsBigInt: false,
            keepSourceTokens: false,
            logLevel: 'warn',
            prettyErrors: true,
            strict: true,
            uniqueKeys: true,
            version: '1.2'
        }, options);
        this.options = opt;
        let { version } = opt;
        if (options?._directives) {
            this.directives = options._directives.atDocument();
            if (this.directives.yaml.explicit)
                version = this.directives.yaml.version;
        }
        else
            this.directives = new Directives({ version });
        this.setSchema(version, options);
        // @ts-expect-error We can't really know that this matches Contents.
        this.contents =
            value === undefined ? null : this.createNode(value, _replacer, options);
    }
    /**
     * Create a deep copy of this Document and its contents.
     *
     * Custom Node values that inherit from `Object` still refer to their original instances.
     */
    clone() {
        const copy = Object.create(Document.prototype, {
            [NODE_TYPE]: { value: DOC }
        });
        copy.commentBefore = this.commentBefore;
        copy.comment = this.comment;
        copy.errors = this.errors.slice();
        copy.warnings = this.warnings.slice();
        copy.options = Object.assign({}, this.options);
        if (this.directives)
            copy.directives = this.directives.clone();
        copy.schema = this.schema.clone();
        // @ts-expect-error We can't really know that this matches Contents.
        copy.contents = isNode(this.contents)
            ? this.contents.clone(copy.schema)
            : this.contents;
        if (this.range)
            copy.range = this.range.slice();
        return copy;
    }
    /** Adds a value to the document. */
    add(value) {
        if (assertCollection(this.contents))
            this.contents.add(value);
    }
    /** Adds a value to the document. */
    addIn(path, value) {
        if (assertCollection(this.contents))
            this.contents.addIn(path, value);
    }
    /**
     * Create a new `Alias` node, ensuring that the target `node` has the required anchor.
     *
     * If `node` already has an anchor, `name` is ignored.
     * Otherwise, the `node.anchor` value will be set to `name`,
     * or if an anchor with that name is already present in the document,
     * `name` will be used as a prefix for a new unique anchor.
     * If `name` is undefined, the generated anchor will use 'a' as a prefix.
     */
    createAlias(node, name) {
        if (!node.anchor) {
            const prev = anchorNames(this);
            node.anchor =
                // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing
                !name || prev.has(name) ? findNewAnchor(name || 'a', prev) : name;
        }
        return new Alias(node.anchor);
    }
    createNode(value, replacer, options) {
        let _replacer = undefined;
        if (typeof replacer === 'function') {
            value = replacer.call({ '': value }, '', value);
            _replacer = replacer;
        }
        else if (Array.isArray(replacer)) {
            const keyToStr = (v) => typeof v === 'number' || v instanceof String || v instanceof Number;
            const asStr = replacer.filter(keyToStr).map(String);
            if (asStr.length > 0)
                replacer = replacer.concat(asStr);
            _replacer = replacer;
        }
        else if (options === undefined && replacer) {
            options = replacer;
            replacer = undefined;
        }
        const { aliasDuplicateObjects, anchorPrefix, flow, keepUndefined, onTagObj, tag } = options ?? {};
        const { onAnchor, setAnchors, sourceObjects } = createNodeAnchors(this, 
        // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing
        anchorPrefix || 'a');
        const ctx = {
            aliasDuplicateObjects: aliasDuplicateObjects ?? true,
            keepUndefined: keepUndefined ?? false,
            onAnchor,
            onTagObj,
            replacer: _replacer,
            schema: this.schema,
            sourceObjects
        };
        const node = createNode(value, tag, ctx);
        if (flow && isCollection(node))
            node.flow = true;
        setAnchors();
        return node;
    }
    /**
     * Convert a key and a value into a `Pair` using the current schema,
     * recursively wrapping all values as `Scalar` or `Collection` nodes.
     */
    createPair(key, value, options = {}) {
        const k = this.createNode(key, null, options);
        const v = this.createNode(value, null, options);
        return new Pair(k, v);
    }
    /**
     * Removes a value from the document.
     * @returns `true` if the item was found and removed.
     */
    delete(key) {
        return assertCollection(this.contents) ? this.contents.delete(key) : false;
    }
    /**
     * Removes a value from the document.
     * @returns `true` if the item was found and removed.
     */
    deleteIn(path) {
        if (isEmptyPath(path)) {
            if (this.contents == null)
                return false;
            // @ts-expect-error Presumed impossible if Strict extends false
            this.contents = null;
            return true;
        }
        return assertCollection(this.contents)
            ? this.contents.deleteIn(path)
            : false;
    }
    /**
     * Returns item at `key`, or `undefined` if not found. By default unwraps
     * scalar values from their surrounding node; to disable set `keepScalar` to
     * `true` (collections are always returned intact).
     */
    get(key, keepScalar) {
        return isCollection(this.contents)
            ? this.contents.get(key, keepScalar)
            : undefined;
    }
    /**
     * Returns item at `path`, or `undefined` if not found. By default unwraps
     * scalar values from their surrounding node; to disable set `keepScalar` to
     * `true` (collections are always returned intact).
     */
    getIn(path, keepScalar) {
        if (isEmptyPath(path))
            return !keepScalar && isScalar(this.contents)
                ? this.contents.value
                : this.contents;
        return isCollection(this.contents)
            ? this.contents.getIn(path, keepScalar)
            : undefined;
    }
    /**
     * Checks if the document includes a value with the key `key`.
     */
    has(key) {
        return isCollection(this.contents) ? this.contents.has(key) : false;
    }
    /**
     * Checks if the document includes a value at `path`.
     */
    hasIn(path) {
        if (isEmptyPath(path))
            return this.contents !== undefined;
        return isCollection(this.contents) ? this.contents.hasIn(path) : false;
    }
    /**
     * Sets a value in this document. For `!!set`, `value` needs to be a
     * boolean to add/remove the item from the set.
     */
    set(key, value) {
        if (this.contents == null) {
            // @ts-expect-error We can't really know that this matches Contents.
            this.contents = collectionFromPath(this.schema, [key], value);
        }
        else if (assertCollection(this.contents)) {
            this.contents.set(key, value);
        }
    }
    /**
     * Sets a value in this document. For `!!set`, `value` needs to be a
     * boolean to add/remove the item from the set.
     */
    setIn(path, value) {
        if (isEmptyPath(path)) {
            // @ts-expect-error We can't really know that this matches Contents.
            this.contents = value;
        }
        else if (this.contents == null) {
            // @ts-expect-error We can't really know that this matches Contents.
            this.contents = collectionFromPath(this.schema, Array.from(path), value);
        }
        else if (assertCollection(this.contents)) {
            this.contents.setIn(path, value);
        }
    }
    /**
     * Change the YAML version and schema used by the document.
     * A `null` version disables support for directives, explicit tags, anchors, and aliases.
     * It also requires the `schema` option to be given as a `Schema` instance value.
     *
     * Overrides all previously set schema options.
     */
    setSchema(version, options = {}) {
        if (typeof version === 'number')
            version = String(version);
        let opt;
        switch (version) {
            case '1.1':
                if (this.directives)
                    this.directives.yaml.version = '1.1';
                else
                    this.directives = new Directives({ version: '1.1' });
                opt = { merge: true, resolveKnownTags: false, schema: 'yaml-1.1' };
                break;
            case '1.2':
            case 'next':
                if (this.directives)
                    this.directives.yaml.version = version;
                else
                    this.directives = new Directives({ version });
                opt = { merge: false, resolveKnownTags: true, schema: 'core' };
                break;
            case null:
                if (this.directives)
                    delete this.directives;
                opt = null;
                break;
            default: {
                const sv = JSON.stringify(version);
                throw new Error(`Expected '1.1', '1.2' or null as first argument, but found: ${sv}`);
            }
        }
        // Not using `instanceof Schema` to allow for duck typing
        if (options.schema instanceof Object)
            this.schema = options.schema;
        else if (opt)
            this.schema = new Schema(Object.assign(opt, options));
        else
            throw new Error(`With a null YAML version, the { schema: Schema } option is required`);
    }
    // json & jsonArg are only used from toJSON()
    toJS({ json, jsonArg, mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {
        const ctx = {
            anchors: new Map(),
            doc: this,
            keep: !json,
            mapAsMap: mapAsMap === true,
            mapKeyWarned: false,
            maxAliasCount: typeof maxAliasCount === 'number' ? maxAliasCount : 100
        };
        const res = toJS(this.contents, jsonArg ?? '', ctx);
        if (typeof onAnchor === 'function')
            for (const { count, res } of ctx.anchors.values())
                onAnchor(res, count);
        return typeof reviver === 'function'
            ? applyReviver(reviver, { '': res }, '', res)
            : res;
    }
    /**
     * A JSON representation of the document `contents`.
     *
     * @param jsonArg Used by `JSON.stringify` to indicate the array index or
     *   property name.
     */
    toJSON(jsonArg, onAnchor) {
        return this.toJS({ json: true, jsonArg, mapAsMap: false, onAnchor });
    }
    /** A YAML representation of the document. */
    toString(options = {}) {
        if (this.errors.length > 0)
            throw new Error('Document with errors cannot be stringified');
        if ('indent' in options &&
            (!Number.isInteger(options.indent) || Number(options.indent) <= 0)) {
            const s = JSON.stringify(options.indent);
            throw new Error(`"indent" option must be a positive integer, not ${s}`);
        }
        return stringifyDocument(this, options);
    }
}
function assertCollection(contents) {
    if (isCollection(contents))
        return true;
    throw new Error('Expected a YAML collection as document contents');
}

class YAMLError extends Error {
    constructor(name, pos, code, message) {
        super();
        this.name = name;
        this.code = code;
        this.message = message;
        this.pos = pos;
    }
}
class YAMLParseError extends YAMLError {
    constructor(pos, code, message) {
        super('YAMLParseError', pos, code, message);
    }
}
class YAMLWarning extends YAMLError {
    constructor(pos, code, message) {
        super('YAMLWarning', pos, code, message);
    }
}
const prettifyError = (src, lc) => (error) => {
    if (error.pos[0] === -1)
        return;
    error.linePos = error.pos.map(pos => lc.linePos(pos));
    const { line, col } = error.linePos[0];
    error.message += ` at line ${line}, column ${col}`;
    let ci = col - 1;
    let lineStr = src
        .substring(lc.lineStarts[line - 1], lc.lineStarts[line])
        .replace(/[\n\r]+$/, '');
    // Trim to max 80 chars, keeping col position near the middle
    if (ci >= 60 && lineStr.length > 80) {
        const trimStart = Math.min(ci - 39, lineStr.length - 79);
        lineStr = '' + lineStr.substring(trimStart);
        ci -= trimStart - 1;
    }
    if (lineStr.length > 80)
        lineStr = lineStr.substring(0, 79) + '';
    // Include previous line in context if pointing at line start
    if (line > 1 && /^ *$/.test(lineStr.substring(0, ci))) {
        // Regexp won't match if start is trimmed
        let prev = src.substring(lc.lineStarts[line - 2], lc.lineStarts[line - 1]);
        if (prev.length > 80)
            prev = prev.substring(0, 79) + '\n';
        lineStr = prev + lineStr;
    }
    if (/[^ ]/.test(lineStr)) {
        let count = 1;
        const end = error.linePos[1];
        if (end && end.line === line && end.col > col) {
            count = Math.max(1, Math.min(end.col - col, 80 - ci));
        }
        const pointer = ' '.repeat(ci) + '^'.repeat(count);
        error.message += `:\n\n${lineStr}\n${pointer}\n`;
    }
};

function resolveProps(tokens, { flow, indicator, next, offset, onError, startOnNewline }) {
    let spaceBefore = false;
    let atNewline = startOnNewline;
    let hasSpace = startOnNewline;
    let comment = '';
    let commentSep = '';
    let hasNewline = false;
    let hasNewlineAfterProp = false;
    let reqSpace = false;
    let anchor = null;
    let tag = null;
    let comma = null;
    let found = null;
    let start = null;
    for (const token of tokens) {
        if (reqSpace) {
            if (token.type !== 'space' &&
                token.type !== 'newline' &&
                token.type !== 'comma')
                onError(token.offset, 'MISSING_CHAR', 'Tags and anchors must be separated from the next token by white space');
            reqSpace = false;
        }
        switch (token.type) {
            case 'space':
                // At the doc level, tabs at line start may be parsed
                // as leading white space rather than indentation.
                // In a flow collection, only the parser handles indent.
                if (!flow &&
                    atNewline &&
                    indicator !== 'doc-start' &&
                    token.source[0] === '\t')
                    onError(token, 'TAB_AS_INDENT', 'Tabs are not allowed as indentation');
                hasSpace = true;
                break;
            case 'comment': {
                if (!hasSpace)
                    onError(token, 'MISSING_CHAR', 'Comments must be separated from other tokens by white space characters');
                const cb = token.source.substring(1) || ' ';
                if (!comment)
                    comment = cb;
                else
                    comment += commentSep + cb;
                commentSep = '';
                atNewline = false;
                break;
            }
            case 'newline':
                if (atNewline) {
                    if (comment)
                        comment += token.source;
                    else
                        spaceBefore = true;
                }
                else
                    commentSep += token.source;
                atNewline = true;
                hasNewline = true;
                if (anchor || tag)
                    hasNewlineAfterProp = true;
                hasSpace = true;
                break;
            case 'anchor':
                if (anchor)
                    onError(token, 'MULTIPLE_ANCHORS', 'A node can have at most one anchor');
                if (token.source.endsWith(':'))
                    onError(token.offset + token.source.length - 1, 'BAD_ALIAS', 'Anchor ending in : is ambiguous', true);
                anchor = token;
                if (start === null)
                    start = token.offset;
                atNewline = false;
                hasSpace = false;
                reqSpace = true;
                break;
            case 'tag': {
                if (tag)
                    onError(token, 'MULTIPLE_TAGS', 'A node can have at most one tag');
                tag = token;
                if (start === null)
                    start = token.offset;
                atNewline = false;
                hasSpace = false;
                reqSpace = true;
                break;
            }
            case indicator:
                // Could here handle preceding comments differently
                if (anchor || tag)
                    onError(token, 'BAD_PROP_ORDER', `Anchors and tags must be after the ${token.source} indicator`);
                if (found)
                    onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${token.source} in ${flow ?? 'collection'}`);
                found = token;
                atNewline = false;
                hasSpace = false;
                break;
            case 'comma':
                if (flow) {
                    if (comma)
                        onError(token, 'UNEXPECTED_TOKEN', `Unexpected , in ${flow}`);
                    comma = token;
                    atNewline = false;
                    hasSpace = false;
                    break;
                }
            // else fallthrough
            default:
                onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${token.type} token`);
                atNewline = false;
                hasSpace = false;
        }
    }
    const last = tokens[tokens.length - 1];
    const end = last ? last.offset + last.source.length : offset;
    if (reqSpace &&
        next &&
        next.type !== 'space' &&
        next.type !== 'newline' &&
        next.type !== 'comma' &&
        (next.type !== 'scalar' || next.source !== ''))
        onError(next.offset, 'MISSING_CHAR', 'Tags and anchors must be separated from the next token by white space');
    return {
        comma,
        found,
        spaceBefore,
        comment,
        hasNewline,
        hasNewlineAfterProp,
        anchor,
        tag,
        end,
        start: start ?? end
    };
}

function containsNewline(key) {
    if (!key)
        return null;
    switch (key.type) {
        case 'alias':
        case 'scalar':
        case 'double-quoted-scalar':
        case 'single-quoted-scalar':
            if (key.source.includes('\n'))
                return true;
            if (key.end)
                for (const st of key.end)
                    if (st.type === 'newline')
                        return true;
            return false;
        case 'flow-collection':
            for (const it of key.items) {
                for (const st of it.start)
                    if (st.type === 'newline')
                        return true;
                if (it.sep)
                    for (const st of it.sep)
                        if (st.type === 'newline')
                            return true;
                if (containsNewline(it.key) || containsNewline(it.value))
                    return true;
            }
            return false;
        default:
            return true;
    }
}

function flowIndentCheck(indent, fc, onError) {
    if (fc?.type === 'flow-collection') {
        const end = fc.end[0];
        if (end.indent === indent &&
            (end.source === ']' || end.source === '}') &&
            containsNewline(fc)) {
            const msg = 'Flow end indicator should be more indented than parent';
            onError(end, 'BAD_INDENT', msg, true);
        }
    }
}

function mapIncludes(ctx, items, search) {
    const { uniqueKeys } = ctx.options;
    if (uniqueKeys === false)
        return false;
    const isEqual = typeof uniqueKeys === 'function'
        ? uniqueKeys
        : (a, b) => a === b ||
            (isScalar(a) &&
                isScalar(b) &&
                a.value === b.value &&
                !(a.value === '<<' && ctx.schema.merge));
    return items.some(pair => isEqual(pair.key, search));
}

const startColMsg = 'All mapping items must start at the same column';
function resolveBlockMap({ composeNode, composeEmptyNode }, ctx, bm, onError, tag) {
    const NodeClass = tag?.nodeClass ?? YAMLMap;
    const map = new NodeClass(ctx.schema);
    if (ctx.atRoot)
        ctx.atRoot = false;
    let offset = bm.offset;
    let commentEnd = null;
    for (const collItem of bm.items) {
        const { start, key, sep, value } = collItem;
        // key properties
        const keyProps = resolveProps(start, {
            indicator: 'explicit-key-ind',
            next: key ?? sep?.[0],
            offset,
            onError,
            startOnNewline: true
        });
        const implicitKey = !keyProps.found;
        if (implicitKey) {
            if (key) {
                if (key.type === 'block-seq')
                    onError(offset, 'BLOCK_AS_IMPLICIT_KEY', 'A block sequence may not be used as an implicit map key');
                else if ('indent' in key && key.indent !== bm.indent)
                    onError(offset, 'BAD_INDENT', startColMsg);
            }
            if (!keyProps.anchor && !keyProps.tag && !sep) {
                commentEnd = keyProps.end;
                if (keyProps.comment) {
                    if (map.comment)
                        map.comment += '\n' + keyProps.comment;
                    else
                        map.comment = keyProps.comment;
                }
                continue;
            }
            if (keyProps.hasNewlineAfterProp || containsNewline(key)) {
                onError(key ?? start[start.length - 1], 'MULTILINE_IMPLICIT_KEY', 'Implicit keys need to be on a single line');
            }
        }
        else if (keyProps.found?.indent !== bm.indent) {
            onError(offset, 'BAD_INDENT', startColMsg);
        }
        // key value
        const keyStart = keyProps.end;
        const keyNode = key
            ? composeNode(ctx, key, keyProps, onError)
            : composeEmptyNode(ctx, keyStart, start, null, keyProps, onError);
        if (ctx.schema.compat)
            flowIndentCheck(bm.indent, key, onError);
        if (mapIncludes(ctx, map.items, keyNode))
            onError(keyStart, 'DUPLICATE_KEY', 'Map keys must be unique');
        // value properties
        const valueProps = resolveProps(sep ?? [], {
            indicator: 'map-value-ind',
            next: value,
            offset: keyNode.range[2],
            onError,
            startOnNewline: !key || key.type === 'block-scalar'
        });
        offset = valueProps.end;
        if (valueProps.found) {
            if (implicitKey) {
                if (value?.type === 'block-map' && !valueProps.hasNewline)
                    onError(offset, 'BLOCK_AS_IMPLICIT_KEY', 'Nested mappings are not allowed in compact mappings');
                if (ctx.options.strict &&
                    keyProps.start < valueProps.found.offset - 1024)
                    onError(keyNode.range, 'KEY_OVER_1024_CHARS', 'The : indicator must be at most 1024 chars after the start of an implicit block mapping key');
            }
            // value value
            const valueNode = value
                ? composeNode(ctx, value, valueProps, onError)
                : composeEmptyNode(ctx, offset, sep, null, valueProps, onError);
            if (ctx.schema.compat)
                flowIndentCheck(bm.indent, value, onError);
            offset = valueNode.range[2];
            const pair = new Pair(keyNode, valueNode);
            if (ctx.options.keepSourceTokens)
                pair.srcToken = collItem;
            map.items.push(pair);
        }
        else {
            // key with no value
            if (implicitKey)
                onError(keyNode.range, 'MISSING_CHAR', 'Implicit map keys need to be followed by map values');
            if (valueProps.comment) {
                if (keyNode.comment)
                    keyNode.comment += '\n' + valueProps.comment;
                else
                    keyNode.comment = valueProps.comment;
            }
            const pair = new Pair(keyNode);
            if (ctx.options.keepSourceTokens)
                pair.srcToken = collItem;
            map.items.push(pair);
        }
    }
    if (commentEnd && commentEnd < offset)
        onError(commentEnd, 'IMPOSSIBLE', 'Map comment with trailing content');
    map.range = [bm.offset, offset, commentEnd ?? offset];
    return map;
}

function resolveBlockSeq({ composeNode, composeEmptyNode }, ctx, bs, onError, tag) {
    const NodeClass = tag?.nodeClass ?? YAMLSeq;
    const seq = new NodeClass(ctx.schema);
    if (ctx.atRoot)
        ctx.atRoot = false;
    let offset = bs.offset;
    let commentEnd = null;
    for (const { start, value } of bs.items) {
        const props = resolveProps(start, {
            indicator: 'seq-item-ind',
            next: value,
            offset,
            onError,
            startOnNewline: true
        });
        if (!props.found) {
            if (props.anchor || props.tag || value) {
                if (value && value.type === 'block-seq')
                    onError(props.end, 'BAD_INDENT', 'All sequence items must start at the same column');
                else
                    onError(offset, 'MISSING_CHAR', 'Sequence item without - indicator');
            }
            else {
                commentEnd = props.end;
                if (props.comment)
                    seq.comment = props.comment;
                continue;
            }
        }
        const node = value
            ? composeNode(ctx, value, props, onError)
            : composeEmptyNode(ctx, props.end, start, null, props, onError);
        if (ctx.schema.compat)
            flowIndentCheck(bs.indent, value, onError);
        offset = node.range[2];
        seq.items.push(node);
    }
    seq.range = [bs.offset, offset, commentEnd ?? offset];
    return seq;
}

function resolveEnd(end, offset, reqSpace, onError) {
    let comment = '';
    if (end) {
        let hasSpace = false;
        let sep = '';
        for (const token of end) {
            const { source, type } = token;
            switch (type) {
                case 'space':
                    hasSpace = true;
                    break;
                case 'comment': {
                    if (reqSpace && !hasSpace)
                        onError(token, 'MISSING_CHAR', 'Comments must be separated from other tokens by white space characters');
                    const cb = source.substring(1) || ' ';
                    if (!comment)
                        comment = cb;
                    else
                        comment += sep + cb;
                    sep = '';
                    break;
                }
                case 'newline':
                    if (comment)
                        sep += source;
                    hasSpace = true;
                    break;
                default:
                    onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${type} at node end`);
            }
            offset += source.length;
        }
    }
    return { comment, offset };
}

const blockMsg = 'Block collections are not allowed within flow collections';
const isBlock = (token) => token && (token.type === 'block-map' || token.type === 'block-seq');
function resolveFlowCollection({ composeNode, composeEmptyNode }, ctx, fc, onError, tag) {
    const isMap = fc.start.source === '{';
    const fcName = isMap ? 'flow map' : 'flow sequence';
    const NodeClass = (tag?.nodeClass ?? (isMap ? YAMLMap : YAMLSeq));
    const coll = new NodeClass(ctx.schema);
    coll.flow = true;
    const atRoot = ctx.atRoot;
    if (atRoot)
        ctx.atRoot = false;
    let offset = fc.offset + fc.start.source.length;
    for (let i = 0; i < fc.items.length; ++i) {
        const collItem = fc.items[i];
        const { start, key, sep, value } = collItem;
        const props = resolveProps(start, {
            flow: fcName,
            indicator: 'explicit-key-ind',
            next: key ?? sep?.[0],
            offset,
            onError,
            startOnNewline: false
        });
        if (!props.found) {
            if (!props.anchor && !props.tag && !sep && !value) {
                if (i === 0 && props.comma)
                    onError(props.comma, 'UNEXPECTED_TOKEN', `Unexpected , in ${fcName}`);
                else if (i < fc.items.length - 1)
                    onError(props.start, 'UNEXPECTED_TOKEN', `Unexpected empty item in ${fcName}`);
                if (props.comment) {
                    if (coll.comment)
                        coll.comment += '\n' + props.comment;
                    else
                        coll.comment = props.comment;
                }
                offset = props.end;
                continue;
            }
            if (!isMap && ctx.options.strict && containsNewline(key))
                onError(key, // checked by containsNewline()
                'MULTILINE_IMPLICIT_KEY', 'Implicit keys of flow sequence pairs need to be on a single line');
        }
        if (i === 0) {
            if (props.comma)
                onError(props.comma, 'UNEXPECTED_TOKEN', `Unexpected , in ${fcName}`);
        }
        else {
            if (!props.comma)
                onError(props.start, 'MISSING_CHAR', `Missing , between ${fcName} items`);
            if (props.comment) {
                let prevItemComment = '';
                loop: for (const st of start) {
                    switch (st.type) {
                        case 'comma':
                        case 'space':
                            break;
                        case 'comment':
                            prevItemComment = st.source.substring(1);
                            break loop;
                        default:
                            break loop;
                    }
                }
                if (prevItemComment) {
                    let prev = coll.items[coll.items.length - 1];
                    if (isPair(prev))
                        prev = prev.value ?? prev.key;
                    if (prev.comment)
                        prev.comment += '\n' + prevItemComment;
                    else
                        prev.comment = prevItemComment;
                    props.comment = props.comment.substring(prevItemComment.length + 1);
                }
            }
        }
        if (!isMap && !sep && !props.found) {
            // item is a value in a seq
            //  key & sep are empty, start does not include ? or :
            const valueNode = value
                ? composeNode(ctx, value, props, onError)
                : composeEmptyNode(ctx, props.end, sep, null, props, onError);
            coll.items.push(valueNode);
            offset = valueNode.range[2];
            if (isBlock(value))
                onError(valueNode.range, 'BLOCK_IN_FLOW', blockMsg);
        }
        else {
            // item is a key+value pair
            // key value
            const keyStart = props.end;
            const keyNode = key
                ? composeNode(ctx, key, props, onError)
                : composeEmptyNode(ctx, keyStart, start, null, props, onError);
            if (isBlock(key))
                onError(keyNode.range, 'BLOCK_IN_FLOW', blockMsg);
            // value properties
            const valueProps = resolveProps(sep ?? [], {
                flow: fcName,
                indicator: 'map-value-ind',
                next: value,
                offset: keyNode.range[2],
                onError,
                startOnNewline: false
            });
            if (valueProps.found) {
                if (!isMap && !props.found && ctx.options.strict) {
                    if (sep)
                        for (const st of sep) {
                            if (st === valueProps.found)
                                break;
                            if (st.type === 'newline') {
                                onError(st, 'MULTILINE_IMPLICIT_KEY', 'Implicit keys of flow sequence pairs need to be on a single line');
                                break;
                            }
                        }
                    if (props.start < valueProps.found.offset - 1024)
                        onError(valueProps.found, 'KEY_OVER_1024_CHARS', 'The : indicator must be at most 1024 chars after the start of an implicit flow sequence key');
                }
            }
            else if (value) {
                if ('source' in value && value.source && value.source[0] === ':')
                    onError(value, 'MISSING_CHAR', `Missing space after : in ${fcName}`);
                else
                    onError(valueProps.start, 'MISSING_CHAR', `Missing , or : between ${fcName} items`);
            }
            // value value
            const valueNode = value
                ? composeNode(ctx, value, valueProps, onError)
                : valueProps.found
                    ? composeEmptyNode(ctx, valueProps.end, sep, null, valueProps, onError)
                    : null;
            if (valueNode) {
                if (isBlock(value))
                    onError(valueNode.range, 'BLOCK_IN_FLOW', blockMsg);
            }
            else if (valueProps.comment) {
                if (keyNode.comment)
                    keyNode.comment += '\n' + valueProps.comment;
                else
                    keyNode.comment = valueProps.comment;
            }
            const pair = new Pair(keyNode, valueNode);
            if (ctx.options.keepSourceTokens)
                pair.srcToken = collItem;
            if (isMap) {
                const map = coll;
                if (mapIncludes(ctx, map.items, keyNode))
                    onError(keyStart, 'DUPLICATE_KEY', 'Map keys must be unique');
                map.items.push(pair);
            }
            else {
                const map = new YAMLMap(ctx.schema);
                map.flow = true;
                map.items.push(pair);
                coll.items.push(map);
            }
            offset = valueNode ? valueNode.range[2] : valueProps.end;
        }
    }
    const expectedEnd = isMap ? '}' : ']';
    const [ce, ...ee] = fc.end;
    let cePos = offset;
    if (ce && ce.source === expectedEnd)
        cePos = ce.offset + ce.source.length;
    else {
        const name = fcName[0].toUpperCase() + fcName.substring(1);
        const msg = atRoot
            ? `${name} must end with a ${expectedEnd}`
            : `${name} in block collection must be sufficiently indented and end with a ${expectedEnd}`;
        onError(offset, atRoot ? 'MISSING_CHAR' : 'BAD_INDENT', msg);
        if (ce && ce.source.length !== 1)
            ee.unshift(ce);
    }
    if (ee.length > 0) {
        const end = resolveEnd(ee, cePos, ctx.options.strict, onError);
        if (end.comment) {
            if (coll.comment)
                coll.comment += '\n' + end.comment;
            else
                coll.comment = end.comment;
        }
        coll.range = [fc.offset, cePos, end.offset];
    }
    else {
        coll.range = [fc.offset, cePos, cePos];
    }
    return coll;
}

function resolveCollection(CN, ctx, token, onError, tagName, tag) {
    const coll = token.type === 'block-map'
        ? resolveBlockMap(CN, ctx, token, onError, tag)
        : token.type === 'block-seq'
            ? resolveBlockSeq(CN, ctx, token, onError, tag)
            : resolveFlowCollection(CN, ctx, token, onError, tag);
    const Coll = coll.constructor;
    // If we got a tagName matching the class, or the tag name is '!',
    // then use the tagName from the node class used to create it.
    if (tagName === '!' || tagName === Coll.tagName) {
        coll.tag = Coll.tagName;
        return coll;
    }
    if (tagName)
        coll.tag = tagName;
    return coll;
}
function composeCollection(CN, ctx, token, tagToken, onError) {
    const tagName = !tagToken
        ? null
        : ctx.directives.tagName(tagToken.source, msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg));
    const expType = token.type === 'block-map'
        ? 'map'
        : token.type === 'block-seq'
            ? 'seq'
            : token.start.source === '{'
                ? 'map'
                : 'seq';
    // shortcut: check if it's a generic YAMLMap or YAMLSeq
    // before jumping into the custom tag logic.
    if (!tagToken ||
        !tagName ||
        tagName === '!' ||
        (tagName === YAMLMap.tagName && expType === 'map') ||
        (tagName === YAMLSeq.tagName && expType === 'seq') ||
        !expType) {
        return resolveCollection(CN, ctx, token, onError, tagName);
    }
    let tag = ctx.schema.tags.find(t => t.tag === tagName && t.collection === expType);
    if (!tag) {
        const kt = ctx.schema.knownTags[tagName];
        if (kt && kt.collection === expType) {
            ctx.schema.tags.push(Object.assign({}, kt, { default: false }));
            tag = kt;
        }
        else {
            if (kt?.collection) {
                onError(tagToken, 'BAD_COLLECTION_TYPE', `${kt.tag} used for ${expType} collection, but expects ${kt.collection}`, true);
            }
            else {
                onError(tagToken, 'TAG_RESOLVE_FAILED', `Unresolved tag: ${tagName}`, true);
            }
            return resolveCollection(CN, ctx, token, onError, tagName);
        }
    }
    const coll = resolveCollection(CN, ctx, token, onError, tagName, tag);
    const res = tag.resolve?.(coll, msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg), ctx.options) ?? coll;
    const node = isNode(res)
        ? res
        : new Scalar(res);
    node.range = coll.range;
    node.tag = tagName;
    if (tag?.format)
        node.format = tag.format;
    return node;
}

function resolveBlockScalar(scalar, strict, onError) {
    const start = scalar.offset;
    const header = parseBlockScalarHeader(scalar, strict, onError);
    if (!header)
        return { value: '', type: null, comment: '', range: [start, start, start] };
    const type = header.mode === '>' ? Scalar.BLOCK_FOLDED : Scalar.BLOCK_LITERAL;
    const lines = scalar.source ? splitLines(scalar.source) : [];
    // determine the end of content & start of chomping
    let chompStart = lines.length;
    for (let i = lines.length - 1; i >= 0; --i) {
        const content = lines[i][1];
        if (content === '' || content === '\r')
            chompStart = i;
        else
            break;
    }
    // shortcut for empty contents
    if (chompStart === 0) {
        const value = header.chomp === '+' && lines.length > 0
            ? '\n'.repeat(Math.max(1, lines.length - 1))
            : '';
        let end = start + header.length;
        if (scalar.source)
            end += scalar.source.length;
        return { value, type, comment: header.comment, range: [start, end, end] };
    }
    // find the indentation level to trim from start
    let trimIndent = scalar.indent + header.indent;
    let offset = scalar.offset + header.length;
    let contentStart = 0;
    for (let i = 0; i < chompStart; ++i) {
        const [indent, content] = lines[i];
        if (content === '' || content === '\r') {
            if (header.indent === 0 && indent.length > trimIndent)
                trimIndent = indent.length;
        }
        else {
            if (indent.length < trimIndent) {
                const message = 'Block scalars with more-indented leading empty lines must use an explicit indentation indicator';
                onError(offset + indent.length, 'MISSING_CHAR', message);
            }
            if (header.indent === 0)
                trimIndent = indent.length;
            contentStart = i;
            break;
        }
        offset += indent.length + content.length + 1;
    }
    // include trailing more-indented empty lines in content
    for (let i = lines.length - 1; i >= chompStart; --i) {
        if (lines[i][0].length > trimIndent)
            chompStart = i + 1;
    }
    let value = '';
    let sep = '';
    let prevMoreIndented = false;
    // leading whitespace is kept intact
    for (let i = 0; i < contentStart; ++i)
        value += lines[i][0].slice(trimIndent) + '\n';
    for (let i = contentStart; i < chompStart; ++i) {
        let [indent, content] = lines[i];
        offset += indent.length + content.length + 1;
        const crlf = content[content.length - 1] === '\r';
        if (crlf)
            content = content.slice(0, -1);
        /* istanbul ignore if already caught in lexer */
        if (content && indent.length < trimIndent) {
            const src = header.indent
                ? 'explicit indentation indicator'
                : 'first line';
            const message = `Block scalar lines must not be less indented than their ${src}`;
            onError(offset - content.length - (crlf ? 2 : 1), 'BAD_INDENT', message);
            indent = '';
        }
        if (type === Scalar.BLOCK_LITERAL) {
            value += sep + indent.slice(trimIndent) + content;
            sep = '\n';
        }
        else if (indent.length > trimIndent || content[0] === '\t') {
            // more-indented content within a folded block
            if (sep === ' ')
                sep = '\n';
            else if (!prevMoreIndented && sep === '\n')
                sep = '\n\n';
            value += sep + indent.slice(trimIndent) + content;
            sep = '\n';
            prevMoreIndented = true;
        }
        else if (content === '') {
            // empty line
            if (sep === '\n')
                value += '\n';
            else
                sep = '\n';
        }
        else {
            value += sep + content;
            sep = ' ';
            prevMoreIndented = false;
        }
    }
    switch (header.chomp) {
        case '-':
            break;
        case '+':
            for (let i = chompStart; i < lines.length; ++i)
                value += '\n' + lines[i][0].slice(trimIndent);
            if (value[value.length - 1] !== '\n')
                value += '\n';
            break;
        default:
            value += '\n';
    }
    const end = start + header.length + scalar.source.length;
    return { value, type, comment: header.comment, range: [start, end, end] };
}
function parseBlockScalarHeader({ offset, props }, strict, onError) {
    /* istanbul ignore if should not happen */
    if (props[0].type !== 'block-scalar-header') {
        onError(props[0], 'IMPOSSIBLE', 'Block scalar header not found');
        return null;
    }
    const { source } = props[0];
    const mode = source[0];
    let indent = 0;
    let chomp = '';
    let error = -1;
    for (let i = 1; i < source.length; ++i) {
        const ch = source[i];
        if (!chomp && (ch === '-' || ch === '+'))
            chomp = ch;
        else {
            const n = Number(ch);
            if (!indent && n)
                indent = n;
            else if (error === -1)
                error = offset + i;
        }
    }
    if (error !== -1)
        onError(error, 'UNEXPECTED_TOKEN', `Block scalar header includes extra characters: ${source}`);
    let hasSpace = false;
    let comment = '';
    let length = source.length;
    for (let i = 1; i < props.length; ++i) {
        const token = props[i];
        switch (token.type) {
            case 'space':
                hasSpace = true;
            // fallthrough
            case 'newline':
                length += token.source.length;
                break;
            case 'comment':
                if (strict && !hasSpace) {
                    const message = 'Comments must be separated from other tokens by white space characters';
                    onError(token, 'MISSING_CHAR', message);
                }
                length += token.source.length;
                comment = token.source.substring(1);
                break;
            case 'error':
                onError(token, 'UNEXPECTED_TOKEN', token.message);
                length += token.source.length;
                break;
            /* istanbul ignore next should not happen */
            default: {
                const message = `Unexpected token in block scalar header: ${token.type}`;
                onError(token, 'UNEXPECTED_TOKEN', message);
                const ts = token.source;
                if (ts && typeof ts === 'string')
                    length += ts.length;
            }
        }
    }
    return { mode, indent, chomp, comment, length };
}
/** @returns Array of lines split up as `[indent, content]` */
function splitLines(source) {
    const split = source.split(/\n( *)/);
    const first = split[0];
    const m = first.match(/^( *)/);
    const line0 = m?.[1]
        ? [m[1], first.slice(m[1].length)]
        : ['', first];
    const lines = [line0];
    for (let i = 1; i < split.length; i += 2)
        lines.push([split[i], split[i + 1]]);
    return lines;
}

function resolveFlowScalar(scalar, strict, onError) {
    const { offset, type, source, end } = scalar;
    let _type;
    let value;
    const _onError = (rel, code, msg) => onError(offset + rel, code, msg);
    switch (type) {
        case 'scalar':
            _type = Scalar.PLAIN;
            value = plainValue(source, _onError);
            break;
        case 'single-quoted-scalar':
            _type = Scalar.QUOTE_SINGLE;
            value = singleQuotedValue(source, _onError);
            break;
        case 'double-quoted-scalar':
            _type = Scalar.QUOTE_DOUBLE;
            value = doubleQuotedValue(source, _onError);
            break;
        /* istanbul ignore next should not happen */
        default:
            onError(scalar, 'UNEXPECTED_TOKEN', `Expected a flow scalar value, but found: ${type}`);
            return {
                value: '',
                type: null,
                comment: '',
                range: [offset, offset + source.length, offset + source.length]
            };
    }
    const valueEnd = offset + source.length;
    const re = resolveEnd(end, valueEnd, strict, onError);
    return {
        value,
        type: _type,
        comment: re.comment,
        range: [offset, valueEnd, re.offset]
    };
}
function plainValue(source, onError) {
    let badChar = '';
    switch (source[0]) {
        /* istanbul ignore next should not happen */
        case '\t':
            badChar = 'a tab character';
            break;
        case ',':
            badChar = 'flow indicator character ,';
            break;
        case '%':
            badChar = 'directive indicator character %';
            break;
        case '|':
        case '>': {
            badChar = `block scalar indicator ${source[0]}`;
            break;
        }
        case '@':
        case '`': {
            badChar = `reserved character ${source[0]}`;
            break;
        }
    }
    if (badChar)
        onError(0, 'BAD_SCALAR_START', `Plain value cannot start with ${badChar}`);
    return foldLines(source);
}
function singleQuotedValue(source, onError) {
    if (source[source.length - 1] !== "'" || source.length === 1)
        onError(source.length, 'MISSING_CHAR', "Missing closing 'quote");
    return foldLines(source.slice(1, -1)).replace(/''/g, "'");
}
function foldLines(source) {
    /**
     * The negative lookbehind here and in the `re` RegExp is to
     * prevent causing a polynomial search time in certain cases.
     *
     * The try-catch is for Safari, which doesn't support this yet:
     * https://caniuse.com/js-regexp-lookbehind
     */
    let first, line;
    try {
        first = new RegExp('(.*?)(?<![ \t])[ \t]*\r?\n', 'sy');
        line = new RegExp('[ \t]*(.*?)(?:(?<![ \t])[ \t]*)?\r?\n', 'sy');
    }
    catch (_) {
        first = /(.*?)[ \t]*\r?\n/sy;
        line = /[ \t]*(.*?)[ \t]*\r?\n/sy;
    }
    let match = first.exec(source);
    if (!match)
        return source;
    let res = match[1];
    let sep = ' ';
    let pos = first.lastIndex;
    line.lastIndex = pos;
    while ((match = line.exec(source))) {
        if (match[1] === '') {
            if (sep === '\n')
                res += sep;
            else
                sep = '\n';
        }
        else {
            res += sep + match[1];
            sep = ' ';
        }
        pos = line.lastIndex;
    }
    const last = /[ \t]*(.*)/sy;
    last.lastIndex = pos;
    match = last.exec(source);
    return res + sep + (match?.[1] ?? '');
}
function doubleQuotedValue(source, onError) {
    let res = '';
    for (let i = 1; i < source.length - 1; ++i) {
        const ch = source[i];
        if (ch === '\r' && source[i + 1] === '\n')
            continue;
        if (ch === '\n') {
            const { fold, offset } = foldNewline(source, i);
            res += fold;
            i = offset;
        }
        else if (ch === '\\') {
            let next = source[++i];
            const cc = escapeCodes[next];
            if (cc)
                res += cc;
            else if (next === '\n') {
                // skip escaped newlines, but still trim the following line
                next = source[i + 1];
                while (next === ' ' || next === '\t')
                    next = source[++i + 1];
            }
            else if (next === '\r' && source[i + 1] === '\n') {
                // skip escaped CRLF newlines, but still trim the following line
                next = source[++i + 1];
                while (next === ' ' || next === '\t')
                    next = source[++i + 1];
            }
            else if (next === 'x' || next === 'u' || next === 'U') {
                const length = { x: 2, u: 4, U: 8 }[next];
                res += parseCharCode(source, i + 1, length, onError);
                i += length;
            }
            else {
                const raw = source.substr(i - 1, 2);
                onError(i - 1, 'BAD_DQ_ESCAPE', `Invalid escape sequence ${raw}`);
                res += raw;
            }
        }
        else if (ch === ' ' || ch === '\t') {
            // trim trailing whitespace
            const wsStart = i;
            let next = source[i + 1];
            while (next === ' ' || next === '\t')
                next = source[++i + 1];
            if (next !== '\n' && !(next === '\r' && source[i + 2] === '\n'))
                res += i > wsStart ? source.slice(wsStart, i + 1) : ch;
        }
        else {
            res += ch;
        }
    }
    if (source[source.length - 1] !== '"' || source.length === 1)
        onError(source.length, 'MISSING_CHAR', 'Missing closing "quote');
    return res;
}
/**
 * Fold a single newline into a space, multiple newlines to N - 1 newlines.
 * Presumes `source[offset] === '\n'`
 */
function foldNewline(source, offset) {
    let fold = '';
    let ch = source[offset + 1];
    while (ch === ' ' || ch === '\t' || ch === '\n' || ch === '\r') {
        if (ch === '\r' && source[offset + 2] !== '\n')
            break;
        if (ch === '\n')
            fold += '\n';
        offset += 1;
        ch = source[offset + 1];
    }
    if (!fold)
        fold = ' ';
    return { fold, offset };
}
const escapeCodes = {
    '0': '\0',
    a: '\x07',
    b: '\b',
    e: '\x1b',
    f: '\f',
    n: '\n',
    r: '\r',
    t: '\t',
    v: '\v',
    N: '\u0085',
    _: '\u00a0',
    L: '\u2028',
    P: '\u2029',
    ' ': ' ',
    '"': '"',
    '/': '/',
    '\\': '\\',
    '\t': '\t'
};
function parseCharCode(source, offset, length, onError) {
    const cc = source.substr(offset, length);
    const ok = cc.length === length && /^[0-9a-fA-F]+$/.test(cc);
    const code = ok ? parseInt(cc, 16) : NaN;
    if (isNaN(code)) {
        const raw = source.substr(offset - 2, length + 2);
        onError(offset - 2, 'BAD_DQ_ESCAPE', `Invalid escape sequence ${raw}`);
        return raw;
    }
    return String.fromCodePoint(code);
}

function composeScalar(ctx, token, tagToken, onError) {
    const { value, type, comment, range } = token.type === 'block-scalar'
        ? resolveBlockScalar(token, ctx.options.strict, onError)
        : resolveFlowScalar(token, ctx.options.strict, onError);
    const tagName = tagToken
        ? ctx.directives.tagName(tagToken.source, msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg))
        : null;
    const tag = tagToken && tagName
        ? findScalarTagByName(ctx.schema, value, tagName, tagToken, onError)
        : token.type === 'scalar'
            ? findScalarTagByTest(ctx, value, token, onError)
            : ctx.schema[SCALAR$1];
    let scalar;
    try {
        const res = tag.resolve(value, msg => onError(tagToken ?? token, 'TAG_RESOLVE_FAILED', msg), ctx.options);
        scalar = isScalar(res) ? res : new Scalar(res);
    }
    catch (error) {
        const msg = error instanceof Error ? error.message : String(error);
        onError(tagToken ?? token, 'TAG_RESOLVE_FAILED', msg);
        scalar = new Scalar(value);
    }
    scalar.range = range;
    scalar.source = value;
    if (type)
        scalar.type = type;
    if (tagName)
        scalar.tag = tagName;
    if (tag.format)
        scalar.format = tag.format;
    if (comment)
        scalar.comment = comment;
    return scalar;
}
function findScalarTagByName(schema, value, tagName, tagToken, onError) {
    if (tagName === '!')
        return schema[SCALAR$1]; // non-specific tag
    const matchWithTest = [];
    for (const tag of schema.tags) {
        if (!tag.collection && tag.tag === tagName) {
            if (tag.default && tag.test)
                matchWithTest.push(tag);
            else
                return tag;
        }
    }
    for (const tag of matchWithTest)
        if (tag.test?.test(value))
            return tag;
    const kt = schema.knownTags[tagName];
    if (kt && !kt.collection) {
        // Ensure that the known tag is available for stringifying,
        // but does not get used by default.
        schema.tags.push(Object.assign({}, kt, { default: false, test: undefined }));
        return kt;
    }
    onError(tagToken, 'TAG_RESOLVE_FAILED', `Unresolved tag: ${tagName}`, tagName !== 'tag:yaml.org,2002:str');
    return schema[SCALAR$1];
}
function findScalarTagByTest({ directives, schema }, value, token, onError) {
    const tag = schema.tags.find(tag => tag.default && tag.test?.test(value)) || schema[SCALAR$1];
    if (schema.compat) {
        const compat = schema.compat.find(tag => tag.default && tag.test?.test(value)) ??
            schema[SCALAR$1];
        if (tag.tag !== compat.tag) {
            const ts = directives.tagString(tag.tag);
            const cs = directives.tagString(compat.tag);
            const msg = `Value may be parsed as either ${ts} or ${cs}`;
            onError(token, 'TAG_RESOLVE_FAILED', msg, true);
        }
    }
    return tag;
}

function emptyScalarPosition(offset, before, pos) {
    if (before) {
        if (pos === null)
            pos = before.length;
        for (let i = pos - 1; i >= 0; --i) {
            let st = before[i];
            switch (st.type) {
                case 'space':
                case 'comment':
                case 'newline':
                    offset -= st.source.length;
                    continue;
            }
            // Technically, an empty scalar is immediately after the last non-empty
            // node, but it's more useful to place it after any whitespace.
            st = before[++i];
            while (st?.type === 'space') {
                offset += st.source.length;
                st = before[++i];
            }
            break;
        }
    }
    return offset;
}

const CN = { composeNode, composeEmptyNode };
function composeNode(ctx, token, props, onError) {
    const { spaceBefore, comment, anchor, tag } = props;
    let node;
    let isSrcToken = true;
    switch (token.type) {
        case 'alias':
            node = composeAlias(ctx, token, onError);
            if (anchor || tag)
                onError(token, 'ALIAS_PROPS', 'An alias node must not specify any properties');
            break;
        case 'scalar':
        case 'single-quoted-scalar':
        case 'double-quoted-scalar':
        case 'block-scalar':
            node = composeScalar(ctx, token, tag, onError);
            if (anchor)
                node.anchor = anchor.source.substring(1);
            break;
        case 'block-map':
        case 'block-seq':
        case 'flow-collection':
            node = composeCollection(CN, ctx, token, tag, onError);
            if (anchor)
                node.anchor = anchor.source.substring(1);
            break;
        default: {
            const message = token.type === 'error'
                ? token.message
                : `Unsupported token (type: ${token.type})`;
            onError(token, 'UNEXPECTED_TOKEN', message);
            node = composeEmptyNode(ctx, token.offset, undefined, null, props, onError);
            isSrcToken = false;
        }
    }
    if (anchor && node.anchor === '')
        onError(anchor, 'BAD_ALIAS', 'Anchor cannot be an empty string');
    if (spaceBefore)
        node.spaceBefore = true;
    if (comment) {
        if (token.type === 'scalar' && token.source === '')
            node.comment = comment;
        else
            node.commentBefore = comment;
    }
    // @ts-expect-error Type checking misses meaning of isSrcToken
    if (ctx.options.keepSourceTokens && isSrcToken)
        node.srcToken = token;
    return node;
}
function composeEmptyNode(ctx, offset, before, pos, { spaceBefore, comment, anchor, tag, end }, onError) {
    const token = {
        type: 'scalar',
        offset: emptyScalarPosition(offset, before, pos),
        indent: -1,
        source: ''
    };
    const node = composeScalar(ctx, token, tag, onError);
    if (anchor) {
        node.anchor = anchor.source.substring(1);
        if (node.anchor === '')
            onError(anchor, 'BAD_ALIAS', 'Anchor cannot be an empty string');
    }
    if (spaceBefore)
        node.spaceBefore = true;
    if (comment) {
        node.comment = comment;
        node.range[2] = end;
    }
    return node;
}
function composeAlias({ options }, { offset, source, end }, onError) {
    const alias = new Alias(source.substring(1));
    if (alias.source === '')
        onError(offset, 'BAD_ALIAS', 'Alias cannot be an empty string');
    if (alias.source.endsWith(':'))
        onError(offset + source.length - 1, 'BAD_ALIAS', 'Alias ending in : is ambiguous', true);
    const valueEnd = offset + source.length;
    const re = resolveEnd(end, valueEnd, options.strict, onError);
    alias.range = [offset, valueEnd, re.offset];
    if (re.comment)
        alias.comment = re.comment;
    return alias;
}

function composeDoc(options, directives, { offset, start, value, end }, onError) {
    const opts = Object.assign({ _directives: directives }, options);
    const doc = new Document(undefined, opts);
    const ctx = {
        atRoot: true,
        directives: doc.directives,
        options: doc.options,
        schema: doc.schema
    };
    const props = resolveProps(start, {
        indicator: 'doc-start',
        next: value ?? end?.[0],
        offset,
        onError,
        startOnNewline: true
    });
    if (props.found) {
        doc.directives.docStart = true;
        if (value &&
            (value.type === 'block-map' || value.type === 'block-seq') &&
            !props.hasNewline)
            onError(props.end, 'MISSING_CHAR', 'Block collection cannot start on same line with directives-end marker');
    }
    // @ts-expect-error If Contents is set, let's trust the user
    doc.contents = value
        ? composeNode(ctx, value, props, onError)
        : composeEmptyNode(ctx, props.end, start, null, props, onError);
    const contentEnd = doc.contents.range[2];
    const re = resolveEnd(end, contentEnd, false, onError);
    if (re.comment)
        doc.comment = re.comment;
    doc.range = [offset, contentEnd, re.offset];
    return doc;
}

function getErrorPos(src) {
    if (typeof src === 'number')
        return [src, src + 1];
    if (Array.isArray(src))
        return src.length === 2 ? src : [src[0], src[1]];
    const { offset, source } = src;
    return [offset, offset + (typeof source === 'string' ? source.length : 1)];
}
function parsePrelude(prelude) {
    let comment = '';
    let atComment = false;
    let afterEmptyLine = false;
    for (let i = 0; i < prelude.length; ++i) {
        const source = prelude[i];
        switch (source[0]) {
            case '#':
                comment +=
                    (comment === '' ? '' : afterEmptyLine ? '\n\n' : '\n') +
                        (source.substring(1) || ' ');
                atComment = true;
                afterEmptyLine = false;
                break;
            case '%':
                if (prelude[i + 1]?.[0] !== '#')
                    i += 1;
                atComment = false;
                break;
            default:
                // This may be wrong after doc-end, but in that case it doesn't matter
                if (!atComment)
                    afterEmptyLine = true;
                atComment = false;
        }
    }
    return { comment, afterEmptyLine };
}
/**
 * Compose a stream of CST nodes into a stream of YAML Documents.
 *
 * ```ts
 * import { Composer, Parser } from 'yaml'
 *
 * const src: string = ...
 * const tokens = new Parser().parse(src)
 * const docs = new Composer().compose(tokens)
 * ```
 */
class Composer {
    constructor(options = {}) {
        this.doc = null;
        this.atDirectives = false;
        this.prelude = [];
        this.errors = [];
        this.warnings = [];
        this.onError = (source, code, message, warning) => {
            const pos = getErrorPos(source);
            if (warning)
                this.warnings.push(new YAMLWarning(pos, code, message));
            else
                this.errors.push(new YAMLParseError(pos, code, message));
        };
        // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing
        this.directives = new Directives({ version: options.version || '1.2' });
        this.options = options;
    }
    decorate(doc, afterDoc) {
        const { comment, afterEmptyLine } = parsePrelude(this.prelude);
        //console.log({ dc: doc.comment, prelude, comment })
        if (comment) {
            const dc = doc.contents;
            if (afterDoc) {
                doc.comment = doc.comment ? `${doc.comment}\n${comment}` : comment;
            }
            else if (afterEmptyLine || doc.directives.docStart || !dc) {
                doc.commentBefore = comment;
            }
            else if (isCollection(dc) && !dc.flow && dc.items.length > 0) {
                let it = dc.items[0];
                if (isPair(it))
                    it = it.key;
                const cb = it.commentBefore;
                it.commentBefore = cb ? `${comment}\n${cb}` : comment;
            }
            else {
                const cb = dc.commentBefore;
                dc.commentBefore = cb ? `${comment}\n${cb}` : comment;
            }
        }
        if (afterDoc) {
            Array.prototype.push.apply(doc.errors, this.errors);
            Array.prototype.push.apply(doc.warnings, this.warnings);
        }
        else {
            doc.errors = this.errors;
            doc.warnings = this.warnings;
        }
        this.prelude = [];
        this.errors = [];
        this.warnings = [];
    }
    /**
     * Current stream status information.
     *
     * Mostly useful at the end of input for an empty stream.
     */
    streamInfo() {
        return {
            comment: parsePrelude(this.prelude).comment,
            directives: this.directives,
            errors: this.errors,
            warnings: this.warnings
        };
    }
    /**
     * Compose tokens into documents.
     *
     * @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.
     * @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.
     */
    *compose(tokens, forceDoc = false, endOffset = -1) {
        for (const token of tokens)
            yield* this.next(token);
        yield* this.end(forceDoc, endOffset);
    }
    /** Advance the composer by one CST token. */
    *next(token) {
        switch (token.type) {
            case 'directive':
                this.directives.add(token.source, (offset, message, warning) => {
                    const pos = getErrorPos(token);
                    pos[0] += offset;
                    this.onError(pos, 'BAD_DIRECTIVE', message, warning);
                });
                this.prelude.push(token.source);
                this.atDirectives = true;
                break;
            case 'document': {
                const doc = composeDoc(this.options, this.directives, token, this.onError);
                if (this.atDirectives && !doc.directives.docStart)
                    this.onError(token, 'MISSING_CHAR', 'Missing directives-end/doc-start indicator line');
                this.decorate(doc, false);
                if (this.doc)
                    yield this.doc;
                this.doc = doc;
                this.atDirectives = false;
                break;
            }
            case 'byte-order-mark':
            case 'space':
                break;
            case 'comment':
            case 'newline':
                this.prelude.push(token.source);
                break;
            case 'error': {
                const msg = token.source
                    ? `${token.message}: ${JSON.stringify(token.source)}`
                    : token.message;
                const error = new YAMLParseError(getErrorPos(token), 'UNEXPECTED_TOKEN', msg);
                if (this.atDirectives || !this.doc)
                    this.errors.push(error);
                else
                    this.doc.errors.push(error);
                break;
            }
            case 'doc-end': {
                if (!this.doc) {
                    const msg = 'Unexpected doc-end without preceding document';
                    this.errors.push(new YAMLParseError(getErrorPos(token), 'UNEXPECTED_TOKEN', msg));
                    break;
                }
                this.doc.directives.docEnd = true;
                const end = resolveEnd(token.end, token.offset + token.source.length, this.doc.options.strict, this.onError);
                this.decorate(this.doc, true);
                if (end.comment) {
                    const dc = this.doc.comment;
                    this.doc.comment = dc ? `${dc}\n${end.comment}` : end.comment;
                }
                this.doc.range[2] = end.offset;
                break;
            }
            default:
                this.errors.push(new YAMLParseError(getErrorPos(token), 'UNEXPECTED_TOKEN', `Unsupported token ${token.type}`));
        }
    }
    /**
     * Call at end of input to yield any remaining document.
     *
     * @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.
     * @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.
     */
    *end(forceDoc = false, endOffset = -1) {
        if (this.doc) {
            this.decorate(this.doc, true);
            yield this.doc;
            this.doc = null;
        }
        else if (forceDoc) {
            const opts = Object.assign({ _directives: this.directives }, this.options);
            const doc = new Document(undefined, opts);
            if (this.atDirectives)
                this.onError(endOffset, 'MISSING_CHAR', 'Missing directives-end indicator line');
            doc.range = [0, endOffset, endOffset];
            this.decorate(doc, false);
            yield doc;
        }
    }
}

/** The byte order mark */
const BOM = '\u{FEFF}';
/** Start of doc-mode */
const DOCUMENT = '\x02'; // C0: Start of Text
/** Unexpected end of flow-mode */
const FLOW_END = '\x18'; // C0: Cancel
/** Next token is a scalar value */
const SCALAR = '\x1f'; // C0: Unit Separator
/** Identify the type of a lexer token. May return `null` for unknown tokens. */
function tokenType(source) {
    switch (source) {
        case BOM:
            return 'byte-order-mark';
        case DOCUMENT:
            return 'doc-mode';
        case FLOW_END:
            return 'flow-error-end';
        case SCALAR:
            return 'scalar';
        case '---':
            return 'doc-start';
        case '...':
            return 'doc-end';
        case '':
        case '\n':
        case '\r\n':
            return 'newline';
        case '-':
            return 'seq-item-ind';
        case '?':
            return 'explicit-key-ind';
        case ':':
            return 'map-value-ind';
        case '{':
            return 'flow-map-start';
        case '}':
            return 'flow-map-end';
        case '[':
            return 'flow-seq-start';
        case ']':
            return 'flow-seq-end';
        case ',':
            return 'comma';
    }
    switch (source[0]) {
        case ' ':
        case '\t':
            return 'space';
        case '#':
            return 'comment';
        case '%':
            return 'directive-line';
        case '*':
            return 'alias';
        case '&':
            return 'anchor';
        case '!':
            return 'tag';
        case "'":
            return 'single-quoted-scalar';
        case '"':
            return 'double-quoted-scalar';
        case '|':
        case '>':
            return 'block-scalar-header';
    }
    return null;
}

/*
START -> stream

stream
  directive -> line-end -> stream
  indent + line-end -> stream
  [else] -> line-start

line-end
  comment -> line-end
  newline -> .
  input-end -> END

line-start
  doc-start -> doc
  doc-end -> stream
  [else] -> indent -> block-start

block-start
  seq-item-start -> block-start
  explicit-key-start -> block-start
  map-value-start -> block-start
  [else] -> doc

doc
  line-end -> line-start
  spaces -> doc
  anchor -> doc
  tag -> doc
  flow-start -> flow -> doc
  flow-end -> error -> doc
  seq-item-start -> error -> doc
  explicit-key-start -> error -> doc
  map-value-start -> doc
  alias -> doc
  quote-start -> quoted-scalar -> doc
  block-scalar-header -> line-end -> block-scalar(min) -> line-start
  [else] -> plain-scalar(false, min) -> doc

flow
  line-end -> flow
  spaces -> flow
  anchor -> flow
  tag -> flow
  flow-start -> flow -> flow
  flow-end -> .
  seq-item-start -> error -> flow
  explicit-key-start -> flow
  map-value-start -> flow
  alias -> flow
  quote-start -> quoted-scalar -> flow
  comma -> flow
  [else] -> plain-scalar(true, 0) -> flow

quoted-scalar
  quote-end -> .
  [else] -> quoted-scalar

block-scalar(min)
  newline + peek(indent < min) -> .
  [else] -> block-scalar(min)

plain-scalar(is-flow, min)
  scalar-end(is-flow) -> .
  peek(newline + (indent < min)) -> .
  [else] -> plain-scalar(min)
*/
function isEmpty(ch) {
    switch (ch) {
        case undefined:
        case ' ':
        case '\n':
        case '\r':
        case '\t':
            return true;
        default:
            return false;
    }
}
const hexDigits = '0123456789ABCDEFabcdef'.split('');
const tagChars = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-#;/?:@&=+$_.!~*'()".split('');
const invalidFlowScalarChars = ',[]{}'.split('');
const invalidAnchorChars = ' ,[]{}\n\r\t'.split('');
const isNotAnchorChar = (ch) => !ch || invalidAnchorChars.includes(ch);
/**
 * Splits an input string into lexical tokens, i.e. smaller strings that are
 * easily identifiable by `tokens.tokenType()`.
 *
 * Lexing starts always in a "stream" context. Incomplete input may be buffered
 * until a complete token can be emitted.
 *
 * In addition to slices of the original input, the following control characters
 * may also be emitted:
 *
 * - `\x02` (Start of Text): A document starts with the next token
 * - `\x18` (Cancel): Unexpected end of flow-mode (indicates an error)
 * - `\x1f` (Unit Separator): Next token is a scalar value
 * - `\u{FEFF}` (Byte order mark): Emitted separately outside documents
 */
class Lexer {
    constructor() {
        /**
         * Flag indicating whether the end of the current buffer marks the end of
         * all input
         */
        this.atEnd = false;
        /**
         * Explicit indent set in block scalar header, as an offset from the current
         * minimum indent, so e.g. set to 1 from a header `|2+`. Set to -1 if not
         * explicitly set.
         */
        this.blockScalarIndent = -1;
        /**
         * Block scalars that include a + (keep) chomping indicator in their header
         * include trailing empty lines, which are otherwise excluded from the
         * scalar's contents.
         */
        this.blockScalarKeep = false;
        /** Current input */
        this.buffer = '';
        /**
         * Flag noting whether the map value indicator : can immediately follow this
         * node within a flow context.
         */
        this.flowKey = false;
        /** Count of surrounding flow collection levels. */
        this.flowLevel = 0;
        /**
         * Minimum level of indentation required for next lines to be parsed as a
         * part of the current scalar value.
         */
        this.indentNext = 0;
        /** Indentation level of the current line. */
        this.indentValue = 0;
        /** Position of the next \n character. */
        this.lineEndPos = null;
        /** Stores the state of the lexer if reaching the end of incpomplete input */
        this.next = null;
        /** A pointer to `buffer`; the current position of the lexer. */
        this.pos = 0;
    }
    /**
     * Generate YAML tokens from the `source` string. If `incomplete`,
     * a part of the last line may be left as a buffer for the next call.
     *
     * @returns A generator of lexical tokens
     */
    *lex(source, incomplete = false) {
        if (source) {
            this.buffer = this.buffer ? this.buffer + source : source;
            this.lineEndPos = null;
        }
        this.atEnd = !incomplete;
        let next = this.next ?? 'stream';
        while (next && (incomplete || this.hasChars(1)))
            next = yield* this.parseNext(next);
    }
    atLineEnd() {
        let i = this.pos;
        let ch = this.buffer[i];
        while (ch === ' ' || ch === '\t')
            ch = this.buffer[++i];
        if (!ch || ch === '#' || ch === '\n')
            return true;
        if (ch === '\r')
            return this.buffer[i + 1] === '\n';
        return false;
    }
    charAt(n) {
        return this.buffer[this.pos + n];
    }
    continueScalar(offset) {
        let ch = this.buffer[offset];
        if (this.indentNext > 0) {
            let indent = 0;
            while (ch === ' ')
                ch = this.buffer[++indent + offset];
            if (ch === '\r') {
                const next = this.buffer[indent + offset + 1];
                if (next === '\n' || (!next && !this.atEnd))
                    return offset + indent + 1;
            }
            return ch === '\n' || indent >= this.indentNext || (!ch && !this.atEnd)
                ? offset + indent
                : -1;
        }
        if (ch === '-' || ch === '.') {
            const dt = this.buffer.substr(offset, 3);
            if ((dt === '---' || dt === '...') && isEmpty(this.buffer[offset + 3]))
                return -1;
        }
        return offset;
    }
    getLine() {
        let end = this.lineEndPos;
        if (typeof end !== 'number' || (end !== -1 && end < this.pos)) {
            end = this.buffer.indexOf('\n', this.pos);
            this.lineEndPos = end;
        }
        if (end === -1)
            return this.atEnd ? this.buffer.substring(this.pos) : null;
        if (this.buffer[end - 1] === '\r')
            end -= 1;
        return this.buffer.substring(this.pos, end);
    }
    hasChars(n) {
        return this.pos + n <= this.buffer.length;
    }
    setNext(state) {
        this.buffer = this.buffer.substring(this.pos);
        this.pos = 0;
        this.lineEndPos = null;
        this.next = state;
        return null;
    }
    peek(n) {
        return this.buffer.substr(this.pos, n);
    }
    *parseNext(next) {
        switch (next) {
            case 'stream':
                return yield* this.parseStream();
            case 'line-start':
                return yield* this.parseLineStart();
            case 'block-start':
                return yield* this.parseBlockStart();
            case 'doc':
                return yield* this.parseDocument();
            case 'flow':
                return yield* this.parseFlowCollection();
            case 'quoted-scalar':
                return yield* this.parseQuotedScalar();
            case 'block-scalar':
                return yield* this.parseBlockScalar();
            case 'plain-scalar':
                return yield* this.parsePlainScalar();
        }
    }
    *parseStream() {
        let line = this.getLine();
        if (line === null)
            return this.setNext('stream');
        if (line[0] === BOM) {
            yield* this.pushCount(1);
            line = line.substring(1);
        }
        if (line[0] === '%') {
            let dirEnd = line.length;
            const cs = line.indexOf('#');
            if (cs !== -1) {
                const ch = line[cs - 1];
                if (ch === ' ' || ch === '\t')
                    dirEnd = cs - 1;
            }
            while (true) {
                const ch = line[dirEnd - 1];
                if (ch === ' ' || ch === '\t')
                    dirEnd -= 1;
                else
                    break;
            }
            const n = (yield* this.pushCount(dirEnd)) + (yield* this.pushSpaces(true));
            yield* this.pushCount(line.length - n); // possible comment
            this.pushNewline();
            return 'stream';
        }
        if (this.atLineEnd()) {
            const sp = yield* this.pushSpaces(true);
            yield* this.pushCount(line.length - sp);
            yield* this.pushNewline();
            return 'stream';
        }
        yield DOCUMENT;
        return yield* this.parseLineStart();
    }
    *parseLineStart() {
        const ch = this.charAt(0);
        if (!ch && !this.atEnd)
            return this.setNext('line-start');
        if (ch === '-' || ch === '.') {
            if (!this.atEnd && !this.hasChars(4))
                return this.setNext('line-start');
            const s = this.peek(3);
            if (s === '---' && isEmpty(this.charAt(3))) {
                yield* this.pushCount(3);
                this.indentValue = 0;
                this.indentNext = 0;
                return 'doc';
            }
            else if (s === '...' && isEmpty(this.charAt(3))) {
                yield* this.pushCount(3);
                return 'stream';
            }
        }
        this.indentValue = yield* this.pushSpaces(false);
        if (this.indentNext > this.indentValue && !isEmpty(this.charAt(1)))
            this.indentNext = this.indentValue;
        return yield* this.parseBlockStart();
    }
    *parseBlockStart() {
        const [ch0, ch1] = this.peek(2);
        if (!ch1 && !this.atEnd)
            return this.setNext('block-start');
        if ((ch0 === '-' || ch0 === '?' || ch0 === ':') && isEmpty(ch1)) {
            const n = (yield* this.pushCount(1)) + (yield* this.pushSpaces(true));
            this.indentNext = this.indentValue + 1;
            this.indentValue += n;
            return yield* this.parseBlockStart();
        }
        return 'doc';
    }
    *parseDocument() {
        yield* this.pushSpaces(true);
        const line = this.getLine();
        if (line === null)
            return this.setNext('doc');
        let n = yield* this.pushIndicators();
        switch (line[n]) {
            case '#':
                yield* this.pushCount(line.length - n);
            // fallthrough
            case undefined:
                yield* this.pushNewline();
                return yield* this.parseLineStart();
            case '{':
            case '[':
                yield* this.pushCount(1);
                this.flowKey = false;
                this.flowLevel = 1;
                return 'flow';
            case '}':
            case ']':
                // this is an error
                yield* this.pushCount(1);
                return 'doc';
            case '*':
                yield* this.pushUntil(isNotAnchorChar);
                return 'doc';
            case '"':
            case "'":
                return yield* this.parseQuotedScalar();
            case '|':
            case '>':
                n += yield* this.parseBlockScalarHeader();
                n += yield* this.pushSpaces(true);
                yield* this.pushCount(line.length - n);
                yield* this.pushNewline();
                return yield* this.parseBlockScalar();
            default:
                return yield* this.parsePlainScalar();
        }
    }
    *parseFlowCollection() {
        let nl, sp;
        let indent = -1;
        do {
            nl = yield* this.pushNewline();
            if (nl > 0) {
                sp = yield* this.pushSpaces(false);
                this.indentValue = indent = sp;
            }
            else {
                sp = 0;
            }
            sp += yield* this.pushSpaces(true);
        } while (nl + sp > 0);
        const line = this.getLine();
        if (line === null)
            return this.setNext('flow');
        if ((indent !== -1 && indent < this.indentNext && line[0] !== '#') ||
            (indent === 0 &&
                (line.startsWith('---') || line.startsWith('...')) &&
                isEmpty(line[3]))) {
            // Allowing for the terminal ] or } at the same (rather than greater)
            // indent level as the initial [ or { is technically invalid, but
            // failing here would be surprising to users.
            const atFlowEndMarker = indent === this.indentNext - 1 &&
                this.flowLevel === 1 &&
                (line[0] === ']' || line[0] === '}');
            if (!atFlowEndMarker) {
                // this is an error
                this.flowLevel = 0;
                yield FLOW_END;
                return yield* this.parseLineStart();
            }
        }
        let n = 0;
        while (line[n] === ',') {
            n += yield* this.pushCount(1);
            n += yield* this.pushSpaces(true);
            this.flowKey = false;
        }
        n += yield* this.pushIndicators();
        switch (line[n]) {
            case undefined:
                return 'flow';
            case '#':
                yield* this.pushCount(line.length - n);
                return 'flow';
            case '{':
            case '[':
                yield* this.pushCount(1);
                this.flowKey = false;
                this.flowLevel += 1;
                return 'flow';
            case '}':
            case ']':
                yield* this.pushCount(1);
                this.flowKey = true;
                this.flowLevel -= 1;
                return this.flowLevel ? 'flow' : 'doc';
            case '*':
                yield* this.pushUntil(isNotAnchorChar);
                return 'flow';
            case '"':
            case "'":
                this.flowKey = true;
                return yield* this.parseQuotedScalar();
            case ':': {
                const next = this.charAt(1);
                if (this.flowKey || isEmpty(next) || next === ',') {
                    this.flowKey = false;
                    yield* this.pushCount(1);
                    yield* this.pushSpaces(true);
                    return 'flow';
                }
            }
            // fallthrough
            default:
                this.flowKey = false;
                return yield* this.parsePlainScalar();
        }
    }
    *parseQuotedScalar() {
        const quote = this.charAt(0);
        let end = this.buffer.indexOf(quote, this.pos + 1);
        if (quote === "'") {
            while (end !== -1 && this.buffer[end + 1] === "'")
                end = this.buffer.indexOf("'", end + 2);
        }
        else {
            // double-quote
            while (end !== -1) {
                let n = 0;
                while (this.buffer[end - 1 - n] === '\\')
                    n += 1;
                if (n % 2 === 0)
                    break;
                end = this.buffer.indexOf('"', end + 1);
            }
        }
        // Only looking for newlines within the quotes
        const qb = this.buffer.substring(0, end);
        let nl = qb.indexOf('\n', this.pos);
        if (nl !== -1) {
            while (nl !== -1) {
                const cs = this.continueScalar(nl + 1);
                if (cs === -1)
                    break;
                nl = qb.indexOf('\n', cs);
            }
            if (nl !== -1) {
                // this is an error caused by an unexpected unindent
                end = nl - (qb[nl - 1] === '\r' ? 2 : 1);
            }
        }
        if (end === -1) {
            if (!this.atEnd)
                return this.setNext('quoted-scalar');
            end = this.buffer.length;
        }
        yield* this.pushToIndex(end + 1, false);
        return this.flowLevel ? 'flow' : 'doc';
    }
    *parseBlockScalarHeader() {
        this.blockScalarIndent = -1;
        this.blockScalarKeep = false;
        let i = this.pos;
        while (true) {
            const ch = this.buffer[++i];
            if (ch === '+')
                this.blockScalarKeep = true;
            else if (ch > '0' && ch <= '9')
                this.blockScalarIndent = Number(ch) - 1;
            else if (ch !== '-')
                break;
        }
        return yield* this.pushUntil(ch => isEmpty(ch) || ch === '#');
    }
    *parseBlockScalar() {
        let nl = this.pos - 1; // may be -1 if this.pos === 0
        let indent = 0;
        let ch;
        loop: for (let i = this.pos; (ch = this.buffer[i]); ++i) {
            switch (ch) {
                case ' ':
                    indent += 1;
                    break;
                case '\n':
                    nl = i;
                    indent = 0;
                    break;
                case '\r': {
                    const next = this.buffer[i + 1];
                    if (!next && !this.atEnd)
                        return this.setNext('block-scalar');
                    if (next === '\n')
                        break;
                } // fallthrough
                default:
                    break loop;
            }
        }
        if (!ch && !this.atEnd)
            return this.setNext('block-scalar');
        if (indent >= this.indentNext) {
            if (this.blockScalarIndent === -1)
                this.indentNext = indent;
            else
                this.indentNext += this.blockScalarIndent;
            do {
                const cs = this.continueScalar(nl + 1);
                if (cs === -1)
                    break;
                nl = this.buffer.indexOf('\n', cs);
            } while (nl !== -1);
            if (nl === -1) {
                if (!this.atEnd)
                    return this.setNext('block-scalar');
                nl = this.buffer.length;
            }
        }
        if (!this.blockScalarKeep) {
            do {
                let i = nl - 1;
                let ch = this.buffer[i];
                if (ch === '\r')
                    ch = this.buffer[--i];
                const lastChar = i; // Drop the line if last char not more indented
                while (ch === ' ' || ch === '\t')
                    ch = this.buffer[--i];
                if (ch === '\n' && i >= this.pos && i + 1 + indent > lastChar)
                    nl = i;
                else
                    break;
            } while (true);
        }
        yield SCALAR;
        yield* this.pushToIndex(nl + 1, true);
        return yield* this.parseLineStart();
    }
    *parsePlainScalar() {
        const inFlow = this.flowLevel > 0;
        let end = this.pos - 1;
        let i = this.pos - 1;
        let ch;
        while ((ch = this.buffer[++i])) {
            if (ch === ':') {
                const next = this.buffer[i + 1];
                if (isEmpty(next) || (inFlow && next === ','))
                    break;
                end = i;
            }
            else if (isEmpty(ch)) {
                let next = this.buffer[i + 1];
                if (ch === '\r') {
                    if (next === '\n') {
                        i += 1;
                        ch = '\n';
                        next = this.buffer[i + 1];
                    }
                    else
                        end = i;
                }
                if (next === '#' || (inFlow && invalidFlowScalarChars.includes(next)))
                    break;
                if (ch === '\n') {
                    const cs = this.continueScalar(i + 1);
                    if (cs === -1)
                        break;
                    i = Math.max(i, cs - 2); // to advance, but still account for ' #'
                }
            }
            else {
                if (inFlow && invalidFlowScalarChars.includes(ch))
                    break;
                end = i;
            }
        }
        if (!ch && !this.atEnd)
            return this.setNext('plain-scalar');
        yield SCALAR;
        yield* this.pushToIndex(end + 1, true);
        return inFlow ? 'flow' : 'doc';
    }
    *pushCount(n) {
        if (n > 0) {
            yield this.buffer.substr(this.pos, n);
            this.pos += n;
            return n;
        }
        return 0;
    }
    *pushToIndex(i, allowEmpty) {
        const s = this.buffer.slice(this.pos, i);
        if (s) {
            yield s;
            this.pos += s.length;
            return s.length;
        }
        else if (allowEmpty)
            yield '';
        return 0;
    }
    *pushIndicators() {
        switch (this.charAt(0)) {
            case '!':
                return ((yield* this.pushTag()) +
                    (yield* this.pushSpaces(true)) +
                    (yield* this.pushIndicators()));
            case '&':
                return ((yield* this.pushUntil(isNotAnchorChar)) +
                    (yield* this.pushSpaces(true)) +
                    (yield* this.pushIndicators()));
            case '-': // this is an error
            case '?': // this is an error outside flow collections
            case ':': {
                const inFlow = this.flowLevel > 0;
                const ch1 = this.charAt(1);
                if (isEmpty(ch1) || (inFlow && invalidFlowScalarChars.includes(ch1))) {
                    if (!inFlow)
                        this.indentNext = this.indentValue + 1;
                    else if (this.flowKey)
                        this.flowKey = false;
                    return ((yield* this.pushCount(1)) +
                        (yield* this.pushSpaces(true)) +
                        (yield* this.pushIndicators()));
                }
            }
        }
        return 0;
    }
    *pushTag() {
        if (this.charAt(1) === '<') {
            let i = this.pos + 2;
            let ch = this.buffer[i];
            while (!isEmpty(ch) && ch !== '>')
                ch = this.buffer[++i];
            return yield* this.pushToIndex(ch === '>' ? i + 1 : i, false);
        }
        else {
            let i = this.pos + 1;
            let ch = this.buffer[i];
            while (ch) {
                if (tagChars.includes(ch))
                    ch = this.buffer[++i];
                else if (ch === '%' &&
                    hexDigits.includes(this.buffer[i + 1]) &&
                    hexDigits.includes(this.buffer[i + 2])) {
                    ch = this.buffer[(i += 3)];
                }
                else
                    break;
            }
            return yield* this.pushToIndex(i, false);
        }
    }
    *pushNewline() {
        const ch = this.buffer[this.pos];
        if (ch === '\n')
            return yield* this.pushCount(1);
        else if (ch === '\r' && this.charAt(1) === '\n')
            return yield* this.pushCount(2);
        else
            return 0;
    }
    *pushSpaces(allowTabs) {
        let i = this.pos - 1;
        let ch;
        do {
            ch = this.buffer[++i];
        } while (ch === ' ' || (allowTabs && ch === '\t'));
        const n = i - this.pos;
        if (n > 0) {
            yield this.buffer.substr(this.pos, n);
            this.pos = i;
        }
        return n;
    }
    *pushUntil(test) {
        let i = this.pos;
        let ch = this.buffer[i];
        while (!test(ch))
            ch = this.buffer[++i];
        return yield* this.pushToIndex(i, false);
    }
}

/**
 * Tracks newlines during parsing in order to provide an efficient API for
 * determining the one-indexed `{ line, col }` position for any offset
 * within the input.
 */
class LineCounter {
    constructor() {
        this.lineStarts = [];
        /**
         * Should be called in ascending order. Otherwise, call
         * `lineCounter.lineStarts.sort()` before calling `linePos()`.
         */
        this.addNewLine = (offset) => this.lineStarts.push(offset);
        /**
         * Performs a binary search and returns the 1-indexed { line, col }
         * position of `offset`. If `line === 0`, `addNewLine` has never been
         * called or `offset` is before the first known newline.
         */
        this.linePos = (offset) => {
            let low = 0;
            let high = this.lineStarts.length;
            while (low < high) {
                const mid = (low + high) >> 1; // Math.floor((low + high) / 2)
                if (this.lineStarts[mid] < offset)
                    low = mid + 1;
                else
                    high = mid;
            }
            if (this.lineStarts[low] === offset)
                return { line: low + 1, col: 1 };
            if (low === 0)
                return { line: 0, col: offset };
            const start = this.lineStarts[low - 1];
            return { line: low, col: offset - start + 1 };
        };
    }
}

function includesToken(list, type) {
    for (let i = 0; i < list.length; ++i)
        if (list[i].type === type)
            return true;
    return false;
}
function findNonEmptyIndex(list) {
    for (let i = 0; i < list.length; ++i) {
        switch (list[i].type) {
            case 'space':
            case 'comment':
            case 'newline':
                break;
            default:
                return i;
        }
    }
    return -1;
}
function isFlowToken(token) {
    switch (token?.type) {
        case 'alias':
        case 'scalar':
        case 'single-quoted-scalar':
        case 'double-quoted-scalar':
        case 'flow-collection':
            return true;
        default:
            return false;
    }
}
function getPrevProps(parent) {
    switch (parent.type) {
        case 'document':
            return parent.start;
        case 'block-map': {
            const it = parent.items[parent.items.length - 1];
            return it.sep ?? it.start;
        }
        case 'block-seq':
            return parent.items[parent.items.length - 1].start;
        /* istanbul ignore next should not happen */
        default:
            return [];
    }
}
/** Note: May modify input array */
function getFirstKeyStartProps(prev) {
    if (prev.length === 0)
        return [];
    let i = prev.length;
    loop: while (--i >= 0) {
        switch (prev[i].type) {
            case 'doc-start':
            case 'explicit-key-ind':
            case 'map-value-ind':
            case 'seq-item-ind':
            case 'newline':
                break loop;
        }
    }
    while (prev[++i]?.type === 'space') {
        /* loop */
    }
    return prev.splice(i, prev.length);
}
function fixFlowSeqItems(fc) {
    if (fc.start.type === 'flow-seq-start') {
        for (const it of fc.items) {
            if (it.sep &&
                !it.value &&
                !includesToken(it.start, 'explicit-key-ind') &&
                !includesToken(it.sep, 'map-value-ind')) {
                if (it.key)
                    it.value = it.key;
                delete it.key;
                if (isFlowToken(it.value)) {
                    if (it.value.end)
                        Array.prototype.push.apply(it.value.end, it.sep);
                    else
                        it.value.end = it.sep;
                }
                else
                    Array.prototype.push.apply(it.start, it.sep);
                delete it.sep;
            }
        }
    }
}
/**
 * A YAML concrete syntax tree (CST) parser
 *
 * ```ts
 * const src: string = ...
 * for (const token of new Parser().parse(src)) {
 *   // token: Token
 * }
 * ```
 *
 * To use the parser with a user-provided lexer:
 *
 * ```ts
 * function* parse(source: string, lexer: Lexer) {
 *   const parser = new Parser()
 *   for (const lexeme of lexer.lex(source))
 *     yield* parser.next(lexeme)
 *   yield* parser.end()
 * }
 *
 * const src: string = ...
 * const lexer = new Lexer()
 * for (const token of parse(src, lexer)) {
 *   // token: Token
 * }
 * ```
 */
class Parser {
    /**
     * @param onNewLine - If defined, called separately with the start position of
     *   each new line (in `parse()`, including the start of input).
     */
    constructor(onNewLine) {
        /** If true, space and sequence indicators count as indentation */
        this.atNewLine = true;
        /** If true, next token is a scalar value */
        this.atScalar = false;
        /** Current indentation level */
        this.indent = 0;
        /** Current offset since the start of parsing */
        this.offset = 0;
        /** On the same line with a block map key */
        this.onKeyLine = false;
        /** Top indicates the node that's currently being built */
        this.stack = [];
        /** The source of the current token, set in parse() */
        this.source = '';
        /** The type of the current token, set in parse() */
        this.type = '';
        // Must be defined after `next()`
        this.lexer = new Lexer();
        this.onNewLine = onNewLine;
    }
    /**
     * Parse `source` as a YAML stream.
     * If `incomplete`, a part of the last line may be left as a buffer for the next call.
     *
     * Errors are not thrown, but yielded as `{ type: 'error', message }` tokens.
     *
     * @returns A generator of tokens representing each directive, document, and other structure.
     */
    *parse(source, incomplete = false) {
        if (this.onNewLine && this.offset === 0)
            this.onNewLine(0);
        for (const lexeme of this.lexer.lex(source, incomplete))
            yield* this.next(lexeme);
        if (!incomplete)
            yield* this.end();
    }
    /**
     * Advance the parser by the `source` of one lexical token.
     */
    *next(source) {
        this.source = source;
        if (this.atScalar) {
            this.atScalar = false;
            yield* this.step();
            this.offset += source.length;
            return;
        }
        const type = tokenType(source);
        if (!type) {
            const message = `Not a YAML token: ${source}`;
            yield* this.pop({ type: 'error', offset: this.offset, message, source });
            this.offset += source.length;
        }
        else if (type === 'scalar') {
            this.atNewLine = false;
            this.atScalar = true;
            this.type = 'scalar';
        }
        else {
            this.type = type;
            yield* this.step();
            switch (type) {
                case 'newline':
                    this.atNewLine = true;
                    this.indent = 0;
                    if (this.onNewLine)
                        this.onNewLine(this.offset + source.length);
                    break;
                case 'space':
                    if (this.atNewLine && source[0] === ' ')
                        this.indent += source.length;
                    break;
                case 'explicit-key-ind':
                case 'map-value-ind':
                case 'seq-item-ind':
                    if (this.atNewLine)
                        this.indent += source.length;
                    break;
                case 'doc-mode':
                case 'flow-error-end':
                    return;
                default:
                    this.atNewLine = false;
            }
            this.offset += source.length;
        }
    }
    /** Call at end of input to push out any remaining constructions */
    *end() {
        while (this.stack.length > 0)
            yield* this.pop();
    }
    get sourceToken() {
        const st = {
            type: this.type,
            offset: this.offset,
            indent: this.indent,
            source: this.source
        };
        return st;
    }
    *step() {
        const top = this.peek(1);
        if (this.type === 'doc-end' && (!top || top.type !== 'doc-end')) {
            while (this.stack.length > 0)
                yield* this.pop();
            this.stack.push({
                type: 'doc-end',
                offset: this.offset,
                source: this.source
            });
            return;
        }
        if (!top)
            return yield* this.stream();
        switch (top.type) {
            case 'document':
                return yield* this.document(top);
            case 'alias':
            case 'scalar':
            case 'single-quoted-scalar':
            case 'double-quoted-scalar':
                return yield* this.scalar(top);
            case 'block-scalar':
                return yield* this.blockScalar(top);
            case 'block-map':
                return yield* this.blockMap(top);
            case 'block-seq':
                return yield* this.blockSequence(top);
            case 'flow-collection':
                return yield* this.flowCollection(top);
            case 'doc-end':
                return yield* this.documentEnd(top);
        }
        /* istanbul ignore next should not happen */
        yield* this.pop();
    }
    peek(n) {
        return this.stack[this.stack.length - n];
    }
    *pop(error) {
        const token = error ?? this.stack.pop();
        /* istanbul ignore if should not happen */
        if (!token) {
            const message = 'Tried to pop an empty stack';
            yield { type: 'error', offset: this.offset, source: '', message };
        }
        else if (this.stack.length === 0) {
            yield token;
        }
        else {
            const top = this.peek(1);
            if (token.type === 'block-scalar') {
                // Block scalars use their parent rather than header indent
                token.indent = 'indent' in top ? top.indent : 0;
            }
            else if (token.type === 'flow-collection' && top.type === 'document') {
                // Ignore all indent for top-level flow collections
                token.indent = 0;
            }
            if (token.type === 'flow-collection')
                fixFlowSeqItems(token);
            switch (top.type) {
                case 'document':
                    top.value = token;
                    break;
                case 'block-scalar':
                    top.props.push(token); // error
                    break;
                case 'block-map': {
                    const it = top.items[top.items.length - 1];
                    if (it.value) {
                        top.items.push({ start: [], key: token, sep: [] });
                        this.onKeyLine = true;
                        return;
                    }
                    else if (it.sep) {
                        it.value = token;
                    }
                    else {
                        Object.assign(it, { key: token, sep: [] });
                        this.onKeyLine = !includesToken(it.start, 'explicit-key-ind');
                        return;
                    }
                    break;
                }
                case 'block-seq': {
                    const it = top.items[top.items.length - 1];
                    if (it.value)
                        top.items.push({ start: [], value: token });
                    else
                        it.value = token;
                    break;
                }
                case 'flow-collection': {
                    const it = top.items[top.items.length - 1];
                    if (!it || it.value)
                        top.items.push({ start: [], key: token, sep: [] });
                    else if (it.sep)
                        it.value = token;
                    else
                        Object.assign(it, { key: token, sep: [] });
                    return;
                }
                /* istanbul ignore next should not happen */
                default:
                    yield* this.pop();
                    yield* this.pop(token);
            }
            if ((top.type === 'document' ||
                top.type === 'block-map' ||
                top.type === 'block-seq') &&
                (token.type === 'block-map' || token.type === 'block-seq')) {
                const last = token.items[token.items.length - 1];
                if (last &&
                    !last.sep &&
                    !last.value &&
                    last.start.length > 0 &&
                    findNonEmptyIndex(last.start) === -1 &&
                    (token.indent === 0 ||
                        last.start.every(st => st.type !== 'comment' || st.indent < token.indent))) {
                    if (top.type === 'document')
                        top.end = last.start;
                    else
                        top.items.push({ start: last.start });
                    token.items.splice(-1, 1);
                }
            }
        }
    }
    *stream() {
        switch (this.type) {
            case 'directive-line':
                yield { type: 'directive', offset: this.offset, source: this.source };
                return;
            case 'byte-order-mark':
            case 'space':
            case 'comment':
            case 'newline':
                yield this.sourceToken;
                return;
            case 'doc-mode':
            case 'doc-start': {
                const doc = {
                    type: 'document',
                    offset: this.offset,
                    start: []
                };
                if (this.type === 'doc-start')
                    doc.start.push(this.sourceToken);
                this.stack.push(doc);
                return;
            }
        }
        yield {
            type: 'error',
            offset: this.offset,
            message: `Unexpected ${this.type} token in YAML stream`,
            source: this.source
        };
    }
    *document(doc) {
        if (doc.value)
            return yield* this.lineEnd(doc);
        switch (this.type) {
            case 'doc-start': {
                if (findNonEmptyIndex(doc.start) !== -1) {
                    yield* this.pop();
                    yield* this.step();
                }
                else
                    doc.start.push(this.sourceToken);
                return;
            }
            case 'anchor':
            case 'tag':
            case 'space':
            case 'comment':
            case 'newline':
                doc.start.push(this.sourceToken);
                return;
        }
        const bv = this.startBlockValue(doc);
        if (bv)
            this.stack.push(bv);
        else {
            yield {
                type: 'error',
                offset: this.offset,
                message: `Unexpected ${this.type} token in YAML document`,
                source: this.source
            };
        }
    }
    *scalar(scalar) {
        if (this.type === 'map-value-ind') {
            const prev = getPrevProps(this.peek(2));
            const start = getFirstKeyStartProps(prev);
            let sep;
            if (scalar.end) {
                sep = scalar.end;
                sep.push(this.sourceToken);
                delete scalar.end;
            }
            else
                sep = [this.sourceToken];
            const map = {
                type: 'block-map',
                offset: scalar.offset,
                indent: scalar.indent,
                items: [{ start, key: scalar, sep }]
            };
            this.onKeyLine = true;
            this.stack[this.stack.length - 1] = map;
        }
        else
            yield* this.lineEnd(scalar);
    }
    *blockScalar(scalar) {
        switch (this.type) {
            case 'space':
            case 'comment':
            case 'newline':
                scalar.props.push(this.sourceToken);
                return;
            case 'scalar':
                scalar.source = this.source;
                // block-scalar source includes trailing newline
                this.atNewLine = true;
                this.indent = 0;
                if (this.onNewLine) {
                    let nl = this.source.indexOf('\n') + 1;
                    while (nl !== 0) {
                        this.onNewLine(this.offset + nl);
                        nl = this.source.indexOf('\n', nl) + 1;
                    }
                }
                yield* this.pop();
                break;
            /* istanbul ignore next should not happen */
            default:
                yield* this.pop();
                yield* this.step();
        }
    }
    *blockMap(map) {
        const it = map.items[map.items.length - 1];
        // it.sep is true-ish if pair already has key or : separator
        switch (this.type) {
            case 'newline':
                this.onKeyLine = false;
                if (it.value) {
                    const end = 'end' in it.value ? it.value.end : undefined;
                    const last = Array.isArray(end) ? end[end.length - 1] : undefined;
                    if (last?.type === 'comment')
                        end?.push(this.sourceToken);
                    else
                        map.items.push({ start: [this.sourceToken] });
                }
                else if (it.sep) {
                    it.sep.push(this.sourceToken);
                }
                else {
                    it.start.push(this.sourceToken);
                }
                return;
            case 'space':
            case 'comment':
                if (it.value) {
                    map.items.push({ start: [this.sourceToken] });
                }
                else if (it.sep) {
                    it.sep.push(this.sourceToken);
                }
                else {
                    if (this.atIndentedComment(it.start, map.indent)) {
                        const prev = map.items[map.items.length - 2];
                        const end = prev?.value?.end;
                        if (Array.isArray(end)) {
                            Array.prototype.push.apply(end, it.start);
                            end.push(this.sourceToken);
                            map.items.pop();
                            return;
                        }
                    }
                    it.start.push(this.sourceToken);
                }
                return;
        }
        if (this.indent >= map.indent) {
            const atNextItem = !this.onKeyLine && this.indent === map.indent && it.sep;
            // For empty nodes, assign newline-separated not indented empty tokens to following node
            let start = [];
            if (atNextItem && it.sep && !it.value) {
                const nl = [];
                for (let i = 0; i < it.sep.length; ++i) {
                    const st = it.sep[i];
                    switch (st.type) {
                        case 'newline':
                            nl.push(i);
                            break;
                        case 'space':
                            break;
                        case 'comment':
                            if (st.indent > map.indent)
                                nl.length = 0;
                            break;
                        default:
                            nl.length = 0;
                    }
                }
                if (nl.length >= 2)
                    start = it.sep.splice(nl[1]);
            }
            switch (this.type) {
                case 'anchor':
                case 'tag':
                    if (atNextItem || it.value) {
                        start.push(this.sourceToken);
                        map.items.push({ start });
                        this.onKeyLine = true;
                    }
                    else if (it.sep) {
                        it.sep.push(this.sourceToken);
                    }
                    else {
                        it.start.push(this.sourceToken);
                    }
                    return;
                case 'explicit-key-ind':
                    if (!it.sep && !includesToken(it.start, 'explicit-key-ind')) {
                        it.start.push(this.sourceToken);
                    }
                    else if (atNextItem || it.value) {
                        start.push(this.sourceToken);
                        map.items.push({ start });
                    }
                    else {
                        this.stack.push({
                            type: 'block-map',
                            offset: this.offset,
                            indent: this.indent,
                            items: [{ start: [this.sourceToken] }]
                        });
                    }
                    this.onKeyLine = true;
                    return;
                case 'map-value-ind':
                    if (includesToken(it.start, 'explicit-key-ind')) {
                        if (!it.sep) {
                            if (includesToken(it.start, 'newline')) {
                                Object.assign(it, { key: null, sep: [this.sourceToken] });
                            }
                            else {
                                const start = getFirstKeyStartProps(it.start);
                                this.stack.push({
                                    type: 'block-map',
                                    offset: this.offset,
                                    indent: this.indent,
                                    items: [{ start, key: null, sep: [this.sourceToken] }]
                                });
                            }
                        }
                        else if (it.value) {
                            map.items.push({ start: [], key: null, sep: [this.sourceToken] });
                        }
                        else if (includesToken(it.sep, 'map-value-ind')) {
                            this.stack.push({
                                type: 'block-map',
                                offset: this.offset,
                                indent: this.indent,
                                items: [{ start, key: null, sep: [this.sourceToken] }]
                            });
                        }
                        else if (isFlowToken(it.key) &&
                            !includesToken(it.sep, 'newline')) {
                            const start = getFirstKeyStartProps(it.start);
                            const key = it.key;
                            const sep = it.sep;
                            sep.push(this.sourceToken);
                            // @ts-expect-error type guard is wrong here
                            delete it.key, delete it.sep;
                            this.stack.push({
                                type: 'block-map',
                                offset: this.offset,
                                indent: this.indent,
                                items: [{ start, key, sep }]
                            });
                        }
                        else if (start.length > 0) {
                            // Not actually at next item
                            it.sep = it.sep.concat(start, this.sourceToken);
                        }
                        else {
                            it.sep.push(this.sourceToken);
                        }
                    }
                    else {
                        if (!it.sep) {
                            Object.assign(it, { key: null, sep: [this.sourceToken] });
                        }
                        else if (it.value || atNextItem) {
                            map.items.push({ start, key: null, sep: [this.sourceToken] });
                        }
                        else if (includesToken(it.sep, 'map-value-ind')) {
                            this.stack.push({
                                type: 'block-map',
                                offset: this.offset,
                                indent: this.indent,
                                items: [{ start: [], key: null, sep: [this.sourceToken] }]
                            });
                        }
                        else {
                            it.sep.push(this.sourceToken);
                        }
                    }
                    this.onKeyLine = true;
                    return;
                case 'alias':
                case 'scalar':
                case 'single-quoted-scalar':
                case 'double-quoted-scalar': {
                    const fs = this.flowScalar(this.type);
                    if (atNextItem || it.value) {
                        map.items.push({ start, key: fs, sep: [] });
                        this.onKeyLine = true;
                    }
                    else if (it.sep) {
                        this.stack.push(fs);
                    }
                    else {
                        Object.assign(it, { key: fs, sep: [] });
                        this.onKeyLine = true;
                    }
                    return;
                }
                default: {
                    const bv = this.startBlockValue(map);
                    if (bv) {
                        if (atNextItem &&
                            bv.type !== 'block-seq' &&
                            includesToken(it.start, 'explicit-key-ind')) {
                            map.items.push({ start });
                        }
                        this.stack.push(bv);
                        return;
                    }
                }
            }
        }
        yield* this.pop();
        yield* this.step();
    }
    *blockSequence(seq) {
        const it = seq.items[seq.items.length - 1];
        switch (this.type) {
            case 'newline':
                if (it.value) {
                    const end = 'end' in it.value ? it.value.end : undefined;
                    const last = Array.isArray(end) ? end[end.length - 1] : undefined;
                    if (last?.type === 'comment')
                        end?.push(this.sourceToken);
                    else
                        seq.items.push({ start: [this.sourceToken] });
                }
                else
                    it.start.push(this.sourceToken);
                return;
            case 'space':
            case 'comment':
                if (it.value)
                    seq.items.push({ start: [this.sourceToken] });
                else {
                    if (this.atIndentedComment(it.start, seq.indent)) {
                        const prev = seq.items[seq.items.length - 2];
                        const end = prev?.value?.end;
                        if (Array.isArray(end)) {
                            Array.prototype.push.apply(end, it.start);
                            end.push(this.sourceToken);
                            seq.items.pop();
                            return;
                        }
                    }
                    it.start.push(this.sourceToken);
                }
                return;
            case 'anchor':
            case 'tag':
                if (it.value || this.indent <= seq.indent)
                    break;
                it.start.push(this.sourceToken);
                return;
            case 'seq-item-ind':
                if (this.indent !== seq.indent)
                    break;
                if (it.value || includesToken(it.start, 'seq-item-ind'))
                    seq.items.push({ start: [this.sourceToken] });
                else
                    it.start.push(this.sourceToken);
                return;
        }
        if (this.indent > seq.indent) {
            const bv = this.startBlockValue(seq);
            if (bv) {
                this.stack.push(bv);
                return;
            }
        }
        yield* this.pop();
        yield* this.step();
    }
    *flowCollection(fc) {
        const it = fc.items[fc.items.length - 1];
        if (this.type === 'flow-error-end') {
            let top;
            do {
                yield* this.pop();
                top = this.peek(1);
            } while (top && top.type === 'flow-collection');
        }
        else if (fc.end.length === 0) {
            switch (this.type) {
                case 'comma':
                case 'explicit-key-ind':
                    if (!it || it.sep)
                        fc.items.push({ start: [this.sourceToken] });
                    else
                        it.start.push(this.sourceToken);
                    return;
                case 'map-value-ind':
                    if (!it || it.value)
                        fc.items.push({ start: [], key: null, sep: [this.sourceToken] });
                    else if (it.sep)
                        it.sep.push(this.sourceToken);
                    else
                        Object.assign(it, { key: null, sep: [this.sourceToken] });
                    return;
                case 'space':
                case 'comment':
                case 'newline':
                case 'anchor':
                case 'tag':
                    if (!it || it.value)
                        fc.items.push({ start: [this.sourceToken] });
                    else if (it.sep)
                        it.sep.push(this.sourceToken);
                    else
                        it.start.push(this.sourceToken);
                    return;
                case 'alias':
                case 'scalar':
                case 'single-quoted-scalar':
                case 'double-quoted-scalar': {
                    const fs = this.flowScalar(this.type);
                    if (!it || it.value)
                        fc.items.push({ start: [], key: fs, sep: [] });
                    else if (it.sep)
                        this.stack.push(fs);
                    else
                        Object.assign(it, { key: fs, sep: [] });
                    return;
                }
                case 'flow-map-end':
                case 'flow-seq-end':
                    fc.end.push(this.sourceToken);
                    return;
            }
            const bv = this.startBlockValue(fc);
            /* istanbul ignore else should not happen */
            if (bv)
                this.stack.push(bv);
            else {
                yield* this.pop();
                yield* this.step();
            }
        }
        else {
            const parent = this.peek(2);
            if (parent.type === 'block-map' &&
                ((this.type === 'map-value-ind' && parent.indent === fc.indent) ||
                    (this.type === 'newline' &&
                        !parent.items[parent.items.length - 1].sep))) {
                yield* this.pop();
                yield* this.step();
            }
            else if (this.type === 'map-value-ind' &&
                parent.type !== 'flow-collection') {
                const prev = getPrevProps(parent);
                const start = getFirstKeyStartProps(prev);
                fixFlowSeqItems(fc);
                const sep = fc.end.splice(1, fc.end.length);
                sep.push(this.sourceToken);
                const map = {
                    type: 'block-map',
                    offset: fc.offset,
                    indent: fc.indent,
                    items: [{ start, key: fc, sep }]
                };
                this.onKeyLine = true;
                this.stack[this.stack.length - 1] = map;
            }
            else {
                yield* this.lineEnd(fc);
            }
        }
    }
    flowScalar(type) {
        if (this.onNewLine) {
            let nl = this.source.indexOf('\n') + 1;
            while (nl !== 0) {
                this.onNewLine(this.offset + nl);
                nl = this.source.indexOf('\n', nl) + 1;
            }
        }
        return {
            type,
            offset: this.offset,
            indent: this.indent,
            source: this.source
        };
    }
    startBlockValue(parent) {
        switch (this.type) {
            case 'alias':
            case 'scalar':
            case 'single-quoted-scalar':
            case 'double-quoted-scalar':
                return this.flowScalar(this.type);
            case 'block-scalar-header':
                return {
                    type: 'block-scalar',
                    offset: this.offset,
                    indent: this.indent,
                    props: [this.sourceToken],
                    source: ''
                };
            case 'flow-map-start':
            case 'flow-seq-start':
                return {
                    type: 'flow-collection',
                    offset: this.offset,
                    indent: this.indent,
                    start: this.sourceToken,
                    items: [],
                    end: []
                };
            case 'seq-item-ind':
                return {
                    type: 'block-seq',
                    offset: this.offset,
                    indent: this.indent,
                    items: [{ start: [this.sourceToken] }]
                };
            case 'explicit-key-ind': {
                this.onKeyLine = true;
                const prev = getPrevProps(parent);
                const start = getFirstKeyStartProps(prev);
                start.push(this.sourceToken);
                return {
                    type: 'block-map',
                    offset: this.offset,
                    indent: this.indent,
                    items: [{ start }]
                };
            }
            case 'map-value-ind': {
                this.onKeyLine = true;
                const prev = getPrevProps(parent);
                const start = getFirstKeyStartProps(prev);
                return {
                    type: 'block-map',
                    offset: this.offset,
                    indent: this.indent,
                    items: [{ start, key: null, sep: [this.sourceToken] }]
                };
            }
        }
        return null;
    }
    atIndentedComment(start, indent) {
        if (this.type !== 'comment')
            return false;
        if (this.indent <= indent)
            return false;
        return start.every(st => st.type === 'newline' || st.type === 'space');
    }
    *documentEnd(docEnd) {
        if (this.type !== 'doc-mode') {
            if (docEnd.end)
                docEnd.end.push(this.sourceToken);
            else
                docEnd.end = [this.sourceToken];
            if (this.type === 'newline')
                yield* this.pop();
        }
    }
    *lineEnd(token) {
        switch (this.type) {
            case 'comma':
            case 'doc-start':
            case 'doc-end':
            case 'flow-seq-end':
            case 'flow-map-end':
            case 'map-value-ind':
                yield* this.pop();
                yield* this.step();
                break;
            case 'newline':
                this.onKeyLine = false;
            // fallthrough
            case 'space':
            case 'comment':
            default:
                // all other values are errors
                if (token.end)
                    token.end.push(this.sourceToken);
                else
                    token.end = [this.sourceToken];
                if (this.type === 'newline')
                    yield* this.pop();
        }
    }
}

function parseOptions(options) {
    const prettyErrors = options.prettyErrors !== false;
    const lineCounter = options.lineCounter || (prettyErrors && new LineCounter()) || null;
    return { lineCounter, prettyErrors };
}
/** Parse an input string into a single YAML.Document */
function parseDocument(source, options = {}) {
    const { lineCounter, prettyErrors } = parseOptions(options);
    const parser = new Parser(lineCounter?.addNewLine);
    const composer = new Composer(options);
    // `doc` is always set by compose.end(true) at the very latest
    let doc = null;
    for (const _doc of composer.compose(parser.parse(source), true, source.length)) {
        if (!doc)
            doc = _doc;
        else if (doc.options.logLevel !== 'silent') {
            doc.errors.push(new YAMLParseError(_doc.range.slice(0, 2), 'MULTIPLE_DOCS', 'Source contains multiple documents; please use YAML.parseAllDocuments()'));
            break;
        }
    }
    if (prettyErrors && lineCounter) {
        doc.errors.forEach(prettifyError(source, lineCounter));
        doc.warnings.forEach(prettifyError(source, lineCounter));
    }
    return doc;
}

function getLocation(location) {
    if (location != null && !isLocation(location)) {
        return location._location;
    }
    else if (isLocation(location)) {
        return location;
    }
    else {
        return undefined;
    }
}
function isLocation(location) {
    return (location != null &&
        typeof location.start == 'number' &&
        typeof location.end == 'number');
}
class SqlRuleError extends Error {
    constructor(message, sql, location) {
        super(message);
        this.sql = sql;
        this.type = 'fatal';
        this.location = getLocation(location) ?? { start: 0, end: sql.length };
    }
}
class YamlError extends Error {
    constructor(source, location) {
        super(source.message);
        this.source = source;
        this.type = 'fatal';
        if (location == null && source instanceof YAMLError) {
            location = {
                start: source.pos[0],
                end: source.pos[1]
            };
        }
        else if (location == null) {
            location = {
                start: 0,
                end: 10
            };
        }
        if (source instanceof YamlError || source instanceof SqlRuleError) {
            this.type = source.type;
        }
        this.location = location;
    }
}
class SyncRulesErrors extends Error {
    static constructMessage(errors) {
        return errors.map((e) => e.message).join(', ');
    }
    constructor(errors) {
        super(SyncRulesErrors.constructMessage(errors));
        this.errors = errors;
    }
}

class IdSequence {
    constructor() {
        this.count = 0;
    }
    nextId() {
        return `${++this.count}`;
    }
}

const TYPE_NONE = 0;
const TYPE_BLOB = 1;
const TYPE_TEXT = 2;
const TYPE_INTEGER = 4;
const TYPE_REAL = 8;
class ExpressionType {
    static of(typeFlags) {
        // TODO: cache?
        return new ExpressionType(typeFlags);
    }
    static fromTypeText(type) {
        if (type == 'null') {
            return ExpressionType.NONE;
        }
        else if (type == 'blob') {
            return ExpressionType.BLOB;
        }
        else if (type == 'text') {
            return ExpressionType.TEXT;
        }
        else if (type == 'integer') {
            return ExpressionType.INTEGER;
        }
        else if (type == 'real') {
            return ExpressionType.REAL;
        }
        else if (type == 'numeric') {
            return ExpressionType.NUMERIC;
        }
        else {
            return ExpressionType.NONE;
        }
    }
    constructor(typeFlags) {
        this.typeFlags = typeFlags;
    }
    or(other) {
        return ExpressionType.of(this.typeFlags | other.typeFlags);
    }
    and(other) {
        return ExpressionType.of(this.typeFlags & other.typeFlags);
    }
    isNumericOnly() {
        return this.typeFlags != TYPE_NONE && (this.typeFlags & (TYPE_INTEGER | TYPE_REAL)) == this.typeFlags;
    }
    isNone() {
        return this.typeFlags == TYPE_NONE;
    }
}
/**
 * Always null.
 */
ExpressionType.NONE = new ExpressionType(0);
/**
 * Any type.
 */
ExpressionType.ANY = new ExpressionType(TYPE_BLOB | TYPE_TEXT | TYPE_INTEGER | TYPE_REAL);
ExpressionType.TEXT = new ExpressionType(TYPE_TEXT);
ExpressionType.INTEGER = new ExpressionType(TYPE_INTEGER);
ExpressionType.REAL = new ExpressionType(TYPE_REAL);
ExpressionType.BLOB = new ExpressionType(TYPE_BLOB);
ExpressionType.ANY_JSON = new ExpressionType(TYPE_TEXT | TYPE_INTEGER | TYPE_REAL);
ExpressionType.NUMERIC = new ExpressionType(TYPE_INTEGER | TYPE_REAL);

/**
 * Test whether a string contains an integer number
 */
function isInteger(value) {
  return INTEGER_REGEX.test(value);
}
var INTEGER_REGEX = /^-?[0-9]+$/;

/**
 * Test whether a string contains a number
 * http://stackoverflow.com/questions/13340717/json-numbers-regular-expression
 */
function isNumber(value) {
  return NUMBER_REGEX.test(value);
}
var NUMBER_REGEX = /^-?(?:0|[1-9]\d*)(?:\.\d+)?(?:[eE][+-]?\d+)?$/;

/**
 * Test whether a string can be safely represented with a number
 * without information loss.
 *
 * When approx is true, floating point numbers that lose a few digits but
 * are still approximately equal in value are considered safe too.
 * Integer numbers must still be exactly equal.
 */
function isSafeNumber(value, config) {
  var num = parseFloat(value);
  var str = String(num);
  var v = extractSignificantDigits(value);
  var s = extractSignificantDigits(str);
  if (v === s) {
    return true;
  }
  if ((config === null || config === void 0 ? void 0 : config.approx) === true) {
    // A value is approximately equal when:
    // 1. it is a floating point number, not an integer
    // 2. it has at least 14 digits
    // 3. the first 14 digits are equal
    var requiredDigits = 14;
    if (!isInteger(value) && s.length >= requiredDigits && v.startsWith(s.substring(0, requiredDigits))) {
      return true;
    }
  }
  return false;
}
var UnsafeNumberReason = /*#__PURE__*/function (UnsafeNumberReason) {
  UnsafeNumberReason["underflow"] = "underflow";
  UnsafeNumberReason["overflow"] = "overflow";
  UnsafeNumberReason["truncate_integer"] = "truncate_integer";
  UnsafeNumberReason["truncate_float"] = "truncate_float";
  return UnsafeNumberReason;
}({});

/**
 * When the provided value is an unsafe number, describe what the reason is:
 * overflow, underflow, truncate_integer, or truncate_float.
 * Returns undefined when the value is safe.
 */
function getUnsafeNumberReason(value) {
  if (isSafeNumber(value, {
    approx: false
  })) {
    return undefined;
  }
  if (isInteger(value)) {
    return UnsafeNumberReason.truncate_integer;
  }
  var num = parseFloat(value);
  if (!isFinite(num)) {
    return UnsafeNumberReason.overflow;
  }
  if (num === 0) {
    return UnsafeNumberReason.underflow;
  }
  return UnsafeNumberReason.truncate_float;
}

/**
 * Get the significant digits of a number.
 *
 * For example:
 *   '2.34' returns '234'
 *   '-77' returns '77'
 *   '0.003400' returns '34'
 *   '120.5e+30' returns '1205'
 **/
function extractSignificantDigits(value) {
  return value
  // from "-0.250e+30" to "-0.250"
  .replace(EXPONENTIAL_PART_REGEX, '')

  // from "-0.250" to "-0250"
  .replace(DOT_REGEX, '')

  // from "-0250" to "-025"
  .replace(TRAILING_ZEROS_REGEX, '')

  // from "-025" to "25"
  .replace(LEADING_MINUS_AND_ZEROS_REGEX, '');
}
var EXPONENTIAL_PART_REGEX = /[eE][+-]?\d+$/;
var LEADING_MINUS_AND_ZEROS_REGEX = /^-?(0*)?/;
var DOT_REGEX = /\./;
var TRAILING_ZEROS_REGEX = /0+$/;

function _typeof$2(obj) { "@babel/helpers - typeof"; return _typeof$2 = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof$2(obj); }
function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }
function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor); } }
function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); Object.defineProperty(Constructor, "prototype", { writable: false }); return Constructor; }
function _defineProperty(obj, key, value) { key = _toPropertyKey(key); if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }
function _toPropertyKey(arg) { var key = _toPrimitive(arg, "string"); return _typeof$2(key) === "symbol" ? key : String(key); }
function _toPrimitive(input, hint) { if (_typeof$2(input) !== "object" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || "default"); if (_typeof$2(res) !== "object") return res; throw new TypeError("@@toPrimitive must return a primitive value."); } return (hint === "string" ? String : Number)(input); }

/**
 * A lossless number. Stores its numeric value as string
 */
var LosslessNumber = /*#__PURE__*/function () {
  function LosslessNumber(value) {
    _classCallCheck(this, LosslessNumber);
    // numeric value as string
    // type information
    _defineProperty(this, "isLosslessNumber", true);
    if (!isNumber(value)) {
      throw new Error('Invalid number (value: "' + value + '")');
    }
    this.value = value;
  }

  /**
   * Get the value of the LosslessNumber as number or bigint.
   *
   * - a number is returned for safe numbers and decimal values that only lose some insignificant digits
   * - a bigint is returned for big integer numbers
   * - an Error is thrown for values that will overflow or underflow
   *
   * Note that you can implement your own strategy for conversion by just getting the value as string
   * via .toString(), and using util functions like isInteger, isSafeNumber, getUnsafeNumberReason,
   * and toSafeNumberOrThrow to convert it to a numeric value.
   */
  _createClass(LosslessNumber, [{
    key: "valueOf",
    value: function valueOf() {
      var unsafeReason = getUnsafeNumberReason(this.value);

      // safe or truncate_float
      if (unsafeReason === undefined || unsafeReason === UnsafeNumberReason.truncate_float) {
        return parseFloat(this.value);
      }

      // truncate_integer
      if (isInteger(this.value)) {
        return BigInt(this.value);
      }

      // overflow or underflow
      throw new Error('Cannot safely convert to number: ' + "the value '".concat(this.value, "' would ").concat(unsafeReason, " and become ").concat(parseFloat(this.value)));
    }

    /**
     * Get the value of the LosslessNumber as string.
     */
  }, {
    key: "toString",
    value: function toString() {
      return this.value;
    }

    // Note: we do NOT implement a .toJSON() method, and you should not implement
    // or use that, it cannot safely turn the numeric value in the string into
    // stringified JSON since it has to be parsed into a number first.
  }]);
  return LosslessNumber;
}();

/**
 * Test whether a value is a LosslessNumber
 */
function isLosslessNumber(value) {
  // eslint-disable-next-line @typescript-eslint/ban-ts-comment
  // @ts-ignore
  return value && _typeof$2(value) === 'object' && value.isLosslessNumber === true || false;
}

function parseLosslessNumber(value) {
  return new LosslessNumber(value);
}

function _typeof$1(obj) { "@babel/helpers - typeof"; return _typeof$1 = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof$1(obj); }
/**
 * Revive a json object.
 * Applies the reviver function recursively on all values in the JSON object.
 * @param json   A JSON Object, Array, or value
 * @param reviver
 *              A reviver function invoked with arguments `key` and `value`,
 *              which must return a replacement value. The function context
 *              (`this`) is the Object or Array that contains the currently
 *              handled value.
 */
function revive(json, reviver) {
  return reviveValue({
    '': json
  }, '', json, reviver);
}

/**
 * Revive a value
 */
function reviveValue(context, key, value, reviver) {
  if (Array.isArray(value)) {
    return reviver.call(context, key, reviveArray(value, reviver));
  } else if (value && _typeof$1(value) === 'object' && !isLosslessNumber(value)) {
    // note the special case for LosslessNumber,
    // we don't want to iterate over the internals of a LosslessNumber
    return reviver.call(context, key, reviveObject(value, reviver));
  } else {
    return reviver.call(context, key, value);
  }
}

/**
 * Revive the properties of an object
 */
function reviveObject(object, reviver) {
  Object.keys(object).forEach(function (key) {
    var value = reviveValue(object, key, object[key], reviver);
    if (value !== undefined) {
      object[key] = value;
    } else {
      delete object[key];
    }
  });
  return object;
}

/**
 * Revive the properties of an Array
 */
function reviveArray(array, reviver) {
  for (var i = 0; i < array.length; i++) {
    array[i] = reviveValue(array, i + '', array[i], reviver);
  }
  return array;
}

function _typeof(obj) { "@babel/helpers - typeof"; return _typeof = "function" == typeof Symbol && "symbol" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && "function" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj; }, _typeof(obj); }
function _toConsumableArray(arr) { return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread(); }
function _nonIterableSpread() { throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); }
function _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === "string") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === "Object" && o.constructor) n = o.constructor.name; if (n === "Map" || n === "Set") return Array.from(o); if (n === "Arguments" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }
function _iterableToArray(iter) { if (typeof Symbol !== "undefined" && iter[Symbol.iterator] != null || iter["@@iterator"] != null) return Array.from(iter); }
function _arrayWithoutHoles(arr) { if (Array.isArray(arr)) return _arrayLikeToArray(arr); }
function _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) arr2[i] = arr[i]; return arr2; }
/**
 * The LosslessJSON.parse() method parses a string as JSON, optionally transforming
 * the value produced by parsing.
 *
 * The parser is based on the parser of Tan Li Hou shared in
 * https://lihautan.com/json-parser-with-javascript/
 *
 * @param text
 * The string to parse as JSON. See the JSON object for a description of JSON syntax.
 *
 * @param [reviver]
 * If a function, prescribes how the value originally produced by parsing is
 * transformed, before being returned.
 *
 * @param [parseNumber=parseLosslessNumber]
 * Pass a custom number parser. Input is a string, and the output can be unknown
 * numeric value: number, bigint, LosslessNumber, or a custom BigNumber library.
 *
 * @returns Returns the Object corresponding to the given JSON text.
 *
 * @throws Throws a SyntaxError exception if the string to parse is not valid JSON.
 */
function parse(text, reviver) {
  var parseNumber = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : parseLosslessNumber;
  var i = 0;
  var value = parseValue();
  expectValue(value);
  expectEndOfInput();
  return reviver ? revive(value, reviver) : value;
  function parseObject() {
    if (text.charCodeAt(i) === codeOpeningBrace) {
      i++;
      skipWhitespace();
      var object = {};
      var initial = true;
      while (i < text.length && text.charCodeAt(i) !== codeClosingBrace) {
        if (!initial) {
          eatComma();
          skipWhitespace();
        } else {
          initial = false;
        }
        var start = i;
        var key = parseString();
        if (key === undefined) {
          throwObjectKeyExpected();
        }
        skipWhitespace();
        eatColon();
        var _value = parseValue();
        if (_value === undefined) {
          throwObjectValueExpected();
        }

        // TODO: test deep equal instead of strict equal
        if (Object.prototype.hasOwnProperty.call(object, key) && !isDeepEqual(_value, object[key])) {
          // Note that we could also test `if(key in object) {...}`
          // or `if (object[key] !== 'undefined') {...}`, but that is slower.
          throwDuplicateKey(key, start + 1);
        }
        object[key] = _value;
      }
      if (text.charCodeAt(i) !== codeClosingBrace) {
        throwObjectKeyOrEndExpected();
      }
      i++;
      return object;
    }
  }
  function parseArray() {
    if (text.charCodeAt(i) === codeOpeningBracket) {
      i++;
      skipWhitespace();
      var array = [];
      var initial = true;
      while (i < text.length && text.charCodeAt(i) !== codeClosingBracket) {
        if (!initial) {
          eatComma();
        } else {
          initial = false;
        }
        var _value2 = parseValue();
        expectArrayItem(_value2);
        array.push(_value2);
      }
      if (text.charCodeAt(i) !== codeClosingBracket) {
        throwArrayItemOrEndExpected();
      }
      i++;
      return array;
    }
  }
  function parseValue() {
    var _ref, _ref2, _ref3, _ref4, _ref5, _parseString;
    skipWhitespace();
    var value = (_ref = (_ref2 = (_ref3 = (_ref4 = (_ref5 = (_parseString = parseString()) !== null && _parseString !== void 0 ? _parseString : parseNumeric()) !== null && _ref5 !== void 0 ? _ref5 : parseObject()) !== null && _ref4 !== void 0 ? _ref4 : parseArray()) !== null && _ref3 !== void 0 ? _ref3 : parseKeyword('true', true)) !== null && _ref2 !== void 0 ? _ref2 : parseKeyword('false', false)) !== null && _ref !== void 0 ? _ref : parseKeyword('null', null);
    skipWhitespace();
    return value;
  }
  function parseKeyword(name, value) {
    if (text.slice(i, i + name.length) === name) {
      i += name.length;
      return value;
    }
  }
  function skipWhitespace() {
    while (isWhitespace(text.charCodeAt(i))) {
      i++;
    }
  }
  function parseString() {
    if (text.charCodeAt(i) === codeDoubleQuote) {
      i++;
      var result = '';
      while (i < text.length && text.charCodeAt(i) !== codeDoubleQuote) {
        if (text.charCodeAt(i) === codeBackslash) {
          var char = text[i + 1];
          var escapeChar = escapeCharacters[char];
          if (escapeChar !== undefined) {
            result += escapeChar;
            i++;
          } else if (char === 'u') {
            if (isHex(text.charCodeAt(i + 2)) && isHex(text.charCodeAt(i + 3)) && isHex(text.charCodeAt(i + 4)) && isHex(text.charCodeAt(i + 5))) {
              result += String.fromCharCode(parseInt(text.slice(i + 2, i + 6), 16));
              i += 5;
            } else {
              throwInvalidUnicodeCharacter(i);
            }
          } else {
            throwInvalidEscapeCharacter(i);
          }
        } else {
          if (isValidStringCharacter(text.charCodeAt(i))) {
            result += text[i];
          } else {
            throwInvalidCharacter(text[i]);
          }
        }
        i++;
      }
      expectEndOfString();
      i++;
      return result;
    }
  }
  function parseNumeric() {
    var start = i;
    if (text.charCodeAt(i) === codeMinus) {
      i++;
      expectDigit(start);
    }
    if (text.charCodeAt(i) === codeZero) {
      i++;
    } else if (isNonZeroDigit(text.charCodeAt(i))) {
      i++;
      while (isDigit(text.charCodeAt(i))) {
        i++;
      }
    }
    if (text.charCodeAt(i) === codeDot) {
      i++;
      expectDigit(start);
      while (isDigit(text.charCodeAt(i))) {
        i++;
      }
    }
    if (text.charCodeAt(i) === codeLowercaseE || text.charCodeAt(i) === codeUppercaseE) {
      i++;
      if (text.charCodeAt(i) === codeMinus || text.charCodeAt(i) === codePlus) {
        i++;
      }
      expectDigit(start);
      while (isDigit(text.charCodeAt(i))) {
        i++;
      }
    }
    if (i > start) {
      return parseNumber(text.slice(start, i));
    }
  }
  function eatComma() {
    if (text.charCodeAt(i) !== codeComma) {
      throw new SyntaxError("Comma ',' expected after value ".concat(gotAt()));
    }
    i++;
  }
  function eatColon() {
    if (text.charCodeAt(i) !== codeColon) {
      throw new SyntaxError("Colon ':' expected after property name ".concat(gotAt()));
    }
    i++;
  }
  function expectValue(value) {
    if (value === undefined) {
      throw new SyntaxError("JSON value expected ".concat(gotAt()));
    }
  }
  function expectArrayItem(value) {
    if (value === undefined) {
      throw new SyntaxError("Array item expected ".concat(gotAt()));
    }
  }
  function expectEndOfInput() {
    if (i < text.length) {
      throw new SyntaxError("Expected end of input ".concat(gotAt()));
    }
  }
  function expectDigit(start) {
    if (!isDigit(text.charCodeAt(i))) {
      var numSoFar = text.slice(start, i);
      throw new SyntaxError("Invalid number '".concat(numSoFar, "', expecting a digit ").concat(gotAt()));
    }
  }
  function expectEndOfString() {
    if (text.charCodeAt(i) !== codeDoubleQuote) {
      throw new SyntaxError("End of string '\"' expected ".concat(gotAt()));
    }
  }
  function throwObjectKeyExpected() {
    throw new SyntaxError("Quoted object key expected ".concat(gotAt()));
  }
  function throwDuplicateKey(key, pos) {
    throw new SyntaxError("Duplicate key '".concat(key, "' encountered at position ").concat(pos));
  }
  function throwObjectKeyOrEndExpected() {
    throw new SyntaxError("Quoted object key or end of object '}' expected ".concat(gotAt()));
  }
  function throwArrayItemOrEndExpected() {
    throw new SyntaxError("Array item or end of array ']' expected ".concat(gotAt()));
  }
  function throwInvalidCharacter(char) {
    throw new SyntaxError("Invalid character '".concat(char, "' ").concat(pos()));
  }
  function throwInvalidEscapeCharacter(start) {
    var chars = text.slice(start, start + 2);
    throw new SyntaxError("Invalid escape character '".concat(chars, "' ").concat(pos()));
  }
  function throwObjectValueExpected() {
    throw new SyntaxError("Object value expected after ':' ".concat(pos()));
  }
  function throwInvalidUnicodeCharacter(start) {
    var end = start + 2;
    while (/\w/.test(text[end])) {
      end++;
    }
    var chars = text.slice(start, end);
    throw new SyntaxError("Invalid unicode character '".concat(chars, "' ").concat(pos()));
  }

  // zero based character position
  function pos() {
    return "at position ".concat(i);
  }
  function got() {
    return i < text.length ? "but got '".concat(text[i], "'") : 'but reached end of input';
  }
  function gotAt() {
    return got() + ' ' + pos();
  }
}
function isWhitespace(code) {
  return code === codeSpace || code === codeNewline || code === codeTab || code === codeReturn;
}
function isHex(code) {
  return code >= codeZero && code <= codeNine || code >= codeUppercaseA && code <= codeUppercaseF || code >= codeLowercaseA && code <= codeLowercaseF;
}
function isDigit(code) {
  return code >= codeZero && code <= codeNine;
}
function isNonZeroDigit(code) {
  return code >= codeOne && code <= codeNine;
}
function isValidStringCharacter(code) {
  return code >= 0x20 && code <= 0x10ffff;
}
function isDeepEqual(a, b) {
  if (a === b) {
    return true;
  }
  if (Array.isArray(a) && Array.isArray(b)) {
    return a.length === b.length && a.every(function (item, index) {
      return isDeepEqual(item, b[index]);
    });
  }
  if (isObject(a) && isObject(b)) {
    var keys = _toConsumableArray(new Set([].concat(_toConsumableArray(Object.keys(a)), _toConsumableArray(Object.keys(b)))));
    return keys.every(function (key) {
      return isDeepEqual(a[key], b[key]);
    });
  }
  return false;
}
function isObject(value) {
  return _typeof(value) === 'object' && value !== null;
}

// map with all escape characters
var escapeCharacters = {
  '"': '"',
  '\\': '\\',
  '/': '/',
  b: '\b',
  f: '\f',
  n: '\n',
  r: '\r',
  t: '\t'
  // note that \u is handled separately in parseString()
};

var codeBackslash = 0x5c; // "\"
var codeOpeningBrace = 0x7b; // "{"
var codeClosingBrace = 0x7d; // "}"
var codeOpeningBracket = 0x5b; // "["
var codeClosingBracket = 0x5d; // "]"
var codeSpace = 0x20; // " "
var codeNewline = 0xa; // "\n"
var codeTab = 0x9; // "\t"
var codeReturn = 0xd; // "\r"
var codeDoubleQuote = 0x0022; // "
var codePlus = 0x2b; // "+"
var codeMinus = 0x2d; // "-"
var codeZero = 0x30;
var codeOne = 0x31;
var codeNine = 0x39;
var codeComma = 0x2c; // ","
var codeDot = 0x2e; // "." (dot, period)
var codeColon = 0x3a; // ":"
var codeUppercaseA = 0x41; // "A"
var codeLowercaseA = 0x61; // "a"
var codeUppercaseE = 0x45; // "E"
var codeLowercaseE = 0x65; // "e"
var codeUppercaseF = 0x46; // "F"
var codeLowercaseF = 0x66; // "f"

/**
 * Store a JSON text value. Used to mark the value as JSON-sourced, but only parse if really needed.
 */
class JsonContainer {
    constructor(data) {
        this.data = data;
    }
    parsed() {
        return JSONBig.parse(this.data);
    }
    /**
     *
     * @returns The JSON representation
     */
    toString() {
        return this.data;
    }
    /**
     *
     * @returns The parsed representation
     */
    toJSON() {
        return this.parsed();
    }
}

// Adapted from https://github.com/josdejong/lossless-json/blob/dfb8a1a787ae167fffec068c3b6623179d3bfb95/src/stringify.ts
/**
 * The LosslessJSON.stringify() method converts a JavaScript value to a JSON string,
 * optionally replacing values if a replacer function is specified, or
 * optionally including only the specified properties if a replacer array is specified.
 *
 * @param value
 * The value to convert to a JSON string.
 *
 * @param [replacer]
 * A function that alters the behavior of the stringification process,
 * or an array of String and Number objects that serve as a whitelist for
 * selecting the properties of the value object to be included in the JSON string.
 * If this value is null or not provided, all properties of the object are
 * included in the resulting JSON string.
 *
 * @param [space]
 * A String or Number object that's used to insert white space into the output
 * JSON string for readability purposes. If this is a Number, it indicates the
 * number of space characters to use as white space; this number is capped at 10
 * if it's larger than that. Values less than 1 indicate that no space should be
 * used. If this is a String, the string (or the first 10 characters of the string,
 * if it's longer than that) is used as white space. If this parameter is not
 * provided (or is null), no white space is used.
 *
 * @param [numberStringifiers]
 * An optional list with additional number stringifiers, for example to serialize
 * a BigNumber. The output of the function must be valid stringified JSON.
 * When `undefined` is returned, the property will be deleted from the object.
 * The difference with using a `replacer` is that the output of a `replacer`
 * must be JSON and will be stringified afterwards, whereas the output of the
 * `numberStringifiers` is already stringified JSON.
 *
 * @returns Returns the string representation of the JSON object.
 */
function stringify(value, replacer, space, numberStringifiers) {
    const resolvedSpace = resolveSpace(space);
    const replacedValue = typeof replacer === 'function' ? replacer.call({ '': value }, '', value) : value;
    return stringifyValue(replacedValue, '');
    /**
     * Stringify a value
     */
    function stringifyValue(value, indent) {
        if (Array.isArray(numberStringifiers)) {
            const stringifier = numberStringifiers.find((item) => item.test(value));
            if (stringifier) {
                const str = stringifier.stringify(value);
                if (typeof str !== 'string' || (!isNumber(str) && false)) {
                    // Changed: The number check is disabled, so that we can use this for other types.
                    throw new Error('Invalid JSON number: ' +
                        'output of a number stringifier must be a string containing a JSON number ' +
                        `(output: ${str})`);
                }
                return str;
            }
        }
        // boolean, null, number, string, or date
        if (typeof value === 'boolean' ||
            typeof value === 'number' ||
            typeof value === 'string' ||
            value === null ||
            value instanceof Date ||
            value instanceof Boolean ||
            value instanceof Number ||
            value instanceof String) {
            return JSON.stringify(value);
        }
        // lossless number, the secret ingredient :)
        // eslint-disable-next-line @typescript-eslint/ban-ts-comment
        // @ts-ignore
        if (value && value.isLosslessNumber) {
            return value.toString();
        }
        // BigInt
        if (typeof value === 'bigint') {
            return value.toString();
        }
        // Array
        if (Array.isArray(value)) {
            return stringifyArray(value, indent);
        }
        // Object (test lastly!)
        if (value && typeof value === 'object') {
            return stringifyObject(value, indent);
        }
        return undefined;
    }
    /**
     * Stringify an array
     */
    function stringifyArray(array, indent) {
        if (array.length === 0) {
            return '[]';
        }
        const childIndent = resolvedSpace ? indent + resolvedSpace : undefined;
        let str = resolvedSpace ? '[\n' : '[';
        for (let i = 0; i < array.length; i++) {
            const item = typeof replacer === 'function' ? replacer.call(array, String(i), array[i]) : array[i];
            if (resolvedSpace) {
                str += childIndent;
            }
            if (typeof item !== 'undefined' && typeof item !== 'function') {
                str += stringifyValue(item, childIndent);
            }
            else {
                str += 'null';
            }
            if (i < array.length - 1) {
                str += resolvedSpace ? ',\n' : ',';
            }
        }
        str += resolvedSpace ? '\n' + indent + ']' : ']';
        return str;
    }
    /**
     * Stringify an object
     */
    function stringifyObject(object, indent) {
        if (typeof object.toJSON === 'function') {
            return stringify(object.toJSON(), replacer, space, numberStringifiers);
        }
        const keys = Array.isArray(replacer) ? replacer.map(String) : Object.keys(object);
        if (keys.length === 0) {
            return '{}';
        }
        const childIndent = resolvedSpace ? indent + resolvedSpace : undefined;
        let first = true;
        let str = resolvedSpace ? '{\n' : '{';
        keys.forEach((key) => {
            const value = typeof replacer === 'function' ? replacer.call(object, key, object[key]) : object[key];
            if (includeProperty(key, value)) {
                if (first) {
                    first = false;
                }
                else {
                    str += resolvedSpace ? ',\n' : ',';
                }
                const keyStr = JSON.stringify(key);
                str += resolvedSpace ? childIndent + keyStr + ': ' : keyStr + ':';
                str += stringifyValue(value, childIndent);
            }
        });
        str += resolvedSpace ? '\n' + indent + '}' : '}';
        return str;
    }
    /**
     * Test whether to include a property in a stringified object or not.
     */
    function includeProperty(key, value) {
        return typeof value !== 'undefined' && typeof value !== 'function' && typeof value !== 'symbol';
    }
}
/**
 * Resolve a JSON stringify space:
 * replace a number with a string containing that number of spaces
 */
function resolveSpace(space) {
    if (typeof space === 'number') {
        return ' '.repeat(space);
    }
    if (typeof space === 'string' && space !== '') {
        return space;
    }
    return undefined;
}

const numberParser = (value) => {
    return isInteger(value) ? BigInt(value) : parseFloat(value);
};
const numberStringifier = {
    test: (value) => typeof value == 'number',
    stringify: (value) => {
        const text = value.toString();
        if (isInteger(text)) {
            // Used to preserve the "type".
            return text + '.0';
        }
        else {
            return text;
        }
    }
};
// Avoid a parse + serialize round-trip for JSON data.
const jsonContainerStringifier = {
    test: (value) => value instanceof JsonContainer,
    stringify: (value) => {
        return value.toString();
    }
};
const stringifiers = [numberStringifier, jsonContainerStringifier];
const JSONBig = {
    parse(text, reviver) {
        return parse(text, reviver, numberParser);
    },
    stringify(value, replacer, space) {
        return stringify(value, replacer, space, stringifiers);
    }
};

function isParameterMatchClause(clause) {
    return Array.isArray(clause.inputParameters);
}
function isRowValueClause(clause) {
    return typeof clause.evaluate == 'function';
}
function isStaticValueClause(clause) {
    return isRowValueClause(clause) && typeof clause.value != 'undefined';
}
function isParameterValueClause(clause) {
    // noinspection SuspiciousTypeOfGuard
    return typeof clause.key == 'string';
}
function isClauseError(clause) {
    return clause.error === true;
}
const SQLITE_TRUE = 1n;
const SQLITE_FALSE = 0n;
function sqliteBool(value) {
    if (value == null) {
        return SQLITE_FALSE;
    }
    else if (typeof value == 'boolean' || typeof value == 'number') {
        return value ? SQLITE_TRUE : SQLITE_FALSE;
    }
    else if (typeof value == 'bigint') {
        return value != 0n ? SQLITE_TRUE : SQLITE_FALSE;
    }
    else if (typeof value == 'string') {
        return parseInt(value) ? SQLITE_TRUE : SQLITE_FALSE;
    }
    else {
        return SQLITE_FALSE;
    }
}
function sqliteNot(value) {
    return sqliteBool(!sqliteBool(value));
}
function compileStaticOperator(op, left, right) {
    return {
        evaluate: (tables) => {
            const leftValue = left.evaluate(tables);
            const rightValue = right.evaluate(tables);
            return evaluateOperator(op, leftValue, rightValue);
        },
        getType(schema) {
            const typeLeft = left.getType(schema);
            const typeRight = right.getType(schema);
            return getOperatorReturnType(op, typeLeft, typeRight);
        }
    };
}
function getOperatorFunction(op) {
    return {
        debugName: `operator${op}`,
        call(...args) {
            return evaluateOperator(op, args[0], args[1]);
        },
        getReturnType(args) {
            return getOperatorReturnType(op, args[0], args[1]);
        }
    };
}
function andFilters(a, b) {
    if (isRowValueClause(a) && isRowValueClause(b)) {
        // Optimization
        return {
            evaluate(tables) {
                const aValue = sqliteBool(a.evaluate(tables));
                const bValue = sqliteBool(b.evaluate(tables));
                return sqliteBool(aValue && bValue);
            },
            getType() {
                return ExpressionType.INTEGER;
            }
        };
    }
    const aFilter = toBooleanParameterSetClause(a);
    const bFilter = toBooleanParameterSetClause(b);
    const aParams = aFilter.inputParameters;
    const bParams = bFilter.inputParameters;
    if (aFilter.unbounded && bFilter.unbounded) {
        // This could explode the number of buckets for the row
        throw new Error('Cannot have multiple IN expressions on bucket parameters');
    }
    const combinedMap = new Map([...aParams, ...bParams].map((p) => [p.key, p]));
    return {
        error: aFilter.error || bFilter.error,
        inputParameters: [...combinedMap.values()],
        unbounded: aFilter.unbounded || bFilter.unbounded,
        filterRow: (tables) => {
            const aResult = aFilter.filterRow(tables);
            const bResult = bFilter.filterRow(tables);
            let results = [];
            for (let result1 of aResult) {
                for (let result2 of bResult) {
                    let combined = { ...result1 };
                    for (let key in result2) {
                        if (key in combined && combined[key] != result2[key]) {
                            break;
                        }
                        combined[key] = result2[key];
                    }
                    results.push(combined);
                }
            }
            return results;
        },
        usesAuthenticatedRequestParameters: aFilter.usesAuthenticatedRequestParameters || bFilter.usesAuthenticatedRequestParameters,
        usesUnauthenticatedRequestParameters: aFilter.usesUnauthenticatedRequestParameters || bFilter.usesUnauthenticatedRequestParameters
    };
}
function orFilters(a, b) {
    if (isRowValueClause(a) && isRowValueClause(b)) {
        // Optimization
        return {
            evaluate(tables) {
                const aValue = sqliteBool(a.evaluate(tables));
                const bValue = sqliteBool(b.evaluate(tables));
                return sqliteBool(aValue || bValue);
            },
            getType() {
                return ExpressionType.INTEGER;
            }
        };
    }
    const aFilter = toBooleanParameterSetClause(a);
    const bFilter = toBooleanParameterSetClause(b);
    return orParameterSetClauses(aFilter, bFilter);
}
function orParameterSetClauses(a, b) {
    const aParams = a.inputParameters;
    const bParams = b.inputParameters;
    // This gives the guaranteed set of parameters matched against.
    const combinedMap = new Map([...aParams, ...bParams].map((p) => [p.key, p]));
    if (combinedMap.size != aParams.length || combinedMap.size != bParams.length) {
        throw new Error(`Left and right sides of OR must use the same parameters, or split into separate queries. ${JSON.stringify(aParams)} != ${JSON.stringify(bParams)}`);
    }
    const parameters = [...combinedMap.values()];
    // assets.region_id = bucket.region_id AND bucket.user_id IN assets.user_ids
    // OR bucket.region_id IN assets.region_ids AND bucket.user_id = assets.user_id
    const unbounded = a.unbounded || b.unbounded;
    return {
        error: a.error || b.error,
        inputParameters: parameters,
        unbounded,
        filterRow: (tables) => {
            const aResult = a.filterRow(tables);
            const bResult = b.filterRow(tables);
            let results = [...aResult, ...bResult];
            return results;
        },
        // Pessimistic check
        usesAuthenticatedRequestParameters: a.usesAuthenticatedRequestParameters && b.usesAuthenticatedRequestParameters,
        // Optimistic check
        usesUnauthenticatedRequestParameters: a.usesUnauthenticatedRequestParameters || b.usesUnauthenticatedRequestParameters
    };
}
/**
 * Given any CompiledClause, convert it into a ParameterMatchClause.
 *
 * @param clause
 */
function toBooleanParameterSetClause(clause) {
    if (isParameterMatchClause(clause)) {
        return clause;
    }
    else if (isRowValueClause(clause)) {
        return {
            error: false,
            inputParameters: [],
            unbounded: false,
            filterRow(tables) {
                const value = sqliteBool(clause.evaluate(tables));
                return value ? MATCH_CONST_TRUE : MATCH_CONST_FALSE;
            },
            usesAuthenticatedRequestParameters: false,
            usesUnauthenticatedRequestParameters: false
        };
    }
    else if (isClauseError(clause)) {
        return {
            error: true,
            inputParameters: [],
            unbounded: false,
            filterRow(tables) {
                throw new Error('invalid clause');
            },
            usesAuthenticatedRequestParameters: false,
            usesUnauthenticatedRequestParameters: false
        };
    }
    else {
        // Equivalent to `bucket.param = true`
        const key = clause.key;
        const inputParam = {
            key: key,
            expands: false,
            filteredRowToLookupValue: (filterParameters) => {
                return filterParameters[key];
            },
            parametersToLookupValue: (parameters) => {
                const inner = clause.lookupParameterValue(parameters);
                return sqliteBool(inner);
            }
        };
        return {
            error: false,
            inputParameters: [inputParam],
            unbounded: false,
            filterRow(tables) {
                return [{ [key]: SQLITE_TRUE }];
            },
            usesAuthenticatedRequestParameters: clause.usesAuthenticatedRequestParameters,
            usesUnauthenticatedRequestParameters: clause.usesUnauthenticatedRequestParameters
        };
    }
}
function checkUnsupportedFeatures(sql, q) {
    let errors = [];
    if (q.limit != null) {
        errors.push(new SqlRuleError('LIMIT is not supported', sql, q.limit._location));
    }
    if (q.orderBy != null) {
        errors.push(new SqlRuleError('ORDER BY is not supported', sql, q.orderBy[0]?._location));
    }
    if (q.skip != null) {
        errors.push(new SqlRuleError('SKIP is not supported', sql, q.skip._location));
    }
    if (q.having != null) {
        errors.push(new SqlRuleError('HAVING is not supported', sql, q.having._location));
    }
    if (q.groupBy != null) {
        errors.push(new SqlRuleError('GROUP BY is not supported', sql, q.groupBy[0]?._location));
    }
    if (q.distinct != null) {
        errors.push(new SqlRuleError('DISTINCT is not supported', sql));
    }
    if (q.for != null) {
        errors.push(new SqlRuleError('SELECT FOR is not supported', sql, q.for._location));
    }
    return errors;
}

function isSelectStatement(q) {
    return q.type == 'select';
}
function getBucketId(descriptor_id, bucket_parameters, params) {
    // Important: REAL and INTEGER values matching the same number needs the same representation in the bucket name.
    const paramArray = bucket_parameters.map((name) => params[`bucket.${name}`]);
    return `${descriptor_id}${JSONBucketNameSerialize.stringify(paramArray)}`;
}
/**
 * SqliteRow -> SqliteJsonRow.
 *
 * Use wherever data should be persisted.
 *
 * Basically just removes Uint8Array.
 */
function filterJsonRow(data) {
    let record = {};
    for (let key of Object.keys(data)) {
        const value = data[key];
        if (isJsonValue(value)) {
            record[key] = value;
        }
    }
    return record;
}
/**
 * Convert a parsed JSON scalar value to SqliteValue.
 *
 * Types specifically not supported in output are `boolean` and `undefined`.
 */
function jsonValueToSqlite(value) {
    if (typeof value == 'boolean') {
        return value ? SQLITE_TRUE : SQLITE_FALSE;
    }
    else {
        return value ?? null;
    }
}
function isJsonValue(value) {
    return value == null || typeof value == 'string' || typeof value == 'number' || typeof value == 'bigint';
}
/**
 * Only use this for serializing bucket names. Bucket names should never be parsed except perhaps for debug purposes.
 *
 * Important: REAL and INTEGER values matching the same number needs the same representation in the bucket name.
 */
const JSONBucketNameSerialize = {
    stringify(value, replacer, space) {
        return stringify(value, replacer, space);
    }
};

var wkx = {};

var types$1 = {
    wkt: {
        Point: 'POINT',
        LineString: 'LINESTRING',
        Polygon: 'POLYGON',
        MultiPoint: 'MULTIPOINT',
        MultiLineString: 'MULTILINESTRING',
        MultiPolygon: 'MULTIPOLYGON',
        GeometryCollection: 'GEOMETRYCOLLECTION'
    },
    wkb: {
        Point: 1,
        LineString: 2,
        Polygon: 3,
        MultiPoint: 4,
        MultiLineString: 5,
        MultiPolygon: 6,
        GeometryCollection: 7
    },
    geoJSON: {
        Point: 'Point',
        LineString: 'LineString',
        Polygon: 'Polygon',
        MultiPoint: 'MultiPoint',
        MultiLineString: 'MultiLineString',
        MultiPolygon: 'MultiPolygon',
        GeometryCollection: 'GeometryCollection'
    }
};

var binarywriter = BinaryWriter;

function BinaryWriter(size, allowResize) {
    this.buffer = new Buffer.alloc(size);
    this.position = 0;
    this.allowResize = allowResize;
}

function _write(write, size) {
    return function (value, noAssert) {
        this.ensureSize(size);

        write.call(this.buffer, value, this.position, noAssert);
        this.position += size;
    };
}

BinaryWriter.prototype.writeUInt8 = _write(Buffer.prototype.writeUInt8, 1);
BinaryWriter.prototype.writeUInt16LE = _write(Buffer.prototype.writeUInt16LE, 2);
BinaryWriter.prototype.writeUInt16BE = _write(Buffer.prototype.writeUInt16BE, 2);
BinaryWriter.prototype.writeUInt32LE = _write(Buffer.prototype.writeUInt32LE, 4);
BinaryWriter.prototype.writeUInt32BE = _write(Buffer.prototype.writeUInt32BE, 4);
BinaryWriter.prototype.writeInt8 = _write(Buffer.prototype.writeInt8, 1);
BinaryWriter.prototype.writeInt16LE = _write(Buffer.prototype.writeInt16LE, 2);
BinaryWriter.prototype.writeInt16BE = _write(Buffer.prototype.writeInt16BE, 2);
BinaryWriter.prototype.writeInt32LE = _write(Buffer.prototype.writeInt32LE, 4);
BinaryWriter.prototype.writeInt32BE = _write(Buffer.prototype.writeInt32BE, 4);
BinaryWriter.prototype.writeFloatLE = _write(Buffer.prototype.writeFloatLE, 4);
BinaryWriter.prototype.writeFloatBE = _write(Buffer.prototype.writeFloatBE, 4);
BinaryWriter.prototype.writeDoubleLE = _write(Buffer.prototype.writeDoubleLE, 8);
BinaryWriter.prototype.writeDoubleBE = _write(Buffer.prototype.writeDoubleBE, 8);

BinaryWriter.prototype.writeBuffer = function (buffer) {
    this.ensureSize(buffer.length);

    buffer.copy(this.buffer, this.position, 0, buffer.length);
    this.position += buffer.length;
};

BinaryWriter.prototype.writeVarInt = function (value) {
    var length = 1;

    while ((value & 0xFFFFFF80) !== 0) {
        this.writeUInt8((value & 0x7F) | 0x80);
        value >>>= 7;
        length++;
    }

    this.writeUInt8(value & 0x7F);

    return length;
};

BinaryWriter.prototype.ensureSize = function (size) {
    if (this.buffer.length < this.position + size) {
        if (this.allowResize) {
            var tempBuffer = new Buffer.alloc(this.position + size);
            this.buffer.copy(tempBuffer, 0, 0, this.buffer.length);
            this.buffer = tempBuffer;
        }
        else {
            throw new RangeError('index out of range');
        }
    }
};

var zigzag = {
    encode: function (value) {
        return (value << 1) ^ (value >> 31);
    },
    decode: function (value) {
        return (value >> 1) ^ (-(value & 1));
    }
};

var point;
var hasRequiredPoint;

function requirePoint () {
	if (hasRequiredPoint) return point;
	hasRequiredPoint = 1;
	point = Point;

	var util = require$$0$1;

	var Geometry = requireGeometry();
	var Types = types$1;
	var BinaryWriter = binarywriter;
	var ZigZag = zigzag;

	function Point(x, y, z, m, srid) {
	    Geometry.call(this);

	    this.x = x;
	    this.y = y;
	    this.z = z;
	    this.m = m;
		this.srid = srid;

	    this.hasZ = typeof this.z !== 'undefined';
	    this.hasM = typeof this.m !== 'undefined';
	}

	util.inherits(Point, Geometry);

	Point.Z = function (x, y, z, srid) {
	    var point = new Point(x, y, z, undefined, srid);
	    point.hasZ = true;
	    return point;
	};

	Point.M = function (x, y, m, srid) {
	    var point = new Point(x, y, undefined, m, srid);
	    point.hasM = true;
	    return point;
	};

	Point.ZM = function (x, y, z, m, srid) {
	    var point = new Point(x, y, z, m, srid);
	    point.hasZ = true;
	    point.hasM = true;
	    return point;
	};

	Point._parseWkt = function (value, options) {
	    var point = new Point();
	    point.srid = options.srid;
	    point.hasZ = options.hasZ;
	    point.hasM = options.hasM;

	    if (value.isMatch(['EMPTY']))
	        return point;

	    value.expectGroupStart();

	    var coordinate = value.matchCoordinate(options);

	    point.x = coordinate.x;
	    point.y = coordinate.y;
	    point.z = coordinate.z;
	    point.m = coordinate.m;

	    value.expectGroupEnd();

	    return point;
	};

	Point._parseWkb = function (value, options) {
	    var point = Point._readWkbPoint(value, options);
	    point.srid = options.srid;
	    return point;
	};

	Point._readWkbPoint = function (value, options) {
	    return new Point(value.readDouble(), value.readDouble(),
	        options.hasZ ? value.readDouble() : undefined,
	        options.hasM ? value.readDouble() : undefined);
	};

	Point._parseTwkb = function (value, options) {
	    var point = new Point();
	    point.hasZ = options.hasZ;
	    point.hasM = options.hasM;

	    if (options.isEmpty)
	        return point;

	    point.x = ZigZag.decode(value.readVarInt()) / options.precisionFactor;
	    point.y = ZigZag.decode(value.readVarInt()) / options.precisionFactor;
	    point.z = options.hasZ ? ZigZag.decode(value.readVarInt()) / options.zPrecisionFactor : undefined;
	    point.m = options.hasM ? ZigZag.decode(value.readVarInt()) / options.mPrecisionFactor : undefined;

	    return point;
	};

	Point._readTwkbPoint = function (value, options, previousPoint) {
	    previousPoint.x += ZigZag.decode(value.readVarInt()) / options.precisionFactor;
	    previousPoint.y += ZigZag.decode(value.readVarInt()) / options.precisionFactor;

	    if (options.hasZ)
	        previousPoint.z += ZigZag.decode(value.readVarInt()) / options.zPrecisionFactor;
	    if (options.hasM)
	        previousPoint.m += ZigZag.decode(value.readVarInt()) / options.mPrecisionFactor;

	    return new Point(previousPoint.x, previousPoint.y, previousPoint.z, previousPoint.m);
	};

	Point._parseGeoJSON = function (value) {
	    return Point._readGeoJSONPoint(value.coordinates);
	};

	Point._readGeoJSONPoint = function (coordinates) {
	    if (coordinates.length === 0)
	        return new Point();

	    if (coordinates.length > 2)
	        return new Point(coordinates[0], coordinates[1], coordinates[2]);

	    return new Point(coordinates[0], coordinates[1]);
	};

	Point.prototype.toWkt = function () {
	    if (typeof this.x === 'undefined' && typeof this.y === 'undefined' &&
	        typeof this.z === 'undefined' && typeof this.m === 'undefined')
	        return this._getWktType(Types.wkt.Point, true);

	    return this._getWktType(Types.wkt.Point, false) + '(' + this._getWktCoordinate(this) + ')';
	};

	Point.prototype.toWkb = function (parentOptions) {
	    var wkb = new BinaryWriter(this._getWkbSize());

	    wkb.writeInt8(1);
	    this._writeWkbType(wkb, Types.wkb.Point, parentOptions);

	    if (typeof this.x === 'undefined' && typeof this.y === 'undefined') {
	        wkb.writeDoubleLE(NaN);
	        wkb.writeDoubleLE(NaN);

	        if (this.hasZ)
	            wkb.writeDoubleLE(NaN);
	        if (this.hasM)
	            wkb.writeDoubleLE(NaN);
	    }
	    else {
	        this._writeWkbPoint(wkb);
	    }

	    return wkb.buffer;
	};

	Point.prototype._writeWkbPoint = function (wkb) {
	    wkb.writeDoubleLE(this.x);
	    wkb.writeDoubleLE(this.y);

	    if (this.hasZ)
	        wkb.writeDoubleLE(this.z);
	    if (this.hasM)
	        wkb.writeDoubleLE(this.m);
	};

	Point.prototype.toTwkb = function () {
	    var twkb = new BinaryWriter(0, true);

	    var precision = Geometry.getTwkbPrecision(5, 0, 0);
	    var isEmpty = typeof this.x === 'undefined' && typeof this.y === 'undefined';

	    this._writeTwkbHeader(twkb, Types.wkb.Point, precision, isEmpty);

	    if (!isEmpty)
	        this._writeTwkbPoint(twkb, precision, new Point(0, 0, 0, 0));

	    return twkb.buffer;
	};

	Point.prototype._writeTwkbPoint = function (twkb, precision, previousPoint) {
	    var x = this.x * precision.xyFactor;
	    var y = this.y * precision.xyFactor;
	    var z = this.z * precision.zFactor;
	    var m = this.m * precision.mFactor;

	    twkb.writeVarInt(ZigZag.encode(x - previousPoint.x));
	    twkb.writeVarInt(ZigZag.encode(y - previousPoint.y));
	    if (this.hasZ)
	        twkb.writeVarInt(ZigZag.encode(z - previousPoint.z));
	    if (this.hasM)
	        twkb.writeVarInt(ZigZag.encode(m - previousPoint.m));

	    previousPoint.x = x;
	    previousPoint.y = y;
	    previousPoint.z = z;
	    previousPoint.m = m;
	};

	Point.prototype._getWkbSize = function () {
	    var size = 1 + 4 + 8 + 8;

	    if (this.hasZ)
	        size += 8;
	    if (this.hasM)
	        size += 8;

	    return size;
	};

	Point.prototype.toGeoJSON = function (options) {
	    var geoJSON = Geometry.prototype.toGeoJSON.call(this, options);
	    geoJSON.type = Types.geoJSON.Point;

	    if (typeof this.x === 'undefined' && typeof this.y === 'undefined')
	        geoJSON.coordinates = [];
	    else if (typeof this.z !== 'undefined')
	        geoJSON.coordinates = [this.x, this.y, this.z];
	    else
	        geoJSON.coordinates = [this.x, this.y];

	    return geoJSON;
	};
	return point;
}

var linestring;
var hasRequiredLinestring;

function requireLinestring () {
	if (hasRequiredLinestring) return linestring;
	hasRequiredLinestring = 1;
	linestring = LineString;

	var util = require$$0$1;

	var Geometry = requireGeometry();
	var Types = types$1;
	var Point = requirePoint();
	var BinaryWriter = binarywriter;

	function LineString(points, srid) {
	    Geometry.call(this);

	    this.points = points || [];
		this.srid = srid;

	    if (this.points.length > 0) {
	        this.hasZ = this.points[0].hasZ;
	        this.hasM = this.points[0].hasM;
	    }
	}

	util.inherits(LineString, Geometry);

	LineString.Z = function (points, srid) {
	    var lineString = new LineString(points, srid);
	    lineString.hasZ = true;
	    return lineString;
	};

	LineString.M = function (points, srid) {
	    var lineString = new LineString(points, srid);
	    lineString.hasM = true;
	    return lineString;
	};

	LineString.ZM = function (points, srid) {
	    var lineString = new LineString(points, srid);
	    lineString.hasZ = true;
	    lineString.hasM = true;
	    return lineString;
	};

	LineString._parseWkt = function (value, options) {
	    var lineString = new LineString();
	    lineString.srid = options.srid;
	    lineString.hasZ = options.hasZ;
	    lineString.hasM = options.hasM;

	    if (value.isMatch(['EMPTY']))
	        return lineString;

	    value.expectGroupStart();
	    lineString.points.push.apply(lineString.points, value.matchCoordinates(options));
	    value.expectGroupEnd();

	    return lineString;
	};

	LineString._parseWkb = function (value, options) {
	    var lineString = new LineString();
	    lineString.srid = options.srid;
	    lineString.hasZ = options.hasZ;
	    lineString.hasM = options.hasM;

	    var pointCount = value.readUInt32();

	    for (var i = 0; i < pointCount; i++)
	        lineString.points.push(Point._readWkbPoint(value, options));

	    return lineString;
	};

	LineString._parseTwkb = function (value, options) {
	    var lineString = new LineString();
	    lineString.hasZ = options.hasZ;
	    lineString.hasM = options.hasM;

	    if (options.isEmpty)
	        return lineString;

	    var previousPoint = new Point(0, 0, options.hasZ ? 0 : undefined, options.hasM ? 0 : undefined);
	    var pointCount = value.readVarInt();

	    for (var i = 0; i < pointCount; i++)
	        lineString.points.push(Point._readTwkbPoint(value, options, previousPoint));

	    return lineString;
	};

	LineString._parseGeoJSON = function (value) {
	    var lineString = new LineString();

	    if (value.coordinates.length > 0)
	        lineString.hasZ = value.coordinates[0].length > 2;

	    for (var i = 0; i < value.coordinates.length; i++)
	        lineString.points.push(Point._readGeoJSONPoint(value.coordinates[i]));

	    return lineString;
	};

	LineString.prototype.toWkt = function () {
	    if (this.points.length === 0)
	        return this._getWktType(Types.wkt.LineString, true);

	    return this._getWktType(Types.wkt.LineString, false) + this._toInnerWkt();
	};

	LineString.prototype._toInnerWkt = function () {
	    var innerWkt = '(';

	    for (var i = 0; i < this.points.length; i++)
	        innerWkt += this._getWktCoordinate(this.points[i]) + ',';

	    innerWkt = innerWkt.slice(0, -1);
	    innerWkt += ')';

	    return innerWkt;
	};

	LineString.prototype.toWkb = function (parentOptions) {
	    var wkb = new BinaryWriter(this._getWkbSize());

	    wkb.writeInt8(1);

	    this._writeWkbType(wkb, Types.wkb.LineString, parentOptions);
	    wkb.writeUInt32LE(this.points.length);

	    for (var i = 0; i < this.points.length; i++)
	        this.points[i]._writeWkbPoint(wkb);

	    return wkb.buffer;
	};

	LineString.prototype.toTwkb = function () {
	    var twkb = new BinaryWriter(0, true);

	    var precision = Geometry.getTwkbPrecision(5, 0, 0);
	    var isEmpty = this.points.length === 0;

	    this._writeTwkbHeader(twkb, Types.wkb.LineString, precision, isEmpty);

	    if (this.points.length > 0) {
	        twkb.writeVarInt(this.points.length);

	        var previousPoint = new Point(0, 0, 0, 0);
	        for (var i = 0; i < this.points.length; i++)
	            this.points[i]._writeTwkbPoint(twkb, precision, previousPoint);
	    }

	    return twkb.buffer;
	};

	LineString.prototype._getWkbSize = function () {
	    var coordinateSize = 16;

	    if (this.hasZ)
	        coordinateSize += 8;
	    if (this.hasM)
	        coordinateSize += 8;

	    return 1 + 4 + 4 + (this.points.length * coordinateSize);
	};

	LineString.prototype.toGeoJSON = function (options) {
	    var geoJSON = Geometry.prototype.toGeoJSON.call(this, options);
	    geoJSON.type = Types.geoJSON.LineString;
	    geoJSON.coordinates = [];

	    for (var i = 0; i < this.points.length; i++) {
	        if (this.hasZ)
	            geoJSON.coordinates.push([this.points[i].x, this.points[i].y, this.points[i].z]);
	        else
	            geoJSON.coordinates.push([this.points[i].x, this.points[i].y]);
	    }

	    return geoJSON;
	};
	return linestring;
}

var polygon;
var hasRequiredPolygon;

function requirePolygon () {
	if (hasRequiredPolygon) return polygon;
	hasRequiredPolygon = 1;
	polygon = Polygon;

	var util = require$$0$1;

	var Geometry = requireGeometry();
	var Types = types$1;
	var Point = requirePoint();
	var BinaryWriter = binarywriter;

	function Polygon(exteriorRing, interiorRings, srid) {
	    Geometry.call(this);

	    this.exteriorRing = exteriorRing || [];
	    this.interiorRings = interiorRings || [];
		this.srid = srid;

	    if (this.exteriorRing.length > 0) {
	        this.hasZ = this.exteriorRing[0].hasZ;
	        this.hasM = this.exteriorRing[0].hasM;
	    }
	}

	util.inherits(Polygon, Geometry);

	Polygon.Z = function (exteriorRing, interiorRings, srid) {
	    var polygon = new Polygon(exteriorRing, interiorRings, srid);
	    polygon.hasZ = true;
	    return polygon;
	};

	Polygon.M = function (exteriorRing, interiorRings, srid) {
	    var polygon = new Polygon(exteriorRing, interiorRings, srid);
	    polygon.hasM = true;
	    return polygon;
	};

	Polygon.ZM = function (exteriorRing, interiorRings, srid) {
	    var polygon = new Polygon(exteriorRing, interiorRings, srid);
	    polygon.hasZ = true;
	    polygon.hasM = true;
	    return polygon;
	};

	Polygon._parseWkt = function (value, options) {
	    var polygon = new Polygon();
	    polygon.srid = options.srid;
	    polygon.hasZ = options.hasZ;
	    polygon.hasM = options.hasM;

	    if (value.isMatch(['EMPTY']))
	        return polygon;

	    value.expectGroupStart();

	    value.expectGroupStart();
	    polygon.exteriorRing.push.apply(polygon.exteriorRing, value.matchCoordinates(options));
	    value.expectGroupEnd();

	    while (value.isMatch([','])) {
	        value.expectGroupStart();
	        polygon.interiorRings.push(value.matchCoordinates(options));
	        value.expectGroupEnd();
	    }

	    value.expectGroupEnd();

	    return polygon;
	};

	Polygon._parseWkb = function (value, options) {
	    var polygon = new Polygon();
	    polygon.srid = options.srid;
	    polygon.hasZ = options.hasZ;
	    polygon.hasM = options.hasM;

	    var ringCount = value.readUInt32();

	    if (ringCount > 0) {
	        var exteriorRingCount = value.readUInt32();

	        for (var i = 0; i < exteriorRingCount; i++)
	            polygon.exteriorRing.push(Point._readWkbPoint(value, options));

	        for (i = 1; i < ringCount; i++) {
	            var interiorRing = [];

	            var interiorRingCount = value.readUInt32();

	            for (var j = 0; j < interiorRingCount; j++)
	                interiorRing.push(Point._readWkbPoint(value, options));

	            polygon.interiorRings.push(interiorRing);
	        }
	    }

	    return polygon;
	};

	Polygon._parseTwkb = function (value, options) {
	    var polygon = new Polygon();
	    polygon.hasZ = options.hasZ;
	    polygon.hasM = options.hasM;

	    if (options.isEmpty)
	        return polygon;

	    var previousPoint = new Point(0, 0, options.hasZ ? 0 : undefined, options.hasM ? 0 : undefined);
	    var ringCount = value.readVarInt();
	    var exteriorRingCount = value.readVarInt();

	    for (var i = 0; i < exteriorRingCount; i++)
	        polygon.exteriorRing.push(Point._readTwkbPoint(value, options, previousPoint));

	    for (i = 1; i < ringCount; i++) {
	        var interiorRing = [];

	        var interiorRingCount = value.readVarInt();

	        for (var j = 0; j < interiorRingCount; j++)
	            interiorRing.push(Point._readTwkbPoint(value, options, previousPoint));

	        polygon.interiorRings.push(interiorRing);
	    }

	    return polygon;
	};

	Polygon._parseGeoJSON = function (value) {
	    var polygon = new Polygon();

	    if (value.coordinates.length > 0 && value.coordinates[0].length > 0)
	        polygon.hasZ = value.coordinates[0][0].length > 2;

	    for (var i = 0; i < value.coordinates.length; i++) {
	        if (i > 0)
	            polygon.interiorRings.push([]);

	        for (var j = 0; j  < value.coordinates[i].length; j++) {
	            if (i === 0)
	                polygon.exteriorRing.push(Point._readGeoJSONPoint(value.coordinates[i][j]));
	            else
	                polygon.interiorRings[i - 1].push(Point._readGeoJSONPoint(value.coordinates[i][j]));
	        }
	    }

	    return polygon;
	};

	Polygon.prototype.toWkt = function () {
	    if (this.exteriorRing.length === 0)
	        return this._getWktType(Types.wkt.Polygon, true);

	    return this._getWktType(Types.wkt.Polygon, false) + this._toInnerWkt();
	};

	Polygon.prototype._toInnerWkt = function () {
	    var innerWkt = '((';

	    for (var i = 0; i < this.exteriorRing.length; i++)
	        innerWkt += this._getWktCoordinate(this.exteriorRing[i]) + ',';

	    innerWkt = innerWkt.slice(0, -1);
	    innerWkt += ')';

	    for (i = 0; i < this.interiorRings.length; i++) {
	        innerWkt += ',(';

	        for (var j = 0; j < this.interiorRings[i].length; j++) {
	            innerWkt += this._getWktCoordinate(this.interiorRings[i][j]) + ',';
	        }

	        innerWkt = innerWkt.slice(0, -1);
	        innerWkt += ')';
	    }

	    innerWkt += ')';

	    return innerWkt;
	};

	Polygon.prototype.toWkb = function (parentOptions) {
	    var wkb = new BinaryWriter(this._getWkbSize());

	    wkb.writeInt8(1);

	    this._writeWkbType(wkb, Types.wkb.Polygon, parentOptions);

	    if (this.exteriorRing.length > 0) {
	        wkb.writeUInt32LE(1 + this.interiorRings.length);
	        wkb.writeUInt32LE(this.exteriorRing.length);
	    }
	    else {
	        wkb.writeUInt32LE(0);
	    }

	    for (var i = 0; i < this.exteriorRing.length; i++)
	        this.exteriorRing[i]._writeWkbPoint(wkb);

	    for (i = 0; i < this.interiorRings.length; i++) {
	        wkb.writeUInt32LE(this.interiorRings[i].length);

	        for (var j = 0; j < this.interiorRings[i].length; j++)
	            this.interiorRings[i][j]._writeWkbPoint(wkb);
	    }

	    return wkb.buffer;
	};

	Polygon.prototype.toTwkb = function () {
	    var twkb = new BinaryWriter(0, true);

	    var precision = Geometry.getTwkbPrecision(5, 0, 0);
	    var isEmpty = this.exteriorRing.length === 0;

	    this._writeTwkbHeader(twkb, Types.wkb.Polygon, precision, isEmpty);

	    if (this.exteriorRing.length > 0) {
	        twkb.writeVarInt(1 + this.interiorRings.length);

	        twkb.writeVarInt(this.exteriorRing.length);

	        var previousPoint = new Point(0, 0, 0, 0);
	        for (var i = 0; i < this.exteriorRing.length; i++)
	            this.exteriorRing[i]._writeTwkbPoint(twkb, precision, previousPoint);

	        for (i = 0; i < this.interiorRings.length; i++) {
	            twkb.writeVarInt(this.interiorRings[i].length);

	            for (var j = 0; j < this.interiorRings[i].length; j++)
	                this.interiorRings[i][j]._writeTwkbPoint(twkb, precision, previousPoint);
	        }
	    }

	    return twkb.buffer;
	};

	Polygon.prototype._getWkbSize = function () {
	    var coordinateSize = 16;

	    if (this.hasZ)
	        coordinateSize += 8;
	    if (this.hasM)
	        coordinateSize += 8;

	    var size = 1 + 4 + 4;

	    if (this.exteriorRing.length > 0)
	        size += 4 + (this.exteriorRing.length * coordinateSize);

	    for (var i = 0; i < this.interiorRings.length; i++)
	        size += 4 + (this.interiorRings[i].length * coordinateSize);

	    return size;
	};

	Polygon.prototype.toGeoJSON = function (options) {
	    var geoJSON = Geometry.prototype.toGeoJSON.call(this, options);
	    geoJSON.type = Types.geoJSON.Polygon;
	    geoJSON.coordinates = [];

	    if (this.exteriorRing.length > 0) {
	        var exteriorRing = [];

	        for (var i = 0; i < this.exteriorRing.length; i++) {
	            if (this.hasZ)
	                exteriorRing.push([this.exteriorRing[i].x, this.exteriorRing[i].y, this.exteriorRing[i].z]);
	            else
	                exteriorRing.push([this.exteriorRing[i].x, this.exteriorRing[i].y]);
	        }

	        geoJSON.coordinates.push(exteriorRing);
	    }

	    for (var j = 0; j < this.interiorRings.length; j++) {
	        var interiorRing = [];

	        for (var k = 0; k < this.interiorRings[j].length; k++) {
	            if (this.hasZ)
	                interiorRing.push([this.interiorRings[j][k].x, this.interiorRings[j][k].y, this.interiorRings[j][k].z]);
	            else
	                interiorRing.push([this.interiorRings[j][k].x, this.interiorRings[j][k].y]);
	        }

	        geoJSON.coordinates.push(interiorRing);
	    }

	    return geoJSON;
	};
	return polygon;
}

var multipoint;
var hasRequiredMultipoint;

function requireMultipoint () {
	if (hasRequiredMultipoint) return multipoint;
	hasRequiredMultipoint = 1;
	multipoint = MultiPoint;

	var util = require$$0$1;

	var Types = types$1;
	var Geometry = requireGeometry();
	var Point = requirePoint();
	var BinaryWriter = binarywriter;

	function MultiPoint(points, srid) {
	    Geometry.call(this);

	    this.points = points || [];
		this.srid = srid;
		
	    if (this.points.length > 0) {
	        this.hasZ = this.points[0].hasZ;
	        this.hasM = this.points[0].hasM;
	    }
	}

	util.inherits(MultiPoint, Geometry);

	MultiPoint.Z = function (points, srid) {
	    var multiPoint = new MultiPoint(points, srid);
	    multiPoint.hasZ = true;
	    return multiPoint;
	};

	MultiPoint.M = function (points, srid) {
	    var multiPoint = new MultiPoint(points, srid);
	    multiPoint.hasM = true;
	    return multiPoint;
	};

	MultiPoint.ZM = function (points, srid) {
	    var multiPoint = new MultiPoint(points, srid);
	    multiPoint.hasZ = true;
	    multiPoint.hasM = true;
	    return multiPoint;
	};

	MultiPoint._parseWkt = function (value, options) {
	    var multiPoint = new MultiPoint();
	    multiPoint.srid = options.srid;
	    multiPoint.hasZ = options.hasZ;
	    multiPoint.hasM = options.hasM;

	    if (value.isMatch(['EMPTY']))
	        return multiPoint;

	    value.expectGroupStart();
	    multiPoint.points.push.apply(multiPoint.points, value.matchCoordinates(options));
	    value.expectGroupEnd();

	    return multiPoint;
	};

	MultiPoint._parseWkb = function (value, options) {
	    var multiPoint = new MultiPoint();
	    multiPoint.srid = options.srid;
	    multiPoint.hasZ = options.hasZ;
	    multiPoint.hasM = options.hasM;

	    var pointCount = value.readUInt32();

	    for (var i = 0; i < pointCount; i++)
	        multiPoint.points.push(Geometry.parse(value, options));

	    return multiPoint;
	};

	MultiPoint._parseTwkb = function (value, options) {
	    var multiPoint = new MultiPoint();
	    multiPoint.hasZ = options.hasZ;
	    multiPoint.hasM = options.hasM;

	    if (options.isEmpty)
	        return multiPoint;

	    var previousPoint = new Point(0, 0, options.hasZ ? 0 : undefined, options.hasM ? 0 : undefined);
	    var pointCount = value.readVarInt();

	    for (var i = 0; i < pointCount; i++)
	        multiPoint.points.push(Point._readTwkbPoint(value, options, previousPoint));

	    return multiPoint;
	};

	MultiPoint._parseGeoJSON = function (value) {
	    var multiPoint = new MultiPoint();

	    if (value.coordinates.length > 0)
	        multiPoint.hasZ = value.coordinates[0].length > 2;

	    for (var i = 0; i < value.coordinates.length; i++)
	        multiPoint.points.push(Point._parseGeoJSON({ coordinates: value.coordinates[i] }));

	    return multiPoint;
	};

	MultiPoint.prototype.toWkt = function () {
	    if (this.points.length === 0)
	        return this._getWktType(Types.wkt.MultiPoint, true);

	    var wkt = this._getWktType(Types.wkt.MultiPoint, false) + '(';

	    for (var i = 0; i < this.points.length; i++)
	        wkt += this._getWktCoordinate(this.points[i]) + ',';

	    wkt = wkt.slice(0, -1);
	    wkt += ')';

	    return wkt;
	};

	MultiPoint.prototype.toWkb = function () {
	    var wkb = new BinaryWriter(this._getWkbSize());

	    wkb.writeInt8(1);

	    this._writeWkbType(wkb, Types.wkb.MultiPoint);
	    wkb.writeUInt32LE(this.points.length);

	    for (var i = 0; i < this.points.length; i++)
	        wkb.writeBuffer(this.points[i].toWkb({ srid: this.srid }));

	    return wkb.buffer;
	};

	MultiPoint.prototype.toTwkb = function () {
	    var twkb = new BinaryWriter(0, true);

	    var precision = Geometry.getTwkbPrecision(5, 0, 0);
	    var isEmpty = this.points.length === 0;

	    this._writeTwkbHeader(twkb, Types.wkb.MultiPoint, precision, isEmpty);

	    if (this.points.length > 0) {
	        twkb.writeVarInt(this.points.length);

	        var previousPoint = new Point(0, 0, 0, 0);
	        for (var i = 0; i < this.points.length; i++)
	            this.points[i]._writeTwkbPoint(twkb, precision, previousPoint);
	    }

	    return twkb.buffer;
	};

	MultiPoint.prototype._getWkbSize = function () {
	    var coordinateSize = 16;

	    if (this.hasZ)
	        coordinateSize += 8;
	    if (this.hasM)
	        coordinateSize += 8;

	    coordinateSize += 5;

	    return 1 + 4 + 4 + (this.points.length * coordinateSize);
	};

	MultiPoint.prototype.toGeoJSON = function (options) {
	    var geoJSON = Geometry.prototype.toGeoJSON.call(this, options);
	    geoJSON.type = Types.geoJSON.MultiPoint;
	    geoJSON.coordinates = [];

	    for (var i = 0; i < this.points.length; i++)
	        geoJSON.coordinates.push(this.points[i].toGeoJSON().coordinates);

	    return geoJSON;
	};
	return multipoint;
}

var multilinestring;
var hasRequiredMultilinestring;

function requireMultilinestring () {
	if (hasRequiredMultilinestring) return multilinestring;
	hasRequiredMultilinestring = 1;
	multilinestring = MultiLineString;

	var util = require$$0$1;

	var Types = types$1;
	var Geometry = requireGeometry();
	var Point = requirePoint();
	var LineString = requireLinestring();
	var BinaryWriter = binarywriter;

	function MultiLineString(lineStrings, srid) {
	    Geometry.call(this);

	    this.lineStrings = lineStrings || [];
		this.srid = srid;

	    if (this.lineStrings.length > 0) {
	        this.hasZ = this.lineStrings[0].hasZ;
	        this.hasM = this.lineStrings[0].hasM;
	    }
	}

	util.inherits(MultiLineString, Geometry);

	MultiLineString.Z = function (lineStrings, srid) {
	    var multiLineString = new MultiLineString(lineStrings, srid);
	    multiLineString.hasZ = true;
	    return multiLineString;
	};

	MultiLineString.M = function (lineStrings, srid) {
	    var multiLineString = new MultiLineString(lineStrings, srid);
	    multiLineString.hasM = true;
	    return multiLineString;
	};

	MultiLineString.ZM = function (lineStrings, srid) {
	    var multiLineString = new MultiLineString(lineStrings, srid);
	    multiLineString.hasZ = true;
	    multiLineString.hasM = true;
	    return multiLineString;
	};

	MultiLineString._parseWkt = function (value, options) {
	    var multiLineString = new MultiLineString();
	    multiLineString.srid = options.srid;
	    multiLineString.hasZ = options.hasZ;
	    multiLineString.hasM = options.hasM;

	    if (value.isMatch(['EMPTY']))
	        return multiLineString;

	    value.expectGroupStart();

	    do {
	        value.expectGroupStart();
	        multiLineString.lineStrings.push(new LineString(value.matchCoordinates(options)));
	        value.expectGroupEnd();
	    } while (value.isMatch([',']));

	    value.expectGroupEnd();

	    return multiLineString;
	};

	MultiLineString._parseWkb = function (value, options) {
	    var multiLineString = new MultiLineString();
	    multiLineString.srid = options.srid;
	    multiLineString.hasZ = options.hasZ;
	    multiLineString.hasM = options.hasM;

	    var lineStringCount = value.readUInt32();

	    for (var i = 0; i < lineStringCount; i++)
	        multiLineString.lineStrings.push(Geometry.parse(value, options));

	    return multiLineString;
	};

	MultiLineString._parseTwkb = function (value, options) {
	    var multiLineString = new MultiLineString();
	    multiLineString.hasZ = options.hasZ;
	    multiLineString.hasM = options.hasM;

	    if (options.isEmpty)
	        return multiLineString;

	    var previousPoint = new Point(0, 0, options.hasZ ? 0 : undefined, options.hasM ? 0 : undefined);
	    var lineStringCount = value.readVarInt();

	    for (var i = 0; i < lineStringCount; i++) {
	        var lineString = new LineString();
	        lineString.hasZ = options.hasZ;
	        lineString.hasM = options.hasM;

	        var pointCount = value.readVarInt();

	        for (var j = 0; j < pointCount; j++)
	            lineString.points.push(Point._readTwkbPoint(value, options, previousPoint));

	        multiLineString.lineStrings.push(lineString);
	    }

	    return multiLineString;
	};

	MultiLineString._parseGeoJSON = function (value) {
	    var multiLineString = new MultiLineString();

	    if (value.coordinates.length > 0 && value.coordinates[0].length > 0)
	        multiLineString.hasZ = value.coordinates[0][0].length > 2;

	    for (var i = 0; i < value.coordinates.length; i++)
	        multiLineString.lineStrings.push(LineString._parseGeoJSON({ coordinates: value.coordinates[i] }));

	    return multiLineString;
	};

	MultiLineString.prototype.toWkt = function () {
	    if (this.lineStrings.length === 0)
	        return this._getWktType(Types.wkt.MultiLineString, true);

	    var wkt = this._getWktType(Types.wkt.MultiLineString, false) + '(';

	    for (var i = 0; i < this.lineStrings.length; i++)
	        wkt += this.lineStrings[i]._toInnerWkt() + ',';

	    wkt = wkt.slice(0, -1);
	    wkt += ')';

	    return wkt;
	};

	MultiLineString.prototype.toWkb = function () {
	    var wkb = new BinaryWriter(this._getWkbSize());

	    wkb.writeInt8(1);

	    this._writeWkbType(wkb, Types.wkb.MultiLineString);
	    wkb.writeUInt32LE(this.lineStrings.length);

	    for (var i = 0; i < this.lineStrings.length; i++)
	        wkb.writeBuffer(this.lineStrings[i].toWkb({ srid: this.srid }));

	    return wkb.buffer;
	};

	MultiLineString.prototype.toTwkb = function () {
	    var twkb = new BinaryWriter(0, true);

	    var precision = Geometry.getTwkbPrecision(5, 0, 0);
	    var isEmpty = this.lineStrings.length === 0;

	    this._writeTwkbHeader(twkb, Types.wkb.MultiLineString, precision, isEmpty);

	    if (this.lineStrings.length > 0) {
	        twkb.writeVarInt(this.lineStrings.length);

	        var previousPoint = new Point(0, 0, 0, 0);
	        for (var i = 0; i < this.lineStrings.length; i++) {
	            twkb.writeVarInt(this.lineStrings[i].points.length);

	            for (var j = 0; j < this.lineStrings[i].points.length; j++)
	                this.lineStrings[i].points[j]._writeTwkbPoint(twkb, precision, previousPoint);
	        }
	    }

	    return twkb.buffer;
	};

	MultiLineString.prototype._getWkbSize = function () {
	    var size = 1 + 4 + 4;

	    for (var i = 0; i < this.lineStrings.length; i++)
	        size += this.lineStrings[i]._getWkbSize();

	    return size;
	};

	MultiLineString.prototype.toGeoJSON = function (options) {
	    var geoJSON = Geometry.prototype.toGeoJSON.call(this, options);
	    geoJSON.type = Types.geoJSON.MultiLineString;
	    geoJSON.coordinates = [];

	    for (var i = 0; i < this.lineStrings.length; i++)
	        geoJSON.coordinates.push(this.lineStrings[i].toGeoJSON().coordinates);

	    return geoJSON;
	};
	return multilinestring;
}

var multipolygon;
var hasRequiredMultipolygon;

function requireMultipolygon () {
	if (hasRequiredMultipolygon) return multipolygon;
	hasRequiredMultipolygon = 1;
	multipolygon = MultiPolygon;

	var util = require$$0$1;

	var Types = types$1;
	var Geometry = requireGeometry();
	var Point = requirePoint();
	var Polygon = requirePolygon();
	var BinaryWriter = binarywriter;

	function MultiPolygon(polygons, srid) {
	    Geometry.call(this);

	    this.polygons = polygons || [];
		this.srid = srid;

	    if (this.polygons.length > 0) {
	        this.hasZ = this.polygons[0].hasZ;
	        this.hasM = this.polygons[0].hasM;
	    }
	}

	util.inherits(MultiPolygon, Geometry);

	MultiPolygon.Z = function (polygons, srid) {
	    var multiPolygon = new MultiPolygon(polygons, srid);
	    multiPolygon.hasZ = true;
	    return multiPolygon;
	};

	MultiPolygon.M = function (polygons, srid) {
	    var multiPolygon = new MultiPolygon(polygons, srid);
	    multiPolygon.hasM = true;
	    return multiPolygon;
	};

	MultiPolygon.ZM = function (polygons, srid) {
	    var multiPolygon = new MultiPolygon(polygons, srid);
	    multiPolygon.hasZ = true;
	    multiPolygon.hasM = true;
	    return multiPolygon;
	};

	MultiPolygon._parseWkt = function (value, options) {
	    var multiPolygon = new MultiPolygon();
	    multiPolygon.srid = options.srid;
	    multiPolygon.hasZ = options.hasZ;
	    multiPolygon.hasM = options.hasM;

	    if (value.isMatch(['EMPTY']))
	        return multiPolygon;

	    value.expectGroupStart();

	    do {
	        value.expectGroupStart();

	        var exteriorRing = [];
	        var interiorRings = [];

	        value.expectGroupStart();
	        exteriorRing.push.apply(exteriorRing, value.matchCoordinates(options));
	        value.expectGroupEnd();

	        while (value.isMatch([','])) {
	            value.expectGroupStart();
	            interiorRings.push(value.matchCoordinates(options));
	            value.expectGroupEnd();
	        }

	        multiPolygon.polygons.push(new Polygon(exteriorRing, interiorRings));

	        value.expectGroupEnd();

	    } while (value.isMatch([',']));

	    value.expectGroupEnd();

	    return multiPolygon;
	};

	MultiPolygon._parseWkb = function (value, options) {
	    var multiPolygon = new MultiPolygon();
	    multiPolygon.srid = options.srid;
	    multiPolygon.hasZ = options.hasZ;
	    multiPolygon.hasM = options.hasM;

	    var polygonCount = value.readUInt32();

	    for (var i = 0; i < polygonCount; i++)
	        multiPolygon.polygons.push(Geometry.parse(value, options));

	    return multiPolygon;
	};

	MultiPolygon._parseTwkb = function (value, options) {
	    var multiPolygon = new MultiPolygon();
	    multiPolygon.hasZ = options.hasZ;
	    multiPolygon.hasM = options.hasM;

	    if (options.isEmpty)
	        return multiPolygon;

	    var previousPoint = new Point(0, 0, options.hasZ ? 0 : undefined, options.hasM ? 0 : undefined);
	    var polygonCount = value.readVarInt();

	    for (var i = 0; i < polygonCount; i++) {
	        var polygon = new Polygon();
	        polygon.hasZ = options.hasZ;
	        polygon.hasM = options.hasM;

	        var ringCount = value.readVarInt();
	        var exteriorRingCount = value.readVarInt();

	        for (var j = 0; j < exteriorRingCount; j++)
	            polygon.exteriorRing.push(Point._readTwkbPoint(value, options, previousPoint));

	        for (j = 1; j < ringCount; j++) {
	            var interiorRing = [];

	            var interiorRingCount = value.readVarInt();

	            for (var k = 0; k < interiorRingCount; k++)
	                interiorRing.push(Point._readTwkbPoint(value, options, previousPoint));

	            polygon.interiorRings.push(interiorRing);
	        }

	        multiPolygon.polygons.push(polygon);
	    }

	    return multiPolygon;
	};

	MultiPolygon._parseGeoJSON = function (value) {
	    var multiPolygon = new MultiPolygon();

	    if (value.coordinates.length > 0 && value.coordinates[0].length > 0 && value.coordinates[0][0].length > 0)
	        multiPolygon.hasZ = value.coordinates[0][0][0].length > 2;

	    for (var i = 0; i < value.coordinates.length; i++)
	        multiPolygon.polygons.push(Polygon._parseGeoJSON({ coordinates: value.coordinates[i] }));

	    return multiPolygon;
	};

	MultiPolygon.prototype.toWkt = function () {
	    if (this.polygons.length === 0)
	        return this._getWktType(Types.wkt.MultiPolygon, true);

	    var wkt = this._getWktType(Types.wkt.MultiPolygon, false) + '(';

	    for (var i = 0; i < this.polygons.length; i++)
	        wkt += this.polygons[i]._toInnerWkt() + ',';

	    wkt = wkt.slice(0, -1);
	    wkt += ')';

	    return wkt;
	};

	MultiPolygon.prototype.toWkb = function () {
	    var wkb = new BinaryWriter(this._getWkbSize());

	    wkb.writeInt8(1);

	    this._writeWkbType(wkb, Types.wkb.MultiPolygon);
	    wkb.writeUInt32LE(this.polygons.length);

	    for (var i = 0; i < this.polygons.length; i++)
	        wkb.writeBuffer(this.polygons[i].toWkb({ srid: this.srid }));

	    return wkb.buffer;
	};

	MultiPolygon.prototype.toTwkb = function () {
	    var twkb = new BinaryWriter(0, true);

	    var precision = Geometry.getTwkbPrecision(5, 0, 0);
	    var isEmpty = this.polygons.length === 0;

	    this._writeTwkbHeader(twkb, Types.wkb.MultiPolygon, precision, isEmpty);

	    if (this.polygons.length > 0) {
	        twkb.writeVarInt(this.polygons.length);

	        var previousPoint = new Point(0, 0, 0, 0);
	        for (var i = 0; i < this.polygons.length; i++) {
	            twkb.writeVarInt(1 + this.polygons[i].interiorRings.length);

	            twkb.writeVarInt(this.polygons[i].exteriorRing.length);

	            for (var j = 0; j < this.polygons[i].exteriorRing.length; j++)
	                this.polygons[i].exteriorRing[j]._writeTwkbPoint(twkb, precision, previousPoint);

	            for (j = 0; j < this.polygons[i].interiorRings.length; j++) {
	                twkb.writeVarInt(this.polygons[i].interiorRings[j].length);

	                for (var k = 0; k < this.polygons[i].interiorRings[j].length; k++)
	                    this.polygons[i].interiorRings[j][k]._writeTwkbPoint(twkb, precision, previousPoint);
	            }
	        }
	    }

	    return twkb.buffer;
	};

	MultiPolygon.prototype._getWkbSize = function () {
	    var size = 1 + 4 + 4;

	    for (var i = 0; i < this.polygons.length; i++)
	        size += this.polygons[i]._getWkbSize();

	    return size;
	};

	MultiPolygon.prototype.toGeoJSON = function (options) {
	    var geoJSON = Geometry.prototype.toGeoJSON.call(this, options);
	    geoJSON.type = Types.geoJSON.MultiPolygon;
	    geoJSON.coordinates = [];

	    for (var i = 0; i < this.polygons.length; i++)
	        geoJSON.coordinates.push(this.polygons[i].toGeoJSON().coordinates);

	    return geoJSON;
	};
	return multipolygon;
}

var geometrycollection;
var hasRequiredGeometrycollection;

function requireGeometrycollection () {
	if (hasRequiredGeometrycollection) return geometrycollection;
	hasRequiredGeometrycollection = 1;
	geometrycollection = GeometryCollection;

	var util = require$$0$1;

	var Types = types$1;
	var Geometry = requireGeometry();
	var BinaryWriter = binarywriter;

	function GeometryCollection(geometries, srid) {
	    Geometry.call(this);

	    this.geometries = geometries || [];
		this.srid = srid;

	    if (this.geometries.length > 0) {
	        this.hasZ = this.geometries[0].hasZ;
	        this.hasM = this.geometries[0].hasM;
	    }
	}

	util.inherits(GeometryCollection, Geometry);

	GeometryCollection.Z = function (geometries, srid) {
	    var geometryCollection = new GeometryCollection(geometries, srid);
	    geometryCollection.hasZ = true;
	    return geometryCollection;
	};

	GeometryCollection.M = function (geometries, srid) {
	    var geometryCollection = new GeometryCollection(geometries, srid);
	    geometryCollection.hasM = true;
	    return geometryCollection;
	};

	GeometryCollection.ZM = function (geometries, srid) {
	    var geometryCollection = new GeometryCollection(geometries, srid);
	    geometryCollection.hasZ = true;
	    geometryCollection.hasM = true;
	    return geometryCollection;
	};

	GeometryCollection._parseWkt = function (value, options) {
	    var geometryCollection = new GeometryCollection();
	    geometryCollection.srid = options.srid;
	    geometryCollection.hasZ = options.hasZ;
	    geometryCollection.hasM = options.hasM;

	    if (value.isMatch(['EMPTY']))
	        return geometryCollection;

	    value.expectGroupStart();

	    do {
	        geometryCollection.geometries.push(Geometry.parse(value));
	    } while (value.isMatch([',']));

	    value.expectGroupEnd();

	    return geometryCollection;
	};

	GeometryCollection._parseWkb = function (value, options) {
	    var geometryCollection = new GeometryCollection();
	    geometryCollection.srid = options.srid;
	    geometryCollection.hasZ = options.hasZ;
	    geometryCollection.hasM = options.hasM;

	    var geometryCount = value.readUInt32();

	    for (var i = 0; i < geometryCount; i++)
	        geometryCollection.geometries.push(Geometry.parse(value, options));

	    return geometryCollection;
	};

	GeometryCollection._parseTwkb = function (value, options) {
	    var geometryCollection = new GeometryCollection();
	    geometryCollection.hasZ = options.hasZ;
	    geometryCollection.hasM = options.hasM;

	    if (options.isEmpty)
	        return geometryCollection;

	    var geometryCount = value.readVarInt();

	    for (var i = 0; i < geometryCount; i++)
	        geometryCollection.geometries.push(Geometry.parseTwkb(value));

	    return geometryCollection;
	};

	GeometryCollection._parseGeoJSON = function (value) {
	    var geometryCollection = new GeometryCollection();

	    for (var i = 0; i < value.geometries.length; i++)
	        geometryCollection.geometries.push(Geometry._parseGeoJSON(value.geometries[i], true));

	    if (geometryCollection.geometries.length > 0)
	        geometryCollection.hasZ = geometryCollection.geometries[0].hasZ;

	    return geometryCollection;
	};

	GeometryCollection.prototype.toWkt = function () {
	    if (this.geometries.length === 0)
	        return this._getWktType(Types.wkt.GeometryCollection, true);

	    var wkt = this._getWktType(Types.wkt.GeometryCollection, false) + '(';

	    for (var i = 0; i < this.geometries.length; i++)
	        wkt += this.geometries[i].toWkt() + ',';

	    wkt = wkt.slice(0, -1);
	    wkt += ')';

	    return wkt;
	};

	GeometryCollection.prototype.toWkb = function () {
	    var wkb = new BinaryWriter(this._getWkbSize());

	    wkb.writeInt8(1);

	    this._writeWkbType(wkb, Types.wkb.GeometryCollection);
	    wkb.writeUInt32LE(this.geometries.length);

	    for (var i = 0; i < this.geometries.length; i++)
	        wkb.writeBuffer(this.geometries[i].toWkb({ srid: this.srid }));

	    return wkb.buffer;
	};

	GeometryCollection.prototype.toTwkb = function () {
	    var twkb = new BinaryWriter(0, true);

	    var precision = Geometry.getTwkbPrecision(5, 0, 0);
	    var isEmpty = this.geometries.length === 0;

	    this._writeTwkbHeader(twkb, Types.wkb.GeometryCollection, precision, isEmpty);

	    if (this.geometries.length > 0) {
	        twkb.writeVarInt(this.geometries.length);

	        for (var i = 0; i < this.geometries.length; i++)
	            twkb.writeBuffer(this.geometries[i].toTwkb());
	    }

	    return twkb.buffer;
	};

	GeometryCollection.prototype._getWkbSize = function () {
	    var size = 1 + 4 + 4;

	    for (var i = 0; i < this.geometries.length; i++)
	        size += this.geometries[i]._getWkbSize();

	    return size;
	};

	GeometryCollection.prototype.toGeoJSON = function (options) {
	    var geoJSON = Geometry.prototype.toGeoJSON.call(this, options);
	    geoJSON.type = Types.geoJSON.GeometryCollection;
	    geoJSON.geometries = [];

	    for (var i = 0; i < this.geometries.length; i++)
	        geoJSON.geometries.push(this.geometries[i].toGeoJSON());

	    return geoJSON;
	};
	return geometrycollection;
}

var binaryreader = BinaryReader;

function BinaryReader(buffer, isBigEndian) {
    this.buffer = buffer;
    this.position = 0;
    this.isBigEndian = isBigEndian || false;
}

function _read(readLE, readBE, size) {
    return function () {
        var value;

        if (this.isBigEndian)
            value = readBE.call(this.buffer, this.position);
        else
            value = readLE.call(this.buffer, this.position);

        this.position += size;

        return value;
    };
}

BinaryReader.prototype.readUInt8 = _read(Buffer.prototype.readUInt8, Buffer.prototype.readUInt8, 1);
BinaryReader.prototype.readUInt16 = _read(Buffer.prototype.readUInt16LE, Buffer.prototype.readUInt16BE, 2);
BinaryReader.prototype.readUInt32 = _read(Buffer.prototype.readUInt32LE, Buffer.prototype.readUInt32BE, 4);
BinaryReader.prototype.readInt8 = _read(Buffer.prototype.readInt8, Buffer.prototype.readInt8, 1);
BinaryReader.prototype.readInt16 = _read(Buffer.prototype.readInt16LE, Buffer.prototype.readInt16BE, 2);
BinaryReader.prototype.readInt32 = _read(Buffer.prototype.readInt32LE, Buffer.prototype.readInt32BE, 4);
BinaryReader.prototype.readFloat = _read(Buffer.prototype.readFloatLE, Buffer.prototype.readFloatBE, 4);
BinaryReader.prototype.readDouble = _read(Buffer.prototype.readDoubleLE, Buffer.prototype.readDoubleBE, 8);

BinaryReader.prototype.readVarInt = function () {
    var nextByte,
        result = 0,
        bytesRead = 0;

    do {
        nextByte = this.buffer[this.position + bytesRead];
        result += (nextByte & 0x7F) << (7 * bytesRead);
        bytesRead++;
    } while (nextByte >= 0x80);

    this.position += bytesRead;

    return result;
};

var wktparser;
var hasRequiredWktparser;

function requireWktparser () {
	if (hasRequiredWktparser) return wktparser;
	hasRequiredWktparser = 1;
	wktparser = WktParser;

	var Types = types$1;
	var Point = requirePoint();

	function WktParser(value) {
	    this.value = value;
	    this.position = 0;
	}

	WktParser.prototype.match = function (tokens) {
	    this.skipWhitespaces();

	    for (var i = 0; i < tokens.length; i++) {
	        if (this.value.substring(this.position).indexOf(tokens[i]) === 0) {
	            this.position += tokens[i].length;
	            return tokens[i];
	        }
	    }

	    return null;
	};

	WktParser.prototype.matchRegex = function (tokens) {
	    this.skipWhitespaces();

	    for (var i = 0; i < tokens.length; i++) {
	        var match = this.value.substring(this.position).match(tokens[i]);

	        if (match) {
	            this.position += match[0].length;
	            return match;
	        }
	    }

	    return null;
	};

	WktParser.prototype.isMatch = function (tokens) {
	    this.skipWhitespaces();

	    for (var i = 0; i < tokens.length; i++) {
	        if (this.value.substring(this.position).indexOf(tokens[i]) === 0) {
	            this.position += tokens[i].length;
	            return true;
	        }
	    }

	    return false;
	};

	WktParser.prototype.matchType = function () {
	    var geometryType = this.match([Types.wkt.Point, Types.wkt.LineString, Types.wkt.Polygon, Types.wkt.MultiPoint,
	    Types.wkt.MultiLineString, Types.wkt.MultiPolygon, Types.wkt.GeometryCollection]);

	    if (!geometryType)
	        throw new Error('Expected geometry type');

	    return geometryType;
	};

	WktParser.prototype.matchDimension = function () {
	    var dimension = this.match(['ZM', 'Z', 'M']);

	    switch (dimension) {
	        case 'ZM': return { hasZ: true, hasM: true };
	        case 'Z': return { hasZ: true, hasM: false };
	        case 'M': return { hasZ: false, hasM: true };
	        default: return { hasZ: false, hasM: false };
	    }
	};

	WktParser.prototype.expectGroupStart = function () {
	    if (!this.isMatch(['(']))
	        throw new Error('Expected group start');
	};

	WktParser.prototype.expectGroupEnd = function () {
	    if (!this.isMatch([')']))
	        throw new Error('Expected group end');
	};

	WktParser.prototype.matchCoordinate = function (options) {
	    var match;

	    if (options.hasZ && options.hasM)
	        match = this.matchRegex([/^(\S*)\s+(\S*)\s+(\S*)\s+([^\s,)]*)/]);
	    else if (options.hasZ || options.hasM)
	        match = this.matchRegex([/^(\S*)\s+(\S*)\s+([^\s,)]*)/]);
	    else
	        match = this.matchRegex([/^(\S*)\s+([^\s,)]*)/]);

	    if (!match)
	        throw new Error('Expected coordinates');

	    if (options.hasZ && options.hasM)
	        return new Point(parseFloat(match[1]), parseFloat(match[2]), parseFloat(match[3]), parseFloat(match[4]));
	    else if (options.hasZ)
	        return new Point(parseFloat(match[1]), parseFloat(match[2]), parseFloat(match[3]));
	    else if (options.hasM)
	        return new Point(parseFloat(match[1]), parseFloat(match[2]), undefined, parseFloat(match[3]));
	    else
	        return new Point(parseFloat(match[1]), parseFloat(match[2]));
	};

	WktParser.prototype.matchCoordinates = function (options) {
	    var coordinates = [];

	    do {
	        var startsWithBracket = this.isMatch(['(']);

	        coordinates.push(this.matchCoordinate(options));

	        if (startsWithBracket)
	            this.expectGroupEnd();
	    } while (this.isMatch([',']));

	    return coordinates;
	};

	WktParser.prototype.skipWhitespaces = function () {
	    while (this.position < this.value.length && this.value[this.position] === ' ')
	        this.position++;
	};
	return wktparser;
}

var geometry;
var hasRequiredGeometry;

function requireGeometry () {
	if (hasRequiredGeometry) return geometry;
	hasRequiredGeometry = 1;
	geometry = Geometry;

	var Types = types$1;
	var Point = requirePoint();
	var LineString = requireLinestring();
	var Polygon = requirePolygon();
	var MultiPoint = requireMultipoint();
	var MultiLineString = requireMultilinestring();
	var MultiPolygon = requireMultipolygon();
	var GeometryCollection = requireGeometrycollection();
	var BinaryReader = binaryreader;
	var BinaryWriter = binarywriter;
	var WktParser = requireWktparser();
	var ZigZag = zigzag;

	function Geometry() {
	    this.srid = undefined;
	    this.hasZ = false;
	    this.hasM = false;
	}

	Geometry.parse = function (value, options) {
	    var valueType = typeof value;

	    if (valueType === 'string' || value instanceof WktParser)
	        return Geometry._parseWkt(value);
	    else if (Buffer.isBuffer(value) || value instanceof BinaryReader)
	        return Geometry._parseWkb(value, options);
	    else
	        throw new Error('first argument must be a string or Buffer');
	};

	Geometry._parseWkt = function (value) {
	    var wktParser,
	        srid;

	    if (value instanceof WktParser)
	        wktParser = value;
	    else
	        wktParser = new WktParser(value);

	    var match = wktParser.matchRegex([/^SRID=(\d+);/]);
	    if (match)
	        srid = parseInt(match[1], 10);

	    var geometryType = wktParser.matchType();
	    var dimension = wktParser.matchDimension();

	    var options = {
	        srid: srid,
	        hasZ: dimension.hasZ,
	        hasM: dimension.hasM
	    };

	    switch (geometryType) {
	        case Types.wkt.Point:
	            return Point._parseWkt(wktParser, options);
	        case Types.wkt.LineString:
	            return LineString._parseWkt(wktParser, options);
	        case Types.wkt.Polygon:
	            return Polygon._parseWkt(wktParser, options);
	        case Types.wkt.MultiPoint:
	            return MultiPoint._parseWkt(wktParser, options);
	        case Types.wkt.MultiLineString:
	            return MultiLineString._parseWkt(wktParser, options);
	        case Types.wkt.MultiPolygon:
	            return MultiPolygon._parseWkt(wktParser, options);
	        case Types.wkt.GeometryCollection:
	            return GeometryCollection._parseWkt(wktParser, options);
	    }
	};

	Geometry._parseWkb = function (value, parentOptions) {
	    var binaryReader,
	        wkbType,
	        geometryType,
	        options = {};

	    if (value instanceof BinaryReader)
	        binaryReader = value;
	    else
	        binaryReader = new BinaryReader(value);

	    binaryReader.isBigEndian = !binaryReader.readInt8();

	    wkbType = binaryReader.readUInt32();

	    options.hasSrid = (wkbType & 0x20000000) === 0x20000000;
	    options.isEwkb = (wkbType & 0x20000000) || (wkbType & 0x40000000) || (wkbType & 0x80000000);

	    if (options.hasSrid)
	        options.srid = binaryReader.readUInt32();

	    options.hasZ = false;
	    options.hasM = false;

	    if (!options.isEwkb && (!parentOptions || !parentOptions.isEwkb)) {
	        if (wkbType >= 1000 && wkbType < 2000) {
	            options.hasZ = true;
	            geometryType = wkbType - 1000;
	        }
	        else if (wkbType >= 2000 && wkbType < 3000) {
	            options.hasM = true;
	            geometryType = wkbType - 2000;
	        }
	        else if (wkbType >= 3000 && wkbType < 4000) {
	            options.hasZ = true;
	            options.hasM = true;
	            geometryType = wkbType - 3000;
	        }
	        else {
	            geometryType = wkbType;
	        }
	    }
	    else {
	        if (wkbType & 0x80000000)
	            options.hasZ = true;
	        if (wkbType & 0x40000000)
	            options.hasM = true;

	        geometryType = wkbType & 0xF;
	    }

	    switch (geometryType) {
	        case Types.wkb.Point:
	            return Point._parseWkb(binaryReader, options);
	        case Types.wkb.LineString:
	            return LineString._parseWkb(binaryReader, options);
	        case Types.wkb.Polygon:
	            return Polygon._parseWkb(binaryReader, options);
	        case Types.wkb.MultiPoint:
	            return MultiPoint._parseWkb(binaryReader, options);
	        case Types.wkb.MultiLineString:
	            return MultiLineString._parseWkb(binaryReader, options);
	        case Types.wkb.MultiPolygon:
	            return MultiPolygon._parseWkb(binaryReader, options);
	        case Types.wkb.GeometryCollection:
	            return GeometryCollection._parseWkb(binaryReader, options);
	        default:
	            throw new Error('GeometryType ' + geometryType + ' not supported');
	    }
	};

	Geometry.parseTwkb = function (value) {
	    var binaryReader,
	        options = {};

	    if (value instanceof BinaryReader)
	        binaryReader = value;
	    else
	        binaryReader = new BinaryReader(value);

	    var type = binaryReader.readUInt8();
	    var metadataHeader = binaryReader.readUInt8();

	    var geometryType = type & 0x0F;
	    options.precision = ZigZag.decode(type >> 4);
	    options.precisionFactor = Math.pow(10, options.precision);

	    options.hasBoundingBox = metadataHeader >> 0 & 1;
	    options.hasSizeAttribute = metadataHeader >> 1 & 1;
	    options.hasIdList = metadataHeader >> 2 & 1;
	    options.hasExtendedPrecision = metadataHeader >> 3 & 1;
	    options.isEmpty = metadataHeader >> 4 & 1;

	    if (options.hasExtendedPrecision) {
	        var extendedPrecision = binaryReader.readUInt8();
	        options.hasZ = (extendedPrecision & 0x01) === 0x01;
	        options.hasM = (extendedPrecision & 0x02) === 0x02;

	        options.zPrecision = ZigZag.decode((extendedPrecision & 0x1C) >> 2);
	        options.zPrecisionFactor = Math.pow(10, options.zPrecision);

	        options.mPrecision = ZigZag.decode((extendedPrecision & 0xE0) >> 5);
	        options.mPrecisionFactor = Math.pow(10, options.mPrecision);
	    }
	    else {
	        options.hasZ = false;
	        options.hasM = false;
	    }

	    if (options.hasSizeAttribute)
	        binaryReader.readVarInt();
	    if (options.hasBoundingBox) {
	        var dimensions = 2;

	        if (options.hasZ)
	            dimensions++;
	        if (options.hasM)
	            dimensions++;

	        for (var i = 0; i < dimensions; i++) {
	            binaryReader.readVarInt();
	            binaryReader.readVarInt();
	        }
	    }

	    switch (geometryType) {
	        case Types.wkb.Point:
	            return Point._parseTwkb(binaryReader, options);
	        case Types.wkb.LineString:
	            return LineString._parseTwkb(binaryReader, options);
	        case Types.wkb.Polygon:
	            return Polygon._parseTwkb(binaryReader, options);
	        case Types.wkb.MultiPoint:
	            return MultiPoint._parseTwkb(binaryReader, options);
	        case Types.wkb.MultiLineString:
	            return MultiLineString._parseTwkb(binaryReader, options);
	        case Types.wkb.MultiPolygon:
	            return MultiPolygon._parseTwkb(binaryReader, options);
	        case Types.wkb.GeometryCollection:
	            return GeometryCollection._parseTwkb(binaryReader, options);
	        default:
	            throw new Error('GeometryType ' + geometryType + ' not supported');
	    }
	};

	Geometry.parseGeoJSON = function (value) {
	    return Geometry._parseGeoJSON(value);
	};

	Geometry._parseGeoJSON = function (value, isSubGeometry) {
	    var geometry;

	    switch (value.type) {
	        case Types.geoJSON.Point:
	            geometry = Point._parseGeoJSON(value); break;
	        case Types.geoJSON.LineString:
	            geometry = LineString._parseGeoJSON(value); break;
	        case Types.geoJSON.Polygon:
	            geometry = Polygon._parseGeoJSON(value); break;
	        case Types.geoJSON.MultiPoint:
	            geometry = MultiPoint._parseGeoJSON(value); break;
	        case Types.geoJSON.MultiLineString:
	            geometry = MultiLineString._parseGeoJSON(value); break;
	        case Types.geoJSON.MultiPolygon:
	            geometry = MultiPolygon._parseGeoJSON(value); break;
	        case Types.geoJSON.GeometryCollection:
	            geometry = GeometryCollection._parseGeoJSON(value); break;
	        default:
	            throw new Error('GeometryType ' + value.type + ' not supported');
	    }

	    if (value.crs && value.crs.type && value.crs.type === 'name' && value.crs.properties && value.crs.properties.name) {
	        var crs = value.crs.properties.name;

	        if (crs.indexOf('EPSG:') === 0)
	            geometry.srid = parseInt(crs.substring(5));
	        else if (crs.indexOf('urn:ogc:def:crs:EPSG::') === 0)
	            geometry.srid = parseInt(crs.substring(22));
	        else
	            throw new Error('Unsupported crs: ' + crs);
	    }
	    else if (!isSubGeometry) {
	        geometry.srid = 4326;
	    }

	    return geometry;
	};

	Geometry.prototype.toEwkt = function () {
	    return 'SRID=' + this.srid + ';' + this.toWkt();
	};

	Geometry.prototype.toEwkb = function () {
	    var ewkb = new BinaryWriter(this._getWkbSize() + 4);
	    var wkb = this.toWkb();

	    ewkb.writeInt8(1);
	    ewkb.writeUInt32LE((wkb.slice(1, 5).readUInt32LE(0) | 0x20000000) >>> 0, true);
	    ewkb.writeUInt32LE(this.srid);

	    ewkb.writeBuffer(wkb.slice(5));

	    return ewkb.buffer;
	};

	Geometry.prototype._getWktType = function (wktType, isEmpty) {
	    var wkt = wktType;

	    if (this.hasZ && this.hasM)
	        wkt += ' ZM ';
	    else if (this.hasZ)
	        wkt += ' Z ';
	    else if (this.hasM)
	        wkt += ' M ';

	    if (isEmpty && !this.hasZ && !this.hasM)
	        wkt += ' ';

	    if (isEmpty)
	        wkt += 'EMPTY';

	    return wkt;
	};

	Geometry.prototype._getWktCoordinate = function (point) {
	    var coordinates = point.x + ' ' + point.y;

	    if (this.hasZ)
	        coordinates += ' ' + point.z;
	    if (this.hasM)
	        coordinates += ' ' + point.m;

	    return coordinates;
	};

	Geometry.prototype._writeWkbType = function (wkb, geometryType, parentOptions) {
	    var dimensionType = 0;

	    if (typeof this.srid === 'undefined' && (!parentOptions || typeof parentOptions.srid === 'undefined')) {
	        if (this.hasZ && this.hasM)
	            dimensionType += 3000;
	        else if (this.hasZ)
	            dimensionType += 1000;
	        else if (this.hasM)
	            dimensionType += 2000;
	    }
	    else {
	        if (this.hasZ)
	            dimensionType |= 0x80000000;
	        if (this.hasM)
	            dimensionType |= 0x40000000;
	    }

	    wkb.writeUInt32LE((dimensionType + geometryType) >>> 0, true);
	};

	Geometry.getTwkbPrecision = function (xyPrecision, zPrecision, mPrecision) {
	    return {
	        xy: xyPrecision,
	        z: zPrecision,
	        m: mPrecision,
	        xyFactor: Math.pow(10, xyPrecision),
	        zFactor: Math.pow(10, zPrecision),
	        mFactor: Math.pow(10, mPrecision)
	    };
	};

	Geometry.prototype._writeTwkbHeader = function (twkb, geometryType, precision, isEmpty) {
	    var type = (ZigZag.encode(precision.xy) << 4) + geometryType;
	    var metadataHeader = (this.hasZ || this.hasM) << 3;
	    metadataHeader += isEmpty << 4;

	    twkb.writeUInt8(type);
	    twkb.writeUInt8(metadataHeader);

	    if (this.hasZ || this.hasM) {
	        var extendedPrecision = 0;
	        if (this.hasZ)
	            extendedPrecision |= 0x1;
	        if (this.hasM)
	            extendedPrecision |= 0x2;

	        twkb.writeUInt8(extendedPrecision);
	    }
	};

	Geometry.prototype.toGeoJSON = function (options) {
	    var geoJSON = {};

	    if (this.srid) {
	        if (options) {
	            if (options.shortCrs) {
	                geoJSON.crs = {
	                    type: 'name',
	                    properties: {
	                        name: 'EPSG:' + this.srid
	                    }
	                };
	            }
	            else if (options.longCrs) {
	                geoJSON.crs = {
	                    type: 'name',
	                    properties: {
	                        name: 'urn:ogc:def:crs:EPSG::' + this.srid
	                    }
	                };
	            }
	        }
	    }

	    return geoJSON;
	};
	return geometry;
}

wkx.Types = types$1;
wkx.Geometry = requireGeometry();
wkx.Point = requirePoint();
wkx.LineString = requireLinestring();
wkx.Polygon = requirePolygon();
wkx.MultiPoint = requireMultipoint();
wkx.MultiLineString = requireMultilinestring();
wkx.MultiPolygon = requireMultipolygon();
wkx.GeometryCollection = requireGeometrycollection();

const BASIC_OPERATORS = new Set([
    '=',
    '!=',
    '<',
    '>',
    '<=',
    '>=',
    '+',
    '-',
    '*',
    '/',
    '||',
    'AND',
    'OR',
    'IS',
    'IS NOT'
]);
const upper = {
    debugName: 'upper',
    call(value) {
        const text = castAsText(value);
        return text?.toUpperCase() ?? null;
    },
    parameters: [{ name: 'value', type: ExpressionType.ANY, optional: false }],
    getReturnType(args) {
        return ExpressionType.TEXT;
    },
    detail: 'Convert text to upper case'
};
const lower = {
    debugName: 'lower',
    call(value) {
        const text = castAsText(value);
        return text?.toLowerCase() ?? null;
    },
    parameters: [{ name: 'value', type: ExpressionType.ANY, optional: false }],
    getReturnType(args) {
        return ExpressionType.TEXT;
    },
    detail: 'Convert text to lower case'
};
const hex = {
    debugName: 'hex',
    call(value) {
        const binary = castAsBlob(value);
        if (binary == null) {
            return '';
        }
        return Buffer.from(binary).toString('hex').toUpperCase();
    },
    parameters: [{ name: 'value', type: ExpressionType.ANY, optional: false }],
    getReturnType(args) {
        return ExpressionType.TEXT;
    },
    detail: 'Convert a blob to hex text'
};
const length = {
    debugName: 'length',
    call(value) {
        if (value == null) {
            return null;
        }
        else if (value instanceof Uint8Array) {
            return BigInt(value.byteLength);
        }
        else {
            value = castAsText(value);
            return BigInt(value.length);
        }
    },
    parameters: [{ name: 'value', type: ExpressionType.ANY, optional: false }],
    getReturnType(args) {
        return ExpressionType.INTEGER;
    },
    detail: 'Returns the length of a text or blob value'
};
const base64 = {
    debugName: 'base64',
    call(value) {
        const binary = castAsBlob(value);
        if (binary == null) {
            return '';
        }
        return Buffer.from(binary).toString('base64');
    },
    parameters: [{ name: 'value', type: ExpressionType.ANY, optional: false }],
    getReturnType(args) {
        return ExpressionType.TEXT;
    },
    detail: 'Convert a blob to base64 text'
};
const fn_typeof = {
    debugName: 'typeof',
    call(value) {
        return sqliteTypeOf(value);
    },
    parameters: [{ name: 'value', type: ExpressionType.ANY, optional: false }],
    getReturnType(args) {
        return ExpressionType.TEXT;
    },
    detail: 'Returns the SQLite type of a value',
    documentation: `Returns 'null', 'text', 'integer', 'real' or 'blob'.`
};
const ifnull = {
    debugName: 'ifnull',
    call(x, y) {
        if (x == null) {
            return y;
        }
        else {
            return x;
        }
    },
    parameters: [
        { name: 'x', type: ExpressionType.ANY, optional: false },
        { name: 'y', type: ExpressionType.ANY, optional: false }
    ],
    getReturnType(args) {
        if (args.length == 0) {
            return ExpressionType.NONE;
        }
        else if (args.length == 1) {
            return args[0];
        }
        else {
            return args[0].or(args[1]);
        }
    },
    detail: 'Returns the first non-null parameter'
};
const json_extract = {
    debugName: 'json_extract',
    call(json, path) {
        return jsonExtract(json, path, 'json_extract');
    },
    parameters: [
        { name: 'json', type: ExpressionType.ANY, optional: false },
        { name: 'path', type: ExpressionType.ANY, optional: false }
    ],
    getReturnType(args) {
        return ExpressionType.ANY_JSON;
    },
    detail: 'Extract a JSON property'
};
const json_array_length = {
    debugName: 'json_array_length',
    call(json, path) {
        if (path != null) {
            json = json_extract.call(json, path);
        }
        const jsonString = castAsText(json);
        if (jsonString == null) {
            return null;
        }
        const jsonParsed = JSONBig.parse(jsonString);
        if (!Array.isArray(jsonParsed)) {
            return 0n;
        }
        return BigInt(jsonParsed.length);
    },
    parameters: [
        { name: 'json', type: ExpressionType.ANY, optional: false },
        { name: 'path', type: ExpressionType.ANY, optional: true }
    ],
    getReturnType(args) {
        return ExpressionType.INTEGER;
    },
    detail: 'Returns the length of a JSON array'
};
const json_valid = {
    debugName: 'json_valid',
    call(json) {
        const jsonString = castAsText(json);
        if (jsonString == null) {
            return SQLITE_FALSE;
        }
        try {
            JSONBig.parse(jsonString);
            return SQLITE_TRUE;
        }
        catch (e) {
            return SQLITE_FALSE;
        }
    },
    parameters: [{ name: 'json', type: ExpressionType.ANY, optional: false }],
    getReturnType(args) {
        return ExpressionType.INTEGER;
    },
    detail: 'Checks whether JSON text is valid',
    documentation: 'Returns 1 if valid, 0 if invalid'
};
const unixepoch = {
    debugName: 'unixepoch',
    call(value, specifier, specifier2) {
        if (value == null) {
            return null;
        }
        let flags = {
            unixepoch: false,
            subsecond: false
        };
        if (specifier == null) ;
        else if (specifier == 'unixepoch') {
            flags.unixepoch = true;
            if (specifier2 == null) ;
            else if (specifier2 == 'subsec' || specifier2 == 'subsecond') {
                flags.subsecond = true;
            }
            else {
                return null;
            }
        }
        else if (specifier == 'subsec' || specifier == 'subsecond') {
            flags.subsecond = true;
        }
        else {
            return null;
        }
        const epoch = convertToDate(value, flags)?.getTime();
        if (epoch == null || !Number.isFinite(epoch)) {
            return null;
        }
        if (flags.subsecond) {
            return epoch / 1000.0;
        }
        else {
            return BigInt(Math.floor(epoch / 1000.0));
        }
    },
    parameters: [
        { name: 'value', type: ExpressionType.ANY, optional: false },
        { name: 'specifier', type: ExpressionType.ANY, optional: true },
        { name: 'specifier2', type: ExpressionType.ANY, optional: true }
    ],
    getReturnType(args) {
        return ExpressionType.INTEGER.or(ExpressionType.REAL);
    },
    detail: 'Convert a date to unix epoch'
};
const datetime = {
    debugName: 'datetime',
    call(value, specifier, specifier2) {
        if (value == null) {
            return null;
        }
        let flags = {
            unixepoch: false,
            subsecond: false
        };
        if (specifier == null) ;
        else if (specifier == 'unixepoch') {
            flags.unixepoch = true;
            if (specifier2 == null) ;
            else if (specifier2 == 'subsec' || specifier2 == 'subsecond') {
                flags.subsecond = true;
            }
            else {
                return null;
            }
        }
        else if (specifier == 'subsec' || specifier == 'subsecond') {
            flags.subsecond = true;
        }
        else {
            return null;
        }
        const epoch = convertToDate(value, flags);
        if (epoch == null || !Number.isFinite(epoch.getTime())) {
            return null;
        }
        const baseString = epoch.toISOString().replace(/T/, ' ').replace(/^\-0+/, '-');
        if (flags.subsecond) {
            return baseString.replace(/Z$/, '');
        }
        else {
            return baseString.replace(/(\.\d+)?Z$/, '');
        }
    },
    parameters: [
        { name: 'value', type: ExpressionType.ANY, optional: false },
        { name: 'specifier', type: ExpressionType.ANY, optional: true },
        { name: 'specifier2', type: ExpressionType.ANY, optional: true }
    ],
    getReturnType(args) {
        return ExpressionType.TEXT;
    },
    detail: 'Convert a date string or unix epoch to a consistent date string'
};
const st_asgeojson = {
    debugName: 'st_asgeojson',
    call(geometry) {
        const geo = parseGeometry(geometry);
        if (geo == null) {
            return null;
        }
        return JSONBig.stringify(geo.toGeoJSON());
    },
    parameters: [{ name: 'geometry', type: ExpressionType.ANY, optional: false }],
    getReturnType(args) {
        return ExpressionType.TEXT;
    },
    detail: 'Covert PostGIS geometry to GeoJSON text'
};
const st_astext = {
    debugName: 'st_astext',
    call(geometry) {
        const geo = parseGeometry(geometry);
        if (geo == null) {
            return null;
        }
        return geo.toWkt();
    },
    parameters: [{ name: 'geometry', type: ExpressionType.ANY, optional: false }],
    getReturnType(args) {
        return ExpressionType.TEXT;
    },
    detail: 'Covert PostGIS geometry to WKT text'
};
const st_x = {
    debugName: 'st_x',
    call(geometry) {
        const geo = parseGeometry(geometry);
        if (geo == null) {
            return null;
        }
        if (geo instanceof wkx.Point) {
            return geo.x;
        }
        return null;
    },
    parameters: [{ name: 'geometry', type: ExpressionType.ANY, optional: false }],
    getReturnType(args) {
        return ExpressionType.REAL;
    },
    detail: 'Get the X value of a PostGIS point'
};
const st_y = {
    debugName: 'st_y',
    call(geometry) {
        const geo = parseGeometry(geometry);
        if (geo == null) {
            return null;
        }
        if (geo instanceof wkx.Point) {
            return geo.y;
        }
        return null;
    },
    parameters: [{ name: 'geometry', type: ExpressionType.ANY, optional: false }],
    getReturnType(args) {
        return ExpressionType.REAL;
    },
    detail: 'Get the Y value of a PostGIS point'
};
const SQL_FUNCTIONS_NAMED = {
    upper,
    lower,
    hex,
    length,
    base64,
    typeof: fn_typeof,
    ifnull,
    json_extract,
    json_array_length,
    json_valid,
    unixepoch,
    datetime,
    st_asgeojson,
    st_astext,
    st_x,
    st_y
};
Object.fromEntries(Object.entries(SQL_FUNCTIONS_NAMED).map(([name, fn]) => [name, fn.call]));
const SQL_FUNCTIONS = SQL_FUNCTIONS_NAMED;
const CAST_TYPES = new Set(['text', 'numeric', 'integer', 'real', 'blob']);
const textEncoder = new TextEncoder();
const textDecoder = new TextDecoder();
function castAsText(value) {
    if (value == null) {
        return null;
    }
    else if (value instanceof Uint8Array) {
        return textDecoder.decode(value);
    }
    else {
        return value.toString();
    }
}
function castAsBlob(value) {
    if (value == null) {
        return null;
    }
    else if (value instanceof Uint8Array) {
        return value;
    }
    if (typeof value != 'string') {
        value = value.toString();
    }
    return textEncoder.encode(value);
}
function cast(value, to) {
    if (value == null) {
        return null;
    }
    if (to == 'text') {
        return castAsText(value);
    }
    else if (to == 'numeric') {
        if (value instanceof Uint8Array) {
            value = textDecoder.decode(value);
        }
        if (typeof value == 'string') {
            return parseNumeric(value);
        }
        else if (typeof value == 'number' || typeof value == 'bigint') {
            return value;
        }
        else {
            return 0n;
        }
    }
    else if (to == 'real') {
        if (value instanceof Uint8Array) {
            value = textDecoder.decode(value);
        }
        if (typeof value == 'string') {
            const nr = parseFloat(value);
            if (isNaN(nr)) {
                return 0.0;
            }
            else {
                return nr;
            }
        }
        else if (typeof value == 'number') {
            return value;
        }
        else if (typeof value == 'bigint') {
            return Number(value);
        }
        else {
            return 0.0;
        }
    }
    else if (to == 'integer') {
        if (value instanceof Uint8Array) {
            value = textDecoder.decode(value);
        }
        if (typeof value == 'string') {
            return parseBigInt(value);
        }
        else if (typeof value == 'number') {
            return Number.isInteger(value) ? BigInt(value) : BigInt(Math.floor(value));
        }
        else if (typeof value == 'bigint') {
            return value;
        }
        else {
            return 0n;
        }
    }
    else if (to == 'blob') {
        return castAsBlob(value);
    }
    else {
        throw new Error(`Type not supported for cast: '${to}'`);
    }
}
function sqliteTypeOf(arg) {
    if (arg == null) {
        return 'null';
    }
    else if (typeof arg == 'string') {
        return 'text';
    }
    else if (typeof arg == 'bigint') {
        return 'integer';
    }
    else if (typeof arg == 'number') {
        return 'real';
    }
    else if (arg instanceof Uint8Array) {
        return 'blob';
    }
    else {
        // Should not happen
        throw new Error(`Unknown type: ${arg}`);
    }
}
function parseGeometry(value) {
    let blob;
    if (value == null) {
        return null;
    }
    else if (value instanceof Uint8Array) {
        blob = Buffer.from(value);
    }
    else if (typeof value == 'string') {
        blob = Buffer.from(value, 'hex');
    }
    else {
        return null;
    }
    const geo = wkx.Geometry.parse(blob);
    return geo;
}
function parseNumeric(text) {
    const match = /^\s*(\d+)(\.\d*)?(e[+\-]?\d+)?/i.exec(text);
    if (!match) {
        return 0n;
    }
    if (match[2] != null || match[3] != null) {
        const v = parseFloat(match[0]);
        return isNaN(v) ? 0n : v;
    }
    else {
        return BigInt(match[1]);
    }
}
function parseBigInt(text) {
    const match = /^\s*(\d+)/.exec(text);
    if (!match) {
        return 0n;
    }
    return BigInt(match[1]);
}
function isNumeric(a) {
    return typeof a == 'number' || typeof a == 'bigint';
}
function evaluateOperator(op, a, b) {
    switch (op) {
        case '=':
        case '!=':
        case '>':
        case '<':
        case '>=':
        case '<=': {
            if (a == null || b == null) {
                return null;
            }
            const diff = compare(a, b);
            if (op == '=') {
                return sqliteBool(diff === 0);
            }
            else if (op == '!=') {
                return sqliteBool(diff !== 0);
            }
            else if (op == '>') {
                return sqliteBool(diff > 0);
            }
            else if (op == '<') {
                return sqliteBool(diff < 0);
            }
            else if (op == '>=') {
                return sqliteBool(diff >= 0);
            }
            else if (op == '<=') {
                return sqliteBool(diff <= 0);
            }
            else {
                throw new Error('unreachable');
            }
        }
        // Not currently supported by the parser, but used with IS NULL
        case 'IS': {
            const diff = compare(a, b);
            return sqliteBool(diff === 0);
        }
        // Not currently supported by the parser, but used with IS NOT NULL
        case 'IS NOT': {
            const diff = compare(a, b);
            return sqliteBool(diff !== 0);
        }
        case '+':
        case '-':
        case '*':
        case '/':
            return doMath(op, a, b);
        case '||':
            return concat(a, b);
        case 'AND':
            return sqliteBool(sqliteBool(a) && sqliteBool(b));
        case 'OR':
            return sqliteBool(sqliteBool(a) || sqliteBool(b));
        case 'IN':
            if (a == null || b == null) {
                return null;
            }
            if (typeof b != 'string') {
                throw new Error('IN is only supported on JSON arrays');
            }
            const bParsed = JSON.parse(b);
            if (!Array.isArray(bParsed)) {
                throw new Error('IN is only supported on JSON arrays');
            }
            return sqliteBool(bParsed.includes(a));
        default:
            throw new Error(`Operator not supported: ${op}`);
    }
}
function getOperatorReturnType(op, left, right) {
    switch (op) {
        case '=':
        case '!=':
        case '>':
        case '<':
        case '>=':
        case '<=': {
            return ExpressionType.INTEGER;
        }
        // Not currently supported by the parser, but used with IS NULL
        case 'IS': {
            return ExpressionType.INTEGER;
        }
        // Not currently supported by the parser, but used with IS NOT NULL
        case 'IS NOT': {
            return ExpressionType.INTEGER;
        }
        case '+':
        case '-':
        case '*':
        case '/':
            if (left.typeFlags == TYPE_INTEGER && right.typeFlags == TYPE_INTEGER) {
                // INT, INT stays INT
                return ExpressionType.INTEGER;
            }
            else if (left.isNumericOnly() && right.isNumericOnly()) {
                // INT, REAL or REAL, INT or REAL, REAL => always REAL
                return ExpressionType.REAL;
            }
            else {
                // Unknown - could be REAL or INT
                return ExpressionType.NUMERIC;
            }
        case '||':
            return ExpressionType.TEXT;
        case 'AND':
            return ExpressionType.INTEGER;
        case 'OR':
            return ExpressionType.INTEGER;
        case 'IN':
            return ExpressionType.INTEGER;
        default:
            return ExpressionType.NONE;
    }
}
function doMath(op, a, b) {
    if (a == null || b == null) {
        return null;
    }
    let na = cast(a, 'numeric');
    let nb = cast(b, 'numeric');
    if (typeof na == 'bigint' && typeof nb != 'bigint') {
        // bigint, real
        na = Number(na);
    }
    else if (typeof na != 'bigint' && typeof nb == 'bigint') {
        // real, bigint
        nb = Number(nb);
    }
    switch (op) {
        case '+':
            return na + nb;
        case '-':
            return na - nb;
        case '*':
            return na * nb;
        case '/':
            return na / nb;
        default:
            throw new Error(`Operator not supported: ${op}`);
    }
}
function concat(a, b) {
    const aText = castAsText(a);
    const bText = castAsText(b);
    if (aText == null || bText == null) {
        return null;
    }
    return aText + bText;
}
function jsonExtract(sourceValue, path, operator) {
    const valueText = castAsText(sourceValue);
    const pathText = castAsText(path);
    if (valueText == null || pathText == null) {
        return null;
    }
    const components = pathText.split('.');
    if (components[0] == '$') {
        components.shift();
    }
    else if (operator == 'json_extract') {
        throw new Error(`JSON path must start with $.`);
    }
    let value = JSONBig.parse(valueText);
    for (let c of components) {
        if (value == null) {
            break;
        }
        value = value[c];
    }
    if (operator == '->') {
        // -> must always stringify
        return JSONBig.stringify(value);
    }
    else if (typeof value == 'object' || Array.isArray(value)) {
        // Objects and arrays must be stringified
        return JSONBig.stringify(value);
    }
    else {
        // Plain scalar value - simple conversion.
        return jsonValueToSqlite(value);
    }
}
const OPERATOR_JSON_EXTRACT_JSON = {
    debugName: 'operator->',
    call(json, path) {
        return jsonExtract(json, path, '->');
    },
    getReturnType(args) {
        return ExpressionType.ANY_JSON;
    }
};
const OPERATOR_JSON_EXTRACT_SQL = {
    debugName: 'operator->>',
    call(json, path) {
        return jsonExtract(json, path, '->>');
    },
    getReturnType(_args) {
        return ExpressionType.ANY_JSON;
    }
};
const OPERATOR_IS_NULL = {
    debugName: 'operator_is_null',
    call(value) {
        return evaluateOperator('IS', value, null);
    },
    getReturnType(_args) {
        return ExpressionType.INTEGER;
    }
};
const OPERATOR_IS_NOT_NULL = {
    debugName: 'operator_is_not_null',
    call(value) {
        return evaluateOperator('IS NOT', value, null);
    },
    getReturnType(_args) {
        return ExpressionType.INTEGER;
    }
};
const OPERATOR_NOT = {
    debugName: 'operator_not',
    call(value) {
        return sqliteNot(value);
    },
    getReturnType(_args) {
        return ExpressionType.INTEGER;
    }
};
function castOperator(castTo) {
    if (castTo == null || !CAST_TYPES.has(castTo)) {
        return null;
    }
    return {
        debugName: `operator_cast_${castTo}`,
        call(value) {
            if (value == null) {
                return null;
            }
            return cast(value, castTo);
        },
        getReturnType(_args) {
            return ExpressionType.fromTypeText(castTo);
        }
    };
}
function convertToDate(dateTime, flags) {
    if (typeof dateTime == 'string') {
        return parseUTCDate(dateTime);
    }
    else if (typeof dateTime == 'bigint') {
        if (flags.unixepoch) {
            return new Date(Number(dateTime) * 1000.0);
        }
        else {
            return julianToJSDate(Number(dateTime));
        }
    }
    else if (typeof dateTime == 'number') {
        if (flags.unixepoch) {
            return new Date(dateTime * 1000.0);
        }
        else {
            return julianToJSDate(dateTime);
        }
    }
    else {
        return null;
    }
}
function parseUTCDate(isoDateString) {
    const hasTimezone = /[Zz]|[+\-]\d{2}:\d{2}$/;
    const isJulienDay = /^\d+(\.\d*)?$/;
    if (hasTimezone.test(isoDateString)) {
        // If the string already has a timezone, parse it directly
        return new Date(isoDateString);
    }
    else if (isJulienDay.test(isoDateString)) {
        return julianToJSDate(parseFloat(isoDateString));
    }
    else {
        // If the string has no timezone, append "Z" to the end to interpret it as UTC
        return new Date(isoDateString + 'Z');
    }
}
function julianToJSDate(julianDay) {
    // The Julian date for the Unix Epoch is 2440587.5
    const julianAtEpoch = 2440587.5;
    // Calculate the difference between the Julian date and the Unix Epoch in days
    const daysSinceEpoch = julianDay - julianAtEpoch;
    // Convert this to milliseconds
    const msSinceEpoch = daysSinceEpoch * 24 * 60 * 60 * 1000;
    // Create a new Date object with this number of milliseconds since the Unix Epoch
    return new Date(msSinceEpoch);
}
const TYPE_ORDERING = {
    null: 0,
    integer: 1,
    real: 1,
    text: 2,
    blob: 3
};
function compare(a, b) {
    // https://www.sqlite.org/datatype3.html#comparisons
    if (a == null && b == null) {
        // Only for IS / IS NOT
        return 0;
    }
    if ((isNumeric(a) && isNumeric(b)) || (typeof a == 'string' && typeof b == 'string')) {
        if (a == b) {
            return 0;
        }
        else if (a > b) {
            return 1;
        }
        else {
            return -1;
        }
    }
    else if (a instanceof Uint8Array && b instanceof Uint8Array) {
        throw new Error('Comparing blobs is not supported currently');
    }
    const typeA = sqliteTypeOf(a);
    const typeB = sqliteTypeOf(b);
    return TYPE_ORDERING[typeA] - TYPE_ORDERING[typeB];
}

const request_parameters = {
    debugName: 'request.parameters',
    call(parameters) {
        return parameters.raw_user_parameters;
    },
    getReturnType() {
        return ExpressionType.TEXT;
    },
    detail: 'Unauthenticated request parameters as JSON',
    documentation: 'Returns parameters passed by the client as a JSON string. These parameters are not authenticated - any value can be passed in by the client.',
    usesAuthenticatedRequestParameters: false,
    usesUnauthenticatedRequestParameters: true
};
const request_jwt = {
    debugName: 'request.jwt',
    call(parameters) {
        return parameters.raw_token_payload;
    },
    getReturnType() {
        return ExpressionType.TEXT;
    },
    detail: 'JWT payload as JSON',
    documentation: 'The JWT payload as a JSON string. This is always validated against trusted keys.',
    usesAuthenticatedRequestParameters: true,
    usesUnauthenticatedRequestParameters: false
};
const request_user_id = {
    debugName: 'request.user_id',
    call(parameters) {
        return parameters.user_id;
    },
    getReturnType() {
        return ExpressionType.TEXT;
    },
    detail: 'Authenticated user id',
    documentation: "The id of the authenticated user.\nSame as `request.jwt() ->> 'sub'`.",
    usesAuthenticatedRequestParameters: true,
    usesUnauthenticatedRequestParameters: false
};
const REQUEST_FUNCTIONS_NAMED = {
    parameters: request_parameters,
    jwt: request_jwt,
    user_id: request_user_id
};
const REQUEST_FUNCTIONS = REQUEST_FUNCTIONS_NAMED;

const MATCH_CONST_FALSE = [];
const MATCH_CONST_TRUE = [{}];
Object.freeze(MATCH_CONST_TRUE);
Object.freeze(MATCH_CONST_FALSE);
class SqlTools {
    constructor(options) {
        this.errors = [];
        this.default_table = options.table;
        this.schema = options.schema;
        if (options.value_tables) {
            this.value_tables = options.value_tables;
        }
        else if (this.default_table) {
            this.value_tables = [this.default_table];
        }
        else {
            this.value_tables = [];
        }
        this.parameter_tables = options.parameter_tables ?? [];
        this.sql = options.sql;
        this.supports_expanding_parameters = options.supports_expanding_parameters ?? false;
        this.supports_parameter_expressions = options.supports_parameter_expressions ?? false;
    }
    error(message, expr) {
        this.errors.push(new SqlRuleError(message, this.sql, expr));
        return { error: true };
    }
    warn(message, expr) {
        const error = new SqlRuleError(message, this.sql, expr);
        error.type = 'warning';
        this.errors.push(error);
    }
    /**
     * Compile the where clause into a ParameterMatchClause.
     *
     * A ParameterMatchClause takes a data row, and returns filter values that
     * would make the expression true for the row.
     */
    compileWhereClause(where) {
        const base = this.compileClause(where);
        return toBooleanParameterSetClause(base);
    }
    compileRowValueExtractor(expr) {
        const clause = this.compileClause(expr);
        if (!isRowValueClause(clause) && !isClauseError(clause)) {
            return this.error('Parameter match expression is not allowed here', expr ?? undefined);
        }
        return clause;
    }
    compileParameterValueExtractor(expr) {
        const clause = this.compileClause(expr);
        if (isClauseError(clause) || isStaticValueClause(clause) || isParameterValueClause(clause)) {
            return clause;
        }
        return this.error('Parameter match expression is not allowed here', expr ?? undefined);
    }
    /**
     * Given an expression, return a compiled clause.
     */
    compileClause(expr) {
        if (expr == null) {
            return staticValueClause(SQLITE_TRUE);
        }
        else if (isStatic(expr)) {
            const value = staticValue(expr);
            return staticValueClause(value);
        }
        else if (expr.type == 'ref') {
            const column = expr.name;
            if (column == '*') {
                return this.error('* not supported here', expr);
            }
            if (this.refHasSchema(expr)) {
                return this.error(`Schema is not supported in column references`, expr);
            }
            if (this.isParameterRef(expr)) {
                return this.getParameterRefClause(expr);
            }
            else if (this.isTableRef(expr)) {
                const table = this.getTableName(expr);
                this.checkRef(table, expr);
                return {
                    evaluate(tables) {
                        return tables[table]?.[column];
                    },
                    getType(schema) {
                        return schema.getType(table, column);
                    }
                };
            }
            else {
                const ref = [expr.table?.schema, expr.table?.name, expr.name]
                    .filter((e) => e != null)
                    .join('.');
                return this.error(`Undefined reference: ${ref}`, expr);
            }
        }
        else if (expr.type == 'binary') {
            const { left, right, op } = expr;
            const leftFilter = this.compileClause(left);
            const rightFilter = this.compileClause(right);
            if (isClauseError(leftFilter) || isClauseError(rightFilter)) {
                return { error: true };
            }
            if (op == 'AND') {
                try {
                    return andFilters(leftFilter, rightFilter);
                }
                catch (e) {
                    return this.error(e.message, expr);
                }
            }
            else if (op == 'OR') {
                try {
                    return orFilters(leftFilter, rightFilter);
                }
                catch (e) {
                    return this.error(e.message, expr);
                }
            }
            else if (op == '=') {
                // Options:
                //  1. row value, row value
                //  2. row value, parameter value
                //  3. static true, parameterMatch - not supported yet
                //  4. parameter value, parameter value
                let staticFilter1;
                let otherFilter1;
                if (this.supports_parameter_expressions &&
                    isParameterValueClause(leftFilter) &&
                    isParameterValueClause(rightFilter)) {
                    // 4. parameterValue, parameterValue
                    // This includes (static value, parameter value)
                    // Not applicable to data queries (composeFunction will error).
                    // Some of those cases can still be handled with case (2),
                    // so we filter for supports_parameter_expressions above.
                    const fnImpl = getOperatorFunction('=');
                    return this.composeFunction(fnImpl, [leftFilter, rightFilter], [left, right]);
                }
                if (!isRowValueClause(leftFilter) && !isRowValueClause(rightFilter)) {
                    return this.error(`Cannot have bucket parameters on both sides of = operator`, expr);
                }
                else if (isRowValueClause(leftFilter)) {
                    staticFilter1 = leftFilter;
                    otherFilter1 = rightFilter;
                }
                else {
                    staticFilter1 = rightFilter;
                    otherFilter1 = leftFilter;
                }
                const staticFilter = staticFilter1;
                const otherFilter = otherFilter1;
                if (isRowValueClause(otherFilter)) {
                    // 1. row value = row value
                    return compileStaticOperator(op, leftFilter, rightFilter);
                }
                else if (isParameterValueClause(otherFilter)) {
                    // 2. row value = parameter value
                    const inputParam = basicInputParameter(otherFilter);
                    return {
                        error: false,
                        inputParameters: [inputParam],
                        unbounded: false,
                        filterRow(tables) {
                            const value = staticFilter.evaluate(tables);
                            if (value == null) {
                                // null never matches on =
                                // Should technically return null, but "false" is sufficient here
                                return MATCH_CONST_FALSE;
                            }
                            if (!isJsonValue(value)) {
                                // Cannot persist this, e.g. BLOB
                                return MATCH_CONST_FALSE;
                            }
                            return [{ [inputParam.key]: value }];
                        },
                        usesAuthenticatedRequestParameters: otherFilter.usesAuthenticatedRequestParameters,
                        usesUnauthenticatedRequestParameters: otherFilter.usesUnauthenticatedRequestParameters
                    };
                }
                else if (isParameterMatchClause(otherFilter)) {
                    // 3. row value = parameterMatch
                    // (bucket.param = 'something') = staticValue
                    // To implement this, we need to ensure the static value here can only be true.
                    return this.error(`Parameter match clauses cannot be used here`, expr);
                }
                else {
                    throw new Error('Unexpected');
                }
            }
            else if (op == 'IN') {
                // Options:
                //  static IN static
                //  parameterValue IN static
                if (isRowValueClause(leftFilter) && isRowValueClause(rightFilter)) {
                    // static1 IN static2
                    return compileStaticOperator(op, leftFilter, rightFilter);
                }
                else if (isParameterValueClause(leftFilter) && isRowValueClause(rightFilter)) {
                    // token_parameters.value IN table.some_array
                    // bucket.param IN table.some_array
                    const inputParam = basicInputParameter(leftFilter);
                    return {
                        error: false,
                        inputParameters: [inputParam],
                        unbounded: true,
                        filterRow(tables) {
                            const aValue = rightFilter.evaluate(tables);
                            if (aValue == null) {
                                return MATCH_CONST_FALSE;
                            }
                            const values = JSON.parse(aValue);
                            if (!Array.isArray(values)) {
                                throw new Error('Not an array');
                            }
                            return values.map((value) => {
                                return { [inputParam.key]: value };
                            });
                        },
                        usesAuthenticatedRequestParameters: leftFilter.usesAuthenticatedRequestParameters,
                        usesUnauthenticatedRequestParameters: leftFilter.usesUnauthenticatedRequestParameters
                    };
                }
                else if (this.supports_expanding_parameters &&
                    isRowValueClause(leftFilter) &&
                    isParameterValueClause(rightFilter)) {
                    // table.some_value IN token_parameters.some_array
                    // This expands into "table_some_value = <value>" for each value of the array.
                    // We only support one such filter per query
                    const key = `${rightFilter.key}[*]`;
                    const inputParam = {
                        key: key,
                        expands: true,
                        filteredRowToLookupValue: (filterParameters) => {
                            return filterParameters[key];
                        },
                        parametersToLookupValue: (parameters) => {
                            return rightFilter.lookupParameterValue(parameters);
                        }
                    };
                    return {
                        error: false,
                        inputParameters: [inputParam],
                        unbounded: false,
                        filterRow(tables) {
                            const value = leftFilter.evaluate(tables);
                            if (!isJsonValue(value)) {
                                // Cannot persist, e.g. BLOB
                                return MATCH_CONST_FALSE;
                            }
                            return [{ [inputParam.key]: value }];
                        },
                        usesAuthenticatedRequestParameters: rightFilter.usesAuthenticatedRequestParameters,
                        usesUnauthenticatedRequestParameters: rightFilter.usesUnauthenticatedRequestParameters
                    };
                }
                else {
                    return this.error(`Unsupported usage of IN operator`, expr);
                }
            }
            else if (BASIC_OPERATORS.has(op)) {
                const fnImpl = getOperatorFunction(op);
                return this.composeFunction(fnImpl, [leftFilter, rightFilter], [left, right]);
            }
            else {
                return this.error(`Operator not supported: ${op}`, expr);
            }
        }
        else if (expr.type == 'unary') {
            if (expr.op == 'NOT') {
                const clause = this.compileClause(expr.operand);
                return this.composeFunction(OPERATOR_NOT, [clause], [expr.operand]);
            }
            else if (expr.op == 'IS NULL') {
                const clause = this.compileClause(expr.operand);
                return this.composeFunction(OPERATOR_IS_NULL, [clause], [expr.operand]);
            }
            else if (expr.op == 'IS NOT NULL') {
                const clause = this.compileClause(expr.operand);
                return this.composeFunction(OPERATOR_IS_NOT_NULL, [clause], [expr.operand]);
            }
            else {
                return this.error(`Operator ${expr.op} is not supported`, expr);
            }
        }
        else if (expr.type == 'call' && expr.function?.name != null) {
            const schema = expr.function.schema; // schema.function()
            const fn = expr.function.name;
            if (schema == null) {
                // Just fn()
                const fnImpl = SQL_FUNCTIONS[fn];
                if (fnImpl == null) {
                    return this.error(`Function '${fn}' is not defined`, expr);
                }
                const argClauses = expr.args.map((arg) => this.compileClause(arg));
                const composed = this.composeFunction(fnImpl, argClauses, expr.args);
                return composed;
            }
            else if (schema == 'request') {
                // Special function
                if (!this.supports_parameter_expressions) {
                    return this.error(`${schema} schema is not available in data queries`, expr);
                }
                if (expr.args.length > 0) {
                    return this.error(`Function '${schema}.${fn}' does not take arguments`, expr);
                }
                if (fn in REQUEST_FUNCTIONS) {
                    const fnImpl = REQUEST_FUNCTIONS[fn];
                    return {
                        key: 'request.parameters()',
                        lookupParameterValue(parameters) {
                            return fnImpl.call(parameters);
                        },
                        usesAuthenticatedRequestParameters: fnImpl.usesAuthenticatedRequestParameters,
                        usesUnauthenticatedRequestParameters: fnImpl.usesUnauthenticatedRequestParameters
                    };
                }
                else {
                    return this.error(`Function '${schema}.${fn}' is not defined`, expr);
                }
            }
            else {
                // Unknown function with schema
                return this.error(`Function '${schema}.${fn}' is not defined`, expr);
            }
        }
        else if (expr.type == 'member') {
            const operand = this.compileClause(expr.operand);
            if (!(typeof expr.member == 'string' && (expr.op == '->>' || expr.op == '->'))) {
                return this.error(`Unsupported member operation ${expr.op}`, expr);
            }
            const debugArgs = [expr.operand, expr];
            const args = [operand, staticValueClause(expr.member)];
            if (expr.op == '->') {
                return this.composeFunction(OPERATOR_JSON_EXTRACT_JSON, args, debugArgs);
            }
            else {
                return this.composeFunction(OPERATOR_JSON_EXTRACT_SQL, args, debugArgs);
            }
        }
        else if (expr.type == 'cast') {
            const operand = this.compileClause(expr.operand);
            const to = expr.to?.name?.toLowerCase();
            const castFn = castOperator(to);
            if (castFn == null) {
                return this.error(`CAST not supported for '${to}'`, expr);
            }
            return this.composeFunction(castFn, [operand], [expr.operand]);
        }
        else {
            return this.error(`${expr.type} not supported here`, expr);
        }
    }
    /**
     * "some_column" => "some_column"
     * "table.some_column" => "some_column".
     * "some_function() AS some_column" => "some_column"
     * "some_function() some_column" => "some_column"
     * "some_function()" => error
     */
    getOutputName(column) {
        let alias = column.alias?.name;
        if (alias) {
            return alias;
        }
        const expr = column.expr;
        if (expr.type == 'ref') {
            return expr.name;
        }
        throw new SqlRuleError(`alias is required`, this.sql, column.expr);
    }
    getSpecificOutputName(column) {
        const name = this.getOutputName(column);
        if (name == '*') {
            throw new SqlRuleError('* is not supported here - use explicit columns', this.sql, column.expr);
        }
        return name;
    }
    /**
     * Check if an expression is a parameter_table reference.
     */
    isParameterRef(expr) {
        if (expr.type != 'ref') {
            return false;
        }
        return this.parameter_tables.includes(expr.table?.name ?? '');
    }
    /**
     * Check if an expression is a value_tables reference.
     *
     * This means the expression can be evaluated directly on a value row.
     */
    isTableRef(expr) {
        if (expr.type != 'ref') {
            return false;
        }
        try {
            this.getTableName(expr);
            return true;
        }
        catch (e) {
            return false;
        }
    }
    checkRef(table, ref) {
        if (this.schema) {
            const type = this.schema.getType(table, ref.name);
            if (type.typeFlags == TYPE_NONE) {
                this.warn(`Column not found: ${ref.name}`, ref);
            }
        }
    }
    getParameterRefClause(expr) {
        const table = expr.table.name;
        const column = expr.name;
        return {
            key: `${table}.${column}`,
            lookupParameterValue: (parameters) => {
                const pt = parameters[table];
                return pt?.[column] ?? null;
            },
            usesAuthenticatedRequestParameters: table == 'token_parameters',
            usesUnauthenticatedRequestParameters: table == 'user_parameters'
        };
    }
    refHasSchema(ref) {
        return ref.table?.schema != null;
    }
    /**
     * Get the table name from an expression.
     *
     * Only "value" tables are supported here, not parameter values.
     */
    getTableName(ref) {
        if (this.refHasSchema(ref)) {
            throw new SqlRuleError(`Specifying schema in column references is not supported`, this.sql, ref);
        }
        if (ref.table?.name == null && this.default_table != null) {
            return this.default_table;
        }
        else if (this.value_tables.includes(ref.table?.name ?? '')) {
            return ref.table.name;
        }
        else if (ref.table?.name == null) {
            throw new SqlRuleError(`Table name required`, this.sql, ref);
        }
        else {
            throw new SqlRuleError(`Undefined table ${ref.table?.name}`, this.sql, ref);
        }
    }
    /**
     * Given a function, compile a clause with the function over compiled arguments.
     *
     * For functions with multiple arguments, the following combinations are supported:
     * fn(StaticValueClause, StaticValueClause) => StaticValueClause
     * fn(ParameterValueClause, ParameterValueClause) => ParameterValueClause
     * fn(RowValueClause, RowValueClause) => RowValueClause
     * fn(ParameterValueClause, StaticValueClause) => ParameterValueClause
     * fn(RowValueClause, StaticValueClause) => RowValueClause
     *
     * This is not supported, and will likely never be supported:
     * fn(ParameterValueClause, RowValueClause) => error
     *
     * @param fnImpl The function or operator implementation
     * @param argClauses The compiled argument clauses
     * @param debugArgExpressions The original parsed expressions, for debug info only
     * @returns a compiled function clause
     */
    composeFunction(fnImpl, argClauses, debugArgExpressions) {
        let argsType = 'static';
        for (let i = 0; i < argClauses.length; i++) {
            const debugArg = debugArgExpressions[i];
            const clause = argClauses[i];
            if (isClauseError(clause)) {
                // Return immediately on error
                return clause;
            }
            else if (isStaticValueClause(clause)) ;
            else if (isParameterValueClause(clause)) {
                if (!this.supports_parameter_expressions) {
                    return this.error(`Cannot use bucket parameters in expressions`, debugArg);
                }
                if (argsType == 'static' || argsType == 'param') {
                    argsType = 'param';
                }
                else {
                    return this.error(`Cannot use table values and parameters in the same clauses`, debugArg);
                }
            }
            else if (isRowValueClause(clause)) {
                if (argsType == 'static' || argsType == 'row') {
                    argsType = 'row';
                }
                else {
                    return this.error(`Cannot use table values and parameters in the same clauses`, debugArg);
                }
            }
            else {
                return this.error(`Parameter match clauses cannot be used here`, debugArg);
            }
        }
        if (argsType == 'row' || argsType == 'static') {
            return {
                evaluate: (tables) => {
                    const args = argClauses.map((e) => e.evaluate(tables));
                    return fnImpl.call(...args);
                },
                getType(schema) {
                    const argTypes = argClauses.map((e) => e.getType(schema));
                    return fnImpl.getReturnType(argTypes);
                }
            };
        }
        else if (argsType == 'param') {
            const argStrings = argClauses.map((e) => e.key);
            const name = `${fnImpl.debugName}(${argStrings.join(',')})`;
            const usesAuthenticatedRequestParameters = argClauses.find((clause) => isParameterValueClause(clause) && clause.usesAuthenticatedRequestParameters) !=
                null;
            const usesUnauthenticatedRequestParameters = argClauses.find((clause) => isParameterValueClause(clause) && clause.usesUnauthenticatedRequestParameters) !=
                null;
            return {
                key: name,
                lookupParameterValue: (parameters) => {
                    const args = argClauses.map((e) => {
                        if (isParameterValueClause(e)) {
                            return e.lookupParameterValue(parameters);
                        }
                        else if (isStaticValueClause(e)) {
                            return e.value;
                        }
                        else {
                            throw new Error('unreachable condition');
                        }
                    });
                    return fnImpl.call(...args);
                },
                usesAuthenticatedRequestParameters,
                usesUnauthenticatedRequestParameters
            };
        }
        else {
            throw new Error('unreachable condition');
        }
    }
    parameterFunction() { }
}
function isStatic(expr) {
    return ['integer', 'string', 'numeric', 'boolean', 'null'].includes(expr.type);
}
function staticValue(expr) {
    if (expr.type == 'boolean') {
        return expr.value ? SQLITE_TRUE : SQLITE_FALSE;
    }
    else if (expr.type == 'integer') {
        return BigInt(expr.value);
    }
    else {
        return expr.value;
    }
}
function staticValueClause(value) {
    return {
        value: value,
        // RowValueClause compatibility
        evaluate: () => value,
        getType() {
            return ExpressionType.fromTypeText(sqliteTypeOf(value));
        },
        // ParamterValueClause compatibility
        key: JSONBig.stringify(value),
        lookupParameterValue(_parameters) {
            return value;
        },
        usesAuthenticatedRequestParameters: false,
        usesUnauthenticatedRequestParameters: false
    };
}
function basicInputParameter(clause) {
    return {
        key: clause.key,
        expands: false,
        filteredRowToLookupValue: (filterParameters) => {
            return filterParameters[clause.key];
        },
        parametersToLookupValue: (parameters) => {
            return clause.lookupParameterValue(parameters);
        }
    };
}

var ajv$1 = {exports: {}};

var core$2 = {};

var validate = {};

var boolSchema = {};

var errors = {};

var codegen = {};

var code$1 = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.regexpCode = exports.getEsmExportName = exports.getProperty = exports.safeStringify = exports.stringify = exports.strConcat = exports.addCodeArg = exports.str = exports._ = exports.nil = exports._Code = exports.Name = exports.IDENTIFIER = exports._CodeOrName = void 0;
	class _CodeOrName {
	}
	exports._CodeOrName = _CodeOrName;
	exports.IDENTIFIER = /^[a-z$_][a-z$_0-9]*$/i;
	class Name extends _CodeOrName {
	    constructor(s) {
	        super();
	        if (!exports.IDENTIFIER.test(s))
	            throw new Error("CodeGen: name must be a valid identifier");
	        this.str = s;
	    }
	    toString() {
	        return this.str;
	    }
	    emptyStr() {
	        return false;
	    }
	    get names() {
	        return { [this.str]: 1 };
	    }
	}
	exports.Name = Name;
	class _Code extends _CodeOrName {
	    constructor(code) {
	        super();
	        this._items = typeof code === "string" ? [code] : code;
	    }
	    toString() {
	        return this.str;
	    }
	    emptyStr() {
	        if (this._items.length > 1)
	            return false;
	        const item = this._items[0];
	        return item === "" || item === '""';
	    }
	    get str() {
	        var _a;
	        return ((_a = this._str) !== null && _a !== void 0 ? _a : (this._str = this._items.reduce((s, c) => `${s}${c}`, "")));
	    }
	    get names() {
	        var _a;
	        return ((_a = this._names) !== null && _a !== void 0 ? _a : (this._names = this._items.reduce((names, c) => {
	            if (c instanceof Name)
	                names[c.str] = (names[c.str] || 0) + 1;
	            return names;
	        }, {})));
	    }
	}
	exports._Code = _Code;
	exports.nil = new _Code("");
	function _(strs, ...args) {
	    const code = [strs[0]];
	    let i = 0;
	    while (i < args.length) {
	        addCodeArg(code, args[i]);
	        code.push(strs[++i]);
	    }
	    return new _Code(code);
	}
	exports._ = _;
	const plus = new _Code("+");
	function str(strs, ...args) {
	    const expr = [safeStringify(strs[0])];
	    let i = 0;
	    while (i < args.length) {
	        expr.push(plus);
	        addCodeArg(expr, args[i]);
	        expr.push(plus, safeStringify(strs[++i]));
	    }
	    optimize(expr);
	    return new _Code(expr);
	}
	exports.str = str;
	function addCodeArg(code, arg) {
	    if (arg instanceof _Code)
	        code.push(...arg._items);
	    else if (arg instanceof Name)
	        code.push(arg);
	    else
	        code.push(interpolate(arg));
	}
	exports.addCodeArg = addCodeArg;
	function optimize(expr) {
	    let i = 1;
	    while (i < expr.length - 1) {
	        if (expr[i] === plus) {
	            const res = mergeExprItems(expr[i - 1], expr[i + 1]);
	            if (res !== undefined) {
	                expr.splice(i - 1, 3, res);
	                continue;
	            }
	            expr[i++] = "+";
	        }
	        i++;
	    }
	}
	function mergeExprItems(a, b) {
	    if (b === '""')
	        return a;
	    if (a === '""')
	        return b;
	    if (typeof a == "string") {
	        if (b instanceof Name || a[a.length - 1] !== '"')
	            return;
	        if (typeof b != "string")
	            return `${a.slice(0, -1)}${b}"`;
	        if (b[0] === '"')
	            return a.slice(0, -1) + b.slice(1);
	        return;
	    }
	    if (typeof b == "string" && b[0] === '"' && !(a instanceof Name))
	        return `"${a}${b.slice(1)}`;
	    return;
	}
	function strConcat(c1, c2) {
	    return c2.emptyStr() ? c1 : c1.emptyStr() ? c2 : str `${c1}${c2}`;
	}
	exports.strConcat = strConcat;
	// TODO do not allow arrays here
	function interpolate(x) {
	    return typeof x == "number" || typeof x == "boolean" || x === null
	        ? x
	        : safeStringify(Array.isArray(x) ? x.join(",") : x);
	}
	function stringify(x) {
	    return new _Code(safeStringify(x));
	}
	exports.stringify = stringify;
	function safeStringify(x) {
	    return JSON.stringify(x)
	        .replace(/\u2028/g, "\\u2028")
	        .replace(/\u2029/g, "\\u2029");
	}
	exports.safeStringify = safeStringify;
	function getProperty(key) {
	    return typeof key == "string" && exports.IDENTIFIER.test(key) ? new _Code(`.${key}`) : _ `[${key}]`;
	}
	exports.getProperty = getProperty;
	//Does best effort to format the name properly
	function getEsmExportName(key) {
	    if (typeof key == "string" && exports.IDENTIFIER.test(key)) {
	        return new _Code(`${key}`);
	    }
	    throw new Error(`CodeGen: invalid export name: ${key}, use explicit $id name mapping`);
	}
	exports.getEsmExportName = getEsmExportName;
	function regexpCode(rx) {
	    return new _Code(rx.toString());
	}
	exports.regexpCode = regexpCode;
	
} (code$1));

var scope = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.ValueScope = exports.ValueScopeName = exports.Scope = exports.varKinds = exports.UsedValueState = void 0;
	const code_1 = code$1;
	class ValueError extends Error {
	    constructor(name) {
	        super(`CodeGen: "code" for ${name} not defined`);
	        this.value = name.value;
	    }
	}
	var UsedValueState;
	(function (UsedValueState) {
	    UsedValueState[UsedValueState["Started"] = 0] = "Started";
	    UsedValueState[UsedValueState["Completed"] = 1] = "Completed";
	})(UsedValueState = exports.UsedValueState || (exports.UsedValueState = {}));
	exports.varKinds = {
	    const: new code_1.Name("const"),
	    let: new code_1.Name("let"),
	    var: new code_1.Name("var"),
	};
	class Scope {
	    constructor({ prefixes, parent } = {}) {
	        this._names = {};
	        this._prefixes = prefixes;
	        this._parent = parent;
	    }
	    toName(nameOrPrefix) {
	        return nameOrPrefix instanceof code_1.Name ? nameOrPrefix : this.name(nameOrPrefix);
	    }
	    name(prefix) {
	        return new code_1.Name(this._newName(prefix));
	    }
	    _newName(prefix) {
	        const ng = this._names[prefix] || this._nameGroup(prefix);
	        return `${prefix}${ng.index++}`;
	    }
	    _nameGroup(prefix) {
	        var _a, _b;
	        if (((_b = (_a = this._parent) === null || _a === void 0 ? void 0 : _a._prefixes) === null || _b === void 0 ? void 0 : _b.has(prefix)) || (this._prefixes && !this._prefixes.has(prefix))) {
	            throw new Error(`CodeGen: prefix "${prefix}" is not allowed in this scope`);
	        }
	        return (this._names[prefix] = { prefix, index: 0 });
	    }
	}
	exports.Scope = Scope;
	class ValueScopeName extends code_1.Name {
	    constructor(prefix, nameStr) {
	        super(nameStr);
	        this.prefix = prefix;
	    }
	    setValue(value, { property, itemIndex }) {
	        this.value = value;
	        this.scopePath = (0, code_1._) `.${new code_1.Name(property)}[${itemIndex}]`;
	    }
	}
	exports.ValueScopeName = ValueScopeName;
	const line = (0, code_1._) `\n`;
	class ValueScope extends Scope {
	    constructor(opts) {
	        super(opts);
	        this._values = {};
	        this._scope = opts.scope;
	        this.opts = { ...opts, _n: opts.lines ? line : code_1.nil };
	    }
	    get() {
	        return this._scope;
	    }
	    name(prefix) {
	        return new ValueScopeName(prefix, this._newName(prefix));
	    }
	    value(nameOrPrefix, value) {
	        var _a;
	        if (value.ref === undefined)
	            throw new Error("CodeGen: ref must be passed in value");
	        const name = this.toName(nameOrPrefix);
	        const { prefix } = name;
	        const valueKey = (_a = value.key) !== null && _a !== void 0 ? _a : value.ref;
	        let vs = this._values[prefix];
	        if (vs) {
	            const _name = vs.get(valueKey);
	            if (_name)
	                return _name;
	        }
	        else {
	            vs = this._values[prefix] = new Map();
	        }
	        vs.set(valueKey, name);
	        const s = this._scope[prefix] || (this._scope[prefix] = []);
	        const itemIndex = s.length;
	        s[itemIndex] = value.ref;
	        name.setValue(value, { property: prefix, itemIndex });
	        return name;
	    }
	    getValue(prefix, keyOrRef) {
	        const vs = this._values[prefix];
	        if (!vs)
	            return;
	        return vs.get(keyOrRef);
	    }
	    scopeRefs(scopeName, values = this._values) {
	        return this._reduceValues(values, (name) => {
	            if (name.scopePath === undefined)
	                throw new Error(`CodeGen: name "${name}" has no value`);
	            return (0, code_1._) `${scopeName}${name.scopePath}`;
	        });
	    }
	    scopeCode(values = this._values, usedValues, getCode) {
	        return this._reduceValues(values, (name) => {
	            if (name.value === undefined)
	                throw new Error(`CodeGen: name "${name}" has no value`);
	            return name.value.code;
	        }, usedValues, getCode);
	    }
	    _reduceValues(values, valueCode, usedValues = {}, getCode) {
	        let code = code_1.nil;
	        for (const prefix in values) {
	            const vs = values[prefix];
	            if (!vs)
	                continue;
	            const nameSet = (usedValues[prefix] = usedValues[prefix] || new Map());
	            vs.forEach((name) => {
	                if (nameSet.has(name))
	                    return;
	                nameSet.set(name, UsedValueState.Started);
	                let c = valueCode(name);
	                if (c) {
	                    const def = this.opts.es5 ? exports.varKinds.var : exports.varKinds.const;
	                    code = (0, code_1._) `${code}${def} ${name} = ${c};${this.opts._n}`;
	                }
	                else if ((c = getCode === null || getCode === void 0 ? void 0 : getCode(name))) {
	                    code = (0, code_1._) `${code}${c}${this.opts._n}`;
	                }
	                else {
	                    throw new ValueError(name);
	                }
	                nameSet.set(name, UsedValueState.Completed);
	            });
	        }
	        return code;
	    }
	}
	exports.ValueScope = ValueScope;
	
} (scope));

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.or = exports.and = exports.not = exports.CodeGen = exports.operators = exports.varKinds = exports.ValueScopeName = exports.ValueScope = exports.Scope = exports.Name = exports.regexpCode = exports.stringify = exports.getProperty = exports.nil = exports.strConcat = exports.str = exports._ = void 0;
	const code_1 = code$1;
	const scope_1 = scope;
	var code_2 = code$1;
	Object.defineProperty(exports, "_", { enumerable: true, get: function () { return code_2._; } });
	Object.defineProperty(exports, "str", { enumerable: true, get: function () { return code_2.str; } });
	Object.defineProperty(exports, "strConcat", { enumerable: true, get: function () { return code_2.strConcat; } });
	Object.defineProperty(exports, "nil", { enumerable: true, get: function () { return code_2.nil; } });
	Object.defineProperty(exports, "getProperty", { enumerable: true, get: function () { return code_2.getProperty; } });
	Object.defineProperty(exports, "stringify", { enumerable: true, get: function () { return code_2.stringify; } });
	Object.defineProperty(exports, "regexpCode", { enumerable: true, get: function () { return code_2.regexpCode; } });
	Object.defineProperty(exports, "Name", { enumerable: true, get: function () { return code_2.Name; } });
	var scope_2 = scope;
	Object.defineProperty(exports, "Scope", { enumerable: true, get: function () { return scope_2.Scope; } });
	Object.defineProperty(exports, "ValueScope", { enumerable: true, get: function () { return scope_2.ValueScope; } });
	Object.defineProperty(exports, "ValueScopeName", { enumerable: true, get: function () { return scope_2.ValueScopeName; } });
	Object.defineProperty(exports, "varKinds", { enumerable: true, get: function () { return scope_2.varKinds; } });
	exports.operators = {
	    GT: new code_1._Code(">"),
	    GTE: new code_1._Code(">="),
	    LT: new code_1._Code("<"),
	    LTE: new code_1._Code("<="),
	    EQ: new code_1._Code("==="),
	    NEQ: new code_1._Code("!=="),
	    NOT: new code_1._Code("!"),
	    OR: new code_1._Code("||"),
	    AND: new code_1._Code("&&"),
	    ADD: new code_1._Code("+"),
	};
	class Node {
	    optimizeNodes() {
	        return this;
	    }
	    optimizeNames(_names, _constants) {
	        return this;
	    }
	}
	class Def extends Node {
	    constructor(varKind, name, rhs) {
	        super();
	        this.varKind = varKind;
	        this.name = name;
	        this.rhs = rhs;
	    }
	    render({ es5, _n }) {
	        const varKind = es5 ? scope_1.varKinds.var : this.varKind;
	        const rhs = this.rhs === undefined ? "" : ` = ${this.rhs}`;
	        return `${varKind} ${this.name}${rhs};` + _n;
	    }
	    optimizeNames(names, constants) {
	        if (!names[this.name.str])
	            return;
	        if (this.rhs)
	            this.rhs = optimizeExpr(this.rhs, names, constants);
	        return this;
	    }
	    get names() {
	        return this.rhs instanceof code_1._CodeOrName ? this.rhs.names : {};
	    }
	}
	class Assign extends Node {
	    constructor(lhs, rhs, sideEffects) {
	        super();
	        this.lhs = lhs;
	        this.rhs = rhs;
	        this.sideEffects = sideEffects;
	    }
	    render({ _n }) {
	        return `${this.lhs} = ${this.rhs};` + _n;
	    }
	    optimizeNames(names, constants) {
	        if (this.lhs instanceof code_1.Name && !names[this.lhs.str] && !this.sideEffects)
	            return;
	        this.rhs = optimizeExpr(this.rhs, names, constants);
	        return this;
	    }
	    get names() {
	        const names = this.lhs instanceof code_1.Name ? {} : { ...this.lhs.names };
	        return addExprNames(names, this.rhs);
	    }
	}
	class AssignOp extends Assign {
	    constructor(lhs, op, rhs, sideEffects) {
	        super(lhs, rhs, sideEffects);
	        this.op = op;
	    }
	    render({ _n }) {
	        return `${this.lhs} ${this.op}= ${this.rhs};` + _n;
	    }
	}
	class Label extends Node {
	    constructor(label) {
	        super();
	        this.label = label;
	        this.names = {};
	    }
	    render({ _n }) {
	        return `${this.label}:` + _n;
	    }
	}
	class Break extends Node {
	    constructor(label) {
	        super();
	        this.label = label;
	        this.names = {};
	    }
	    render({ _n }) {
	        const label = this.label ? ` ${this.label}` : "";
	        return `break${label};` + _n;
	    }
	}
	class Throw extends Node {
	    constructor(error) {
	        super();
	        this.error = error;
	    }
	    render({ _n }) {
	        return `throw ${this.error};` + _n;
	    }
	    get names() {
	        return this.error.names;
	    }
	}
	class AnyCode extends Node {
	    constructor(code) {
	        super();
	        this.code = code;
	    }
	    render({ _n }) {
	        return `${this.code};` + _n;
	    }
	    optimizeNodes() {
	        return `${this.code}` ? this : undefined;
	    }
	    optimizeNames(names, constants) {
	        this.code = optimizeExpr(this.code, names, constants);
	        return this;
	    }
	    get names() {
	        return this.code instanceof code_1._CodeOrName ? this.code.names : {};
	    }
	}
	class ParentNode extends Node {
	    constructor(nodes = []) {
	        super();
	        this.nodes = nodes;
	    }
	    render(opts) {
	        return this.nodes.reduce((code, n) => code + n.render(opts), "");
	    }
	    optimizeNodes() {
	        const { nodes } = this;
	        let i = nodes.length;
	        while (i--) {
	            const n = nodes[i].optimizeNodes();
	            if (Array.isArray(n))
	                nodes.splice(i, 1, ...n);
	            else if (n)
	                nodes[i] = n;
	            else
	                nodes.splice(i, 1);
	        }
	        return nodes.length > 0 ? this : undefined;
	    }
	    optimizeNames(names, constants) {
	        const { nodes } = this;
	        let i = nodes.length;
	        while (i--) {
	            // iterating backwards improves 1-pass optimization
	            const n = nodes[i];
	            if (n.optimizeNames(names, constants))
	                continue;
	            subtractNames(names, n.names);
	            nodes.splice(i, 1);
	        }
	        return nodes.length > 0 ? this : undefined;
	    }
	    get names() {
	        return this.nodes.reduce((names, n) => addNames(names, n.names), {});
	    }
	}
	class BlockNode extends ParentNode {
	    render(opts) {
	        return "{" + opts._n + super.render(opts) + "}" + opts._n;
	    }
	}
	class Root extends ParentNode {
	}
	class Else extends BlockNode {
	}
	Else.kind = "else";
	class If extends BlockNode {
	    constructor(condition, nodes) {
	        super(nodes);
	        this.condition = condition;
	    }
	    render(opts) {
	        let code = `if(${this.condition})` + super.render(opts);
	        if (this.else)
	            code += "else " + this.else.render(opts);
	        return code;
	    }
	    optimizeNodes() {
	        super.optimizeNodes();
	        const cond = this.condition;
	        if (cond === true)
	            return this.nodes; // else is ignored here
	        let e = this.else;
	        if (e) {
	            const ns = e.optimizeNodes();
	            e = this.else = Array.isArray(ns) ? new Else(ns) : ns;
	        }
	        if (e) {
	            if (cond === false)
	                return e instanceof If ? e : e.nodes;
	            if (this.nodes.length)
	                return this;
	            return new If(not(cond), e instanceof If ? [e] : e.nodes);
	        }
	        if (cond === false || !this.nodes.length)
	            return undefined;
	        return this;
	    }
	    optimizeNames(names, constants) {
	        var _a;
	        this.else = (_a = this.else) === null || _a === void 0 ? void 0 : _a.optimizeNames(names, constants);
	        if (!(super.optimizeNames(names, constants) || this.else))
	            return;
	        this.condition = optimizeExpr(this.condition, names, constants);
	        return this;
	    }
	    get names() {
	        const names = super.names;
	        addExprNames(names, this.condition);
	        if (this.else)
	            addNames(names, this.else.names);
	        return names;
	    }
	}
	If.kind = "if";
	class For extends BlockNode {
	}
	For.kind = "for";
	class ForLoop extends For {
	    constructor(iteration) {
	        super();
	        this.iteration = iteration;
	    }
	    render(opts) {
	        return `for(${this.iteration})` + super.render(opts);
	    }
	    optimizeNames(names, constants) {
	        if (!super.optimizeNames(names, constants))
	            return;
	        this.iteration = optimizeExpr(this.iteration, names, constants);
	        return this;
	    }
	    get names() {
	        return addNames(super.names, this.iteration.names);
	    }
	}
	class ForRange extends For {
	    constructor(varKind, name, from, to) {
	        super();
	        this.varKind = varKind;
	        this.name = name;
	        this.from = from;
	        this.to = to;
	    }
	    render(opts) {
	        const varKind = opts.es5 ? scope_1.varKinds.var : this.varKind;
	        const { name, from, to } = this;
	        return `for(${varKind} ${name}=${from}; ${name}<${to}; ${name}++)` + super.render(opts);
	    }
	    get names() {
	        const names = addExprNames(super.names, this.from);
	        return addExprNames(names, this.to);
	    }
	}
	class ForIter extends For {
	    constructor(loop, varKind, name, iterable) {
	        super();
	        this.loop = loop;
	        this.varKind = varKind;
	        this.name = name;
	        this.iterable = iterable;
	    }
	    render(opts) {
	        return `for(${this.varKind} ${this.name} ${this.loop} ${this.iterable})` + super.render(opts);
	    }
	    optimizeNames(names, constants) {
	        if (!super.optimizeNames(names, constants))
	            return;
	        this.iterable = optimizeExpr(this.iterable, names, constants);
	        return this;
	    }
	    get names() {
	        return addNames(super.names, this.iterable.names);
	    }
	}
	class Func extends BlockNode {
	    constructor(name, args, async) {
	        super();
	        this.name = name;
	        this.args = args;
	        this.async = async;
	    }
	    render(opts) {
	        const _async = this.async ? "async " : "";
	        return `${_async}function ${this.name}(${this.args})` + super.render(opts);
	    }
	}
	Func.kind = "func";
	class Return extends ParentNode {
	    render(opts) {
	        return "return " + super.render(opts);
	    }
	}
	Return.kind = "return";
	class Try extends BlockNode {
	    render(opts) {
	        let code = "try" + super.render(opts);
	        if (this.catch)
	            code += this.catch.render(opts);
	        if (this.finally)
	            code += this.finally.render(opts);
	        return code;
	    }
	    optimizeNodes() {
	        var _a, _b;
	        super.optimizeNodes();
	        (_a = this.catch) === null || _a === void 0 ? void 0 : _a.optimizeNodes();
	        (_b = this.finally) === null || _b === void 0 ? void 0 : _b.optimizeNodes();
	        return this;
	    }
	    optimizeNames(names, constants) {
	        var _a, _b;
	        super.optimizeNames(names, constants);
	        (_a = this.catch) === null || _a === void 0 ? void 0 : _a.optimizeNames(names, constants);
	        (_b = this.finally) === null || _b === void 0 ? void 0 : _b.optimizeNames(names, constants);
	        return this;
	    }
	    get names() {
	        const names = super.names;
	        if (this.catch)
	            addNames(names, this.catch.names);
	        if (this.finally)
	            addNames(names, this.finally.names);
	        return names;
	    }
	}
	class Catch extends BlockNode {
	    constructor(error) {
	        super();
	        this.error = error;
	    }
	    render(opts) {
	        return `catch(${this.error})` + super.render(opts);
	    }
	}
	Catch.kind = "catch";
	class Finally extends BlockNode {
	    render(opts) {
	        return "finally" + super.render(opts);
	    }
	}
	Finally.kind = "finally";
	class CodeGen {
	    constructor(extScope, opts = {}) {
	        this._values = {};
	        this._blockStarts = [];
	        this._constants = {};
	        this.opts = { ...opts, _n: opts.lines ? "\n" : "" };
	        this._extScope = extScope;
	        this._scope = new scope_1.Scope({ parent: extScope });
	        this._nodes = [new Root()];
	    }
	    toString() {
	        return this._root.render(this.opts);
	    }
	    // returns unique name in the internal scope
	    name(prefix) {
	        return this._scope.name(prefix);
	    }
	    // reserves unique name in the external scope
	    scopeName(prefix) {
	        return this._extScope.name(prefix);
	    }
	    // reserves unique name in the external scope and assigns value to it
	    scopeValue(prefixOrName, value) {
	        const name = this._extScope.value(prefixOrName, value);
	        const vs = this._values[name.prefix] || (this._values[name.prefix] = new Set());
	        vs.add(name);
	        return name;
	    }
	    getScopeValue(prefix, keyOrRef) {
	        return this._extScope.getValue(prefix, keyOrRef);
	    }
	    // return code that assigns values in the external scope to the names that are used internally
	    // (same names that were returned by gen.scopeName or gen.scopeValue)
	    scopeRefs(scopeName) {
	        return this._extScope.scopeRefs(scopeName, this._values);
	    }
	    scopeCode() {
	        return this._extScope.scopeCode(this._values);
	    }
	    _def(varKind, nameOrPrefix, rhs, constant) {
	        const name = this._scope.toName(nameOrPrefix);
	        if (rhs !== undefined && constant)
	            this._constants[name.str] = rhs;
	        this._leafNode(new Def(varKind, name, rhs));
	        return name;
	    }
	    // `const` declaration (`var` in es5 mode)
	    const(nameOrPrefix, rhs, _constant) {
	        return this._def(scope_1.varKinds.const, nameOrPrefix, rhs, _constant);
	    }
	    // `let` declaration with optional assignment (`var` in es5 mode)
	    let(nameOrPrefix, rhs, _constant) {
	        return this._def(scope_1.varKinds.let, nameOrPrefix, rhs, _constant);
	    }
	    // `var` declaration with optional assignment
	    var(nameOrPrefix, rhs, _constant) {
	        return this._def(scope_1.varKinds.var, nameOrPrefix, rhs, _constant);
	    }
	    // assignment code
	    assign(lhs, rhs, sideEffects) {
	        return this._leafNode(new Assign(lhs, rhs, sideEffects));
	    }
	    // `+=` code
	    add(lhs, rhs) {
	        return this._leafNode(new AssignOp(lhs, exports.operators.ADD, rhs));
	    }
	    // appends passed SafeExpr to code or executes Block
	    code(c) {
	        if (typeof c == "function")
	            c();
	        else if (c !== code_1.nil)
	            this._leafNode(new AnyCode(c));
	        return this;
	    }
	    // returns code for object literal for the passed argument list of key-value pairs
	    object(...keyValues) {
	        const code = ["{"];
	        for (const [key, value] of keyValues) {
	            if (code.length > 1)
	                code.push(",");
	            code.push(key);
	            if (key !== value || this.opts.es5) {
	                code.push(":");
	                (0, code_1.addCodeArg)(code, value);
	            }
	        }
	        code.push("}");
	        return new code_1._Code(code);
	    }
	    // `if` clause (or statement if `thenBody` and, optionally, `elseBody` are passed)
	    if(condition, thenBody, elseBody) {
	        this._blockNode(new If(condition));
	        if (thenBody && elseBody) {
	            this.code(thenBody).else().code(elseBody).endIf();
	        }
	        else if (thenBody) {
	            this.code(thenBody).endIf();
	        }
	        else if (elseBody) {
	            throw new Error('CodeGen: "else" body without "then" body');
	        }
	        return this;
	    }
	    // `else if` clause - invalid without `if` or after `else` clauses
	    elseIf(condition) {
	        return this._elseNode(new If(condition));
	    }
	    // `else` clause - only valid after `if` or `else if` clauses
	    else() {
	        return this._elseNode(new Else());
	    }
	    // end `if` statement (needed if gen.if was used only with condition)
	    endIf() {
	        return this._endBlockNode(If, Else);
	    }
	    _for(node, forBody) {
	        this._blockNode(node);
	        if (forBody)
	            this.code(forBody).endFor();
	        return this;
	    }
	    // a generic `for` clause (or statement if `forBody` is passed)
	    for(iteration, forBody) {
	        return this._for(new ForLoop(iteration), forBody);
	    }
	    // `for` statement for a range of values
	    forRange(nameOrPrefix, from, to, forBody, varKind = this.opts.es5 ? scope_1.varKinds.var : scope_1.varKinds.let) {
	        const name = this._scope.toName(nameOrPrefix);
	        return this._for(new ForRange(varKind, name, from, to), () => forBody(name));
	    }
	    // `for-of` statement (in es5 mode replace with a normal for loop)
	    forOf(nameOrPrefix, iterable, forBody, varKind = scope_1.varKinds.const) {
	        const name = this._scope.toName(nameOrPrefix);
	        if (this.opts.es5) {
	            const arr = iterable instanceof code_1.Name ? iterable : this.var("_arr", iterable);
	            return this.forRange("_i", 0, (0, code_1._) `${arr}.length`, (i) => {
	                this.var(name, (0, code_1._) `${arr}[${i}]`);
	                forBody(name);
	            });
	        }
	        return this._for(new ForIter("of", varKind, name, iterable), () => forBody(name));
	    }
	    // `for-in` statement.
	    // With option `ownProperties` replaced with a `for-of` loop for object keys
	    forIn(nameOrPrefix, obj, forBody, varKind = this.opts.es5 ? scope_1.varKinds.var : scope_1.varKinds.const) {
	        if (this.opts.ownProperties) {
	            return this.forOf(nameOrPrefix, (0, code_1._) `Object.keys(${obj})`, forBody);
	        }
	        const name = this._scope.toName(nameOrPrefix);
	        return this._for(new ForIter("in", varKind, name, obj), () => forBody(name));
	    }
	    // end `for` loop
	    endFor() {
	        return this._endBlockNode(For);
	    }
	    // `label` statement
	    label(label) {
	        return this._leafNode(new Label(label));
	    }
	    // `break` statement
	    break(label) {
	        return this._leafNode(new Break(label));
	    }
	    // `return` statement
	    return(value) {
	        const node = new Return();
	        this._blockNode(node);
	        this.code(value);
	        if (node.nodes.length !== 1)
	            throw new Error('CodeGen: "return" should have one node');
	        return this._endBlockNode(Return);
	    }
	    // `try` statement
	    try(tryBody, catchCode, finallyCode) {
	        if (!catchCode && !finallyCode)
	            throw new Error('CodeGen: "try" without "catch" and "finally"');
	        const node = new Try();
	        this._blockNode(node);
	        this.code(tryBody);
	        if (catchCode) {
	            const error = this.name("e");
	            this._currNode = node.catch = new Catch(error);
	            catchCode(error);
	        }
	        if (finallyCode) {
	            this._currNode = node.finally = new Finally();
	            this.code(finallyCode);
	        }
	        return this._endBlockNode(Catch, Finally);
	    }
	    // `throw` statement
	    throw(error) {
	        return this._leafNode(new Throw(error));
	    }
	    // start self-balancing block
	    block(body, nodeCount) {
	        this._blockStarts.push(this._nodes.length);
	        if (body)
	            this.code(body).endBlock(nodeCount);
	        return this;
	    }
	    // end the current self-balancing block
	    endBlock(nodeCount) {
	        const len = this._blockStarts.pop();
	        if (len === undefined)
	            throw new Error("CodeGen: not in self-balancing block");
	        const toClose = this._nodes.length - len;
	        if (toClose < 0 || (nodeCount !== undefined && toClose !== nodeCount)) {
	            throw new Error(`CodeGen: wrong number of nodes: ${toClose} vs ${nodeCount} expected`);
	        }
	        this._nodes.length = len;
	        return this;
	    }
	    // `function` heading (or definition if funcBody is passed)
	    func(name, args = code_1.nil, async, funcBody) {
	        this._blockNode(new Func(name, args, async));
	        if (funcBody)
	            this.code(funcBody).endFunc();
	        return this;
	    }
	    // end function definition
	    endFunc() {
	        return this._endBlockNode(Func);
	    }
	    optimize(n = 1) {
	        while (n-- > 0) {
	            this._root.optimizeNodes();
	            this._root.optimizeNames(this._root.names, this._constants);
	        }
	    }
	    _leafNode(node) {
	        this._currNode.nodes.push(node);
	        return this;
	    }
	    _blockNode(node) {
	        this._currNode.nodes.push(node);
	        this._nodes.push(node);
	    }
	    _endBlockNode(N1, N2) {
	        const n = this._currNode;
	        if (n instanceof N1 || (N2 && n instanceof N2)) {
	            this._nodes.pop();
	            return this;
	        }
	        throw new Error(`CodeGen: not in block "${N2 ? `${N1.kind}/${N2.kind}` : N1.kind}"`);
	    }
	    _elseNode(node) {
	        const n = this._currNode;
	        if (!(n instanceof If)) {
	            throw new Error('CodeGen: "else" without "if"');
	        }
	        this._currNode = n.else = node;
	        return this;
	    }
	    get _root() {
	        return this._nodes[0];
	    }
	    get _currNode() {
	        const ns = this._nodes;
	        return ns[ns.length - 1];
	    }
	    set _currNode(node) {
	        const ns = this._nodes;
	        ns[ns.length - 1] = node;
	    }
	}
	exports.CodeGen = CodeGen;
	function addNames(names, from) {
	    for (const n in from)
	        names[n] = (names[n] || 0) + (from[n] || 0);
	    return names;
	}
	function addExprNames(names, from) {
	    return from instanceof code_1._CodeOrName ? addNames(names, from.names) : names;
	}
	function optimizeExpr(expr, names, constants) {
	    if (expr instanceof code_1.Name)
	        return replaceName(expr);
	    if (!canOptimize(expr))
	        return expr;
	    return new code_1._Code(expr._items.reduce((items, c) => {
	        if (c instanceof code_1.Name)
	            c = replaceName(c);
	        if (c instanceof code_1._Code)
	            items.push(...c._items);
	        else
	            items.push(c);
	        return items;
	    }, []));
	    function replaceName(n) {
	        const c = constants[n.str];
	        if (c === undefined || names[n.str] !== 1)
	            return n;
	        delete names[n.str];
	        return c;
	    }
	    function canOptimize(e) {
	        return (e instanceof code_1._Code &&
	            e._items.some((c) => c instanceof code_1.Name && names[c.str] === 1 && constants[c.str] !== undefined));
	    }
	}
	function subtractNames(names, from) {
	    for (const n in from)
	        names[n] = (names[n] || 0) - (from[n] || 0);
	}
	function not(x) {
	    return typeof x == "boolean" || typeof x == "number" || x === null ? !x : (0, code_1._) `!${par(x)}`;
	}
	exports.not = not;
	const andCode = mappend(exports.operators.AND);
	// boolean AND (&&) expression with the passed arguments
	function and(...args) {
	    return args.reduce(andCode);
	}
	exports.and = and;
	const orCode = mappend(exports.operators.OR);
	// boolean OR (||) expression with the passed arguments
	function or(...args) {
	    return args.reduce(orCode);
	}
	exports.or = or;
	function mappend(op) {
	    return (x, y) => (x === code_1.nil ? y : y === code_1.nil ? x : (0, code_1._) `${par(x)} ${op} ${par(y)}`);
	}
	function par(x) {
	    return x instanceof code_1.Name ? x : (0, code_1._) `(${x})`;
	}
	
} (codegen));

var util = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.checkStrictMode = exports.getErrorPath = exports.Type = exports.useFunc = exports.setEvaluated = exports.evaluatedPropsToName = exports.mergeEvaluated = exports.eachItem = exports.unescapeJsonPointer = exports.escapeJsonPointer = exports.escapeFragment = exports.unescapeFragment = exports.schemaRefOrVal = exports.schemaHasRulesButRef = exports.schemaHasRules = exports.checkUnknownRules = exports.alwaysValidSchema = exports.toHash = void 0;
	const codegen_1 = codegen;
	const code_1 = code$1;
	// TODO refactor to use Set
	function toHash(arr) {
	    const hash = {};
	    for (const item of arr)
	        hash[item] = true;
	    return hash;
	}
	exports.toHash = toHash;
	function alwaysValidSchema(it, schema) {
	    if (typeof schema == "boolean")
	        return schema;
	    if (Object.keys(schema).length === 0)
	        return true;
	    checkUnknownRules(it, schema);
	    return !schemaHasRules(schema, it.self.RULES.all);
	}
	exports.alwaysValidSchema = alwaysValidSchema;
	function checkUnknownRules(it, schema = it.schema) {
	    const { opts, self } = it;
	    if (!opts.strictSchema)
	        return;
	    if (typeof schema === "boolean")
	        return;
	    const rules = self.RULES.keywords;
	    for (const key in schema) {
	        if (!rules[key])
	            checkStrictMode(it, `unknown keyword: "${key}"`);
	    }
	}
	exports.checkUnknownRules = checkUnknownRules;
	function schemaHasRules(schema, rules) {
	    if (typeof schema == "boolean")
	        return !schema;
	    for (const key in schema)
	        if (rules[key])
	            return true;
	    return false;
	}
	exports.schemaHasRules = schemaHasRules;
	function schemaHasRulesButRef(schema, RULES) {
	    if (typeof schema == "boolean")
	        return !schema;
	    for (const key in schema)
	        if (key !== "$ref" && RULES.all[key])
	            return true;
	    return false;
	}
	exports.schemaHasRulesButRef = schemaHasRulesButRef;
	function schemaRefOrVal({ topSchemaRef, schemaPath }, schema, keyword, $data) {
	    if (!$data) {
	        if (typeof schema == "number" || typeof schema == "boolean")
	            return schema;
	        if (typeof schema == "string")
	            return (0, codegen_1._) `${schema}`;
	    }
	    return (0, codegen_1._) `${topSchemaRef}${schemaPath}${(0, codegen_1.getProperty)(keyword)}`;
	}
	exports.schemaRefOrVal = schemaRefOrVal;
	function unescapeFragment(str) {
	    return unescapeJsonPointer(decodeURIComponent(str));
	}
	exports.unescapeFragment = unescapeFragment;
	function escapeFragment(str) {
	    return encodeURIComponent(escapeJsonPointer(str));
	}
	exports.escapeFragment = escapeFragment;
	function escapeJsonPointer(str) {
	    if (typeof str == "number")
	        return `${str}`;
	    return str.replace(/~/g, "~0").replace(/\//g, "~1");
	}
	exports.escapeJsonPointer = escapeJsonPointer;
	function unescapeJsonPointer(str) {
	    return str.replace(/~1/g, "/").replace(/~0/g, "~");
	}
	exports.unescapeJsonPointer = unescapeJsonPointer;
	function eachItem(xs, f) {
	    if (Array.isArray(xs)) {
	        for (const x of xs)
	            f(x);
	    }
	    else {
	        f(xs);
	    }
	}
	exports.eachItem = eachItem;
	function makeMergeEvaluated({ mergeNames, mergeToName, mergeValues, resultToName, }) {
	    return (gen, from, to, toName) => {
	        const res = to === undefined
	            ? from
	            : to instanceof codegen_1.Name
	                ? (from instanceof codegen_1.Name ? mergeNames(gen, from, to) : mergeToName(gen, from, to), to)
	                : from instanceof codegen_1.Name
	                    ? (mergeToName(gen, to, from), from)
	                    : mergeValues(from, to);
	        return toName === codegen_1.Name && !(res instanceof codegen_1.Name) ? resultToName(gen, res) : res;
	    };
	}
	exports.mergeEvaluated = {
	    props: makeMergeEvaluated({
	        mergeNames: (gen, from, to) => gen.if((0, codegen_1._) `${to} !== true && ${from} !== undefined`, () => {
	            gen.if((0, codegen_1._) `${from} === true`, () => gen.assign(to, true), () => gen.assign(to, (0, codegen_1._) `${to} || {}`).code((0, codegen_1._) `Object.assign(${to}, ${from})`));
	        }),
	        mergeToName: (gen, from, to) => gen.if((0, codegen_1._) `${to} !== true`, () => {
	            if (from === true) {
	                gen.assign(to, true);
	            }
	            else {
	                gen.assign(to, (0, codegen_1._) `${to} || {}`);
	                setEvaluated(gen, to, from);
	            }
	        }),
	        mergeValues: (from, to) => (from === true ? true : { ...from, ...to }),
	        resultToName: evaluatedPropsToName,
	    }),
	    items: makeMergeEvaluated({
	        mergeNames: (gen, from, to) => gen.if((0, codegen_1._) `${to} !== true && ${from} !== undefined`, () => gen.assign(to, (0, codegen_1._) `${from} === true ? true : ${to} > ${from} ? ${to} : ${from}`)),
	        mergeToName: (gen, from, to) => gen.if((0, codegen_1._) `${to} !== true`, () => gen.assign(to, from === true ? true : (0, codegen_1._) `${to} > ${from} ? ${to} : ${from}`)),
	        mergeValues: (from, to) => (from === true ? true : Math.max(from, to)),
	        resultToName: (gen, items) => gen.var("items", items),
	    }),
	};
	function evaluatedPropsToName(gen, ps) {
	    if (ps === true)
	        return gen.var("props", true);
	    const props = gen.var("props", (0, codegen_1._) `{}`);
	    if (ps !== undefined)
	        setEvaluated(gen, props, ps);
	    return props;
	}
	exports.evaluatedPropsToName = evaluatedPropsToName;
	function setEvaluated(gen, props, ps) {
	    Object.keys(ps).forEach((p) => gen.assign((0, codegen_1._) `${props}${(0, codegen_1.getProperty)(p)}`, true));
	}
	exports.setEvaluated = setEvaluated;
	const snippets = {};
	function useFunc(gen, f) {
	    return gen.scopeValue("func", {
	        ref: f,
	        code: snippets[f.code] || (snippets[f.code] = new code_1._Code(f.code)),
	    });
	}
	exports.useFunc = useFunc;
	var Type;
	(function (Type) {
	    Type[Type["Num"] = 0] = "Num";
	    Type[Type["Str"] = 1] = "Str";
	})(Type = exports.Type || (exports.Type = {}));
	function getErrorPath(dataProp, dataPropType, jsPropertySyntax) {
	    // let path
	    if (dataProp instanceof codegen_1.Name) {
	        const isNumber = dataPropType === Type.Num;
	        return jsPropertySyntax
	            ? isNumber
	                ? (0, codegen_1._) `"[" + ${dataProp} + "]"`
	                : (0, codegen_1._) `"['" + ${dataProp} + "']"`
	            : isNumber
	                ? (0, codegen_1._) `"/" + ${dataProp}`
	                : (0, codegen_1._) `"/" + ${dataProp}.replace(/~/g, "~0").replace(/\\//g, "~1")`; // TODO maybe use global escapePointer
	    }
	    return jsPropertySyntax ? (0, codegen_1.getProperty)(dataProp).toString() : "/" + escapeJsonPointer(dataProp);
	}
	exports.getErrorPath = getErrorPath;
	function checkStrictMode(it, msg, mode = it.opts.strictSchema) {
	    if (!mode)
	        return;
	    msg = `strict mode: ${msg}`;
	    if (mode === true)
	        throw new Error(msg);
	    it.self.logger.warn(msg);
	}
	exports.checkStrictMode = checkStrictMode;
	
} (util));

var names$1 = {};

Object.defineProperty(names$1, "__esModule", { value: true });
const codegen_1$t = codegen;
const names = {
    // validation function arguments
    data: new codegen_1$t.Name("data"),
    // args passed from referencing schema
    valCxt: new codegen_1$t.Name("valCxt"),
    instancePath: new codegen_1$t.Name("instancePath"),
    parentData: new codegen_1$t.Name("parentData"),
    parentDataProperty: new codegen_1$t.Name("parentDataProperty"),
    rootData: new codegen_1$t.Name("rootData"),
    dynamicAnchors: new codegen_1$t.Name("dynamicAnchors"),
    // function scoped variables
    vErrors: new codegen_1$t.Name("vErrors"),
    errors: new codegen_1$t.Name("errors"),
    this: new codegen_1$t.Name("this"),
    // "globals"
    self: new codegen_1$t.Name("self"),
    scope: new codegen_1$t.Name("scope"),
    // JTD serialize/parse name for JSON string and position
    json: new codegen_1$t.Name("json"),
    jsonPos: new codegen_1$t.Name("jsonPos"),
    jsonLen: new codegen_1$t.Name("jsonLen"),
    jsonPart: new codegen_1$t.Name("jsonPart"),
};
names$1.default = names;

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.extendErrors = exports.resetErrorsCount = exports.reportExtraError = exports.reportError = exports.keyword$DataError = exports.keywordError = void 0;
	const codegen_1 = codegen;
	const util_1 = util;
	const names_1 = names$1;
	exports.keywordError = {
	    message: ({ keyword }) => (0, codegen_1.str) `must pass "${keyword}" keyword validation`,
	};
	exports.keyword$DataError = {
	    message: ({ keyword, schemaType }) => schemaType
	        ? (0, codegen_1.str) `"${keyword}" keyword must be ${schemaType} ($data)`
	        : (0, codegen_1.str) `"${keyword}" keyword is invalid ($data)`,
	};
	function reportError(cxt, error = exports.keywordError, errorPaths, overrideAllErrors) {
	    const { it } = cxt;
	    const { gen, compositeRule, allErrors } = it;
	    const errObj = errorObjectCode(cxt, error, errorPaths);
	    if (overrideAllErrors !== null && overrideAllErrors !== void 0 ? overrideAllErrors : (compositeRule || allErrors)) {
	        addError(gen, errObj);
	    }
	    else {
	        returnErrors(it, (0, codegen_1._) `[${errObj}]`);
	    }
	}
	exports.reportError = reportError;
	function reportExtraError(cxt, error = exports.keywordError, errorPaths) {
	    const { it } = cxt;
	    const { gen, compositeRule, allErrors } = it;
	    const errObj = errorObjectCode(cxt, error, errorPaths);
	    addError(gen, errObj);
	    if (!(compositeRule || allErrors)) {
	        returnErrors(it, names_1.default.vErrors);
	    }
	}
	exports.reportExtraError = reportExtraError;
	function resetErrorsCount(gen, errsCount) {
	    gen.assign(names_1.default.errors, errsCount);
	    gen.if((0, codegen_1._) `${names_1.default.vErrors} !== null`, () => gen.if(errsCount, () => gen.assign((0, codegen_1._) `${names_1.default.vErrors}.length`, errsCount), () => gen.assign(names_1.default.vErrors, null)));
	}
	exports.resetErrorsCount = resetErrorsCount;
	function extendErrors({ gen, keyword, schemaValue, data, errsCount, it, }) {
	    /* istanbul ignore if */
	    if (errsCount === undefined)
	        throw new Error("ajv implementation error");
	    const err = gen.name("err");
	    gen.forRange("i", errsCount, names_1.default.errors, (i) => {
	        gen.const(err, (0, codegen_1._) `${names_1.default.vErrors}[${i}]`);
	        gen.if((0, codegen_1._) `${err}.instancePath === undefined`, () => gen.assign((0, codegen_1._) `${err}.instancePath`, (0, codegen_1.strConcat)(names_1.default.instancePath, it.errorPath)));
	        gen.assign((0, codegen_1._) `${err}.schemaPath`, (0, codegen_1.str) `${it.errSchemaPath}/${keyword}`);
	        if (it.opts.verbose) {
	            gen.assign((0, codegen_1._) `${err}.schema`, schemaValue);
	            gen.assign((0, codegen_1._) `${err}.data`, data);
	        }
	    });
	}
	exports.extendErrors = extendErrors;
	function addError(gen, errObj) {
	    const err = gen.const("err", errObj);
	    gen.if((0, codegen_1._) `${names_1.default.vErrors} === null`, () => gen.assign(names_1.default.vErrors, (0, codegen_1._) `[${err}]`), (0, codegen_1._) `${names_1.default.vErrors}.push(${err})`);
	    gen.code((0, codegen_1._) `${names_1.default.errors}++`);
	}
	function returnErrors(it, errs) {
	    const { gen, validateName, schemaEnv } = it;
	    if (schemaEnv.$async) {
	        gen.throw((0, codegen_1._) `new ${it.ValidationError}(${errs})`);
	    }
	    else {
	        gen.assign((0, codegen_1._) `${validateName}.errors`, errs);
	        gen.return(false);
	    }
	}
	const E = {
	    keyword: new codegen_1.Name("keyword"),
	    schemaPath: new codegen_1.Name("schemaPath"),
	    params: new codegen_1.Name("params"),
	    propertyName: new codegen_1.Name("propertyName"),
	    message: new codegen_1.Name("message"),
	    schema: new codegen_1.Name("schema"),
	    parentSchema: new codegen_1.Name("parentSchema"),
	};
	function errorObjectCode(cxt, error, errorPaths) {
	    const { createErrors } = cxt.it;
	    if (createErrors === false)
	        return (0, codegen_1._) `{}`;
	    return errorObject(cxt, error, errorPaths);
	}
	function errorObject(cxt, error, errorPaths = {}) {
	    const { gen, it } = cxt;
	    const keyValues = [
	        errorInstancePath(it, errorPaths),
	        errorSchemaPath(cxt, errorPaths),
	    ];
	    extraErrorProps(cxt, error, keyValues);
	    return gen.object(...keyValues);
	}
	function errorInstancePath({ errorPath }, { instancePath }) {
	    const instPath = instancePath
	        ? (0, codegen_1.str) `${errorPath}${(0, util_1.getErrorPath)(instancePath, util_1.Type.Str)}`
	        : errorPath;
	    return [names_1.default.instancePath, (0, codegen_1.strConcat)(names_1.default.instancePath, instPath)];
	}
	function errorSchemaPath({ keyword, it: { errSchemaPath } }, { schemaPath, parentSchema }) {
	    let schPath = parentSchema ? errSchemaPath : (0, codegen_1.str) `${errSchemaPath}/${keyword}`;
	    if (schemaPath) {
	        schPath = (0, codegen_1.str) `${schPath}${(0, util_1.getErrorPath)(schemaPath, util_1.Type.Str)}`;
	    }
	    return [E.schemaPath, schPath];
	}
	function extraErrorProps(cxt, { params, message }, keyValues) {
	    const { keyword, data, schemaValue, it } = cxt;
	    const { opts, propertyName, topSchemaRef, schemaPath } = it;
	    keyValues.push([E.keyword, keyword], [E.params, typeof params == "function" ? params(cxt) : params || (0, codegen_1._) `{}`]);
	    if (opts.messages) {
	        keyValues.push([E.message, typeof message == "function" ? message(cxt) : message]);
	    }
	    if (opts.verbose) {
	        keyValues.push([E.schema, schemaValue], [E.parentSchema, (0, codegen_1._) `${topSchemaRef}${schemaPath}`], [names_1.default.data, data]);
	    }
	    if (propertyName)
	        keyValues.push([E.propertyName, propertyName]);
	}
	
} (errors));

Object.defineProperty(boolSchema, "__esModule", { value: true });
boolSchema.boolOrEmptySchema = boolSchema.topBoolOrEmptySchema = void 0;
const errors_1$2 = errors;
const codegen_1$s = codegen;
const names_1$6 = names$1;
const boolError = {
    message: "boolean schema is false",
};
function topBoolOrEmptySchema(it) {
    const { gen, schema, validateName } = it;
    if (schema === false) {
        falseSchemaError(it, false);
    }
    else if (typeof schema == "object" && schema.$async === true) {
        gen.return(names_1$6.default.data);
    }
    else {
        gen.assign((0, codegen_1$s._) `${validateName}.errors`, null);
        gen.return(true);
    }
}
boolSchema.topBoolOrEmptySchema = topBoolOrEmptySchema;
function boolOrEmptySchema(it, valid) {
    const { gen, schema } = it;
    if (schema === false) {
        gen.var(valid, false); // TODO var
        falseSchemaError(it);
    }
    else {
        gen.var(valid, true); // TODO var
    }
}
boolSchema.boolOrEmptySchema = boolOrEmptySchema;
function falseSchemaError(it, overrideAllErrors) {
    const { gen, data } = it;
    // TODO maybe some other interface should be used for non-keyword validation errors...
    const cxt = {
        gen,
        keyword: "false schema",
        data,
        schema: false,
        schemaCode: false,
        schemaValue: false,
        params: {},
        it,
    };
    (0, errors_1$2.reportError)(cxt, boolError, undefined, overrideAllErrors);
}

var dataType = {};

var rules = {};

Object.defineProperty(rules, "__esModule", { value: true });
rules.getRules = rules.isJSONType = void 0;
const _jsonTypes = ["string", "number", "integer", "boolean", "null", "object", "array"];
const jsonTypes = new Set(_jsonTypes);
function isJSONType(x) {
    return typeof x == "string" && jsonTypes.has(x);
}
rules.isJSONType = isJSONType;
function getRules() {
    const groups = {
        number: { type: "number", rules: [] },
        string: { type: "string", rules: [] },
        array: { type: "array", rules: [] },
        object: { type: "object", rules: [] },
    };
    return {
        types: { ...groups, integer: true, boolean: true, null: true },
        rules: [{ rules: [] }, groups.number, groups.string, groups.array, groups.object],
        post: { rules: [] },
        all: {},
        keywords: {},
    };
}
rules.getRules = getRules;

var applicability = {};

Object.defineProperty(applicability, "__esModule", { value: true });
applicability.shouldUseRule = applicability.shouldUseGroup = applicability.schemaHasRulesForType = void 0;
function schemaHasRulesForType({ schema, self }, type) {
    const group = self.RULES.types[type];
    return group && group !== true && shouldUseGroup(schema, group);
}
applicability.schemaHasRulesForType = schemaHasRulesForType;
function shouldUseGroup(schema, group) {
    return group.rules.some((rule) => shouldUseRule(schema, rule));
}
applicability.shouldUseGroup = shouldUseGroup;
function shouldUseRule(schema, rule) {
    var _a;
    return (schema[rule.keyword] !== undefined ||
        ((_a = rule.definition.implements) === null || _a === void 0 ? void 0 : _a.some((kwd) => schema[kwd] !== undefined)));
}
applicability.shouldUseRule = shouldUseRule;

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.reportTypeError = exports.checkDataTypes = exports.checkDataType = exports.coerceAndCheckDataType = exports.getJSONTypes = exports.getSchemaTypes = exports.DataType = void 0;
	const rules_1 = rules;
	const applicability_1 = applicability;
	const errors_1 = errors;
	const codegen_1 = codegen;
	const util_1 = util;
	var DataType;
	(function (DataType) {
	    DataType[DataType["Correct"] = 0] = "Correct";
	    DataType[DataType["Wrong"] = 1] = "Wrong";
	})(DataType = exports.DataType || (exports.DataType = {}));
	function getSchemaTypes(schema) {
	    const types = getJSONTypes(schema.type);
	    const hasNull = types.includes("null");
	    if (hasNull) {
	        if (schema.nullable === false)
	            throw new Error("type: null contradicts nullable: false");
	    }
	    else {
	        if (!types.length && schema.nullable !== undefined) {
	            throw new Error('"nullable" cannot be used without "type"');
	        }
	        if (schema.nullable === true)
	            types.push("null");
	    }
	    return types;
	}
	exports.getSchemaTypes = getSchemaTypes;
	function getJSONTypes(ts) {
	    const types = Array.isArray(ts) ? ts : ts ? [ts] : [];
	    if (types.every(rules_1.isJSONType))
	        return types;
	    throw new Error("type must be JSONType or JSONType[]: " + types.join(","));
	}
	exports.getJSONTypes = getJSONTypes;
	function coerceAndCheckDataType(it, types) {
	    const { gen, data, opts } = it;
	    const coerceTo = coerceToTypes(types, opts.coerceTypes);
	    const checkTypes = types.length > 0 &&
	        !(coerceTo.length === 0 && types.length === 1 && (0, applicability_1.schemaHasRulesForType)(it, types[0]));
	    if (checkTypes) {
	        const wrongType = checkDataTypes(types, data, opts.strictNumbers, DataType.Wrong);
	        gen.if(wrongType, () => {
	            if (coerceTo.length)
	                coerceData(it, types, coerceTo);
	            else
	                reportTypeError(it);
	        });
	    }
	    return checkTypes;
	}
	exports.coerceAndCheckDataType = coerceAndCheckDataType;
	const COERCIBLE = new Set(["string", "number", "integer", "boolean", "null"]);
	function coerceToTypes(types, coerceTypes) {
	    return coerceTypes
	        ? types.filter((t) => COERCIBLE.has(t) || (coerceTypes === "array" && t === "array"))
	        : [];
	}
	function coerceData(it, types, coerceTo) {
	    const { gen, data, opts } = it;
	    const dataType = gen.let("dataType", (0, codegen_1._) `typeof ${data}`);
	    const coerced = gen.let("coerced", (0, codegen_1._) `undefined`);
	    if (opts.coerceTypes === "array") {
	        gen.if((0, codegen_1._) `${dataType} == 'object' && Array.isArray(${data}) && ${data}.length == 1`, () => gen
	            .assign(data, (0, codegen_1._) `${data}[0]`)
	            .assign(dataType, (0, codegen_1._) `typeof ${data}`)
	            .if(checkDataTypes(types, data, opts.strictNumbers), () => gen.assign(coerced, data)));
	    }
	    gen.if((0, codegen_1._) `${coerced} !== undefined`);
	    for (const t of coerceTo) {
	        if (COERCIBLE.has(t) || (t === "array" && opts.coerceTypes === "array")) {
	            coerceSpecificType(t);
	        }
	    }
	    gen.else();
	    reportTypeError(it);
	    gen.endIf();
	    gen.if((0, codegen_1._) `${coerced} !== undefined`, () => {
	        gen.assign(data, coerced);
	        assignParentData(it, coerced);
	    });
	    function coerceSpecificType(t) {
	        switch (t) {
	            case "string":
	                gen
	                    .elseIf((0, codegen_1._) `${dataType} == "number" || ${dataType} == "boolean"`)
	                    .assign(coerced, (0, codegen_1._) `"" + ${data}`)
	                    .elseIf((0, codegen_1._) `${data} === null`)
	                    .assign(coerced, (0, codegen_1._) `""`);
	                return;
	            case "number":
	                gen
	                    .elseIf((0, codegen_1._) `${dataType} == "boolean" || ${data} === null
              || (${dataType} == "string" && ${data} && ${data} == +${data})`)
	                    .assign(coerced, (0, codegen_1._) `+${data}`);
	                return;
	            case "integer":
	                gen
	                    .elseIf((0, codegen_1._) `${dataType} === "boolean" || ${data} === null
              || (${dataType} === "string" && ${data} && ${data} == +${data} && !(${data} % 1))`)
	                    .assign(coerced, (0, codegen_1._) `+${data}`);
	                return;
	            case "boolean":
	                gen
	                    .elseIf((0, codegen_1._) `${data} === "false" || ${data} === 0 || ${data} === null`)
	                    .assign(coerced, false)
	                    .elseIf((0, codegen_1._) `${data} === "true" || ${data} === 1`)
	                    .assign(coerced, true);
	                return;
	            case "null":
	                gen.elseIf((0, codegen_1._) `${data} === "" || ${data} === 0 || ${data} === false`);
	                gen.assign(coerced, null);
	                return;
	            case "array":
	                gen
	                    .elseIf((0, codegen_1._) `${dataType} === "string" || ${dataType} === "number"
              || ${dataType} === "boolean" || ${data} === null`)
	                    .assign(coerced, (0, codegen_1._) `[${data}]`);
	        }
	    }
	}
	function assignParentData({ gen, parentData, parentDataProperty }, expr) {
	    // TODO use gen.property
	    gen.if((0, codegen_1._) `${parentData} !== undefined`, () => gen.assign((0, codegen_1._) `${parentData}[${parentDataProperty}]`, expr));
	}
	function checkDataType(dataType, data, strictNums, correct = DataType.Correct) {
	    const EQ = correct === DataType.Correct ? codegen_1.operators.EQ : codegen_1.operators.NEQ;
	    let cond;
	    switch (dataType) {
	        case "null":
	            return (0, codegen_1._) `${data} ${EQ} null`;
	        case "array":
	            cond = (0, codegen_1._) `Array.isArray(${data})`;
	            break;
	        case "object":
	            cond = (0, codegen_1._) `${data} && typeof ${data} == "object" && !Array.isArray(${data})`;
	            break;
	        case "integer":
	            cond = numCond((0, codegen_1._) `!(${data} % 1) && !isNaN(${data})`);
	            break;
	        case "number":
	            cond = numCond();
	            break;
	        default:
	            return (0, codegen_1._) `typeof ${data} ${EQ} ${dataType}`;
	    }
	    return correct === DataType.Correct ? cond : (0, codegen_1.not)(cond);
	    function numCond(_cond = codegen_1.nil) {
	        return (0, codegen_1.and)((0, codegen_1._) `typeof ${data} == "number"`, _cond, strictNums ? (0, codegen_1._) `isFinite(${data})` : codegen_1.nil);
	    }
	}
	exports.checkDataType = checkDataType;
	function checkDataTypes(dataTypes, data, strictNums, correct) {
	    if (dataTypes.length === 1) {
	        return checkDataType(dataTypes[0], data, strictNums, correct);
	    }
	    let cond;
	    const types = (0, util_1.toHash)(dataTypes);
	    if (types.array && types.object) {
	        const notObj = (0, codegen_1._) `typeof ${data} != "object"`;
	        cond = types.null ? notObj : (0, codegen_1._) `!${data} || ${notObj}`;
	        delete types.null;
	        delete types.array;
	        delete types.object;
	    }
	    else {
	        cond = codegen_1.nil;
	    }
	    if (types.number)
	        delete types.integer;
	    for (const t in types)
	        cond = (0, codegen_1.and)(cond, checkDataType(t, data, strictNums, correct));
	    return cond;
	}
	exports.checkDataTypes = checkDataTypes;
	const typeError = {
	    message: ({ schema }) => `must be ${schema}`,
	    params: ({ schema, schemaValue }) => typeof schema == "string" ? (0, codegen_1._) `{type: ${schema}}` : (0, codegen_1._) `{type: ${schemaValue}}`,
	};
	function reportTypeError(it) {
	    const cxt = getTypeErrorContext(it);
	    (0, errors_1.reportError)(cxt, typeError);
	}
	exports.reportTypeError = reportTypeError;
	function getTypeErrorContext(it) {
	    const { gen, data, schema } = it;
	    const schemaCode = (0, util_1.schemaRefOrVal)(it, schema, "type");
	    return {
	        gen,
	        keyword: "type",
	        data,
	        schema: schema.type,
	        schemaCode,
	        schemaValue: schemaCode,
	        parentSchema: schema,
	        params: {},
	        it,
	    };
	}
	
} (dataType));

var defaults = {};

Object.defineProperty(defaults, "__esModule", { value: true });
defaults.assignDefaults = void 0;
const codegen_1$r = codegen;
const util_1$p = util;
function assignDefaults(it, ty) {
    const { properties, items } = it.schema;
    if (ty === "object" && properties) {
        for (const key in properties) {
            assignDefault(it, key, properties[key].default);
        }
    }
    else if (ty === "array" && Array.isArray(items)) {
        items.forEach((sch, i) => assignDefault(it, i, sch.default));
    }
}
defaults.assignDefaults = assignDefaults;
function assignDefault(it, prop, defaultValue) {
    const { gen, compositeRule, data, opts } = it;
    if (defaultValue === undefined)
        return;
    const childData = (0, codegen_1$r._) `${data}${(0, codegen_1$r.getProperty)(prop)}`;
    if (compositeRule) {
        (0, util_1$p.checkStrictMode)(it, `default is ignored for: ${childData}`);
        return;
    }
    let condition = (0, codegen_1$r._) `${childData} === undefined`;
    if (opts.useDefaults === "empty") {
        condition = (0, codegen_1$r._) `${condition} || ${childData} === null || ${childData} === ""`;
    }
    // `${childData} === undefined` +
    // (opts.useDefaults === "empty" ? ` || ${childData} === null || ${childData} === ""` : "")
    gen.if(condition, (0, codegen_1$r._) `${childData} = ${(0, codegen_1$r.stringify)(defaultValue)}`);
}

var keyword = {};

var code = {};

Object.defineProperty(code, "__esModule", { value: true });
code.validateUnion = code.validateArray = code.usePattern = code.callValidateCode = code.schemaProperties = code.allSchemaProperties = code.noPropertyInData = code.propertyInData = code.isOwnProperty = code.hasPropFunc = code.reportMissingProp = code.checkMissingProp = code.checkReportMissingProp = void 0;
const codegen_1$q = codegen;
const util_1$o = util;
const names_1$5 = names$1;
const util_2$1 = util;
function checkReportMissingProp(cxt, prop) {
    const { gen, data, it } = cxt;
    gen.if(noPropertyInData(gen, data, prop, it.opts.ownProperties), () => {
        cxt.setParams({ missingProperty: (0, codegen_1$q._) `${prop}` }, true);
        cxt.error();
    });
}
code.checkReportMissingProp = checkReportMissingProp;
function checkMissingProp({ gen, data, it: { opts } }, properties, missing) {
    return (0, codegen_1$q.or)(...properties.map((prop) => (0, codegen_1$q.and)(noPropertyInData(gen, data, prop, opts.ownProperties), (0, codegen_1$q._) `${missing} = ${prop}`)));
}
code.checkMissingProp = checkMissingProp;
function reportMissingProp(cxt, missing) {
    cxt.setParams({ missingProperty: missing }, true);
    cxt.error();
}
code.reportMissingProp = reportMissingProp;
function hasPropFunc(gen) {
    return gen.scopeValue("func", {
        // eslint-disable-next-line @typescript-eslint/unbound-method
        ref: Object.prototype.hasOwnProperty,
        code: (0, codegen_1$q._) `Object.prototype.hasOwnProperty`,
    });
}
code.hasPropFunc = hasPropFunc;
function isOwnProperty(gen, data, property) {
    return (0, codegen_1$q._) `${hasPropFunc(gen)}.call(${data}, ${property})`;
}
code.isOwnProperty = isOwnProperty;
function propertyInData(gen, data, property, ownProperties) {
    const cond = (0, codegen_1$q._) `${data}${(0, codegen_1$q.getProperty)(property)} !== undefined`;
    return ownProperties ? (0, codegen_1$q._) `${cond} && ${isOwnProperty(gen, data, property)}` : cond;
}
code.propertyInData = propertyInData;
function noPropertyInData(gen, data, property, ownProperties) {
    const cond = (0, codegen_1$q._) `${data}${(0, codegen_1$q.getProperty)(property)} === undefined`;
    return ownProperties ? (0, codegen_1$q.or)(cond, (0, codegen_1$q.not)(isOwnProperty(gen, data, property))) : cond;
}
code.noPropertyInData = noPropertyInData;
function allSchemaProperties(schemaMap) {
    return schemaMap ? Object.keys(schemaMap).filter((p) => p !== "__proto__") : [];
}
code.allSchemaProperties = allSchemaProperties;
function schemaProperties(it, schemaMap) {
    return allSchemaProperties(schemaMap).filter((p) => !(0, util_1$o.alwaysValidSchema)(it, schemaMap[p]));
}
code.schemaProperties = schemaProperties;
function callValidateCode({ schemaCode, data, it: { gen, topSchemaRef, schemaPath, errorPath }, it }, func, context, passSchema) {
    const dataAndSchema = passSchema ? (0, codegen_1$q._) `${schemaCode}, ${data}, ${topSchemaRef}${schemaPath}` : data;
    const valCxt = [
        [names_1$5.default.instancePath, (0, codegen_1$q.strConcat)(names_1$5.default.instancePath, errorPath)],
        [names_1$5.default.parentData, it.parentData],
        [names_1$5.default.parentDataProperty, it.parentDataProperty],
        [names_1$5.default.rootData, names_1$5.default.rootData],
    ];
    if (it.opts.dynamicRef)
        valCxt.push([names_1$5.default.dynamicAnchors, names_1$5.default.dynamicAnchors]);
    const args = (0, codegen_1$q._) `${dataAndSchema}, ${gen.object(...valCxt)}`;
    return context !== codegen_1$q.nil ? (0, codegen_1$q._) `${func}.call(${context}, ${args})` : (0, codegen_1$q._) `${func}(${args})`;
}
code.callValidateCode = callValidateCode;
const newRegExp = (0, codegen_1$q._) `new RegExp`;
function usePattern({ gen, it: { opts } }, pattern) {
    const u = opts.unicodeRegExp ? "u" : "";
    const { regExp } = opts.code;
    const rx = regExp(pattern, u);
    return gen.scopeValue("pattern", {
        key: rx.toString(),
        ref: rx,
        code: (0, codegen_1$q._) `${regExp.code === "new RegExp" ? newRegExp : (0, util_2$1.useFunc)(gen, regExp)}(${pattern}, ${u})`,
    });
}
code.usePattern = usePattern;
function validateArray(cxt) {
    const { gen, data, keyword, it } = cxt;
    const valid = gen.name("valid");
    if (it.allErrors) {
        const validArr = gen.let("valid", true);
        validateItems(() => gen.assign(validArr, false));
        return validArr;
    }
    gen.var(valid, true);
    validateItems(() => gen.break());
    return valid;
    function validateItems(notValid) {
        const len = gen.const("len", (0, codegen_1$q._) `${data}.length`);
        gen.forRange("i", 0, len, (i) => {
            cxt.subschema({
                keyword,
                dataProp: i,
                dataPropType: util_1$o.Type.Num,
            }, valid);
            gen.if((0, codegen_1$q.not)(valid), notValid);
        });
    }
}
code.validateArray = validateArray;
function validateUnion(cxt) {
    const { gen, schema, keyword, it } = cxt;
    /* istanbul ignore if */
    if (!Array.isArray(schema))
        throw new Error("ajv implementation error");
    const alwaysValid = schema.some((sch) => (0, util_1$o.alwaysValidSchema)(it, sch));
    if (alwaysValid && !it.opts.unevaluated)
        return;
    const valid = gen.let("valid", false);
    const schValid = gen.name("_valid");
    gen.block(() => schema.forEach((_sch, i) => {
        const schCxt = cxt.subschema({
            keyword,
            schemaProp: i,
            compositeRule: true,
        }, schValid);
        gen.assign(valid, (0, codegen_1$q._) `${valid} || ${schValid}`);
        const merged = cxt.mergeValidEvaluated(schCxt, schValid);
        // can short-circuit if `unevaluatedProperties/Items` not supported (opts.unevaluated !== true)
        // or if all properties and items were evaluated (it.props === true && it.items === true)
        if (!merged)
            gen.if((0, codegen_1$q.not)(valid));
    }));
    cxt.result(valid, () => cxt.reset(), () => cxt.error(true));
}
code.validateUnion = validateUnion;

Object.defineProperty(keyword, "__esModule", { value: true });
keyword.validateKeywordUsage = keyword.validSchemaType = keyword.funcKeywordCode = keyword.macroKeywordCode = void 0;
const codegen_1$p = codegen;
const names_1$4 = names$1;
const code_1$9 = code;
const errors_1$1 = errors;
function macroKeywordCode(cxt, def) {
    const { gen, keyword, schema, parentSchema, it } = cxt;
    const macroSchema = def.macro.call(it.self, schema, parentSchema, it);
    const schemaRef = useKeyword(gen, keyword, macroSchema);
    if (it.opts.validateSchema !== false)
        it.self.validateSchema(macroSchema, true);
    const valid = gen.name("valid");
    cxt.subschema({
        schema: macroSchema,
        schemaPath: codegen_1$p.nil,
        errSchemaPath: `${it.errSchemaPath}/${keyword}`,
        topSchemaRef: schemaRef,
        compositeRule: true,
    }, valid);
    cxt.pass(valid, () => cxt.error(true));
}
keyword.macroKeywordCode = macroKeywordCode;
function funcKeywordCode(cxt, def) {
    var _a;
    const { gen, keyword, schema, parentSchema, $data, it } = cxt;
    checkAsyncKeyword(it, def);
    const validate = !$data && def.compile ? def.compile.call(it.self, schema, parentSchema, it) : def.validate;
    const validateRef = useKeyword(gen, keyword, validate);
    const valid = gen.let("valid");
    cxt.block$data(valid, validateKeyword);
    cxt.ok((_a = def.valid) !== null && _a !== void 0 ? _a : valid);
    function validateKeyword() {
        if (def.errors === false) {
            assignValid();
            if (def.modifying)
                modifyData(cxt);
            reportErrs(() => cxt.error());
        }
        else {
            const ruleErrs = def.async ? validateAsync() : validateSync();
            if (def.modifying)
                modifyData(cxt);
            reportErrs(() => addErrs(cxt, ruleErrs));
        }
    }
    function validateAsync() {
        const ruleErrs = gen.let("ruleErrs", null);
        gen.try(() => assignValid((0, codegen_1$p._) `await `), (e) => gen.assign(valid, false).if((0, codegen_1$p._) `${e} instanceof ${it.ValidationError}`, () => gen.assign(ruleErrs, (0, codegen_1$p._) `${e}.errors`), () => gen.throw(e)));
        return ruleErrs;
    }
    function validateSync() {
        const validateErrs = (0, codegen_1$p._) `${validateRef}.errors`;
        gen.assign(validateErrs, null);
        assignValid(codegen_1$p.nil);
        return validateErrs;
    }
    function assignValid(_await = def.async ? (0, codegen_1$p._) `await ` : codegen_1$p.nil) {
        const passCxt = it.opts.passContext ? names_1$4.default.this : names_1$4.default.self;
        const passSchema = !(("compile" in def && !$data) || def.schema === false);
        gen.assign(valid, (0, codegen_1$p._) `${_await}${(0, code_1$9.callValidateCode)(cxt, validateRef, passCxt, passSchema)}`, def.modifying);
    }
    function reportErrs(errors) {
        var _a;
        gen.if((0, codegen_1$p.not)((_a = def.valid) !== null && _a !== void 0 ? _a : valid), errors);
    }
}
keyword.funcKeywordCode = funcKeywordCode;
function modifyData(cxt) {
    const { gen, data, it } = cxt;
    gen.if(it.parentData, () => gen.assign(data, (0, codegen_1$p._) `${it.parentData}[${it.parentDataProperty}]`));
}
function addErrs(cxt, errs) {
    const { gen } = cxt;
    gen.if((0, codegen_1$p._) `Array.isArray(${errs})`, () => {
        gen
            .assign(names_1$4.default.vErrors, (0, codegen_1$p._) `${names_1$4.default.vErrors} === null ? ${errs} : ${names_1$4.default.vErrors}.concat(${errs})`)
            .assign(names_1$4.default.errors, (0, codegen_1$p._) `${names_1$4.default.vErrors}.length`);
        (0, errors_1$1.extendErrors)(cxt);
    }, () => cxt.error());
}
function checkAsyncKeyword({ schemaEnv }, def) {
    if (def.async && !schemaEnv.$async)
        throw new Error("async keyword in sync schema");
}
function useKeyword(gen, keyword, result) {
    if (result === undefined)
        throw new Error(`keyword "${keyword}" failed to compile`);
    return gen.scopeValue("keyword", typeof result == "function" ? { ref: result } : { ref: result, code: (0, codegen_1$p.stringify)(result) });
}
function validSchemaType(schema, schemaType, allowUndefined = false) {
    // TODO add tests
    return (!schemaType.length ||
        schemaType.some((st) => st === "array"
            ? Array.isArray(schema)
            : st === "object"
                ? schema && typeof schema == "object" && !Array.isArray(schema)
                : typeof schema == st || (allowUndefined && typeof schema == "undefined")));
}
keyword.validSchemaType = validSchemaType;
function validateKeywordUsage({ schema, opts, self, errSchemaPath }, def, keyword) {
    /* istanbul ignore if */
    if (Array.isArray(def.keyword) ? !def.keyword.includes(keyword) : def.keyword !== keyword) {
        throw new Error("ajv implementation error");
    }
    const deps = def.dependencies;
    if (deps === null || deps === void 0 ? void 0 : deps.some((kwd) => !Object.prototype.hasOwnProperty.call(schema, kwd))) {
        throw new Error(`parent schema must have dependencies of ${keyword}: ${deps.join(",")}`);
    }
    if (def.validateSchema) {
        const valid = def.validateSchema(schema[keyword]);
        if (!valid) {
            const msg = `keyword "${keyword}" value is invalid at path "${errSchemaPath}": ` +
                self.errorsText(def.validateSchema.errors);
            if (opts.validateSchema === "log")
                self.logger.error(msg);
            else
                throw new Error(msg);
        }
    }
}
keyword.validateKeywordUsage = validateKeywordUsage;

var subschema = {};

Object.defineProperty(subschema, "__esModule", { value: true });
subschema.extendSubschemaMode = subschema.extendSubschemaData = subschema.getSubschema = void 0;
const codegen_1$o = codegen;
const util_1$n = util;
function getSubschema(it, { keyword, schemaProp, schema, schemaPath, errSchemaPath, topSchemaRef }) {
    if (keyword !== undefined && schema !== undefined) {
        throw new Error('both "keyword" and "schema" passed, only one allowed');
    }
    if (keyword !== undefined) {
        const sch = it.schema[keyword];
        return schemaProp === undefined
            ? {
                schema: sch,
                schemaPath: (0, codegen_1$o._) `${it.schemaPath}${(0, codegen_1$o.getProperty)(keyword)}`,
                errSchemaPath: `${it.errSchemaPath}/${keyword}`,
            }
            : {
                schema: sch[schemaProp],
                schemaPath: (0, codegen_1$o._) `${it.schemaPath}${(0, codegen_1$o.getProperty)(keyword)}${(0, codegen_1$o.getProperty)(schemaProp)}`,
                errSchemaPath: `${it.errSchemaPath}/${keyword}/${(0, util_1$n.escapeFragment)(schemaProp)}`,
            };
    }
    if (schema !== undefined) {
        if (schemaPath === undefined || errSchemaPath === undefined || topSchemaRef === undefined) {
            throw new Error('"schemaPath", "errSchemaPath" and "topSchemaRef" are required with "schema"');
        }
        return {
            schema,
            schemaPath,
            topSchemaRef,
            errSchemaPath,
        };
    }
    throw new Error('either "keyword" or "schema" must be passed');
}
subschema.getSubschema = getSubschema;
function extendSubschemaData(subschema, it, { dataProp, dataPropType: dpType, data, dataTypes, propertyName }) {
    if (data !== undefined && dataProp !== undefined) {
        throw new Error('both "data" and "dataProp" passed, only one allowed');
    }
    const { gen } = it;
    if (dataProp !== undefined) {
        const { errorPath, dataPathArr, opts } = it;
        const nextData = gen.let("data", (0, codegen_1$o._) `${it.data}${(0, codegen_1$o.getProperty)(dataProp)}`, true);
        dataContextProps(nextData);
        subschema.errorPath = (0, codegen_1$o.str) `${errorPath}${(0, util_1$n.getErrorPath)(dataProp, dpType, opts.jsPropertySyntax)}`;
        subschema.parentDataProperty = (0, codegen_1$o._) `${dataProp}`;
        subschema.dataPathArr = [...dataPathArr, subschema.parentDataProperty];
    }
    if (data !== undefined) {
        const nextData = data instanceof codegen_1$o.Name ? data : gen.let("data", data, true); // replaceable if used once?
        dataContextProps(nextData);
        if (propertyName !== undefined)
            subschema.propertyName = propertyName;
        // TODO something is possibly wrong here with not changing parentDataProperty and not appending dataPathArr
    }
    if (dataTypes)
        subschema.dataTypes = dataTypes;
    function dataContextProps(_nextData) {
        subschema.data = _nextData;
        subschema.dataLevel = it.dataLevel + 1;
        subschema.dataTypes = [];
        it.definedProperties = new Set();
        subschema.parentData = it.data;
        subschema.dataNames = [...it.dataNames, _nextData];
    }
}
subschema.extendSubschemaData = extendSubschemaData;
function extendSubschemaMode(subschema, { jtdDiscriminator, jtdMetadata, compositeRule, createErrors, allErrors }) {
    if (compositeRule !== undefined)
        subschema.compositeRule = compositeRule;
    if (createErrors !== undefined)
        subschema.createErrors = createErrors;
    if (allErrors !== undefined)
        subschema.allErrors = allErrors;
    subschema.jtdDiscriminator = jtdDiscriminator; // not inherited
    subschema.jtdMetadata = jtdMetadata; // not inherited
}
subschema.extendSubschemaMode = extendSubschemaMode;

var resolve$1 = {};

// do not edit .js files directly - edit src/index.jst



var fastDeepEqual = function equal(a, b) {
  if (a === b) return true;

  if (a && b && typeof a == 'object' && typeof b == 'object') {
    if (a.constructor !== b.constructor) return false;

    var length, i, keys;
    if (Array.isArray(a)) {
      length = a.length;
      if (length != b.length) return false;
      for (i = length; i-- !== 0;)
        if (!equal(a[i], b[i])) return false;
      return true;
    }



    if (a.constructor === RegExp) return a.source === b.source && a.flags === b.flags;
    if (a.valueOf !== Object.prototype.valueOf) return a.valueOf() === b.valueOf();
    if (a.toString !== Object.prototype.toString) return a.toString() === b.toString();

    keys = Object.keys(a);
    length = keys.length;
    if (length !== Object.keys(b).length) return false;

    for (i = length; i-- !== 0;)
      if (!Object.prototype.hasOwnProperty.call(b, keys[i])) return false;

    for (i = length; i-- !== 0;) {
      var key = keys[i];

      if (!equal(a[key], b[key])) return false;
    }

    return true;
  }

  // true if both NaN, false otherwise
  return a!==a && b!==b;
};

var jsonSchemaTraverse = {exports: {}};

var traverse$1 = jsonSchemaTraverse.exports = function (schema, opts, cb) {
  // Legacy support for v0.3.1 and earlier.
  if (typeof opts == 'function') {
    cb = opts;
    opts = {};
  }

  cb = opts.cb || cb;
  var pre = (typeof cb == 'function') ? cb : cb.pre || function() {};
  var post = cb.post || function() {};

  _traverse(opts, pre, post, schema, '', schema);
};


traverse$1.keywords = {
  additionalItems: true,
  items: true,
  contains: true,
  additionalProperties: true,
  propertyNames: true,
  not: true,
  if: true,
  then: true,
  else: true
};

traverse$1.arrayKeywords = {
  items: true,
  allOf: true,
  anyOf: true,
  oneOf: true
};

traverse$1.propsKeywords = {
  $defs: true,
  definitions: true,
  properties: true,
  patternProperties: true,
  dependencies: true
};

traverse$1.skipKeywords = {
  default: true,
  enum: true,
  const: true,
  required: true,
  maximum: true,
  minimum: true,
  exclusiveMaximum: true,
  exclusiveMinimum: true,
  multipleOf: true,
  maxLength: true,
  minLength: true,
  pattern: true,
  format: true,
  maxItems: true,
  minItems: true,
  uniqueItems: true,
  maxProperties: true,
  minProperties: true
};


function _traverse(opts, pre, post, schema, jsonPtr, rootSchema, parentJsonPtr, parentKeyword, parentSchema, keyIndex) {
  if (schema && typeof schema == 'object' && !Array.isArray(schema)) {
    pre(schema, jsonPtr, rootSchema, parentJsonPtr, parentKeyword, parentSchema, keyIndex);
    for (var key in schema) {
      var sch = schema[key];
      if (Array.isArray(sch)) {
        if (key in traverse$1.arrayKeywords) {
          for (var i=0; i<sch.length; i++)
            _traverse(opts, pre, post, sch[i], jsonPtr + '/' + key + '/' + i, rootSchema, jsonPtr, key, schema, i);
        }
      } else if (key in traverse$1.propsKeywords) {
        if (sch && typeof sch == 'object') {
          for (var prop in sch)
            _traverse(opts, pre, post, sch[prop], jsonPtr + '/' + key + '/' + escapeJsonPtr(prop), rootSchema, jsonPtr, key, schema, prop);
        }
      } else if (key in traverse$1.keywords || (opts.allKeys && !(key in traverse$1.skipKeywords))) {
        _traverse(opts, pre, post, sch, jsonPtr + '/' + key, rootSchema, jsonPtr, key, schema);
      }
    }
    post(schema, jsonPtr, rootSchema, parentJsonPtr, parentKeyword, parentSchema, keyIndex);
  }
}


function escapeJsonPtr(str) {
  return str.replace(/~/g, '~0').replace(/\//g, '~1');
}

var jsonSchemaTraverseExports = jsonSchemaTraverse.exports;

Object.defineProperty(resolve$1, "__esModule", { value: true });
resolve$1.getSchemaRefs = resolve$1.resolveUrl = resolve$1.normalizeId = resolve$1._getFullPath = resolve$1.getFullPath = resolve$1.inlineRef = void 0;
const util_1$m = util;
const equal$2 = fastDeepEqual;
const traverse = jsonSchemaTraverseExports;
// TODO refactor to use keyword definitions
const SIMPLE_INLINED = new Set([
    "type",
    "format",
    "pattern",
    "maxLength",
    "minLength",
    "maxProperties",
    "minProperties",
    "maxItems",
    "minItems",
    "maximum",
    "minimum",
    "uniqueItems",
    "multipleOf",
    "required",
    "enum",
    "const",
]);
function inlineRef(schema, limit = true) {
    if (typeof schema == "boolean")
        return true;
    if (limit === true)
        return !hasRef(schema);
    if (!limit)
        return false;
    return countKeys(schema) <= limit;
}
resolve$1.inlineRef = inlineRef;
const REF_KEYWORDS = new Set([
    "$ref",
    "$recursiveRef",
    "$recursiveAnchor",
    "$dynamicRef",
    "$dynamicAnchor",
]);
function hasRef(schema) {
    for (const key in schema) {
        if (REF_KEYWORDS.has(key))
            return true;
        const sch = schema[key];
        if (Array.isArray(sch) && sch.some(hasRef))
            return true;
        if (typeof sch == "object" && hasRef(sch))
            return true;
    }
    return false;
}
function countKeys(schema) {
    let count = 0;
    for (const key in schema) {
        if (key === "$ref")
            return Infinity;
        count++;
        if (SIMPLE_INLINED.has(key))
            continue;
        if (typeof schema[key] == "object") {
            (0, util_1$m.eachItem)(schema[key], (sch) => (count += countKeys(sch)));
        }
        if (count === Infinity)
            return Infinity;
    }
    return count;
}
function getFullPath(resolver, id = "", normalize) {
    if (normalize !== false)
        id = normalizeId(id);
    const p = resolver.parse(id);
    return _getFullPath(resolver, p);
}
resolve$1.getFullPath = getFullPath;
function _getFullPath(resolver, p) {
    const serialized = resolver.serialize(p);
    return serialized.split("#")[0] + "#";
}
resolve$1._getFullPath = _getFullPath;
const TRAILING_SLASH_HASH = /#\/?$/;
function normalizeId(id) {
    return id ? id.replace(TRAILING_SLASH_HASH, "") : "";
}
resolve$1.normalizeId = normalizeId;
function resolveUrl(resolver, baseId, id) {
    id = normalizeId(id);
    return resolver.resolve(baseId, id);
}
resolve$1.resolveUrl = resolveUrl;
const ANCHOR = /^[a-z_][-a-z0-9._]*$/i;
function getSchemaRefs(schema, baseId) {
    if (typeof schema == "boolean")
        return {};
    const { schemaId, uriResolver } = this.opts;
    const schId = normalizeId(schema[schemaId] || baseId);
    const baseIds = { "": schId };
    const pathPrefix = getFullPath(uriResolver, schId, false);
    const localRefs = {};
    const schemaRefs = new Set();
    traverse(schema, { allKeys: true }, (sch, jsonPtr, _, parentJsonPtr) => {
        if (parentJsonPtr === undefined)
            return;
        const fullPath = pathPrefix + jsonPtr;
        let baseId = baseIds[parentJsonPtr];
        if (typeof sch[schemaId] == "string")
            baseId = addRef.call(this, sch[schemaId]);
        addAnchor.call(this, sch.$anchor);
        addAnchor.call(this, sch.$dynamicAnchor);
        baseIds[jsonPtr] = baseId;
        function addRef(ref) {
            // eslint-disable-next-line @typescript-eslint/unbound-method
            const _resolve = this.opts.uriResolver.resolve;
            ref = normalizeId(baseId ? _resolve(baseId, ref) : ref);
            if (schemaRefs.has(ref))
                throw ambiguos(ref);
            schemaRefs.add(ref);
            let schOrRef = this.refs[ref];
            if (typeof schOrRef == "string")
                schOrRef = this.refs[schOrRef];
            if (typeof schOrRef == "object") {
                checkAmbiguosRef(sch, schOrRef.schema, ref);
            }
            else if (ref !== normalizeId(fullPath)) {
                if (ref[0] === "#") {
                    checkAmbiguosRef(sch, localRefs[ref], ref);
                    localRefs[ref] = sch;
                }
                else {
                    this.refs[ref] = fullPath;
                }
            }
            return ref;
        }
        function addAnchor(anchor) {
            if (typeof anchor == "string") {
                if (!ANCHOR.test(anchor))
                    throw new Error(`invalid anchor "${anchor}"`);
                addRef.call(this, `#${anchor}`);
            }
        }
    });
    return localRefs;
    function checkAmbiguosRef(sch1, sch2, ref) {
        if (sch2 !== undefined && !equal$2(sch1, sch2))
            throw ambiguos(ref);
    }
    function ambiguos(ref) {
        return new Error(`reference "${ref}" resolves to more than one schema`);
    }
}
resolve$1.getSchemaRefs = getSchemaRefs;

Object.defineProperty(validate, "__esModule", { value: true });
validate.getData = validate.KeywordCxt = validate.validateFunctionCode = void 0;
const boolSchema_1 = boolSchema;
const dataType_1$1 = dataType;
const applicability_1 = applicability;
const dataType_2 = dataType;
const defaults_1 = defaults;
const keyword_1 = keyword;
const subschema_1 = subschema;
const codegen_1$n = codegen;
const names_1$3 = names$1;
const resolve_1$2 = resolve$1;
const util_1$l = util;
const errors_1 = errors;
// schema compilation - generates validation function, subschemaCode (below) is used for subschemas
function validateFunctionCode(it) {
    if (isSchemaObj(it)) {
        checkKeywords(it);
        if (schemaCxtHasRules(it)) {
            topSchemaObjCode(it);
            return;
        }
    }
    validateFunction(it, () => (0, boolSchema_1.topBoolOrEmptySchema)(it));
}
validate.validateFunctionCode = validateFunctionCode;
function validateFunction({ gen, validateName, schema, schemaEnv, opts }, body) {
    if (opts.code.es5) {
        gen.func(validateName, (0, codegen_1$n._) `${names_1$3.default.data}, ${names_1$3.default.valCxt}`, schemaEnv.$async, () => {
            gen.code((0, codegen_1$n._) `"use strict"; ${funcSourceUrl(schema, opts)}`);
            destructureValCxtES5(gen, opts);
            gen.code(body);
        });
    }
    else {
        gen.func(validateName, (0, codegen_1$n._) `${names_1$3.default.data}, ${destructureValCxt(opts)}`, schemaEnv.$async, () => gen.code(funcSourceUrl(schema, opts)).code(body));
    }
}
function destructureValCxt(opts) {
    return (0, codegen_1$n._) `{${names_1$3.default.instancePath}="", ${names_1$3.default.parentData}, ${names_1$3.default.parentDataProperty}, ${names_1$3.default.rootData}=${names_1$3.default.data}${opts.dynamicRef ? (0, codegen_1$n._) `, ${names_1$3.default.dynamicAnchors}={}` : codegen_1$n.nil}}={}`;
}
function destructureValCxtES5(gen, opts) {
    gen.if(names_1$3.default.valCxt, () => {
        gen.var(names_1$3.default.instancePath, (0, codegen_1$n._) `${names_1$3.default.valCxt}.${names_1$3.default.instancePath}`);
        gen.var(names_1$3.default.parentData, (0, codegen_1$n._) `${names_1$3.default.valCxt}.${names_1$3.default.parentData}`);
        gen.var(names_1$3.default.parentDataProperty, (0, codegen_1$n._) `${names_1$3.default.valCxt}.${names_1$3.default.parentDataProperty}`);
        gen.var(names_1$3.default.rootData, (0, codegen_1$n._) `${names_1$3.default.valCxt}.${names_1$3.default.rootData}`);
        if (opts.dynamicRef)
            gen.var(names_1$3.default.dynamicAnchors, (0, codegen_1$n._) `${names_1$3.default.valCxt}.${names_1$3.default.dynamicAnchors}`);
    }, () => {
        gen.var(names_1$3.default.instancePath, (0, codegen_1$n._) `""`);
        gen.var(names_1$3.default.parentData, (0, codegen_1$n._) `undefined`);
        gen.var(names_1$3.default.parentDataProperty, (0, codegen_1$n._) `undefined`);
        gen.var(names_1$3.default.rootData, names_1$3.default.data);
        if (opts.dynamicRef)
            gen.var(names_1$3.default.dynamicAnchors, (0, codegen_1$n._) `{}`);
    });
}
function topSchemaObjCode(it) {
    const { schema, opts, gen } = it;
    validateFunction(it, () => {
        if (opts.$comment && schema.$comment)
            commentKeyword(it);
        checkNoDefault(it);
        gen.let(names_1$3.default.vErrors, null);
        gen.let(names_1$3.default.errors, 0);
        if (opts.unevaluated)
            resetEvaluated(it);
        typeAndKeywords(it);
        returnResults(it);
    });
    return;
}
function resetEvaluated(it) {
    // TODO maybe some hook to execute it in the end to check whether props/items are Name, as in assignEvaluated
    const { gen, validateName } = it;
    it.evaluated = gen.const("evaluated", (0, codegen_1$n._) `${validateName}.evaluated`);
    gen.if((0, codegen_1$n._) `${it.evaluated}.dynamicProps`, () => gen.assign((0, codegen_1$n._) `${it.evaluated}.props`, (0, codegen_1$n._) `undefined`));
    gen.if((0, codegen_1$n._) `${it.evaluated}.dynamicItems`, () => gen.assign((0, codegen_1$n._) `${it.evaluated}.items`, (0, codegen_1$n._) `undefined`));
}
function funcSourceUrl(schema, opts) {
    const schId = typeof schema == "object" && schema[opts.schemaId];
    return schId && (opts.code.source || opts.code.process) ? (0, codegen_1$n._) `/*# sourceURL=${schId} */` : codegen_1$n.nil;
}
// schema compilation - this function is used recursively to generate code for sub-schemas
function subschemaCode(it, valid) {
    if (isSchemaObj(it)) {
        checkKeywords(it);
        if (schemaCxtHasRules(it)) {
            subSchemaObjCode(it, valid);
            return;
        }
    }
    (0, boolSchema_1.boolOrEmptySchema)(it, valid);
}
function schemaCxtHasRules({ schema, self }) {
    if (typeof schema == "boolean")
        return !schema;
    for (const key in schema)
        if (self.RULES.all[key])
            return true;
    return false;
}
function isSchemaObj(it) {
    return typeof it.schema != "boolean";
}
function subSchemaObjCode(it, valid) {
    const { schema, gen, opts } = it;
    if (opts.$comment && schema.$comment)
        commentKeyword(it);
    updateContext(it);
    checkAsyncSchema(it);
    const errsCount = gen.const("_errs", names_1$3.default.errors);
    typeAndKeywords(it, errsCount);
    // TODO var
    gen.var(valid, (0, codegen_1$n._) `${errsCount} === ${names_1$3.default.errors}`);
}
function checkKeywords(it) {
    (0, util_1$l.checkUnknownRules)(it);
    checkRefsAndKeywords(it);
}
function typeAndKeywords(it, errsCount) {
    if (it.opts.jtd)
        return schemaKeywords(it, [], false, errsCount);
    const types = (0, dataType_1$1.getSchemaTypes)(it.schema);
    const checkedTypes = (0, dataType_1$1.coerceAndCheckDataType)(it, types);
    schemaKeywords(it, types, !checkedTypes, errsCount);
}
function checkRefsAndKeywords(it) {
    const { schema, errSchemaPath, opts, self } = it;
    if (schema.$ref && opts.ignoreKeywordsWithRef && (0, util_1$l.schemaHasRulesButRef)(schema, self.RULES)) {
        self.logger.warn(`$ref: keywords ignored in schema at path "${errSchemaPath}"`);
    }
}
function checkNoDefault(it) {
    const { schema, opts } = it;
    if (schema.default !== undefined && opts.useDefaults && opts.strictSchema) {
        (0, util_1$l.checkStrictMode)(it, "default is ignored in the schema root");
    }
}
function updateContext(it) {
    const schId = it.schema[it.opts.schemaId];
    if (schId)
        it.baseId = (0, resolve_1$2.resolveUrl)(it.opts.uriResolver, it.baseId, schId);
}
function checkAsyncSchema(it) {
    if (it.schema.$async && !it.schemaEnv.$async)
        throw new Error("async schema in sync schema");
}
function commentKeyword({ gen, schemaEnv, schema, errSchemaPath, opts }) {
    const msg = schema.$comment;
    if (opts.$comment === true) {
        gen.code((0, codegen_1$n._) `${names_1$3.default.self}.logger.log(${msg})`);
    }
    else if (typeof opts.$comment == "function") {
        const schemaPath = (0, codegen_1$n.str) `${errSchemaPath}/$comment`;
        const rootName = gen.scopeValue("root", { ref: schemaEnv.root });
        gen.code((0, codegen_1$n._) `${names_1$3.default.self}.opts.$comment(${msg}, ${schemaPath}, ${rootName}.schema)`);
    }
}
function returnResults(it) {
    const { gen, schemaEnv, validateName, ValidationError, opts } = it;
    if (schemaEnv.$async) {
        // TODO assign unevaluated
        gen.if((0, codegen_1$n._) `${names_1$3.default.errors} === 0`, () => gen.return(names_1$3.default.data), () => gen.throw((0, codegen_1$n._) `new ${ValidationError}(${names_1$3.default.vErrors})`));
    }
    else {
        gen.assign((0, codegen_1$n._) `${validateName}.errors`, names_1$3.default.vErrors);
        if (opts.unevaluated)
            assignEvaluated(it);
        gen.return((0, codegen_1$n._) `${names_1$3.default.errors} === 0`);
    }
}
function assignEvaluated({ gen, evaluated, props, items }) {
    if (props instanceof codegen_1$n.Name)
        gen.assign((0, codegen_1$n._) `${evaluated}.props`, props);
    if (items instanceof codegen_1$n.Name)
        gen.assign((0, codegen_1$n._) `${evaluated}.items`, items);
}
function schemaKeywords(it, types, typeErrors, errsCount) {
    const { gen, schema, data, allErrors, opts, self } = it;
    const { RULES } = self;
    if (schema.$ref && (opts.ignoreKeywordsWithRef || !(0, util_1$l.schemaHasRulesButRef)(schema, RULES))) {
        gen.block(() => keywordCode(it, "$ref", RULES.all.$ref.definition)); // TODO typecast
        return;
    }
    if (!opts.jtd)
        checkStrictTypes(it, types);
    gen.block(() => {
        for (const group of RULES.rules)
            groupKeywords(group);
        groupKeywords(RULES.post);
    });
    function groupKeywords(group) {
        if (!(0, applicability_1.shouldUseGroup)(schema, group))
            return;
        if (group.type) {
            gen.if((0, dataType_2.checkDataType)(group.type, data, opts.strictNumbers));
            iterateKeywords(it, group);
            if (types.length === 1 && types[0] === group.type && typeErrors) {
                gen.else();
                (0, dataType_2.reportTypeError)(it);
            }
            gen.endIf();
        }
        else {
            iterateKeywords(it, group);
        }
        // TODO make it "ok" call?
        if (!allErrors)
            gen.if((0, codegen_1$n._) `${names_1$3.default.errors} === ${errsCount || 0}`);
    }
}
function iterateKeywords(it, group) {
    const { gen, schema, opts: { useDefaults }, } = it;
    if (useDefaults)
        (0, defaults_1.assignDefaults)(it, group.type);
    gen.block(() => {
        for (const rule of group.rules) {
            if ((0, applicability_1.shouldUseRule)(schema, rule)) {
                keywordCode(it, rule.keyword, rule.definition, group.type);
            }
        }
    });
}
function checkStrictTypes(it, types) {
    if (it.schemaEnv.meta || !it.opts.strictTypes)
        return;
    checkContextTypes(it, types);
    if (!it.opts.allowUnionTypes)
        checkMultipleTypes(it, types);
    checkKeywordTypes(it, it.dataTypes);
}
function checkContextTypes(it, types) {
    if (!types.length)
        return;
    if (!it.dataTypes.length) {
        it.dataTypes = types;
        return;
    }
    types.forEach((t) => {
        if (!includesType(it.dataTypes, t)) {
            strictTypesError(it, `type "${t}" not allowed by context "${it.dataTypes.join(",")}"`);
        }
    });
    narrowSchemaTypes(it, types);
}
function checkMultipleTypes(it, ts) {
    if (ts.length > 1 && !(ts.length === 2 && ts.includes("null"))) {
        strictTypesError(it, "use allowUnionTypes to allow union type keyword");
    }
}
function checkKeywordTypes(it, ts) {
    const rules = it.self.RULES.all;
    for (const keyword in rules) {
        const rule = rules[keyword];
        if (typeof rule == "object" && (0, applicability_1.shouldUseRule)(it.schema, rule)) {
            const { type } = rule.definition;
            if (type.length && !type.some((t) => hasApplicableType(ts, t))) {
                strictTypesError(it, `missing type "${type.join(",")}" for keyword "${keyword}"`);
            }
        }
    }
}
function hasApplicableType(schTs, kwdT) {
    return schTs.includes(kwdT) || (kwdT === "number" && schTs.includes("integer"));
}
function includesType(ts, t) {
    return ts.includes(t) || (t === "integer" && ts.includes("number"));
}
function narrowSchemaTypes(it, withTypes) {
    const ts = [];
    for (const t of it.dataTypes) {
        if (includesType(withTypes, t))
            ts.push(t);
        else if (withTypes.includes("integer") && t === "number")
            ts.push("integer");
    }
    it.dataTypes = ts;
}
function strictTypesError(it, msg) {
    const schemaPath = it.schemaEnv.baseId + it.errSchemaPath;
    msg += ` at "${schemaPath}" (strictTypes)`;
    (0, util_1$l.checkStrictMode)(it, msg, it.opts.strictTypes);
}
class KeywordCxt {
    constructor(it, def, keyword) {
        (0, keyword_1.validateKeywordUsage)(it, def, keyword);
        this.gen = it.gen;
        this.allErrors = it.allErrors;
        this.keyword = keyword;
        this.data = it.data;
        this.schema = it.schema[keyword];
        this.$data = def.$data && it.opts.$data && this.schema && this.schema.$data;
        this.schemaValue = (0, util_1$l.schemaRefOrVal)(it, this.schema, keyword, this.$data);
        this.schemaType = def.schemaType;
        this.parentSchema = it.schema;
        this.params = {};
        this.it = it;
        this.def = def;
        if (this.$data) {
            this.schemaCode = it.gen.const("vSchema", getData(this.$data, it));
        }
        else {
            this.schemaCode = this.schemaValue;
            if (!(0, keyword_1.validSchemaType)(this.schema, def.schemaType, def.allowUndefined)) {
                throw new Error(`${keyword} value must be ${JSON.stringify(def.schemaType)}`);
            }
        }
        if ("code" in def ? def.trackErrors : def.errors !== false) {
            this.errsCount = it.gen.const("_errs", names_1$3.default.errors);
        }
    }
    result(condition, successAction, failAction) {
        this.failResult((0, codegen_1$n.not)(condition), successAction, failAction);
    }
    failResult(condition, successAction, failAction) {
        this.gen.if(condition);
        if (failAction)
            failAction();
        else
            this.error();
        if (successAction) {
            this.gen.else();
            successAction();
            if (this.allErrors)
                this.gen.endIf();
        }
        else {
            if (this.allErrors)
                this.gen.endIf();
            else
                this.gen.else();
        }
    }
    pass(condition, failAction) {
        this.failResult((0, codegen_1$n.not)(condition), undefined, failAction);
    }
    fail(condition) {
        if (condition === undefined) {
            this.error();
            if (!this.allErrors)
                this.gen.if(false); // this branch will be removed by gen.optimize
            return;
        }
        this.gen.if(condition);
        this.error();
        if (this.allErrors)
            this.gen.endIf();
        else
            this.gen.else();
    }
    fail$data(condition) {
        if (!this.$data)
            return this.fail(condition);
        const { schemaCode } = this;
        this.fail((0, codegen_1$n._) `${schemaCode} !== undefined && (${(0, codegen_1$n.or)(this.invalid$data(), condition)})`);
    }
    error(append, errorParams, errorPaths) {
        if (errorParams) {
            this.setParams(errorParams);
            this._error(append, errorPaths);
            this.setParams({});
            return;
        }
        this._error(append, errorPaths);
    }
    _error(append, errorPaths) {
        (append ? errors_1.reportExtraError : errors_1.reportError)(this, this.def.error, errorPaths);
    }
    $dataError() {
        (0, errors_1.reportError)(this, this.def.$dataError || errors_1.keyword$DataError);
    }
    reset() {
        if (this.errsCount === undefined)
            throw new Error('add "trackErrors" to keyword definition');
        (0, errors_1.resetErrorsCount)(this.gen, this.errsCount);
    }
    ok(cond) {
        if (!this.allErrors)
            this.gen.if(cond);
    }
    setParams(obj, assign) {
        if (assign)
            Object.assign(this.params, obj);
        else
            this.params = obj;
    }
    block$data(valid, codeBlock, $dataValid = codegen_1$n.nil) {
        this.gen.block(() => {
            this.check$data(valid, $dataValid);
            codeBlock();
        });
    }
    check$data(valid = codegen_1$n.nil, $dataValid = codegen_1$n.nil) {
        if (!this.$data)
            return;
        const { gen, schemaCode, schemaType, def } = this;
        gen.if((0, codegen_1$n.or)((0, codegen_1$n._) `${schemaCode} === undefined`, $dataValid));
        if (valid !== codegen_1$n.nil)
            gen.assign(valid, true);
        if (schemaType.length || def.validateSchema) {
            gen.elseIf(this.invalid$data());
            this.$dataError();
            if (valid !== codegen_1$n.nil)
                gen.assign(valid, false);
        }
        gen.else();
    }
    invalid$data() {
        const { gen, schemaCode, schemaType, def, it } = this;
        return (0, codegen_1$n.or)(wrong$DataType(), invalid$DataSchema());
        function wrong$DataType() {
            if (schemaType.length) {
                /* istanbul ignore if */
                if (!(schemaCode instanceof codegen_1$n.Name))
                    throw new Error("ajv implementation error");
                const st = Array.isArray(schemaType) ? schemaType : [schemaType];
                return (0, codegen_1$n._) `${(0, dataType_2.checkDataTypes)(st, schemaCode, it.opts.strictNumbers, dataType_2.DataType.Wrong)}`;
            }
            return codegen_1$n.nil;
        }
        function invalid$DataSchema() {
            if (def.validateSchema) {
                const validateSchemaRef = gen.scopeValue("validate$data", { ref: def.validateSchema }); // TODO value.code for standalone
                return (0, codegen_1$n._) `!${validateSchemaRef}(${schemaCode})`;
            }
            return codegen_1$n.nil;
        }
    }
    subschema(appl, valid) {
        const subschema = (0, subschema_1.getSubschema)(this.it, appl);
        (0, subschema_1.extendSubschemaData)(subschema, this.it, appl);
        (0, subschema_1.extendSubschemaMode)(subschema, appl);
        const nextContext = { ...this.it, ...subschema, items: undefined, props: undefined };
        subschemaCode(nextContext, valid);
        return nextContext;
    }
    mergeEvaluated(schemaCxt, toName) {
        const { it, gen } = this;
        if (!it.opts.unevaluated)
            return;
        if (it.props !== true && schemaCxt.props !== undefined) {
            it.props = util_1$l.mergeEvaluated.props(gen, schemaCxt.props, it.props, toName);
        }
        if (it.items !== true && schemaCxt.items !== undefined) {
            it.items = util_1$l.mergeEvaluated.items(gen, schemaCxt.items, it.items, toName);
        }
    }
    mergeValidEvaluated(schemaCxt, valid) {
        const { it, gen } = this;
        if (it.opts.unevaluated && (it.props !== true || it.items !== true)) {
            gen.if(valid, () => this.mergeEvaluated(schemaCxt, codegen_1$n.Name));
            return true;
        }
    }
}
validate.KeywordCxt = KeywordCxt;
function keywordCode(it, keyword, def, ruleType) {
    const cxt = new KeywordCxt(it, def, keyword);
    if ("code" in def) {
        def.code(cxt, ruleType);
    }
    else if (cxt.$data && def.validate) {
        (0, keyword_1.funcKeywordCode)(cxt, def);
    }
    else if ("macro" in def) {
        (0, keyword_1.macroKeywordCode)(cxt, def);
    }
    else if (def.compile || def.validate) {
        (0, keyword_1.funcKeywordCode)(cxt, def);
    }
}
const JSON_POINTER = /^\/(?:[^~]|~0|~1)*$/;
const RELATIVE_JSON_POINTER = /^([0-9]+)(#|\/(?:[^~]|~0|~1)*)?$/;
function getData($data, { dataLevel, dataNames, dataPathArr }) {
    let jsonPointer;
    let data;
    if ($data === "")
        return names_1$3.default.rootData;
    if ($data[0] === "/") {
        if (!JSON_POINTER.test($data))
            throw new Error(`Invalid JSON-pointer: ${$data}`);
        jsonPointer = $data;
        data = names_1$3.default.rootData;
    }
    else {
        const matches = RELATIVE_JSON_POINTER.exec($data);
        if (!matches)
            throw new Error(`Invalid JSON-pointer: ${$data}`);
        const up = +matches[1];
        jsonPointer = matches[2];
        if (jsonPointer === "#") {
            if (up >= dataLevel)
                throw new Error(errorMsg("property/index", up));
            return dataPathArr[dataLevel - up];
        }
        if (up > dataLevel)
            throw new Error(errorMsg("data", up));
        data = dataNames[dataLevel - up];
        if (!jsonPointer)
            return data;
    }
    let expr = data;
    const segments = jsonPointer.split("/");
    for (const segment of segments) {
        if (segment) {
            data = (0, codegen_1$n._) `${data}${(0, codegen_1$n.getProperty)((0, util_1$l.unescapeJsonPointer)(segment))}`;
            expr = (0, codegen_1$n._) `${expr} && ${data}`;
        }
    }
    return expr;
    function errorMsg(pointerType, up) {
        return `Cannot access ${pointerType} ${up} levels up, current level is ${dataLevel}`;
    }
}
validate.getData = getData;

var validation_error = {};

Object.defineProperty(validation_error, "__esModule", { value: true });
class ValidationError extends Error {
    constructor(errors) {
        super("validation failed");
        this.errors = errors;
        this.ajv = this.validation = true;
    }
}
validation_error.default = ValidationError;

var ref_error = {};

Object.defineProperty(ref_error, "__esModule", { value: true });
const resolve_1$1 = resolve$1;
class MissingRefError extends Error {
    constructor(resolver, baseId, ref, msg) {
        super(msg || `can't resolve reference ${ref} from id ${baseId}`);
        this.missingRef = (0, resolve_1$1.resolveUrl)(resolver, baseId, ref);
        this.missingSchema = (0, resolve_1$1.normalizeId)((0, resolve_1$1.getFullPath)(resolver, this.missingRef));
    }
}
ref_error.default = MissingRefError;

var compile = {};

Object.defineProperty(compile, "__esModule", { value: true });
compile.resolveSchema = compile.getCompilingSchema = compile.resolveRef = compile.compileSchema = compile.SchemaEnv = void 0;
const codegen_1$m = codegen;
const validation_error_1 = validation_error;
const names_1$2 = names$1;
const resolve_1 = resolve$1;
const util_1$k = util;
const validate_1$1 = validate;
class SchemaEnv {
    constructor(env) {
        var _a;
        this.refs = {};
        this.dynamicAnchors = {};
        let schema;
        if (typeof env.schema == "object")
            schema = env.schema;
        this.schema = env.schema;
        this.schemaId = env.schemaId;
        this.root = env.root || this;
        this.baseId = (_a = env.baseId) !== null && _a !== void 0 ? _a : (0, resolve_1.normalizeId)(schema === null || schema === void 0 ? void 0 : schema[env.schemaId || "$id"]);
        this.schemaPath = env.schemaPath;
        this.localRefs = env.localRefs;
        this.meta = env.meta;
        this.$async = schema === null || schema === void 0 ? void 0 : schema.$async;
        this.refs = {};
    }
}
compile.SchemaEnv = SchemaEnv;
// let codeSize = 0
// let nodeCount = 0
// Compiles schema in SchemaEnv
function compileSchema(sch) {
    // TODO refactor - remove compilations
    const _sch = getCompilingSchema.call(this, sch);
    if (_sch)
        return _sch;
    const rootId = (0, resolve_1.getFullPath)(this.opts.uriResolver, sch.root.baseId); // TODO if getFullPath removed 1 tests fails
    const { es5, lines } = this.opts.code;
    const { ownProperties } = this.opts;
    const gen = new codegen_1$m.CodeGen(this.scope, { es5, lines, ownProperties });
    let _ValidationError;
    if (sch.$async) {
        _ValidationError = gen.scopeValue("Error", {
            ref: validation_error_1.default,
            code: (0, codegen_1$m._) `require("ajv/dist/runtime/validation_error").default`,
        });
    }
    const validateName = gen.scopeName("validate");
    sch.validateName = validateName;
    const schemaCxt = {
        gen,
        allErrors: this.opts.allErrors,
        data: names_1$2.default.data,
        parentData: names_1$2.default.parentData,
        parentDataProperty: names_1$2.default.parentDataProperty,
        dataNames: [names_1$2.default.data],
        dataPathArr: [codegen_1$m.nil],
        dataLevel: 0,
        dataTypes: [],
        definedProperties: new Set(),
        topSchemaRef: gen.scopeValue("schema", this.opts.code.source === true
            ? { ref: sch.schema, code: (0, codegen_1$m.stringify)(sch.schema) }
            : { ref: sch.schema }),
        validateName,
        ValidationError: _ValidationError,
        schema: sch.schema,
        schemaEnv: sch,
        rootId,
        baseId: sch.baseId || rootId,
        schemaPath: codegen_1$m.nil,
        errSchemaPath: sch.schemaPath || (this.opts.jtd ? "" : "#"),
        errorPath: (0, codegen_1$m._) `""`,
        opts: this.opts,
        self: this,
    };
    let sourceCode;
    try {
        this._compilations.add(sch);
        (0, validate_1$1.validateFunctionCode)(schemaCxt);
        gen.optimize(this.opts.code.optimize);
        // gen.optimize(1)
        const validateCode = gen.toString();
        sourceCode = `${gen.scopeRefs(names_1$2.default.scope)}return ${validateCode}`;
        // console.log((codeSize += sourceCode.length), (nodeCount += gen.nodeCount))
        if (this.opts.code.process)
            sourceCode = this.opts.code.process(sourceCode, sch);
        // console.log("\n\n\n *** \n", sourceCode)
        const makeValidate = new Function(`${names_1$2.default.self}`, `${names_1$2.default.scope}`, sourceCode);
        const validate = makeValidate(this, this.scope.get());
        this.scope.value(validateName, { ref: validate });
        validate.errors = null;
        validate.schema = sch.schema;
        validate.schemaEnv = sch;
        if (sch.$async)
            validate.$async = true;
        if (this.opts.code.source === true) {
            validate.source = { validateName, validateCode, scopeValues: gen._values };
        }
        if (this.opts.unevaluated) {
            const { props, items } = schemaCxt;
            validate.evaluated = {
                props: props instanceof codegen_1$m.Name ? undefined : props,
                items: items instanceof codegen_1$m.Name ? undefined : items,
                dynamicProps: props instanceof codegen_1$m.Name,
                dynamicItems: items instanceof codegen_1$m.Name,
            };
            if (validate.source)
                validate.source.evaluated = (0, codegen_1$m.stringify)(validate.evaluated);
        }
        sch.validate = validate;
        return sch;
    }
    catch (e) {
        delete sch.validate;
        delete sch.validateName;
        if (sourceCode)
            this.logger.error("Error compiling schema, function code:", sourceCode);
        // console.log("\n\n\n *** \n", sourceCode, this.opts)
        throw e;
    }
    finally {
        this._compilations.delete(sch);
    }
}
compile.compileSchema = compileSchema;
function resolveRef(root, baseId, ref) {
    var _a;
    ref = (0, resolve_1.resolveUrl)(this.opts.uriResolver, baseId, ref);
    const schOrFunc = root.refs[ref];
    if (schOrFunc)
        return schOrFunc;
    let _sch = resolve.call(this, root, ref);
    if (_sch === undefined) {
        const schema = (_a = root.localRefs) === null || _a === void 0 ? void 0 : _a[ref]; // TODO maybe localRefs should hold SchemaEnv
        const { schemaId } = this.opts;
        if (schema)
            _sch = new SchemaEnv({ schema, schemaId, root, baseId });
    }
    if (_sch === undefined)
        return;
    return (root.refs[ref] = inlineOrCompile.call(this, _sch));
}
compile.resolveRef = resolveRef;
function inlineOrCompile(sch) {
    if ((0, resolve_1.inlineRef)(sch.schema, this.opts.inlineRefs))
        return sch.schema;
    return sch.validate ? sch : compileSchema.call(this, sch);
}
// Index of schema compilation in the currently compiled list
function getCompilingSchema(schEnv) {
    for (const sch of this._compilations) {
        if (sameSchemaEnv(sch, schEnv))
            return sch;
    }
}
compile.getCompilingSchema = getCompilingSchema;
function sameSchemaEnv(s1, s2) {
    return s1.schema === s2.schema && s1.root === s2.root && s1.baseId === s2.baseId;
}
// resolve and compile the references ($ref)
// TODO returns AnySchemaObject (if the schema can be inlined) or validation function
function resolve(root, // information about the root schema for the current schema
ref // reference to resolve
) {
    let sch;
    while (typeof (sch = this.refs[ref]) == "string")
        ref = sch;
    return sch || this.schemas[ref] || resolveSchema.call(this, root, ref);
}
// Resolve schema, its root and baseId
function resolveSchema(root, // root object with properties schema, refs TODO below SchemaEnv is assigned to it
ref // reference to resolve
) {
    const p = this.opts.uriResolver.parse(ref);
    const refPath = (0, resolve_1._getFullPath)(this.opts.uriResolver, p);
    let baseId = (0, resolve_1.getFullPath)(this.opts.uriResolver, root.baseId, undefined);
    // TODO `Object.keys(root.schema).length > 0` should not be needed - but removing breaks 2 tests
    if (Object.keys(root.schema).length > 0 && refPath === baseId) {
        return getJsonPointer.call(this, p, root);
    }
    const id = (0, resolve_1.normalizeId)(refPath);
    const schOrRef = this.refs[id] || this.schemas[id];
    if (typeof schOrRef == "string") {
        const sch = resolveSchema.call(this, root, schOrRef);
        if (typeof (sch === null || sch === void 0 ? void 0 : sch.schema) !== "object")
            return;
        return getJsonPointer.call(this, p, sch);
    }
    if (typeof (schOrRef === null || schOrRef === void 0 ? void 0 : schOrRef.schema) !== "object")
        return;
    if (!schOrRef.validate)
        compileSchema.call(this, schOrRef);
    if (id === (0, resolve_1.normalizeId)(ref)) {
        const { schema } = schOrRef;
        const { schemaId } = this.opts;
        const schId = schema[schemaId];
        if (schId)
            baseId = (0, resolve_1.resolveUrl)(this.opts.uriResolver, baseId, schId);
        return new SchemaEnv({ schema, schemaId, root, baseId });
    }
    return getJsonPointer.call(this, p, schOrRef);
}
compile.resolveSchema = resolveSchema;
const PREVENT_SCOPE_CHANGE = new Set([
    "properties",
    "patternProperties",
    "enum",
    "dependencies",
    "definitions",
]);
function getJsonPointer(parsedRef, { baseId, schema, root }) {
    var _a;
    if (((_a = parsedRef.fragment) === null || _a === void 0 ? void 0 : _a[0]) !== "/")
        return;
    for (const part of parsedRef.fragment.slice(1).split("/")) {
        if (typeof schema === "boolean")
            return;
        const partSchema = schema[(0, util_1$k.unescapeFragment)(part)];
        if (partSchema === undefined)
            return;
        schema = partSchema;
        // TODO PREVENT_SCOPE_CHANGE could be defined in keyword def?
        const schId = typeof schema === "object" && schema[this.opts.schemaId];
        if (!PREVENT_SCOPE_CHANGE.has(part) && schId) {
            baseId = (0, resolve_1.resolveUrl)(this.opts.uriResolver, baseId, schId);
        }
    }
    let env;
    if (typeof schema != "boolean" && schema.$ref && !(0, util_1$k.schemaHasRulesButRef)(schema, this.RULES)) {
        const $ref = (0, resolve_1.resolveUrl)(this.opts.uriResolver, baseId, schema.$ref);
        env = resolveSchema.call(this, root, $ref);
    }
    // even though resolution failed we need to return SchemaEnv to throw exception
    // so that compileAsync loads missing schema.
    const { schemaId } = this.opts;
    env = env || new SchemaEnv({ schema, schemaId, root, baseId });
    if (env.schema !== env.root.schema)
        return env;
    return undefined;
}

var $id$1 = "https://raw.githubusercontent.com/ajv-validator/ajv/master/lib/refs/data.json#";
var description = "Meta-schema for $data reference (JSON AnySchema extension proposal)";
var type$1 = "object";
var required$1 = [
	"$data"
];
var properties$2 = {
	$data: {
		type: "string",
		anyOf: [
			{
				format: "relative-json-pointer"
			},
			{
				format: "json-pointer"
			}
		]
	}
};
var additionalProperties$1 = false;
var require$$9 = {
	$id: $id$1,
	description: description,
	type: type$1,
	required: required$1,
	properties: properties$2,
	additionalProperties: additionalProperties$1
};

var uri$1 = {};

Object.defineProperty(uri$1, "__esModule", { value: true });
const uri = uri_allExports;
uri.code = 'require("ajv/dist/runtime/uri").default';
uri$1.default = uri;

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.CodeGen = exports.Name = exports.nil = exports.stringify = exports.str = exports._ = exports.KeywordCxt = void 0;
	var validate_1 = validate;
	Object.defineProperty(exports, "KeywordCxt", { enumerable: true, get: function () { return validate_1.KeywordCxt; } });
	var codegen_1 = codegen;
	Object.defineProperty(exports, "_", { enumerable: true, get: function () { return codegen_1._; } });
	Object.defineProperty(exports, "str", { enumerable: true, get: function () { return codegen_1.str; } });
	Object.defineProperty(exports, "stringify", { enumerable: true, get: function () { return codegen_1.stringify; } });
	Object.defineProperty(exports, "nil", { enumerable: true, get: function () { return codegen_1.nil; } });
	Object.defineProperty(exports, "Name", { enumerable: true, get: function () { return codegen_1.Name; } });
	Object.defineProperty(exports, "CodeGen", { enumerable: true, get: function () { return codegen_1.CodeGen; } });
	const validation_error_1 = validation_error;
	const ref_error_1 = ref_error;
	const rules_1 = rules;
	const compile_1 = compile;
	const codegen_2 = codegen;
	const resolve_1 = resolve$1;
	const dataType_1 = dataType;
	const util_1 = util;
	const $dataRefSchema = require$$9;
	const uri_1 = uri$1;
	const defaultRegExp = (str, flags) => new RegExp(str, flags);
	defaultRegExp.code = "new RegExp";
	const META_IGNORE_OPTIONS = ["removeAdditional", "useDefaults", "coerceTypes"];
	const EXT_SCOPE_NAMES = new Set([
	    "validate",
	    "serialize",
	    "parse",
	    "wrapper",
	    "root",
	    "schema",
	    "keyword",
	    "pattern",
	    "formats",
	    "validate$data",
	    "func",
	    "obj",
	    "Error",
	]);
	const removedOptions = {
	    errorDataPath: "",
	    format: "`validateFormats: false` can be used instead.",
	    nullable: '"nullable" keyword is supported by default.',
	    jsonPointers: "Deprecated jsPropertySyntax can be used instead.",
	    extendRefs: "Deprecated ignoreKeywordsWithRef can be used instead.",
	    missingRefs: "Pass empty schema with $id that should be ignored to ajv.addSchema.",
	    processCode: "Use option `code: {process: (code, schemaEnv: object) => string}`",
	    sourceCode: "Use option `code: {source: true}`",
	    strictDefaults: "It is default now, see option `strict`.",
	    strictKeywords: "It is default now, see option `strict`.",
	    uniqueItems: '"uniqueItems" keyword is always validated.',
	    unknownFormats: "Disable strict mode or pass `true` to `ajv.addFormat` (or `formats` option).",
	    cache: "Map is used as cache, schema object as key.",
	    serialize: "Map is used as cache, schema object as key.",
	    ajvErrors: "It is default now.",
	};
	const deprecatedOptions = {
	    ignoreKeywordsWithRef: "",
	    jsPropertySyntax: "",
	    unicode: '"minLength"/"maxLength" account for unicode characters by default.',
	};
	const MAX_EXPRESSION = 200;
	// eslint-disable-next-line complexity
	function requiredOptions(o) {
	    var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v, _w, _x, _y, _z, _0;
	    const s = o.strict;
	    const _optz = (_a = o.code) === null || _a === void 0 ? void 0 : _a.optimize;
	    const optimize = _optz === true || _optz === undefined ? 1 : _optz || 0;
	    const regExp = (_c = (_b = o.code) === null || _b === void 0 ? void 0 : _b.regExp) !== null && _c !== void 0 ? _c : defaultRegExp;
	    const uriResolver = (_d = o.uriResolver) !== null && _d !== void 0 ? _d : uri_1.default;
	    return {
	        strictSchema: (_f = (_e = o.strictSchema) !== null && _e !== void 0 ? _e : s) !== null && _f !== void 0 ? _f : true,
	        strictNumbers: (_h = (_g = o.strictNumbers) !== null && _g !== void 0 ? _g : s) !== null && _h !== void 0 ? _h : true,
	        strictTypes: (_k = (_j = o.strictTypes) !== null && _j !== void 0 ? _j : s) !== null && _k !== void 0 ? _k : "log",
	        strictTuples: (_m = (_l = o.strictTuples) !== null && _l !== void 0 ? _l : s) !== null && _m !== void 0 ? _m : "log",
	        strictRequired: (_p = (_o = o.strictRequired) !== null && _o !== void 0 ? _o : s) !== null && _p !== void 0 ? _p : false,
	        code: o.code ? { ...o.code, optimize, regExp } : { optimize, regExp },
	        loopRequired: (_q = o.loopRequired) !== null && _q !== void 0 ? _q : MAX_EXPRESSION,
	        loopEnum: (_r = o.loopEnum) !== null && _r !== void 0 ? _r : MAX_EXPRESSION,
	        meta: (_s = o.meta) !== null && _s !== void 0 ? _s : true,
	        messages: (_t = o.messages) !== null && _t !== void 0 ? _t : true,
	        inlineRefs: (_u = o.inlineRefs) !== null && _u !== void 0 ? _u : true,
	        schemaId: (_v = o.schemaId) !== null && _v !== void 0 ? _v : "$id",
	        addUsedSchema: (_w = o.addUsedSchema) !== null && _w !== void 0 ? _w : true,
	        validateSchema: (_x = o.validateSchema) !== null && _x !== void 0 ? _x : true,
	        validateFormats: (_y = o.validateFormats) !== null && _y !== void 0 ? _y : true,
	        unicodeRegExp: (_z = o.unicodeRegExp) !== null && _z !== void 0 ? _z : true,
	        int32range: (_0 = o.int32range) !== null && _0 !== void 0 ? _0 : true,
	        uriResolver: uriResolver,
	    };
	}
	class Ajv {
	    constructor(opts = {}) {
	        this.schemas = {};
	        this.refs = {};
	        this.formats = {};
	        this._compilations = new Set();
	        this._loading = {};
	        this._cache = new Map();
	        opts = this.opts = { ...opts, ...requiredOptions(opts) };
	        const { es5, lines } = this.opts.code;
	        this.scope = new codegen_2.ValueScope({ scope: {}, prefixes: EXT_SCOPE_NAMES, es5, lines });
	        this.logger = getLogger(opts.logger);
	        const formatOpt = opts.validateFormats;
	        opts.validateFormats = false;
	        this.RULES = (0, rules_1.getRules)();
	        checkOptions.call(this, removedOptions, opts, "NOT SUPPORTED");
	        checkOptions.call(this, deprecatedOptions, opts, "DEPRECATED", "warn");
	        this._metaOpts = getMetaSchemaOptions.call(this);
	        if (opts.formats)
	            addInitialFormats.call(this);
	        this._addVocabularies();
	        this._addDefaultMetaSchema();
	        if (opts.keywords)
	            addInitialKeywords.call(this, opts.keywords);
	        if (typeof opts.meta == "object")
	            this.addMetaSchema(opts.meta);
	        addInitialSchemas.call(this);
	        opts.validateFormats = formatOpt;
	    }
	    _addVocabularies() {
	        this.addKeyword("$async");
	    }
	    _addDefaultMetaSchema() {
	        const { $data, meta, schemaId } = this.opts;
	        let _dataRefSchema = $dataRefSchema;
	        if (schemaId === "id") {
	            _dataRefSchema = { ...$dataRefSchema };
	            _dataRefSchema.id = _dataRefSchema.$id;
	            delete _dataRefSchema.$id;
	        }
	        if (meta && $data)
	            this.addMetaSchema(_dataRefSchema, _dataRefSchema[schemaId], false);
	    }
	    defaultMeta() {
	        const { meta, schemaId } = this.opts;
	        return (this.opts.defaultMeta = typeof meta == "object" ? meta[schemaId] || meta : undefined);
	    }
	    validate(schemaKeyRef, // key, ref or schema object
	    data // to be validated
	    ) {
	        let v;
	        if (typeof schemaKeyRef == "string") {
	            v = this.getSchema(schemaKeyRef);
	            if (!v)
	                throw new Error(`no schema with key or ref "${schemaKeyRef}"`);
	        }
	        else {
	            v = this.compile(schemaKeyRef);
	        }
	        const valid = v(data);
	        if (!("$async" in v))
	            this.errors = v.errors;
	        return valid;
	    }
	    compile(schema, _meta) {
	        const sch = this._addSchema(schema, _meta);
	        return (sch.validate || this._compileSchemaEnv(sch));
	    }
	    compileAsync(schema, meta) {
	        if (typeof this.opts.loadSchema != "function") {
	            throw new Error("options.loadSchema should be a function");
	        }
	        const { loadSchema } = this.opts;
	        return runCompileAsync.call(this, schema, meta);
	        async function runCompileAsync(_schema, _meta) {
	            await loadMetaSchema.call(this, _schema.$schema);
	            const sch = this._addSchema(_schema, _meta);
	            return sch.validate || _compileAsync.call(this, sch);
	        }
	        async function loadMetaSchema($ref) {
	            if ($ref && !this.getSchema($ref)) {
	                await runCompileAsync.call(this, { $ref }, true);
	            }
	        }
	        async function _compileAsync(sch) {
	            try {
	                return this._compileSchemaEnv(sch);
	            }
	            catch (e) {
	                if (!(e instanceof ref_error_1.default))
	                    throw e;
	                checkLoaded.call(this, e);
	                await loadMissingSchema.call(this, e.missingSchema);
	                return _compileAsync.call(this, sch);
	            }
	        }
	        function checkLoaded({ missingSchema: ref, missingRef }) {
	            if (this.refs[ref]) {
	                throw new Error(`AnySchema ${ref} is loaded but ${missingRef} cannot be resolved`);
	            }
	        }
	        async function loadMissingSchema(ref) {
	            const _schema = await _loadSchema.call(this, ref);
	            if (!this.refs[ref])
	                await loadMetaSchema.call(this, _schema.$schema);
	            if (!this.refs[ref])
	                this.addSchema(_schema, ref, meta);
	        }
	        async function _loadSchema(ref) {
	            const p = this._loading[ref];
	            if (p)
	                return p;
	            try {
	                return await (this._loading[ref] = loadSchema(ref));
	            }
	            finally {
	                delete this._loading[ref];
	            }
	        }
	    }
	    // Adds schema to the instance
	    addSchema(schema, // If array is passed, `key` will be ignored
	    key, // Optional schema key. Can be passed to `validate` method instead of schema object or id/ref. One schema per instance can have empty `id` and `key`.
	    _meta, // true if schema is a meta-schema. Used internally, addMetaSchema should be used instead.
	    _validateSchema = this.opts.validateSchema // false to skip schema validation. Used internally, option validateSchema should be used instead.
	    ) {
	        if (Array.isArray(schema)) {
	            for (const sch of schema)
	                this.addSchema(sch, undefined, _meta, _validateSchema);
	            return this;
	        }
	        let id;
	        if (typeof schema === "object") {
	            const { schemaId } = this.opts;
	            id = schema[schemaId];
	            if (id !== undefined && typeof id != "string") {
	                throw new Error(`schema ${schemaId} must be string`);
	            }
	        }
	        key = (0, resolve_1.normalizeId)(key || id);
	        this._checkUnique(key);
	        this.schemas[key] = this._addSchema(schema, _meta, key, _validateSchema, true);
	        return this;
	    }
	    // Add schema that will be used to validate other schemas
	    // options in META_IGNORE_OPTIONS are alway set to false
	    addMetaSchema(schema, key, // schema key
	    _validateSchema = this.opts.validateSchema // false to skip schema validation, can be used to override validateSchema option for meta-schema
	    ) {
	        this.addSchema(schema, key, true, _validateSchema);
	        return this;
	    }
	    //  Validate schema against its meta-schema
	    validateSchema(schema, throwOrLogError) {
	        if (typeof schema == "boolean")
	            return true;
	        let $schema;
	        $schema = schema.$schema;
	        if ($schema !== undefined && typeof $schema != "string") {
	            throw new Error("$schema must be a string");
	        }
	        $schema = $schema || this.opts.defaultMeta || this.defaultMeta();
	        if (!$schema) {
	            this.logger.warn("meta-schema not available");
	            this.errors = null;
	            return true;
	        }
	        const valid = this.validate($schema, schema);
	        if (!valid && throwOrLogError) {
	            const message = "schema is invalid: " + this.errorsText();
	            if (this.opts.validateSchema === "log")
	                this.logger.error(message);
	            else
	                throw new Error(message);
	        }
	        return valid;
	    }
	    // Get compiled schema by `key` or `ref`.
	    // (`key` that was passed to `addSchema` or full schema reference - `schema.$id` or resolved id)
	    getSchema(keyRef) {
	        let sch;
	        while (typeof (sch = getSchEnv.call(this, keyRef)) == "string")
	            keyRef = sch;
	        if (sch === undefined) {
	            const { schemaId } = this.opts;
	            const root = new compile_1.SchemaEnv({ schema: {}, schemaId });
	            sch = compile_1.resolveSchema.call(this, root, keyRef);
	            if (!sch)
	                return;
	            this.refs[keyRef] = sch;
	        }
	        return (sch.validate || this._compileSchemaEnv(sch));
	    }
	    // Remove cached schema(s).
	    // If no parameter is passed all schemas but meta-schemas are removed.
	    // If RegExp is passed all schemas with key/id matching pattern but meta-schemas are removed.
	    // Even if schema is referenced by other schemas it still can be removed as other schemas have local references.
	    removeSchema(schemaKeyRef) {
	        if (schemaKeyRef instanceof RegExp) {
	            this._removeAllSchemas(this.schemas, schemaKeyRef);
	            this._removeAllSchemas(this.refs, schemaKeyRef);
	            return this;
	        }
	        switch (typeof schemaKeyRef) {
	            case "undefined":
	                this._removeAllSchemas(this.schemas);
	                this._removeAllSchemas(this.refs);
	                this._cache.clear();
	                return this;
	            case "string": {
	                const sch = getSchEnv.call(this, schemaKeyRef);
	                if (typeof sch == "object")
	                    this._cache.delete(sch.schema);
	                delete this.schemas[schemaKeyRef];
	                delete this.refs[schemaKeyRef];
	                return this;
	            }
	            case "object": {
	                const cacheKey = schemaKeyRef;
	                this._cache.delete(cacheKey);
	                let id = schemaKeyRef[this.opts.schemaId];
	                if (id) {
	                    id = (0, resolve_1.normalizeId)(id);
	                    delete this.schemas[id];
	                    delete this.refs[id];
	                }
	                return this;
	            }
	            default:
	                throw new Error("ajv.removeSchema: invalid parameter");
	        }
	    }
	    // add "vocabulary" - a collection of keywords
	    addVocabulary(definitions) {
	        for (const def of definitions)
	            this.addKeyword(def);
	        return this;
	    }
	    addKeyword(kwdOrDef, def // deprecated
	    ) {
	        let keyword;
	        if (typeof kwdOrDef == "string") {
	            keyword = kwdOrDef;
	            if (typeof def == "object") {
	                this.logger.warn("these parameters are deprecated, see docs for addKeyword");
	                def.keyword = keyword;
	            }
	        }
	        else if (typeof kwdOrDef == "object" && def === undefined) {
	            def = kwdOrDef;
	            keyword = def.keyword;
	            if (Array.isArray(keyword) && !keyword.length) {
	                throw new Error("addKeywords: keyword must be string or non-empty array");
	            }
	        }
	        else {
	            throw new Error("invalid addKeywords parameters");
	        }
	        checkKeyword.call(this, keyword, def);
	        if (!def) {
	            (0, util_1.eachItem)(keyword, (kwd) => addRule.call(this, kwd));
	            return this;
	        }
	        keywordMetaschema.call(this, def);
	        const definition = {
	            ...def,
	            type: (0, dataType_1.getJSONTypes)(def.type),
	            schemaType: (0, dataType_1.getJSONTypes)(def.schemaType),
	        };
	        (0, util_1.eachItem)(keyword, definition.type.length === 0
	            ? (k) => addRule.call(this, k, definition)
	            : (k) => definition.type.forEach((t) => addRule.call(this, k, definition, t)));
	        return this;
	    }
	    getKeyword(keyword) {
	        const rule = this.RULES.all[keyword];
	        return typeof rule == "object" ? rule.definition : !!rule;
	    }
	    // Remove keyword
	    removeKeyword(keyword) {
	        // TODO return type should be Ajv
	        const { RULES } = this;
	        delete RULES.keywords[keyword];
	        delete RULES.all[keyword];
	        for (const group of RULES.rules) {
	            const i = group.rules.findIndex((rule) => rule.keyword === keyword);
	            if (i >= 0)
	                group.rules.splice(i, 1);
	        }
	        return this;
	    }
	    // Add format
	    addFormat(name, format) {
	        if (typeof format == "string")
	            format = new RegExp(format);
	        this.formats[name] = format;
	        return this;
	    }
	    errorsText(errors = this.errors, // optional array of validation errors
	    { separator = ", ", dataVar = "data" } = {} // optional options with properties `separator` and `dataVar`
	    ) {
	        if (!errors || errors.length === 0)
	            return "No errors";
	        return errors
	            .map((e) => `${dataVar}${e.instancePath} ${e.message}`)
	            .reduce((text, msg) => text + separator + msg);
	    }
	    $dataMetaSchema(metaSchema, keywordsJsonPointers) {
	        const rules = this.RULES.all;
	        metaSchema = JSON.parse(JSON.stringify(metaSchema));
	        for (const jsonPointer of keywordsJsonPointers) {
	            const segments = jsonPointer.split("/").slice(1); // first segment is an empty string
	            let keywords = metaSchema;
	            for (const seg of segments)
	                keywords = keywords[seg];
	            for (const key in rules) {
	                const rule = rules[key];
	                if (typeof rule != "object")
	                    continue;
	                const { $data } = rule.definition;
	                const schema = keywords[key];
	                if ($data && schema)
	                    keywords[key] = schemaOrData(schema);
	            }
	        }
	        return metaSchema;
	    }
	    _removeAllSchemas(schemas, regex) {
	        for (const keyRef in schemas) {
	            const sch = schemas[keyRef];
	            if (!regex || regex.test(keyRef)) {
	                if (typeof sch == "string") {
	                    delete schemas[keyRef];
	                }
	                else if (sch && !sch.meta) {
	                    this._cache.delete(sch.schema);
	                    delete schemas[keyRef];
	                }
	            }
	        }
	    }
	    _addSchema(schema, meta, baseId, validateSchema = this.opts.validateSchema, addSchema = this.opts.addUsedSchema) {
	        let id;
	        const { schemaId } = this.opts;
	        if (typeof schema == "object") {
	            id = schema[schemaId];
	        }
	        else {
	            if (this.opts.jtd)
	                throw new Error("schema must be object");
	            else if (typeof schema != "boolean")
	                throw new Error("schema must be object or boolean");
	        }
	        let sch = this._cache.get(schema);
	        if (sch !== undefined)
	            return sch;
	        baseId = (0, resolve_1.normalizeId)(id || baseId);
	        const localRefs = resolve_1.getSchemaRefs.call(this, schema, baseId);
	        sch = new compile_1.SchemaEnv({ schema, schemaId, meta, baseId, localRefs });
	        this._cache.set(sch.schema, sch);
	        if (addSchema && !baseId.startsWith("#")) {
	            // TODO atm it is allowed to overwrite schemas without id (instead of not adding them)
	            if (baseId)
	                this._checkUnique(baseId);
	            this.refs[baseId] = sch;
	        }
	        if (validateSchema)
	            this.validateSchema(schema, true);
	        return sch;
	    }
	    _checkUnique(id) {
	        if (this.schemas[id] || this.refs[id]) {
	            throw new Error(`schema with key or id "${id}" already exists`);
	        }
	    }
	    _compileSchemaEnv(sch) {
	        if (sch.meta)
	            this._compileMetaSchema(sch);
	        else
	            compile_1.compileSchema.call(this, sch);
	        /* istanbul ignore if */
	        if (!sch.validate)
	            throw new Error("ajv implementation error");
	        return sch.validate;
	    }
	    _compileMetaSchema(sch) {
	        const currentOpts = this.opts;
	        this.opts = this._metaOpts;
	        try {
	            compile_1.compileSchema.call(this, sch);
	        }
	        finally {
	            this.opts = currentOpts;
	        }
	    }
	}
	exports.default = Ajv;
	Ajv.ValidationError = validation_error_1.default;
	Ajv.MissingRefError = ref_error_1.default;
	function checkOptions(checkOpts, options, msg, log = "error") {
	    for (const key in checkOpts) {
	        const opt = key;
	        if (opt in options)
	            this.logger[log](`${msg}: option ${key}. ${checkOpts[opt]}`);
	    }
	}
	function getSchEnv(keyRef) {
	    keyRef = (0, resolve_1.normalizeId)(keyRef); // TODO tests fail without this line
	    return this.schemas[keyRef] || this.refs[keyRef];
	}
	function addInitialSchemas() {
	    const optsSchemas = this.opts.schemas;
	    if (!optsSchemas)
	        return;
	    if (Array.isArray(optsSchemas))
	        this.addSchema(optsSchemas);
	    else
	        for (const key in optsSchemas)
	            this.addSchema(optsSchemas[key], key);
	}
	function addInitialFormats() {
	    for (const name in this.opts.formats) {
	        const format = this.opts.formats[name];
	        if (format)
	            this.addFormat(name, format);
	    }
	}
	function addInitialKeywords(defs) {
	    if (Array.isArray(defs)) {
	        this.addVocabulary(defs);
	        return;
	    }
	    this.logger.warn("keywords option as map is deprecated, pass array");
	    for (const keyword in defs) {
	        const def = defs[keyword];
	        if (!def.keyword)
	            def.keyword = keyword;
	        this.addKeyword(def);
	    }
	}
	function getMetaSchemaOptions() {
	    const metaOpts = { ...this.opts };
	    for (const opt of META_IGNORE_OPTIONS)
	        delete metaOpts[opt];
	    return metaOpts;
	}
	const noLogs = { log() { }, warn() { }, error() { } };
	function getLogger(logger) {
	    if (logger === false)
	        return noLogs;
	    if (logger === undefined)
	        return console;
	    if (logger.log && logger.warn && logger.error)
	        return logger;
	    throw new Error("logger must implement log, warn and error methods");
	}
	const KEYWORD_NAME = /^[a-z_$][a-z0-9_$:-]*$/i;
	function checkKeyword(keyword, def) {
	    const { RULES } = this;
	    (0, util_1.eachItem)(keyword, (kwd) => {
	        if (RULES.keywords[kwd])
	            throw new Error(`Keyword ${kwd} is already defined`);
	        if (!KEYWORD_NAME.test(kwd))
	            throw new Error(`Keyword ${kwd} has invalid name`);
	    });
	    if (!def)
	        return;
	    if (def.$data && !("code" in def || "validate" in def)) {
	        throw new Error('$data keyword must have "code" or "validate" function');
	    }
	}
	function addRule(keyword, definition, dataType) {
	    var _a;
	    const post = definition === null || definition === void 0 ? void 0 : definition.post;
	    if (dataType && post)
	        throw new Error('keyword with "post" flag cannot have "type"');
	    const { RULES } = this;
	    let ruleGroup = post ? RULES.post : RULES.rules.find(({ type: t }) => t === dataType);
	    if (!ruleGroup) {
	        ruleGroup = { type: dataType, rules: [] };
	        RULES.rules.push(ruleGroup);
	    }
	    RULES.keywords[keyword] = true;
	    if (!definition)
	        return;
	    const rule = {
	        keyword,
	        definition: {
	            ...definition,
	            type: (0, dataType_1.getJSONTypes)(definition.type),
	            schemaType: (0, dataType_1.getJSONTypes)(definition.schemaType),
	        },
	    };
	    if (definition.before)
	        addBeforeRule.call(this, ruleGroup, rule, definition.before);
	    else
	        ruleGroup.rules.push(rule);
	    RULES.all[keyword] = rule;
	    (_a = definition.implements) === null || _a === void 0 ? void 0 : _a.forEach((kwd) => this.addKeyword(kwd));
	}
	function addBeforeRule(ruleGroup, rule, before) {
	    const i = ruleGroup.rules.findIndex((_rule) => _rule.keyword === before);
	    if (i >= 0) {
	        ruleGroup.rules.splice(i, 0, rule);
	    }
	    else {
	        ruleGroup.rules.push(rule);
	        this.logger.warn(`rule ${before} is not defined`);
	    }
	}
	function keywordMetaschema(def) {
	    let { metaSchema } = def;
	    if (metaSchema === undefined)
	        return;
	    if (def.$data && this.opts.$data)
	        metaSchema = schemaOrData(metaSchema);
	    def.validateSchema = this.compile(metaSchema, true);
	}
	const $dataRef = {
	    $ref: "https://raw.githubusercontent.com/ajv-validator/ajv/master/lib/refs/data.json#",
	};
	function schemaOrData(schema) {
	    return { anyOf: [schema, $dataRef] };
	}
	
} (core$2));

var draft7 = {};

var core$1 = {};

var id = {};

Object.defineProperty(id, "__esModule", { value: true });
const def$s = {
    keyword: "id",
    code() {
        throw new Error('NOT SUPPORTED: keyword "id", use "$id" for schema ID');
    },
};
id.default = def$s;

var ref = {};

Object.defineProperty(ref, "__esModule", { value: true });
ref.callRef = ref.getValidate = void 0;
const ref_error_1 = ref_error;
const code_1$8 = code;
const codegen_1$l = codegen;
const names_1$1 = names$1;
const compile_1$1 = compile;
const util_1$j = util;
const def$r = {
    keyword: "$ref",
    schemaType: "string",
    code(cxt) {
        const { gen, schema: $ref, it } = cxt;
        const { baseId, schemaEnv: env, validateName, opts, self } = it;
        const { root } = env;
        if (($ref === "#" || $ref === "#/") && baseId === root.baseId)
            return callRootRef();
        const schOrEnv = compile_1$1.resolveRef.call(self, root, baseId, $ref);
        if (schOrEnv === undefined)
            throw new ref_error_1.default(it.opts.uriResolver, baseId, $ref);
        if (schOrEnv instanceof compile_1$1.SchemaEnv)
            return callValidate(schOrEnv);
        return inlineRefSchema(schOrEnv);
        function callRootRef() {
            if (env === root)
                return callRef(cxt, validateName, env, env.$async);
            const rootName = gen.scopeValue("root", { ref: root });
            return callRef(cxt, (0, codegen_1$l._) `${rootName}.validate`, root, root.$async);
        }
        function callValidate(sch) {
            const v = getValidate(cxt, sch);
            callRef(cxt, v, sch, sch.$async);
        }
        function inlineRefSchema(sch) {
            const schName = gen.scopeValue("schema", opts.code.source === true ? { ref: sch, code: (0, codegen_1$l.stringify)(sch) } : { ref: sch });
            const valid = gen.name("valid");
            const schCxt = cxt.subschema({
                schema: sch,
                dataTypes: [],
                schemaPath: codegen_1$l.nil,
                topSchemaRef: schName,
                errSchemaPath: $ref,
            }, valid);
            cxt.mergeEvaluated(schCxt);
            cxt.ok(valid);
        }
    },
};
function getValidate(cxt, sch) {
    const { gen } = cxt;
    return sch.validate
        ? gen.scopeValue("validate", { ref: sch.validate })
        : (0, codegen_1$l._) `${gen.scopeValue("wrapper", { ref: sch })}.validate`;
}
ref.getValidate = getValidate;
function callRef(cxt, v, sch, $async) {
    const { gen, it } = cxt;
    const { allErrors, schemaEnv: env, opts } = it;
    const passCxt = opts.passContext ? names_1$1.default.this : codegen_1$l.nil;
    if ($async)
        callAsyncRef();
    else
        callSyncRef();
    function callAsyncRef() {
        if (!env.$async)
            throw new Error("async schema referenced by sync schema");
        const valid = gen.let("valid");
        gen.try(() => {
            gen.code((0, codegen_1$l._) `await ${(0, code_1$8.callValidateCode)(cxt, v, passCxt)}`);
            addEvaluatedFrom(v); // TODO will not work with async, it has to be returned with the result
            if (!allErrors)
                gen.assign(valid, true);
        }, (e) => {
            gen.if((0, codegen_1$l._) `!(${e} instanceof ${it.ValidationError})`, () => gen.throw(e));
            addErrorsFrom(e);
            if (!allErrors)
                gen.assign(valid, false);
        });
        cxt.ok(valid);
    }
    function callSyncRef() {
        cxt.result((0, code_1$8.callValidateCode)(cxt, v, passCxt), () => addEvaluatedFrom(v), () => addErrorsFrom(v));
    }
    function addErrorsFrom(source) {
        const errs = (0, codegen_1$l._) `${source}.errors`;
        gen.assign(names_1$1.default.vErrors, (0, codegen_1$l._) `${names_1$1.default.vErrors} === null ? ${errs} : ${names_1$1.default.vErrors}.concat(${errs})`); // TODO tagged
        gen.assign(names_1$1.default.errors, (0, codegen_1$l._) `${names_1$1.default.vErrors}.length`);
    }
    function addEvaluatedFrom(source) {
        var _a;
        if (!it.opts.unevaluated)
            return;
        const schEvaluated = (_a = sch === null || sch === void 0 ? void 0 : sch.validate) === null || _a === void 0 ? void 0 : _a.evaluated;
        // TODO refactor
        if (it.props !== true) {
            if (schEvaluated && !schEvaluated.dynamicProps) {
                if (schEvaluated.props !== undefined) {
                    it.props = util_1$j.mergeEvaluated.props(gen, schEvaluated.props, it.props);
                }
            }
            else {
                const props = gen.var("props", (0, codegen_1$l._) `${source}.evaluated.props`);
                it.props = util_1$j.mergeEvaluated.props(gen, props, it.props, codegen_1$l.Name);
            }
        }
        if (it.items !== true) {
            if (schEvaluated && !schEvaluated.dynamicItems) {
                if (schEvaluated.items !== undefined) {
                    it.items = util_1$j.mergeEvaluated.items(gen, schEvaluated.items, it.items);
                }
            }
            else {
                const items = gen.var("items", (0, codegen_1$l._) `${source}.evaluated.items`);
                it.items = util_1$j.mergeEvaluated.items(gen, items, it.items, codegen_1$l.Name);
            }
        }
    }
}
ref.callRef = callRef;
ref.default = def$r;

Object.defineProperty(core$1, "__esModule", { value: true });
const id_1 = id;
const ref_1 = ref;
const core = [
    "$schema",
    "$id",
    "$defs",
    "$vocabulary",
    { keyword: "$comment" },
    "definitions",
    id_1.default,
    ref_1.default,
];
core$1.default = core;

var validation$1 = {};

var limitNumber = {};

Object.defineProperty(limitNumber, "__esModule", { value: true });
const codegen_1$k = codegen;
const ops = codegen_1$k.operators;
const KWDs = {
    maximum: { okStr: "<=", ok: ops.LTE, fail: ops.GT },
    minimum: { okStr: ">=", ok: ops.GTE, fail: ops.LT },
    exclusiveMaximum: { okStr: "<", ok: ops.LT, fail: ops.GTE },
    exclusiveMinimum: { okStr: ">", ok: ops.GT, fail: ops.LTE },
};
const error$i = {
    message: ({ keyword, schemaCode }) => (0, codegen_1$k.str) `must be ${KWDs[keyword].okStr} ${schemaCode}`,
    params: ({ keyword, schemaCode }) => (0, codegen_1$k._) `{comparison: ${KWDs[keyword].okStr}, limit: ${schemaCode}}`,
};
const def$q = {
    keyword: Object.keys(KWDs),
    type: "number",
    schemaType: "number",
    $data: true,
    error: error$i,
    code(cxt) {
        const { keyword, data, schemaCode } = cxt;
        cxt.fail$data((0, codegen_1$k._) `${data} ${KWDs[keyword].fail} ${schemaCode} || isNaN(${data})`);
    },
};
limitNumber.default = def$q;

var multipleOf = {};

Object.defineProperty(multipleOf, "__esModule", { value: true });
const codegen_1$j = codegen;
const error$h = {
    message: ({ schemaCode }) => (0, codegen_1$j.str) `must be multiple of ${schemaCode}`,
    params: ({ schemaCode }) => (0, codegen_1$j._) `{multipleOf: ${schemaCode}}`,
};
const def$p = {
    keyword: "multipleOf",
    type: "number",
    schemaType: "number",
    $data: true,
    error: error$h,
    code(cxt) {
        const { gen, data, schemaCode, it } = cxt;
        // const bdt = bad$DataType(schemaCode, <string>def.schemaType, $data)
        const prec = it.opts.multipleOfPrecision;
        const res = gen.let("res");
        const invalid = prec
            ? (0, codegen_1$j._) `Math.abs(Math.round(${res}) - ${res}) > 1e-${prec}`
            : (0, codegen_1$j._) `${res} !== parseInt(${res})`;
        cxt.fail$data((0, codegen_1$j._) `(${schemaCode} === 0 || (${res} = ${data}/${schemaCode}, ${invalid}))`);
    },
};
multipleOf.default = def$p;

var limitLength = {};

var ucs2length$1 = {};

Object.defineProperty(ucs2length$1, "__esModule", { value: true });
// https://mathiasbynens.be/notes/javascript-encoding
// https://github.com/bestiejs/punycode.js - punycode.ucs2.decode
function ucs2length(str) {
    const len = str.length;
    let length = 0;
    let pos = 0;
    let value;
    while (pos < len) {
        length++;
        value = str.charCodeAt(pos++);
        if (value >= 0xd800 && value <= 0xdbff && pos < len) {
            // high surrogate, and there is a next character
            value = str.charCodeAt(pos);
            if ((value & 0xfc00) === 0xdc00)
                pos++; // low surrogate
        }
    }
    return length;
}
ucs2length$1.default = ucs2length;
ucs2length.code = 'require("ajv/dist/runtime/ucs2length").default';

Object.defineProperty(limitLength, "__esModule", { value: true });
const codegen_1$i = codegen;
const util_1$i = util;
const ucs2length_1 = ucs2length$1;
const error$g = {
    message({ keyword, schemaCode }) {
        const comp = keyword === "maxLength" ? "more" : "fewer";
        return (0, codegen_1$i.str) `must NOT have ${comp} than ${schemaCode} characters`;
    },
    params: ({ schemaCode }) => (0, codegen_1$i._) `{limit: ${schemaCode}}`,
};
const def$o = {
    keyword: ["maxLength", "minLength"],
    type: "string",
    schemaType: "number",
    $data: true,
    error: error$g,
    code(cxt) {
        const { keyword, data, schemaCode, it } = cxt;
        const op = keyword === "maxLength" ? codegen_1$i.operators.GT : codegen_1$i.operators.LT;
        const len = it.opts.unicode === false ? (0, codegen_1$i._) `${data}.length` : (0, codegen_1$i._) `${(0, util_1$i.useFunc)(cxt.gen, ucs2length_1.default)}(${data})`;
        cxt.fail$data((0, codegen_1$i._) `${len} ${op} ${schemaCode}`);
    },
};
limitLength.default = def$o;

var pattern = {};

Object.defineProperty(pattern, "__esModule", { value: true });
const code_1$7 = code;
const codegen_1$h = codegen;
const error$f = {
    message: ({ schemaCode }) => (0, codegen_1$h.str) `must match pattern "${schemaCode}"`,
    params: ({ schemaCode }) => (0, codegen_1$h._) `{pattern: ${schemaCode}}`,
};
const def$n = {
    keyword: "pattern",
    type: "string",
    schemaType: "string",
    $data: true,
    error: error$f,
    code(cxt) {
        const { data, $data, schema, schemaCode, it } = cxt;
        // TODO regexp should be wrapped in try/catchs
        const u = it.opts.unicodeRegExp ? "u" : "";
        const regExp = $data ? (0, codegen_1$h._) `(new RegExp(${schemaCode}, ${u}))` : (0, code_1$7.usePattern)(cxt, schema);
        cxt.fail$data((0, codegen_1$h._) `!${regExp}.test(${data})`);
    },
};
pattern.default = def$n;

var limitProperties = {};

Object.defineProperty(limitProperties, "__esModule", { value: true });
const codegen_1$g = codegen;
const error$e = {
    message({ keyword, schemaCode }) {
        const comp = keyword === "maxProperties" ? "more" : "fewer";
        return (0, codegen_1$g.str) `must NOT have ${comp} than ${schemaCode} properties`;
    },
    params: ({ schemaCode }) => (0, codegen_1$g._) `{limit: ${schemaCode}}`,
};
const def$m = {
    keyword: ["maxProperties", "minProperties"],
    type: "object",
    schemaType: "number",
    $data: true,
    error: error$e,
    code(cxt) {
        const { keyword, data, schemaCode } = cxt;
        const op = keyword === "maxProperties" ? codegen_1$g.operators.GT : codegen_1$g.operators.LT;
        cxt.fail$data((0, codegen_1$g._) `Object.keys(${data}).length ${op} ${schemaCode}`);
    },
};
limitProperties.default = def$m;

var required = {};

Object.defineProperty(required, "__esModule", { value: true });
const code_1$6 = code;
const codegen_1$f = codegen;
const util_1$h = util;
const error$d = {
    message: ({ params: { missingProperty } }) => (0, codegen_1$f.str) `must have required property '${missingProperty}'`,
    params: ({ params: { missingProperty } }) => (0, codegen_1$f._) `{missingProperty: ${missingProperty}}`,
};
const def$l = {
    keyword: "required",
    type: "object",
    schemaType: "array",
    $data: true,
    error: error$d,
    code(cxt) {
        const { gen, schema, schemaCode, data, $data, it } = cxt;
        const { opts } = it;
        if (!$data && schema.length === 0)
            return;
        const useLoop = schema.length >= opts.loopRequired;
        if (it.allErrors)
            allErrorsMode();
        else
            exitOnErrorMode();
        if (opts.strictRequired) {
            const props = cxt.parentSchema.properties;
            const { definedProperties } = cxt.it;
            for (const requiredKey of schema) {
                if ((props === null || props === void 0 ? void 0 : props[requiredKey]) === undefined && !definedProperties.has(requiredKey)) {
                    const schemaPath = it.schemaEnv.baseId + it.errSchemaPath;
                    const msg = `required property "${requiredKey}" is not defined at "${schemaPath}" (strictRequired)`;
                    (0, util_1$h.checkStrictMode)(it, msg, it.opts.strictRequired);
                }
            }
        }
        function allErrorsMode() {
            if (useLoop || $data) {
                cxt.block$data(codegen_1$f.nil, loopAllRequired);
            }
            else {
                for (const prop of schema) {
                    (0, code_1$6.checkReportMissingProp)(cxt, prop);
                }
            }
        }
        function exitOnErrorMode() {
            const missing = gen.let("missing");
            if (useLoop || $data) {
                const valid = gen.let("valid", true);
                cxt.block$data(valid, () => loopUntilMissing(missing, valid));
                cxt.ok(valid);
            }
            else {
                gen.if((0, code_1$6.checkMissingProp)(cxt, schema, missing));
                (0, code_1$6.reportMissingProp)(cxt, missing);
                gen.else();
            }
        }
        function loopAllRequired() {
            gen.forOf("prop", schemaCode, (prop) => {
                cxt.setParams({ missingProperty: prop });
                gen.if((0, code_1$6.noPropertyInData)(gen, data, prop, opts.ownProperties), () => cxt.error());
            });
        }
        function loopUntilMissing(missing, valid) {
            cxt.setParams({ missingProperty: missing });
            gen.forOf(missing, schemaCode, () => {
                gen.assign(valid, (0, code_1$6.propertyInData)(gen, data, missing, opts.ownProperties));
                gen.if((0, codegen_1$f.not)(valid), () => {
                    cxt.error();
                    gen.break();
                });
            }, codegen_1$f.nil);
        }
    },
};
required.default = def$l;

var limitItems = {};

Object.defineProperty(limitItems, "__esModule", { value: true });
const codegen_1$e = codegen;
const error$c = {
    message({ keyword, schemaCode }) {
        const comp = keyword === "maxItems" ? "more" : "fewer";
        return (0, codegen_1$e.str) `must NOT have ${comp} than ${schemaCode} items`;
    },
    params: ({ schemaCode }) => (0, codegen_1$e._) `{limit: ${schemaCode}}`,
};
const def$k = {
    keyword: ["maxItems", "minItems"],
    type: "array",
    schemaType: "number",
    $data: true,
    error: error$c,
    code(cxt) {
        const { keyword, data, schemaCode } = cxt;
        const op = keyword === "maxItems" ? codegen_1$e.operators.GT : codegen_1$e.operators.LT;
        cxt.fail$data((0, codegen_1$e._) `${data}.length ${op} ${schemaCode}`);
    },
};
limitItems.default = def$k;

var uniqueItems = {};

var equal$1 = {};

Object.defineProperty(equal$1, "__esModule", { value: true });
// https://github.com/ajv-validator/ajv/issues/889
const equal = fastDeepEqual;
equal.code = 'require("ajv/dist/runtime/equal").default';
equal$1.default = equal;

Object.defineProperty(uniqueItems, "__esModule", { value: true });
const dataType_1 = dataType;
const codegen_1$d = codegen;
const util_1$g = util;
const equal_1$2 = equal$1;
const error$b = {
    message: ({ params: { i, j } }) => (0, codegen_1$d.str) `must NOT have duplicate items (items ## ${j} and ${i} are identical)`,
    params: ({ params: { i, j } }) => (0, codegen_1$d._) `{i: ${i}, j: ${j}}`,
};
const def$j = {
    keyword: "uniqueItems",
    type: "array",
    schemaType: "boolean",
    $data: true,
    error: error$b,
    code(cxt) {
        const { gen, data, $data, schema, parentSchema, schemaCode, it } = cxt;
        if (!$data && !schema)
            return;
        const valid = gen.let("valid");
        const itemTypes = parentSchema.items ? (0, dataType_1.getSchemaTypes)(parentSchema.items) : [];
        cxt.block$data(valid, validateUniqueItems, (0, codegen_1$d._) `${schemaCode} === false`);
        cxt.ok(valid);
        function validateUniqueItems() {
            const i = gen.let("i", (0, codegen_1$d._) `${data}.length`);
            const j = gen.let("j");
            cxt.setParams({ i, j });
            gen.assign(valid, true);
            gen.if((0, codegen_1$d._) `${i} > 1`, () => (canOptimize() ? loopN : loopN2)(i, j));
        }
        function canOptimize() {
            return itemTypes.length > 0 && !itemTypes.some((t) => t === "object" || t === "array");
        }
        function loopN(i, j) {
            const item = gen.name("item");
            const wrongType = (0, dataType_1.checkDataTypes)(itemTypes, item, it.opts.strictNumbers, dataType_1.DataType.Wrong);
            const indices = gen.const("indices", (0, codegen_1$d._) `{}`);
            gen.for((0, codegen_1$d._) `;${i}--;`, () => {
                gen.let(item, (0, codegen_1$d._) `${data}[${i}]`);
                gen.if(wrongType, (0, codegen_1$d._) `continue`);
                if (itemTypes.length > 1)
                    gen.if((0, codegen_1$d._) `typeof ${item} == "string"`, (0, codegen_1$d._) `${item} += "_"`);
                gen
                    .if((0, codegen_1$d._) `typeof ${indices}[${item}] == "number"`, () => {
                    gen.assign(j, (0, codegen_1$d._) `${indices}[${item}]`);
                    cxt.error();
                    gen.assign(valid, false).break();
                })
                    .code((0, codegen_1$d._) `${indices}[${item}] = ${i}`);
            });
        }
        function loopN2(i, j) {
            const eql = (0, util_1$g.useFunc)(gen, equal_1$2.default);
            const outer = gen.name("outer");
            gen.label(outer).for((0, codegen_1$d._) `;${i}--;`, () => gen.for((0, codegen_1$d._) `${j} = ${i}; ${j}--;`, () => gen.if((0, codegen_1$d._) `${eql}(${data}[${i}], ${data}[${j}])`, () => {
                cxt.error();
                gen.assign(valid, false).break(outer);
            })));
        }
    },
};
uniqueItems.default = def$j;

var _const = {};

Object.defineProperty(_const, "__esModule", { value: true });
const codegen_1$c = codegen;
const util_1$f = util;
const equal_1$1 = equal$1;
const error$a = {
    message: "must be equal to constant",
    params: ({ schemaCode }) => (0, codegen_1$c._) `{allowedValue: ${schemaCode}}`,
};
const def$i = {
    keyword: "const",
    $data: true,
    error: error$a,
    code(cxt) {
        const { gen, data, $data, schemaCode, schema } = cxt;
        if ($data || (schema && typeof schema == "object")) {
            cxt.fail$data((0, codegen_1$c._) `!${(0, util_1$f.useFunc)(gen, equal_1$1.default)}(${data}, ${schemaCode})`);
        }
        else {
            cxt.fail((0, codegen_1$c._) `${schema} !== ${data}`);
        }
    },
};
_const.default = def$i;

var _enum = {};

Object.defineProperty(_enum, "__esModule", { value: true });
const codegen_1$b = codegen;
const util_1$e = util;
const equal_1 = equal$1;
const error$9 = {
    message: "must be equal to one of the allowed values",
    params: ({ schemaCode }) => (0, codegen_1$b._) `{allowedValues: ${schemaCode}}`,
};
const def$h = {
    keyword: "enum",
    schemaType: "array",
    $data: true,
    error: error$9,
    code(cxt) {
        const { gen, data, $data, schema, schemaCode, it } = cxt;
        if (!$data && schema.length === 0)
            throw new Error("enum must have non-empty array");
        const useLoop = schema.length >= it.opts.loopEnum;
        let eql;
        const getEql = () => (eql !== null && eql !== void 0 ? eql : (eql = (0, util_1$e.useFunc)(gen, equal_1.default)));
        let valid;
        if (useLoop || $data) {
            valid = gen.let("valid");
            cxt.block$data(valid, loopEnum);
        }
        else {
            /* istanbul ignore if */
            if (!Array.isArray(schema))
                throw new Error("ajv implementation error");
            const vSchema = gen.const("vSchema", schemaCode);
            valid = (0, codegen_1$b.or)(...schema.map((_x, i) => equalCode(vSchema, i)));
        }
        cxt.pass(valid);
        function loopEnum() {
            gen.assign(valid, false);
            gen.forOf("v", schemaCode, (v) => gen.if((0, codegen_1$b._) `${getEql()}(${data}, ${v})`, () => gen.assign(valid, true).break()));
        }
        function equalCode(vSchema, i) {
            const sch = schema[i];
            return typeof sch === "object" && sch !== null
                ? (0, codegen_1$b._) `${getEql()}(${data}, ${vSchema}[${i}])`
                : (0, codegen_1$b._) `${data} === ${sch}`;
        }
    },
};
_enum.default = def$h;

Object.defineProperty(validation$1, "__esModule", { value: true });
const limitNumber_1 = limitNumber;
const multipleOf_1 = multipleOf;
const limitLength_1 = limitLength;
const pattern_1 = pattern;
const limitProperties_1 = limitProperties;
const required_1 = required;
const limitItems_1 = limitItems;
const uniqueItems_1 = uniqueItems;
const const_1 = _const;
const enum_1 = _enum;
const validation = [
    // number
    limitNumber_1.default,
    multipleOf_1.default,
    // string
    limitLength_1.default,
    pattern_1.default,
    // object
    limitProperties_1.default,
    required_1.default,
    // array
    limitItems_1.default,
    uniqueItems_1.default,
    // any
    { keyword: "type", schemaType: ["string", "array"] },
    { keyword: "nullable", schemaType: "boolean" },
    const_1.default,
    enum_1.default,
];
validation$1.default = validation;

var applicator = {};

var additionalItems = {};

Object.defineProperty(additionalItems, "__esModule", { value: true });
additionalItems.validateAdditionalItems = void 0;
const codegen_1$a = codegen;
const util_1$d = util;
const error$8 = {
    message: ({ params: { len } }) => (0, codegen_1$a.str) `must NOT have more than ${len} items`,
    params: ({ params: { len } }) => (0, codegen_1$a._) `{limit: ${len}}`,
};
const def$g = {
    keyword: "additionalItems",
    type: "array",
    schemaType: ["boolean", "object"],
    before: "uniqueItems",
    error: error$8,
    code(cxt) {
        const { parentSchema, it } = cxt;
        const { items } = parentSchema;
        if (!Array.isArray(items)) {
            (0, util_1$d.checkStrictMode)(it, '"additionalItems" is ignored when "items" is not an array of schemas');
            return;
        }
        validateAdditionalItems(cxt, items);
    },
};
function validateAdditionalItems(cxt, items) {
    const { gen, schema, data, keyword, it } = cxt;
    it.items = true;
    const len = gen.const("len", (0, codegen_1$a._) `${data}.length`);
    if (schema === false) {
        cxt.setParams({ len: items.length });
        cxt.pass((0, codegen_1$a._) `${len} <= ${items.length}`);
    }
    else if (typeof schema == "object" && !(0, util_1$d.alwaysValidSchema)(it, schema)) {
        const valid = gen.var("valid", (0, codegen_1$a._) `${len} <= ${items.length}`); // TODO var
        gen.if((0, codegen_1$a.not)(valid), () => validateItems(valid));
        cxt.ok(valid);
    }
    function validateItems(valid) {
        gen.forRange("i", items.length, len, (i) => {
            cxt.subschema({ keyword, dataProp: i, dataPropType: util_1$d.Type.Num }, valid);
            if (!it.allErrors)
                gen.if((0, codegen_1$a.not)(valid), () => gen.break());
        });
    }
}
additionalItems.validateAdditionalItems = validateAdditionalItems;
additionalItems.default = def$g;

var prefixItems = {};

var items = {};

Object.defineProperty(items, "__esModule", { value: true });
items.validateTuple = void 0;
const codegen_1$9 = codegen;
const util_1$c = util;
const code_1$5 = code;
const def$f = {
    keyword: "items",
    type: "array",
    schemaType: ["object", "array", "boolean"],
    before: "uniqueItems",
    code(cxt) {
        const { schema, it } = cxt;
        if (Array.isArray(schema))
            return validateTuple(cxt, "additionalItems", schema);
        it.items = true;
        if ((0, util_1$c.alwaysValidSchema)(it, schema))
            return;
        cxt.ok((0, code_1$5.validateArray)(cxt));
    },
};
function validateTuple(cxt, extraItems, schArr = cxt.schema) {
    const { gen, parentSchema, data, keyword, it } = cxt;
    checkStrictTuple(parentSchema);
    if (it.opts.unevaluated && schArr.length && it.items !== true) {
        it.items = util_1$c.mergeEvaluated.items(gen, schArr.length, it.items);
    }
    const valid = gen.name("valid");
    const len = gen.const("len", (0, codegen_1$9._) `${data}.length`);
    schArr.forEach((sch, i) => {
        if ((0, util_1$c.alwaysValidSchema)(it, sch))
            return;
        gen.if((0, codegen_1$9._) `${len} > ${i}`, () => cxt.subschema({
            keyword,
            schemaProp: i,
            dataProp: i,
        }, valid));
        cxt.ok(valid);
    });
    function checkStrictTuple(sch) {
        const { opts, errSchemaPath } = it;
        const l = schArr.length;
        const fullTuple = l === sch.minItems && (l === sch.maxItems || sch[extraItems] === false);
        if (opts.strictTuples && !fullTuple) {
            const msg = `"${keyword}" is ${l}-tuple, but minItems or maxItems/${extraItems} are not specified or different at path "${errSchemaPath}"`;
            (0, util_1$c.checkStrictMode)(it, msg, opts.strictTuples);
        }
    }
}
items.validateTuple = validateTuple;
items.default = def$f;

Object.defineProperty(prefixItems, "__esModule", { value: true });
const items_1$1 = items;
const def$e = {
    keyword: "prefixItems",
    type: "array",
    schemaType: ["array"],
    before: "uniqueItems",
    code: (cxt) => (0, items_1$1.validateTuple)(cxt, "items"),
};
prefixItems.default = def$e;

var items2020 = {};

Object.defineProperty(items2020, "__esModule", { value: true });
const codegen_1$8 = codegen;
const util_1$b = util;
const code_1$4 = code;
const additionalItems_1$1 = additionalItems;
const error$7 = {
    message: ({ params: { len } }) => (0, codegen_1$8.str) `must NOT have more than ${len} items`,
    params: ({ params: { len } }) => (0, codegen_1$8._) `{limit: ${len}}`,
};
const def$d = {
    keyword: "items",
    type: "array",
    schemaType: ["object", "boolean"],
    before: "uniqueItems",
    error: error$7,
    code(cxt) {
        const { schema, parentSchema, it } = cxt;
        const { prefixItems } = parentSchema;
        it.items = true;
        if ((0, util_1$b.alwaysValidSchema)(it, schema))
            return;
        if (prefixItems)
            (0, additionalItems_1$1.validateAdditionalItems)(cxt, prefixItems);
        else
            cxt.ok((0, code_1$4.validateArray)(cxt));
    },
};
items2020.default = def$d;

var contains = {};

Object.defineProperty(contains, "__esModule", { value: true });
const codegen_1$7 = codegen;
const util_1$a = util;
const error$6 = {
    message: ({ params: { min, max } }) => max === undefined
        ? (0, codegen_1$7.str) `must contain at least ${min} valid item(s)`
        : (0, codegen_1$7.str) `must contain at least ${min} and no more than ${max} valid item(s)`,
    params: ({ params: { min, max } }) => max === undefined ? (0, codegen_1$7._) `{minContains: ${min}}` : (0, codegen_1$7._) `{minContains: ${min}, maxContains: ${max}}`,
};
const def$c = {
    keyword: "contains",
    type: "array",
    schemaType: ["object", "boolean"],
    before: "uniqueItems",
    trackErrors: true,
    error: error$6,
    code(cxt) {
        const { gen, schema, parentSchema, data, it } = cxt;
        let min;
        let max;
        const { minContains, maxContains } = parentSchema;
        if (it.opts.next) {
            min = minContains === undefined ? 1 : minContains;
            max = maxContains;
        }
        else {
            min = 1;
        }
        const len = gen.const("len", (0, codegen_1$7._) `${data}.length`);
        cxt.setParams({ min, max });
        if (max === undefined && min === 0) {
            (0, util_1$a.checkStrictMode)(it, `"minContains" == 0 without "maxContains": "contains" keyword ignored`);
            return;
        }
        if (max !== undefined && min > max) {
            (0, util_1$a.checkStrictMode)(it, `"minContains" > "maxContains" is always invalid`);
            cxt.fail();
            return;
        }
        if ((0, util_1$a.alwaysValidSchema)(it, schema)) {
            let cond = (0, codegen_1$7._) `${len} >= ${min}`;
            if (max !== undefined)
                cond = (0, codegen_1$7._) `${cond} && ${len} <= ${max}`;
            cxt.pass(cond);
            return;
        }
        it.items = true;
        const valid = gen.name("valid");
        if (max === undefined && min === 1) {
            validateItems(valid, () => gen.if(valid, () => gen.break()));
        }
        else if (min === 0) {
            gen.let(valid, true);
            if (max !== undefined)
                gen.if((0, codegen_1$7._) `${data}.length > 0`, validateItemsWithCount);
        }
        else {
            gen.let(valid, false);
            validateItemsWithCount();
        }
        cxt.result(valid, () => cxt.reset());
        function validateItemsWithCount() {
            const schValid = gen.name("_valid");
            const count = gen.let("count", 0);
            validateItems(schValid, () => gen.if(schValid, () => checkLimits(count)));
        }
        function validateItems(_valid, block) {
            gen.forRange("i", 0, len, (i) => {
                cxt.subschema({
                    keyword: "contains",
                    dataProp: i,
                    dataPropType: util_1$a.Type.Num,
                    compositeRule: true,
                }, _valid);
                block();
            });
        }
        function checkLimits(count) {
            gen.code((0, codegen_1$7._) `${count}++`);
            if (max === undefined) {
                gen.if((0, codegen_1$7._) `${count} >= ${min}`, () => gen.assign(valid, true).break());
            }
            else {
                gen.if((0, codegen_1$7._) `${count} > ${max}`, () => gen.assign(valid, false).break());
                if (min === 1)
                    gen.assign(valid, true);
                else
                    gen.if((0, codegen_1$7._) `${count} >= ${min}`, () => gen.assign(valid, true));
            }
        }
    },
};
contains.default = def$c;

var dependencies = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.validateSchemaDeps = exports.validatePropertyDeps = exports.error = void 0;
	const codegen_1 = codegen;
	const util_1 = util;
	const code_1 = code;
	exports.error = {
	    message: ({ params: { property, depsCount, deps } }) => {
	        const property_ies = depsCount === 1 ? "property" : "properties";
	        return (0, codegen_1.str) `must have ${property_ies} ${deps} when property ${property} is present`;
	    },
	    params: ({ params: { property, depsCount, deps, missingProperty } }) => (0, codegen_1._) `{property: ${property},
    missingProperty: ${missingProperty},
    depsCount: ${depsCount},
    deps: ${deps}}`, // TODO change to reference
	};
	const def = {
	    keyword: "dependencies",
	    type: "object",
	    schemaType: "object",
	    error: exports.error,
	    code(cxt) {
	        const [propDeps, schDeps] = splitDependencies(cxt);
	        validatePropertyDeps(cxt, propDeps);
	        validateSchemaDeps(cxt, schDeps);
	    },
	};
	function splitDependencies({ schema }) {
	    const propertyDeps = {};
	    const schemaDeps = {};
	    for (const key in schema) {
	        if (key === "__proto__")
	            continue;
	        const deps = Array.isArray(schema[key]) ? propertyDeps : schemaDeps;
	        deps[key] = schema[key];
	    }
	    return [propertyDeps, schemaDeps];
	}
	function validatePropertyDeps(cxt, propertyDeps = cxt.schema) {
	    const { gen, data, it } = cxt;
	    if (Object.keys(propertyDeps).length === 0)
	        return;
	    const missing = gen.let("missing");
	    for (const prop in propertyDeps) {
	        const deps = propertyDeps[prop];
	        if (deps.length === 0)
	            continue;
	        const hasProperty = (0, code_1.propertyInData)(gen, data, prop, it.opts.ownProperties);
	        cxt.setParams({
	            property: prop,
	            depsCount: deps.length,
	            deps: deps.join(", "),
	        });
	        if (it.allErrors) {
	            gen.if(hasProperty, () => {
	                for (const depProp of deps) {
	                    (0, code_1.checkReportMissingProp)(cxt, depProp);
	                }
	            });
	        }
	        else {
	            gen.if((0, codegen_1._) `${hasProperty} && (${(0, code_1.checkMissingProp)(cxt, deps, missing)})`);
	            (0, code_1.reportMissingProp)(cxt, missing);
	            gen.else();
	        }
	    }
	}
	exports.validatePropertyDeps = validatePropertyDeps;
	function validateSchemaDeps(cxt, schemaDeps = cxt.schema) {
	    const { gen, data, keyword, it } = cxt;
	    const valid = gen.name("valid");
	    for (const prop in schemaDeps) {
	        if ((0, util_1.alwaysValidSchema)(it, schemaDeps[prop]))
	            continue;
	        gen.if((0, code_1.propertyInData)(gen, data, prop, it.opts.ownProperties), () => {
	            const schCxt = cxt.subschema({ keyword, schemaProp: prop }, valid);
	            cxt.mergeValidEvaluated(schCxt, valid);
	        }, () => gen.var(valid, true) // TODO var
	        );
	        cxt.ok(valid);
	    }
	}
	exports.validateSchemaDeps = validateSchemaDeps;
	exports.default = def;
	
} (dependencies));

var propertyNames = {};

Object.defineProperty(propertyNames, "__esModule", { value: true });
const codegen_1$6 = codegen;
const util_1$9 = util;
const error$5 = {
    message: "property name must be valid",
    params: ({ params }) => (0, codegen_1$6._) `{propertyName: ${params.propertyName}}`,
};
const def$b = {
    keyword: "propertyNames",
    type: "object",
    schemaType: ["object", "boolean"],
    error: error$5,
    code(cxt) {
        const { gen, schema, data, it } = cxt;
        if ((0, util_1$9.alwaysValidSchema)(it, schema))
            return;
        const valid = gen.name("valid");
        gen.forIn("key", data, (key) => {
            cxt.setParams({ propertyName: key });
            cxt.subschema({
                keyword: "propertyNames",
                data: key,
                dataTypes: ["string"],
                propertyName: key,
                compositeRule: true,
            }, valid);
            gen.if((0, codegen_1$6.not)(valid), () => {
                cxt.error(true);
                if (!it.allErrors)
                    gen.break();
            });
        });
        cxt.ok(valid);
    },
};
propertyNames.default = def$b;

var additionalProperties = {};

Object.defineProperty(additionalProperties, "__esModule", { value: true });
const code_1$3 = code;
const codegen_1$5 = codegen;
const names_1 = names$1;
const util_1$8 = util;
const error$4 = {
    message: "must NOT have additional properties",
    params: ({ params }) => (0, codegen_1$5._) `{additionalProperty: ${params.additionalProperty}}`,
};
const def$a = {
    keyword: "additionalProperties",
    type: ["object"],
    schemaType: ["boolean", "object"],
    allowUndefined: true,
    trackErrors: true,
    error: error$4,
    code(cxt) {
        const { gen, schema, parentSchema, data, errsCount, it } = cxt;
        /* istanbul ignore if */
        if (!errsCount)
            throw new Error("ajv implementation error");
        const { allErrors, opts } = it;
        it.props = true;
        if (opts.removeAdditional !== "all" && (0, util_1$8.alwaysValidSchema)(it, schema))
            return;
        const props = (0, code_1$3.allSchemaProperties)(parentSchema.properties);
        const patProps = (0, code_1$3.allSchemaProperties)(parentSchema.patternProperties);
        checkAdditionalProperties();
        cxt.ok((0, codegen_1$5._) `${errsCount} === ${names_1.default.errors}`);
        function checkAdditionalProperties() {
            gen.forIn("key", data, (key) => {
                if (!props.length && !patProps.length)
                    additionalPropertyCode(key);
                else
                    gen.if(isAdditional(key), () => additionalPropertyCode(key));
            });
        }
        function isAdditional(key) {
            let definedProp;
            if (props.length > 8) {
                // TODO maybe an option instead of hard-coded 8?
                const propsSchema = (0, util_1$8.schemaRefOrVal)(it, parentSchema.properties, "properties");
                definedProp = (0, code_1$3.isOwnProperty)(gen, propsSchema, key);
            }
            else if (props.length) {
                definedProp = (0, codegen_1$5.or)(...props.map((p) => (0, codegen_1$5._) `${key} === ${p}`));
            }
            else {
                definedProp = codegen_1$5.nil;
            }
            if (patProps.length) {
                definedProp = (0, codegen_1$5.or)(definedProp, ...patProps.map((p) => (0, codegen_1$5._) `${(0, code_1$3.usePattern)(cxt, p)}.test(${key})`));
            }
            return (0, codegen_1$5.not)(definedProp);
        }
        function deleteAdditional(key) {
            gen.code((0, codegen_1$5._) `delete ${data}[${key}]`);
        }
        function additionalPropertyCode(key) {
            if (opts.removeAdditional === "all" || (opts.removeAdditional && schema === false)) {
                deleteAdditional(key);
                return;
            }
            if (schema === false) {
                cxt.setParams({ additionalProperty: key });
                cxt.error();
                if (!allErrors)
                    gen.break();
                return;
            }
            if (typeof schema == "object" && !(0, util_1$8.alwaysValidSchema)(it, schema)) {
                const valid = gen.name("valid");
                if (opts.removeAdditional === "failing") {
                    applyAdditionalSchema(key, valid, false);
                    gen.if((0, codegen_1$5.not)(valid), () => {
                        cxt.reset();
                        deleteAdditional(key);
                    });
                }
                else {
                    applyAdditionalSchema(key, valid);
                    if (!allErrors)
                        gen.if((0, codegen_1$5.not)(valid), () => gen.break());
                }
            }
        }
        function applyAdditionalSchema(key, valid, errors) {
            const subschema = {
                keyword: "additionalProperties",
                dataProp: key,
                dataPropType: util_1$8.Type.Str,
            };
            if (errors === false) {
                Object.assign(subschema, {
                    compositeRule: true,
                    createErrors: false,
                    allErrors: false,
                });
            }
            cxt.subschema(subschema, valid);
        }
    },
};
additionalProperties.default = def$a;

var properties$1 = {};

Object.defineProperty(properties$1, "__esModule", { value: true });
const validate_1 = validate;
const code_1$2 = code;
const util_1$7 = util;
const additionalProperties_1$1 = additionalProperties;
const def$9 = {
    keyword: "properties",
    type: "object",
    schemaType: "object",
    code(cxt) {
        const { gen, schema, parentSchema, data, it } = cxt;
        if (it.opts.removeAdditional === "all" && parentSchema.additionalProperties === undefined) {
            additionalProperties_1$1.default.code(new validate_1.KeywordCxt(it, additionalProperties_1$1.default, "additionalProperties"));
        }
        const allProps = (0, code_1$2.allSchemaProperties)(schema);
        for (const prop of allProps) {
            it.definedProperties.add(prop);
        }
        if (it.opts.unevaluated && allProps.length && it.props !== true) {
            it.props = util_1$7.mergeEvaluated.props(gen, (0, util_1$7.toHash)(allProps), it.props);
        }
        const properties = allProps.filter((p) => !(0, util_1$7.alwaysValidSchema)(it, schema[p]));
        if (properties.length === 0)
            return;
        const valid = gen.name("valid");
        for (const prop of properties) {
            if (hasDefault(prop)) {
                applyPropertySchema(prop);
            }
            else {
                gen.if((0, code_1$2.propertyInData)(gen, data, prop, it.opts.ownProperties));
                applyPropertySchema(prop);
                if (!it.allErrors)
                    gen.else().var(valid, true);
                gen.endIf();
            }
            cxt.it.definedProperties.add(prop);
            cxt.ok(valid);
        }
        function hasDefault(prop) {
            return it.opts.useDefaults && !it.compositeRule && schema[prop].default !== undefined;
        }
        function applyPropertySchema(prop) {
            cxt.subschema({
                keyword: "properties",
                schemaProp: prop,
                dataProp: prop,
            }, valid);
        }
    },
};
properties$1.default = def$9;

var patternProperties = {};

Object.defineProperty(patternProperties, "__esModule", { value: true });
const code_1$1 = code;
const codegen_1$4 = codegen;
const util_1$6 = util;
const util_2 = util;
const def$8 = {
    keyword: "patternProperties",
    type: "object",
    schemaType: "object",
    code(cxt) {
        const { gen, schema, data, parentSchema, it } = cxt;
        const { opts } = it;
        const patterns = (0, code_1$1.allSchemaProperties)(schema);
        const alwaysValidPatterns = patterns.filter((p) => (0, util_1$6.alwaysValidSchema)(it, schema[p]));
        if (patterns.length === 0 ||
            (alwaysValidPatterns.length === patterns.length &&
                (!it.opts.unevaluated || it.props === true))) {
            return;
        }
        const checkProperties = opts.strictSchema && !opts.allowMatchingProperties && parentSchema.properties;
        const valid = gen.name("valid");
        if (it.props !== true && !(it.props instanceof codegen_1$4.Name)) {
            it.props = (0, util_2.evaluatedPropsToName)(gen, it.props);
        }
        const { props } = it;
        validatePatternProperties();
        function validatePatternProperties() {
            for (const pat of patterns) {
                if (checkProperties)
                    checkMatchingProperties(pat);
                if (it.allErrors) {
                    validateProperties(pat);
                }
                else {
                    gen.var(valid, true); // TODO var
                    validateProperties(pat);
                    gen.if(valid);
                }
            }
        }
        function checkMatchingProperties(pat) {
            for (const prop in checkProperties) {
                if (new RegExp(pat).test(prop)) {
                    (0, util_1$6.checkStrictMode)(it, `property ${prop} matches pattern ${pat} (use allowMatchingProperties)`);
                }
            }
        }
        function validateProperties(pat) {
            gen.forIn("key", data, (key) => {
                gen.if((0, codegen_1$4._) `${(0, code_1$1.usePattern)(cxt, pat)}.test(${key})`, () => {
                    const alwaysValid = alwaysValidPatterns.includes(pat);
                    if (!alwaysValid) {
                        cxt.subschema({
                            keyword: "patternProperties",
                            schemaProp: pat,
                            dataProp: key,
                            dataPropType: util_2.Type.Str,
                        }, valid);
                    }
                    if (it.opts.unevaluated && props !== true) {
                        gen.assign((0, codegen_1$4._) `${props}[${key}]`, true);
                    }
                    else if (!alwaysValid && !it.allErrors) {
                        // can short-circuit if `unevaluatedProperties` is not supported (opts.next === false)
                        // or if all properties were evaluated (props === true)
                        gen.if((0, codegen_1$4.not)(valid), () => gen.break());
                    }
                });
            });
        }
    },
};
patternProperties.default = def$8;

var not = {};

Object.defineProperty(not, "__esModule", { value: true });
const util_1$5 = util;
const def$7 = {
    keyword: "not",
    schemaType: ["object", "boolean"],
    trackErrors: true,
    code(cxt) {
        const { gen, schema, it } = cxt;
        if ((0, util_1$5.alwaysValidSchema)(it, schema)) {
            cxt.fail();
            return;
        }
        const valid = gen.name("valid");
        cxt.subschema({
            keyword: "not",
            compositeRule: true,
            createErrors: false,
            allErrors: false,
        }, valid);
        cxt.failResult(valid, () => cxt.reset(), () => cxt.error());
    },
    error: { message: "must NOT be valid" },
};
not.default = def$7;

var anyOf = {};

Object.defineProperty(anyOf, "__esModule", { value: true });
const code_1 = code;
const def$6 = {
    keyword: "anyOf",
    schemaType: "array",
    trackErrors: true,
    code: code_1.validateUnion,
    error: { message: "must match a schema in anyOf" },
};
anyOf.default = def$6;

var oneOf = {};

Object.defineProperty(oneOf, "__esModule", { value: true });
const codegen_1$3 = codegen;
const util_1$4 = util;
const error$3 = {
    message: "must match exactly one schema in oneOf",
    params: ({ params }) => (0, codegen_1$3._) `{passingSchemas: ${params.passing}}`,
};
const def$5 = {
    keyword: "oneOf",
    schemaType: "array",
    trackErrors: true,
    error: error$3,
    code(cxt) {
        const { gen, schema, parentSchema, it } = cxt;
        /* istanbul ignore if */
        if (!Array.isArray(schema))
            throw new Error("ajv implementation error");
        if (it.opts.discriminator && parentSchema.discriminator)
            return;
        const schArr = schema;
        const valid = gen.let("valid", false);
        const passing = gen.let("passing", null);
        const schValid = gen.name("_valid");
        cxt.setParams({ passing });
        // TODO possibly fail straight away (with warning or exception) if there are two empty always valid schemas
        gen.block(validateOneOf);
        cxt.result(valid, () => cxt.reset(), () => cxt.error(true));
        function validateOneOf() {
            schArr.forEach((sch, i) => {
                let schCxt;
                if ((0, util_1$4.alwaysValidSchema)(it, sch)) {
                    gen.var(schValid, true);
                }
                else {
                    schCxt = cxt.subschema({
                        keyword: "oneOf",
                        schemaProp: i,
                        compositeRule: true,
                    }, schValid);
                }
                if (i > 0) {
                    gen
                        .if((0, codegen_1$3._) `${schValid} && ${valid}`)
                        .assign(valid, false)
                        .assign(passing, (0, codegen_1$3._) `[${passing}, ${i}]`)
                        .else();
                }
                gen.if(schValid, () => {
                    gen.assign(valid, true);
                    gen.assign(passing, i);
                    if (schCxt)
                        cxt.mergeEvaluated(schCxt, codegen_1$3.Name);
                });
            });
        }
    },
};
oneOf.default = def$5;

var allOf = {};

Object.defineProperty(allOf, "__esModule", { value: true });
const util_1$3 = util;
const def$4 = {
    keyword: "allOf",
    schemaType: "array",
    code(cxt) {
        const { gen, schema, it } = cxt;
        /* istanbul ignore if */
        if (!Array.isArray(schema))
            throw new Error("ajv implementation error");
        const valid = gen.name("valid");
        schema.forEach((sch, i) => {
            if ((0, util_1$3.alwaysValidSchema)(it, sch))
                return;
            const schCxt = cxt.subschema({ keyword: "allOf", schemaProp: i }, valid);
            cxt.ok(valid);
            cxt.mergeEvaluated(schCxt);
        });
    },
};
allOf.default = def$4;

var _if = {};

Object.defineProperty(_if, "__esModule", { value: true });
const codegen_1$2 = codegen;
const util_1$2 = util;
const error$2 = {
    message: ({ params }) => (0, codegen_1$2.str) `must match "${params.ifClause}" schema`,
    params: ({ params }) => (0, codegen_1$2._) `{failingKeyword: ${params.ifClause}}`,
};
const def$3 = {
    keyword: "if",
    schemaType: ["object", "boolean"],
    trackErrors: true,
    error: error$2,
    code(cxt) {
        const { gen, parentSchema, it } = cxt;
        if (parentSchema.then === undefined && parentSchema.else === undefined) {
            (0, util_1$2.checkStrictMode)(it, '"if" without "then" and "else" is ignored');
        }
        const hasThen = hasSchema(it, "then");
        const hasElse = hasSchema(it, "else");
        if (!hasThen && !hasElse)
            return;
        const valid = gen.let("valid", true);
        const schValid = gen.name("_valid");
        validateIf();
        cxt.reset();
        if (hasThen && hasElse) {
            const ifClause = gen.let("ifClause");
            cxt.setParams({ ifClause });
            gen.if(schValid, validateClause("then", ifClause), validateClause("else", ifClause));
        }
        else if (hasThen) {
            gen.if(schValid, validateClause("then"));
        }
        else {
            gen.if((0, codegen_1$2.not)(schValid), validateClause("else"));
        }
        cxt.pass(valid, () => cxt.error(true));
        function validateIf() {
            const schCxt = cxt.subschema({
                keyword: "if",
                compositeRule: true,
                createErrors: false,
                allErrors: false,
            }, schValid);
            cxt.mergeEvaluated(schCxt);
        }
        function validateClause(keyword, ifClause) {
            return () => {
                const schCxt = cxt.subschema({ keyword }, schValid);
                gen.assign(valid, schValid);
                cxt.mergeValidEvaluated(schCxt, valid);
                if (ifClause)
                    gen.assign(ifClause, (0, codegen_1$2._) `${keyword}`);
                else
                    cxt.setParams({ ifClause: keyword });
            };
        }
    },
};
function hasSchema(it, keyword) {
    const schema = it.schema[keyword];
    return schema !== undefined && !(0, util_1$2.alwaysValidSchema)(it, schema);
}
_if.default = def$3;

var thenElse = {};

Object.defineProperty(thenElse, "__esModule", { value: true });
const util_1$1 = util;
const def$2 = {
    keyword: ["then", "else"],
    schemaType: ["object", "boolean"],
    code({ keyword, parentSchema, it }) {
        if (parentSchema.if === undefined)
            (0, util_1$1.checkStrictMode)(it, `"${keyword}" without "if" is ignored`);
    },
};
thenElse.default = def$2;

Object.defineProperty(applicator, "__esModule", { value: true });
const additionalItems_1 = additionalItems;
const prefixItems_1 = prefixItems;
const items_1 = items;
const items2020_1 = items2020;
const contains_1 = contains;
const dependencies_1 = dependencies;
const propertyNames_1 = propertyNames;
const additionalProperties_1 = additionalProperties;
const properties_1 = properties$1;
const patternProperties_1 = patternProperties;
const not_1 = not;
const anyOf_1 = anyOf;
const oneOf_1 = oneOf;
const allOf_1 = allOf;
const if_1 = _if;
const thenElse_1 = thenElse;
function getApplicator(draft2020 = false) {
    const applicator = [
        // any
        not_1.default,
        anyOf_1.default,
        oneOf_1.default,
        allOf_1.default,
        if_1.default,
        thenElse_1.default,
        // object
        propertyNames_1.default,
        additionalProperties_1.default,
        dependencies_1.default,
        properties_1.default,
        patternProperties_1.default,
    ];
    // array
    if (draft2020)
        applicator.push(prefixItems_1.default, items2020_1.default);
    else
        applicator.push(additionalItems_1.default, items_1.default);
    applicator.push(contains_1.default);
    return applicator;
}
applicator.default = getApplicator;

var format$2 = {};

var format$1 = {};

Object.defineProperty(format$1, "__esModule", { value: true });
const codegen_1$1 = codegen;
const error$1 = {
    message: ({ schemaCode }) => (0, codegen_1$1.str) `must match format "${schemaCode}"`,
    params: ({ schemaCode }) => (0, codegen_1$1._) `{format: ${schemaCode}}`,
};
const def$1 = {
    keyword: "format",
    type: ["number", "string"],
    schemaType: "string",
    $data: true,
    error: error$1,
    code(cxt, ruleType) {
        const { gen, data, $data, schema, schemaCode, it } = cxt;
        const { opts, errSchemaPath, schemaEnv, self } = it;
        if (!opts.validateFormats)
            return;
        if ($data)
            validate$DataFormat();
        else
            validateFormat();
        function validate$DataFormat() {
            const fmts = gen.scopeValue("formats", {
                ref: self.formats,
                code: opts.code.formats,
            });
            const fDef = gen.const("fDef", (0, codegen_1$1._) `${fmts}[${schemaCode}]`);
            const fType = gen.let("fType");
            const format = gen.let("format");
            // TODO simplify
            gen.if((0, codegen_1$1._) `typeof ${fDef} == "object" && !(${fDef} instanceof RegExp)`, () => gen.assign(fType, (0, codegen_1$1._) `${fDef}.type || "string"`).assign(format, (0, codegen_1$1._) `${fDef}.validate`), () => gen.assign(fType, (0, codegen_1$1._) `"string"`).assign(format, fDef));
            cxt.fail$data((0, codegen_1$1.or)(unknownFmt(), invalidFmt()));
            function unknownFmt() {
                if (opts.strictSchema === false)
                    return codegen_1$1.nil;
                return (0, codegen_1$1._) `${schemaCode} && !${format}`;
            }
            function invalidFmt() {
                const callFormat = schemaEnv.$async
                    ? (0, codegen_1$1._) `(${fDef}.async ? await ${format}(${data}) : ${format}(${data}))`
                    : (0, codegen_1$1._) `${format}(${data})`;
                const validData = (0, codegen_1$1._) `(typeof ${format} == "function" ? ${callFormat} : ${format}.test(${data}))`;
                return (0, codegen_1$1._) `${format} && ${format} !== true && ${fType} === ${ruleType} && !${validData}`;
            }
        }
        function validateFormat() {
            const formatDef = self.formats[schema];
            if (!formatDef) {
                unknownFormat();
                return;
            }
            if (formatDef === true)
                return;
            const [fmtType, format, fmtRef] = getFormat(formatDef);
            if (fmtType === ruleType)
                cxt.pass(validCondition());
            function unknownFormat() {
                if (opts.strictSchema === false) {
                    self.logger.warn(unknownMsg());
                    return;
                }
                throw new Error(unknownMsg());
                function unknownMsg() {
                    return `unknown format "${schema}" ignored in schema at path "${errSchemaPath}"`;
                }
            }
            function getFormat(fmtDef) {
                const code = fmtDef instanceof RegExp
                    ? (0, codegen_1$1.regexpCode)(fmtDef)
                    : opts.code.formats
                        ? (0, codegen_1$1._) `${opts.code.formats}${(0, codegen_1$1.getProperty)(schema)}`
                        : undefined;
                const fmt = gen.scopeValue("formats", { key: schema, ref: fmtDef, code });
                if (typeof fmtDef == "object" && !(fmtDef instanceof RegExp)) {
                    return [fmtDef.type || "string", fmtDef.validate, (0, codegen_1$1._) `${fmt}.validate`];
                }
                return ["string", fmtDef, fmt];
            }
            function validCondition() {
                if (typeof formatDef == "object" && !(formatDef instanceof RegExp) && formatDef.async) {
                    if (!schemaEnv.$async)
                        throw new Error("async format in sync schema");
                    return (0, codegen_1$1._) `await ${fmtRef}(${data})`;
                }
                return typeof format == "function" ? (0, codegen_1$1._) `${fmtRef}(${data})` : (0, codegen_1$1._) `${fmtRef}.test(${data})`;
            }
        }
    },
};
format$1.default = def$1;

Object.defineProperty(format$2, "__esModule", { value: true });
const format_1$1 = format$1;
const format = [format_1$1.default];
format$2.default = format;

var metadata = {};

Object.defineProperty(metadata, "__esModule", { value: true });
metadata.contentVocabulary = metadata.metadataVocabulary = void 0;
metadata.metadataVocabulary = [
    "title",
    "description",
    "default",
    "deprecated",
    "readOnly",
    "writeOnly",
    "examples",
];
metadata.contentVocabulary = [
    "contentMediaType",
    "contentEncoding",
    "contentSchema",
];

Object.defineProperty(draft7, "__esModule", { value: true });
const core_1 = core$1;
const validation_1 = validation$1;
const applicator_1 = applicator;
const format_1 = format$2;
const metadata_1 = metadata;
const draft7Vocabularies = [
    core_1.default,
    validation_1.default,
    (0, applicator_1.default)(),
    format_1.default,
    metadata_1.metadataVocabulary,
    metadata_1.contentVocabulary,
];
draft7.default = draft7Vocabularies;

var discriminator = {};

var types = {};

(function (exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.DiscrError = void 0;
	(function (DiscrError) {
	    DiscrError["Tag"] = "tag";
	    DiscrError["Mapping"] = "mapping";
	})(exports.DiscrError || (exports.DiscrError = {}));
	
} (types));

Object.defineProperty(discriminator, "__esModule", { value: true });
const codegen_1 = codegen;
const types_1 = types;
const compile_1 = compile;
const util_1 = util;
const error = {
    message: ({ params: { discrError, tagName } }) => discrError === types_1.DiscrError.Tag
        ? `tag "${tagName}" must be string`
        : `value of tag "${tagName}" must be in oneOf`,
    params: ({ params: { discrError, tag, tagName } }) => (0, codegen_1._) `{error: ${discrError}, tag: ${tagName}, tagValue: ${tag}}`,
};
const def = {
    keyword: "discriminator",
    type: "object",
    schemaType: "object",
    error,
    code(cxt) {
        const { gen, data, schema, parentSchema, it } = cxt;
        const { oneOf } = parentSchema;
        if (!it.opts.discriminator) {
            throw new Error("discriminator: requires discriminator option");
        }
        const tagName = schema.propertyName;
        if (typeof tagName != "string")
            throw new Error("discriminator: requires propertyName");
        if (schema.mapping)
            throw new Error("discriminator: mapping is not supported");
        if (!oneOf)
            throw new Error("discriminator: requires oneOf keyword");
        const valid = gen.let("valid", false);
        const tag = gen.const("tag", (0, codegen_1._) `${data}${(0, codegen_1.getProperty)(tagName)}`);
        gen.if((0, codegen_1._) `typeof ${tag} == "string"`, () => validateMapping(), () => cxt.error(false, { discrError: types_1.DiscrError.Tag, tag, tagName }));
        cxt.ok(valid);
        function validateMapping() {
            const mapping = getMapping();
            gen.if(false);
            for (const tagValue in mapping) {
                gen.elseIf((0, codegen_1._) `${tag} === ${tagValue}`);
                gen.assign(valid, applyTagSchema(mapping[tagValue]));
            }
            gen.else();
            cxt.error(false, { discrError: types_1.DiscrError.Mapping, tag, tagName });
            gen.endIf();
        }
        function applyTagSchema(schemaProp) {
            const _valid = gen.name("valid");
            const schCxt = cxt.subschema({ keyword: "oneOf", schemaProp }, _valid);
            cxt.mergeEvaluated(schCxt, codegen_1.Name);
            return _valid;
        }
        function getMapping() {
            var _a;
            const oneOfMapping = {};
            const topRequired = hasRequired(parentSchema);
            let tagRequired = true;
            for (let i = 0; i < oneOf.length; i++) {
                let sch = oneOf[i];
                if ((sch === null || sch === void 0 ? void 0 : sch.$ref) && !(0, util_1.schemaHasRulesButRef)(sch, it.self.RULES)) {
                    sch = compile_1.resolveRef.call(it.self, it.schemaEnv.root, it.baseId, sch === null || sch === void 0 ? void 0 : sch.$ref);
                    if (sch instanceof compile_1.SchemaEnv)
                        sch = sch.schema;
                }
                const propSch = (_a = sch === null || sch === void 0 ? void 0 : sch.properties) === null || _a === void 0 ? void 0 : _a[tagName];
                if (typeof propSch != "object") {
                    throw new Error(`discriminator: oneOf subschemas (or referenced schemas) must have "properties/${tagName}"`);
                }
                tagRequired = tagRequired && (topRequired || hasRequired(sch));
                addMappings(propSch, i);
            }
            if (!tagRequired)
                throw new Error(`discriminator: "${tagName}" must be required`);
            return oneOfMapping;
            function hasRequired({ required }) {
                return Array.isArray(required) && required.includes(tagName);
            }
            function addMappings(sch, i) {
                if (sch.const) {
                    addMapping(sch.const, i);
                }
                else if (sch.enum) {
                    for (const tagValue of sch.enum) {
                        addMapping(tagValue, i);
                    }
                }
                else {
                    throw new Error(`discriminator: "properties/${tagName}" must have "const" or "enum"`);
                }
            }
            function addMapping(tagValue, i) {
                if (typeof tagValue != "string" || tagValue in oneOfMapping) {
                    throw new Error(`discriminator: "${tagName}" values must be unique strings`);
                }
                oneOfMapping[tagValue] = i;
            }
        }
    },
};
discriminator.default = def;

var $schema = "http://json-schema.org/draft-07/schema#";
var $id = "http://json-schema.org/draft-07/schema#";
var title = "Core schema meta-schema";
var definitions = {
	schemaArray: {
		type: "array",
		minItems: 1,
		items: {
			$ref: "#"
		}
	},
	nonNegativeInteger: {
		type: "integer",
		minimum: 0
	},
	nonNegativeIntegerDefault0: {
		allOf: [
			{
				$ref: "#/definitions/nonNegativeInteger"
			},
			{
				"default": 0
			}
		]
	},
	simpleTypes: {
		"enum": [
			"array",
			"boolean",
			"integer",
			"null",
			"number",
			"object",
			"string"
		]
	},
	stringArray: {
		type: "array",
		items: {
			type: "string"
		},
		uniqueItems: true,
		"default": [
		]
	}
};
var type = [
	"object",
	"boolean"
];
var properties = {
	$id: {
		type: "string",
		format: "uri-reference"
	},
	$schema: {
		type: "string",
		format: "uri"
	},
	$ref: {
		type: "string",
		format: "uri-reference"
	},
	$comment: {
		type: "string"
	},
	title: {
		type: "string"
	},
	description: {
		type: "string"
	},
	"default": true,
	readOnly: {
		type: "boolean",
		"default": false
	},
	examples: {
		type: "array",
		items: true
	},
	multipleOf: {
		type: "number",
		exclusiveMinimum: 0
	},
	maximum: {
		type: "number"
	},
	exclusiveMaximum: {
		type: "number"
	},
	minimum: {
		type: "number"
	},
	exclusiveMinimum: {
		type: "number"
	},
	maxLength: {
		$ref: "#/definitions/nonNegativeInteger"
	},
	minLength: {
		$ref: "#/definitions/nonNegativeIntegerDefault0"
	},
	pattern: {
		type: "string",
		format: "regex"
	},
	additionalItems: {
		$ref: "#"
	},
	items: {
		anyOf: [
			{
				$ref: "#"
			},
			{
				$ref: "#/definitions/schemaArray"
			}
		],
		"default": true
	},
	maxItems: {
		$ref: "#/definitions/nonNegativeInteger"
	},
	minItems: {
		$ref: "#/definitions/nonNegativeIntegerDefault0"
	},
	uniqueItems: {
		type: "boolean",
		"default": false
	},
	contains: {
		$ref: "#"
	},
	maxProperties: {
		$ref: "#/definitions/nonNegativeInteger"
	},
	minProperties: {
		$ref: "#/definitions/nonNegativeIntegerDefault0"
	},
	required: {
		$ref: "#/definitions/stringArray"
	},
	additionalProperties: {
		$ref: "#"
	},
	definitions: {
		type: "object",
		additionalProperties: {
			$ref: "#"
		},
		"default": {
		}
	},
	properties: {
		type: "object",
		additionalProperties: {
			$ref: "#"
		},
		"default": {
		}
	},
	patternProperties: {
		type: "object",
		additionalProperties: {
			$ref: "#"
		},
		propertyNames: {
			format: "regex"
		},
		"default": {
		}
	},
	dependencies: {
		type: "object",
		additionalProperties: {
			anyOf: [
				{
					$ref: "#"
				},
				{
					$ref: "#/definitions/stringArray"
				}
			]
		}
	},
	propertyNames: {
		$ref: "#"
	},
	"const": true,
	"enum": {
		type: "array",
		items: true,
		minItems: 1,
		uniqueItems: true
	},
	type: {
		anyOf: [
			{
				$ref: "#/definitions/simpleTypes"
			},
			{
				type: "array",
				items: {
					$ref: "#/definitions/simpleTypes"
				},
				minItems: 1,
				uniqueItems: true
			}
		]
	},
	format: {
		type: "string"
	},
	contentMediaType: {
		type: "string"
	},
	contentEncoding: {
		type: "string"
	},
	"if": {
		$ref: "#"
	},
	then: {
		$ref: "#"
	},
	"else": {
		$ref: "#"
	},
	allOf: {
		$ref: "#/definitions/schemaArray"
	},
	anyOf: {
		$ref: "#/definitions/schemaArray"
	},
	oneOf: {
		$ref: "#/definitions/schemaArray"
	},
	not: {
		$ref: "#"
	}
};
var require$$3 = {
	$schema: $schema,
	$id: $id,
	title: title,
	definitions: definitions,
	type: type,
	properties: properties,
	"default": true
};

(function (module, exports) {
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.MissingRefError = exports.ValidationError = exports.CodeGen = exports.Name = exports.nil = exports.stringify = exports.str = exports._ = exports.KeywordCxt = void 0;
	const core_1 = core$2;
	const draft7_1 = draft7;
	const discriminator_1 = discriminator;
	const draft7MetaSchema = require$$3;
	const META_SUPPORT_DATA = ["/properties"];
	const META_SCHEMA_ID = "http://json-schema.org/draft-07/schema";
	class Ajv extends core_1.default {
	    _addVocabularies() {
	        super._addVocabularies();
	        draft7_1.default.forEach((v) => this.addVocabulary(v));
	        if (this.opts.discriminator)
	            this.addKeyword(discriminator_1.default);
	    }
	    _addDefaultMetaSchema() {
	        super._addDefaultMetaSchema();
	        if (!this.opts.meta)
	            return;
	        const metaSchema = this.opts.$data
	            ? this.$dataMetaSchema(draft7MetaSchema, META_SUPPORT_DATA)
	            : draft7MetaSchema;
	        this.addMetaSchema(metaSchema, META_SCHEMA_ID, false);
	        this.refs["http://json-schema.org/schema"] = META_SCHEMA_ID;
	    }
	    defaultMeta() {
	        return (this.opts.defaultMeta =
	            super.defaultMeta() || (this.getSchema(META_SCHEMA_ID) ? META_SCHEMA_ID : undefined));
	    }
	}
	module.exports = exports = Ajv;
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.default = Ajv;
	var validate_1 = validate;
	Object.defineProperty(exports, "KeywordCxt", { enumerable: true, get: function () { return validate_1.KeywordCxt; } });
	var codegen_1 = codegen;
	Object.defineProperty(exports, "_", { enumerable: true, get: function () { return codegen_1._; } });
	Object.defineProperty(exports, "str", { enumerable: true, get: function () { return codegen_1.str; } });
	Object.defineProperty(exports, "stringify", { enumerable: true, get: function () { return codegen_1.stringify; } });
	Object.defineProperty(exports, "nil", { enumerable: true, get: function () { return codegen_1.nil; } });
	Object.defineProperty(exports, "Name", { enumerable: true, get: function () { return codegen_1.Name; } });
	Object.defineProperty(exports, "CodeGen", { enumerable: true, get: function () { return codegen_1.CodeGen; } });
	var validation_error_1 = validation_error;
	Object.defineProperty(exports, "ValidationError", { enumerable: true, get: function () { return validation_error_1.default; } });
	var ref_error_1 = ref_error;
	Object.defineProperty(exports, "MissingRefError", { enumerable: true, get: function () { return ref_error_1.default; } });
	
} (ajv$1, ajv$1.exports));

var ajvExports = ajv$1.exports;
var ajvModule = /*@__PURE__*/getDefaultExportFromCjs(ajvExports);

// Hack to make this work both in NodeJS and a browser
const Ajv = ajvModule.default ?? ajvModule;
const ajv = new Ajv({ allErrors: true, verbose: true });
const syncRulesSchema = {
    type: 'object',
    properties: {
        bucket_definitions: {
            type: 'object',
            description: 'List of bucket definitions',
            examples: [{ global: { data: 'select * from mytable' } }],
            patternProperties: {
                '.*': {
                    type: 'object',
                    required: ['data'],
                    examples: [{ data: ['select * from mytable'] }],
                    properties: {
                        accept_potentially_dangerous_queries: {
                            description: 'If true, disables warnings on potentially dangerous queries',
                            type: 'boolean'
                        },
                        parameters: {
                            description: 'Parameter query(ies)',
                            anyOf: [
                                { type: 'string', description: 'Parameter query' },
                                {
                                    type: 'array',
                                    description: 'Parameter queries',
                                    items: {
                                        type: 'string'
                                    }
                                }
                            ]
                        },
                        data: {
                            type: 'array',
                            description: 'Data queries',
                            items: {
                                type: 'string'
                            }
                        }
                    },
                    additionalProperties: false
                }
            }
        }
    },
    required: ['bucket_definitions'],
    additionalProperties: false
};
const validateSyncRulesSchema = ajv.compile(syncRulesSchema);

var pgsqlAstParser = {};

var moo = {exports: {}};

var hasRequiredMoo;

function requireMoo () {
	if (hasRequiredMoo) return moo.exports;
	hasRequiredMoo = 1;
	(function (module) {
		(function(root, factory) {
		  if (module.exports) {
		    module.exports = factory();
		  } else {
		    root.moo = factory();
		  }
		}(commonjsGlobal, function() {

		  var hasOwnProperty = Object.prototype.hasOwnProperty;
		  var toString = Object.prototype.toString;
		  var hasSticky = typeof new RegExp().sticky === 'boolean';

		  /***************************************************************************/

		  function isRegExp(o) { return o && toString.call(o) === '[object RegExp]' }
		  function isObject(o) { return o && typeof o === 'object' && !isRegExp(o) && !Array.isArray(o) }

		  function reEscape(s) {
		    return s.replace(/[-\/\\^$*+?.()|[\]{}]/g, '\\$&')
		  }
		  function reGroups(s) {
		    var re = new RegExp('|' + s);
		    return re.exec('').length - 1
		  }
		  function reCapture(s) {
		    return '(' + s + ')'
		  }
		  function reUnion(regexps) {
		    if (!regexps.length) return '(?!)'
		    var source =  regexps.map(function(s) {
		      return "(?:" + s + ")"
		    }).join('|');
		    return "(?:" + source + ")"
		  }

		  function regexpOrLiteral(obj) {
		    if (typeof obj === 'string') {
		      return '(?:' + reEscape(obj) + ')'

		    } else if (isRegExp(obj)) {
		      // TODO: consider /u support
		      if (obj.ignoreCase) throw new Error('RegExp /i flag not allowed')
		      if (obj.global) throw new Error('RegExp /g flag is implied')
		      if (obj.sticky) throw new Error('RegExp /y flag is implied')
		      if (obj.multiline) throw new Error('RegExp /m flag is implied')
		      return obj.source

		    } else {
		      throw new Error('Not a pattern: ' + obj)
		    }
		  }

		  function pad(s, length) {
		    if (s.length > length) {
		      return s
		    }
		    return Array(length - s.length + 1).join(" ") + s
		  }

		  function lastNLines(string, numLines) {
		    var position = string.length;
		    var lineBreaks = 0;
		    while (true) {
		      var idx = string.lastIndexOf("\n", position - 1);
		      if (idx === -1) {
		        break;
		      } else {
		        lineBreaks++;
		      }
		      position = idx;
		      if (lineBreaks === numLines) {
		        break;
		      }
		      if (position === 0) {
		        break;
		      }
		    }
		    var startPosition = 
		      lineBreaks < numLines ?
		      0 : 
		      position + 1;
		    return string.substring(startPosition).split("\n")
		  }

		  function objectToRules(object) {
		    var keys = Object.getOwnPropertyNames(object);
		    var result = [];
		    for (var i = 0; i < keys.length; i++) {
		      var key = keys[i];
		      var thing = object[key];
		      var rules = [].concat(thing);
		      if (key === 'include') {
		        for (var j = 0; j < rules.length; j++) {
		          result.push({include: rules[j]});
		        }
		        continue
		      }
		      var match = [];
		      rules.forEach(function(rule) {
		        if (isObject(rule)) {
		          if (match.length) result.push(ruleOptions(key, match));
		          result.push(ruleOptions(key, rule));
		          match = [];
		        } else {
		          match.push(rule);
		        }
		      });
		      if (match.length) result.push(ruleOptions(key, match));
		    }
		    return result
		  }

		  function arrayToRules(array) {
		    var result = [];
		    for (var i = 0; i < array.length; i++) {
		      var obj = array[i];
		      if (obj.include) {
		        var include = [].concat(obj.include);
		        for (var j = 0; j < include.length; j++) {
		          result.push({include: include[j]});
		        }
		        continue
		      }
		      if (!obj.type) {
		        throw new Error('Rule has no type: ' + JSON.stringify(obj))
		      }
		      result.push(ruleOptions(obj.type, obj));
		    }
		    return result
		  }

		  function ruleOptions(type, obj) {
		    if (!isObject(obj)) {
		      obj = { match: obj };
		    }
		    if (obj.include) {
		      throw new Error('Matching rules cannot also include states')
		    }

		    // nb. error and fallback imply lineBreaks
		    var options = {
		      defaultType: type,
		      lineBreaks: !!obj.error || !!obj.fallback,
		      pop: false,
		      next: null,
		      push: null,
		      error: false,
		      fallback: false,
		      value: null,
		      type: null,
		      shouldThrow: false,
		    };

		    // Avoid Object.assign(), so we support IE9+
		    for (var key in obj) {
		      if (hasOwnProperty.call(obj, key)) {
		        options[key] = obj[key];
		      }
		    }

		    // type transform cannot be a string
		    if (typeof options.type === 'string' && type !== options.type) {
		      throw new Error("Type transform cannot be a string (type '" + options.type + "' for token '" + type + "')")
		    }

		    // convert to array
		    var match = options.match;
		    options.match = Array.isArray(match) ? match : match ? [match] : [];
		    options.match.sort(function(a, b) {
		      return isRegExp(a) && isRegExp(b) ? 0
		           : isRegExp(b) ? -1 : isRegExp(a) ? +1 : b.length - a.length
		    });
		    return options
		  }

		  function toRules(spec) {
		    return Array.isArray(spec) ? arrayToRules(spec) : objectToRules(spec)
		  }

		  var defaultErrorRule = ruleOptions('error', {lineBreaks: true, shouldThrow: true});
		  function compileRules(rules, hasStates) {
		    var errorRule = null;
		    var fast = Object.create(null);
		    var fastAllowed = true;
		    var unicodeFlag = null;
		    var groups = [];
		    var parts = [];

		    // If there is a fallback rule, then disable fast matching
		    for (var i = 0; i < rules.length; i++) {
		      if (rules[i].fallback) {
		        fastAllowed = false;
		      }
		    }

		    for (var i = 0; i < rules.length; i++) {
		      var options = rules[i];

		      if (options.include) {
		        // all valid inclusions are removed by states() preprocessor
		        throw new Error('Inheritance is not allowed in stateless lexers')
		      }

		      if (options.error || options.fallback) {
		        // errorRule can only be set once
		        if (errorRule) {
		          if (!options.fallback === !errorRule.fallback) {
		            throw new Error("Multiple " + (options.fallback ? "fallback" : "error") + " rules not allowed (for token '" + options.defaultType + "')")
		          } else {
		            throw new Error("fallback and error are mutually exclusive (for token '" + options.defaultType + "')")
		          }
		        }
		        errorRule = options;
		      }

		      var match = options.match.slice();
		      if (fastAllowed) {
		        while (match.length && typeof match[0] === 'string' && match[0].length === 1) {
		          var word = match.shift();
		          fast[word.charCodeAt(0)] = options;
		        }
		      }

		      // Warn about inappropriate state-switching options
		      if (options.pop || options.push || options.next) {
		        if (!hasStates) {
		          throw new Error("State-switching options are not allowed in stateless lexers (for token '" + options.defaultType + "')")
		        }
		        if (options.fallback) {
		          throw new Error("State-switching options are not allowed on fallback tokens (for token '" + options.defaultType + "')")
		        }
		      }

		      // Only rules with a .match are included in the RegExp
		      if (match.length === 0) {
		        continue
		      }
		      fastAllowed = false;

		      groups.push(options);

		      // Check unicode flag is used everywhere or nowhere
		      for (var j = 0; j < match.length; j++) {
		        var obj = match[j];
		        if (!isRegExp(obj)) {
		          continue
		        }

		        if (unicodeFlag === null) {
		          unicodeFlag = obj.unicode;
		        } else if (unicodeFlag !== obj.unicode && options.fallback === false) {
		          throw new Error('If one rule is /u then all must be')
		        }
		      }

		      // convert to RegExp
		      var pat = reUnion(match.map(regexpOrLiteral));

		      // validate
		      var regexp = new RegExp(pat);
		      if (regexp.test("")) {
		        throw new Error("RegExp matches empty string: " + regexp)
		      }
		      var groupCount = reGroups(pat);
		      if (groupCount > 0) {
		        throw new Error("RegExp has capture groups: " + regexp + "\nUse (?:  ) instead")
		      }

		      // try and detect rules matching newlines
		      if (!options.lineBreaks && regexp.test('\n')) {
		        throw new Error('Rule should declare lineBreaks: ' + regexp)
		      }

		      // store regex
		      parts.push(reCapture(pat));
		    }


		    // If there's no fallback rule, use the sticky flag so we only look for
		    // matches at the current index.
		    //
		    // If we don't support the sticky flag, then fake it using an irrefutable
		    // match (i.e. an empty pattern).
		    var fallbackRule = errorRule && errorRule.fallback;
		    var flags = hasSticky && !fallbackRule ? 'ym' : 'gm';
		    var suffix = hasSticky || fallbackRule ? '' : '|';

		    if (unicodeFlag === true) flags += "u";
		    var combined = new RegExp(reUnion(parts) + suffix, flags);
		    return {regexp: combined, groups: groups, fast: fast, error: errorRule || defaultErrorRule}
		  }

		  function compile(rules) {
		    var result = compileRules(toRules(rules));
		    return new Lexer({start: result}, 'start')
		  }

		  function checkStateGroup(g, name, map) {
		    var state = g && (g.push || g.next);
		    if (state && !map[state]) {
		      throw new Error("Missing state '" + state + "' (in token '" + g.defaultType + "' of state '" + name + "')")
		    }
		    if (g && g.pop && +g.pop !== 1) {
		      throw new Error("pop must be 1 (in token '" + g.defaultType + "' of state '" + name + "')")
		    }
		  }
		  function compileStates(states, start) {
		    var all = states.$all ? toRules(states.$all) : [];
		    delete states.$all;

		    var keys = Object.getOwnPropertyNames(states);
		    if (!start) start = keys[0];

		    var ruleMap = Object.create(null);
		    for (var i = 0; i < keys.length; i++) {
		      var key = keys[i];
		      ruleMap[key] = toRules(states[key]).concat(all);
		    }
		    for (var i = 0; i < keys.length; i++) {
		      var key = keys[i];
		      var rules = ruleMap[key];
		      var included = Object.create(null);
		      for (var j = 0; j < rules.length; j++) {
		        var rule = rules[j];
		        if (!rule.include) continue
		        var splice = [j, 1];
		        if (rule.include !== key && !included[rule.include]) {
		          included[rule.include] = true;
		          var newRules = ruleMap[rule.include];
		          if (!newRules) {
		            throw new Error("Cannot include nonexistent state '" + rule.include + "' (in state '" + key + "')")
		          }
		          for (var k = 0; k < newRules.length; k++) {
		            var newRule = newRules[k];
		            if (rules.indexOf(newRule) !== -1) continue
		            splice.push(newRule);
		          }
		        }
		        rules.splice.apply(rules, splice);
		        j--;
		      }
		    }

		    var map = Object.create(null);
		    for (var i = 0; i < keys.length; i++) {
		      var key = keys[i];
		      map[key] = compileRules(ruleMap[key], true);
		    }

		    for (var i = 0; i < keys.length; i++) {
		      var name = keys[i];
		      var state = map[name];
		      var groups = state.groups;
		      for (var j = 0; j < groups.length; j++) {
		        checkStateGroup(groups[j], name, map);
		      }
		      var fastKeys = Object.getOwnPropertyNames(state.fast);
		      for (var j = 0; j < fastKeys.length; j++) {
		        checkStateGroup(state.fast[fastKeys[j]], name, map);
		      }
		    }

		    return new Lexer(map, start)
		  }

		  function keywordTransform(map) {

		    // Use a JavaScript Map to map keywords to their corresponding token type
		    // unless Map is unsupported, then fall back to using an Object:
		    var isMap = typeof Map !== 'undefined';
		    var reverseMap = isMap ? new Map : Object.create(null);

		    var types = Object.getOwnPropertyNames(map);
		    for (var i = 0; i < types.length; i++) {
		      var tokenType = types[i];
		      var item = map[tokenType];
		      var keywordList = Array.isArray(item) ? item : [item];
		      keywordList.forEach(function(keyword) {
		        if (typeof keyword !== 'string') {
		          throw new Error("keyword must be string (in keyword '" + tokenType + "')")
		        }
		        if (isMap) {
		          reverseMap.set(keyword, tokenType);
		        } else {
		          reverseMap[keyword] = tokenType;
		        }
		      });
		    }
		    return function(k) {
		      return isMap ? reverseMap.get(k) : reverseMap[k]
		    }
		  }

		  /***************************************************************************/

		  var Lexer = function(states, state) {
		    this.startState = state;
		    this.states = states;
		    this.buffer = '';
		    this.stack = [];
		    this.reset();
		  };

		  Lexer.prototype.reset = function(data, info) {
		    this.buffer = data || '';
		    this.index = 0;
		    this.line = info ? info.line : 1;
		    this.col = info ? info.col : 1;
		    this.queuedToken = info ? info.queuedToken : null;
		    this.queuedText = info ? info.queuedText: "";
		    this.queuedThrow = info ? info.queuedThrow : null;
		    this.setState(info ? info.state : this.startState);
		    this.stack = info && info.stack ? info.stack.slice() : [];
		    return this
		  };

		  Lexer.prototype.save = function() {
		    return {
		      line: this.line,
		      col: this.col,
		      state: this.state,
		      stack: this.stack.slice(),
		      queuedToken: this.queuedToken,
		      queuedText: this.queuedText,
		      queuedThrow: this.queuedThrow,
		    }
		  };

		  Lexer.prototype.setState = function(state) {
		    if (!state || this.state === state) return
		    this.state = state;
		    var info = this.states[state];
		    this.groups = info.groups;
		    this.error = info.error;
		    this.re = info.regexp;
		    this.fast = info.fast;
		  };

		  Lexer.prototype.popState = function() {
		    this.setState(this.stack.pop());
		  };

		  Lexer.prototype.pushState = function(state) {
		    this.stack.push(this.state);
		    this.setState(state);
		  };

		  var eat = hasSticky ? function(re, buffer) { // assume re is /y
		    return re.exec(buffer)
		  } : function(re, buffer) { // assume re is /g
		    var match = re.exec(buffer);
		    // will always match, since we used the |(?:) trick
		    if (match[0].length === 0) {
		      return null
		    }
		    return match
		  };

		  Lexer.prototype._getGroup = function(match) {
		    var groupCount = this.groups.length;
		    for (var i = 0; i < groupCount; i++) {
		      if (match[i + 1] !== undefined) {
		        return this.groups[i]
		      }
		    }
		    throw new Error('Cannot find token type for matched text')
		  };

		  function tokenToString() {
		    return this.value
		  }

		  Lexer.prototype.next = function() {
		    var index = this.index;

		    // If a fallback token matched, we don't need to re-run the RegExp
		    if (this.queuedGroup) {
		      var token = this._token(this.queuedGroup, this.queuedText, index);
		      this.queuedGroup = null;
		      this.queuedText = "";
		      return token
		    }

		    var buffer = this.buffer;
		    if (index === buffer.length) {
		      return // EOF
		    }

		    // Fast matching for single characters
		    var group = this.fast[buffer.charCodeAt(index)];
		    if (group) {
		      return this._token(group, buffer.charAt(index), index)
		    }

		    // Execute RegExp
		    var re = this.re;
		    re.lastIndex = index;
		    var match = eat(re, buffer);

		    // Error tokens match the remaining buffer
		    var error = this.error;
		    if (match == null) {
		      return this._token(error, buffer.slice(index, buffer.length), index)
		    }

		    var group = this._getGroup(match);
		    var text = match[0];

		    if (error.fallback && match.index !== index) {
		      this.queuedGroup = group;
		      this.queuedText = text;

		      // Fallback tokens contain the unmatched portion of the buffer
		      return this._token(error, buffer.slice(index, match.index), index)
		    }

		    return this._token(group, text, index)
		  };

		  Lexer.prototype._token = function(group, text, offset) {
		    // count line breaks
		    var lineBreaks = 0;
		    if (group.lineBreaks) {
		      var matchNL = /\n/g;
		      var nl = 1;
		      if (text === '\n') {
		        lineBreaks = 1;
		      } else {
		        while (matchNL.exec(text)) { lineBreaks++; nl = matchNL.lastIndex; }
		      }
		    }

		    var token = {
		      type: (typeof group.type === 'function' && group.type(text)) || group.defaultType,
		      value: typeof group.value === 'function' ? group.value(text) : text,
		      text: text,
		      toString: tokenToString,
		      offset: offset,
		      lineBreaks: lineBreaks,
		      line: this.line,
		      col: this.col,
		    };
		    // nb. adding more props to token object will make V8 sad!

		    var size = text.length;
		    this.index += size;
		    this.line += lineBreaks;
		    if (lineBreaks !== 0) {
		      this.col = size - nl + 1;
		    } else {
		      this.col += size;
		    }

		    // throw, if no rule with {error: true}
		    if (group.shouldThrow) {
		      var err = new Error(this.formatError(token, "invalid syntax"));
		      throw err;
		    }

		    if (group.pop) this.popState();
		    else if (group.push) this.pushState(group.push);
		    else if (group.next) this.setState(group.next);

		    return token
		  };

		  if (typeof Symbol !== 'undefined' && Symbol.iterator) {
		    var LexerIterator = function(lexer) {
		      this.lexer = lexer;
		    };

		    LexerIterator.prototype.next = function() {
		      var token = this.lexer.next();
		      return {value: token, done: !token}
		    };

		    LexerIterator.prototype[Symbol.iterator] = function() {
		      return this
		    };

		    Lexer.prototype[Symbol.iterator] = function() {
		      return new LexerIterator(this)
		    };
		  }

		  Lexer.prototype.formatError = function(token, message) {
		    if (token == null) {
		      // An undefined token indicates EOF
		      var text = this.buffer.slice(this.index);
		      var token = {
		        text: text,
		        offset: this.index,
		        lineBreaks: text.indexOf('\n') === -1 ? 0 : 1,
		        line: this.line,
		        col: this.col,
		      };
		    }
		    
		    var numLinesAround = 2;
		    var firstDisplayedLine = Math.max(token.line - numLinesAround, 1);
		    var lastDisplayedLine = token.line + numLinesAround;
		    var lastLineDigits = String(lastDisplayedLine).length;
		    var displayedLines = lastNLines(
		        this.buffer, 
		        (this.line - token.line) + numLinesAround + 1
		      )
		      .slice(0, 5);
		    var errorLines = [];
		    errorLines.push(message + " at line " + token.line + " col " + token.col + ":");
		    errorLines.push("");
		    for (var i = 0; i < displayedLines.length; i++) {
		      var line = displayedLines[i];
		      var lineNo = firstDisplayedLine + i;
		      errorLines.push(pad(String(lineNo), lastLineDigits) + "  " + line);
		      if (lineNo === token.line) {
		        errorLines.push(pad("", lastLineDigits + token.col + 1) + "^");
		      }
		    }
		    return errorLines.join("\n")
		  };

		  Lexer.prototype.clone = function() {
		    return new Lexer(this.states, this.state)
		  };

		  Lexer.prototype.has = function(tokenType) {
		    return true
		  };


		  return {
		    compile: compile,
		    states: compileStates,
		    error: Object.freeze({error: true}),
		    fallback: Object.freeze({fallback: true}),
		    keywords: keywordTransform,
		  }

		})); 
	} (moo));
	return moo.exports;
}

var nearley = {exports: {}};

var hasRequiredNearley;

function requireNearley () {
	if (hasRequiredNearley) return nearley.exports;
	hasRequiredNearley = 1;
	(function (module) {
		(function(root, factory) {
		    if (module.exports) {
		        module.exports = factory();
		    } else {
		        root.nearley = factory();
		    }
		}(commonjsGlobal, function() {

		    function Rule(name, symbols, postprocess) {
		        this.id = ++Rule.highestId;
		        this.name = name;
		        this.symbols = symbols;        // a list of literal | regex class | nonterminal
		        this.postprocess = postprocess;
		        return this;
		    }
		    Rule.highestId = 0;

		    Rule.prototype.toString = function(withCursorAt) {
		        var symbolSequence = (typeof withCursorAt === "undefined")
		                             ? this.symbols.map(getSymbolShortDisplay).join(' ')
		                             : (   this.symbols.slice(0, withCursorAt).map(getSymbolShortDisplay).join(' ')
		                                 + "  "
		                                 + this.symbols.slice(withCursorAt).map(getSymbolShortDisplay).join(' ')     );
		        return this.name + "  " + symbolSequence;
		    };


		    // a State is a rule at a position from a given starting point in the input stream (reference)
		    function State(rule, dot, reference, wantedBy) {
		        this.rule = rule;
		        this.dot = dot;
		        this.reference = reference;
		        this.data = [];
		        this.wantedBy = wantedBy;
		        this.isComplete = this.dot === rule.symbols.length;
		    }

		    State.prototype.toString = function() {
		        return "{" + this.rule.toString(this.dot) + "}, from: " + (this.reference || 0);
		    };

		    State.prototype.nextState = function(child) {
		        var state = new State(this.rule, this.dot + 1, this.reference, this.wantedBy);
		        state.left = this;
		        state.right = child;
		        if (state.isComplete) {
		            state.data = state.build();
		            // Having right set here will prevent the right state and its children
		            // form being garbage collected
		            state.right = undefined;
		        }
		        return state;
		    };

		    State.prototype.build = function() {
		        var children = [];
		        var node = this;
		        do {
		            children.push(node.right.data);
		            node = node.left;
		        } while (node.left);
		        children.reverse();
		        return children;
		    };

		    State.prototype.finish = function() {
		        if (this.rule.postprocess) {
		            this.data = this.rule.postprocess(this.data, this.reference, Parser.fail);
		        }
		    };


		    function Column(grammar, index) {
		        this.grammar = grammar;
		        this.index = index;
		        this.states = [];
		        this.wants = {}; // states indexed by the non-terminal they expect
		        this.scannable = []; // list of states that expect a token
		        this.completed = {}; // states that are nullable
		    }


		    Column.prototype.process = function(nextColumn) {
		        var states = this.states;
		        var wants = this.wants;
		        var completed = this.completed;

		        for (var w = 0; w < states.length; w++) { // nb. we push() during iteration
		            var state = states[w];

		            if (state.isComplete) {
		                state.finish();
		                if (state.data !== Parser.fail) {
		                    // complete
		                    var wantedBy = state.wantedBy;
		                    for (var i = wantedBy.length; i--; ) { // this line is hot
		                        var left = wantedBy[i];
		                        this.complete(left, state);
		                    }

		                    // special-case nullables
		                    if (state.reference === this.index) {
		                        // make sure future predictors of this rule get completed.
		                        var exp = state.rule.name;
		                        (this.completed[exp] = this.completed[exp] || []).push(state);
		                    }
		                }

		            } else {
		                // queue scannable states
		                var exp = state.rule.symbols[state.dot];
		                if (typeof exp !== 'string') {
		                    this.scannable.push(state);
		                    continue;
		                }

		                // predict
		                if (wants[exp]) {
		                    wants[exp].push(state);

		                    if (completed.hasOwnProperty(exp)) {
		                        var nulls = completed[exp];
		                        for (var i = 0; i < nulls.length; i++) {
		                            var right = nulls[i];
		                            this.complete(state, right);
		                        }
		                    }
		                } else {
		                    wants[exp] = [state];
		                    this.predict(exp);
		                }
		            }
		        }
		    };

		    Column.prototype.predict = function(exp) {
		        var rules = this.grammar.byName[exp] || [];

		        for (var i = 0; i < rules.length; i++) {
		            var r = rules[i];
		            var wantedBy = this.wants[exp];
		            var s = new State(r, 0, this.index, wantedBy);
		            this.states.push(s);
		        }
		    };

		    Column.prototype.complete = function(left, right) {
		        var copy = left.nextState(right);
		        this.states.push(copy);
		    };


		    function Grammar(rules, start) {
		        this.rules = rules;
		        this.start = start || this.rules[0].name;
		        var byName = this.byName = {};
		        this.rules.forEach(function(rule) {
		            if (!byName.hasOwnProperty(rule.name)) {
		                byName[rule.name] = [];
		            }
		            byName[rule.name].push(rule);
		        });
		    }

		    // So we can allow passing (rules, start) directly to Parser for backwards compatibility
		    Grammar.fromCompiled = function(rules, start) {
		        var lexer = rules.Lexer;
		        if (rules.ParserStart) {
		          start = rules.ParserStart;
		          rules = rules.ParserRules;
		        }
		        var rules = rules.map(function (r) { return (new Rule(r.name, r.symbols, r.postprocess)); });
		        var g = new Grammar(rules, start);
		        g.lexer = lexer; // nb. storing lexer on Grammar is iffy, but unavoidable
		        return g;
		    };


		    function StreamLexer() {
		      this.reset("");
		    }

		    StreamLexer.prototype.reset = function(data, state) {
		        this.buffer = data;
		        this.index = 0;
		        this.line = state ? state.line : 1;
		        this.lastLineBreak = state ? -state.col : 0;
		    };

		    StreamLexer.prototype.next = function() {
		        if (this.index < this.buffer.length) {
		            var ch = this.buffer[this.index++];
		            if (ch === '\n') {
		              this.line += 1;
		              this.lastLineBreak = this.index;
		            }
		            return {value: ch};
		        }
		    };

		    StreamLexer.prototype.save = function() {
		      return {
		        line: this.line,
		        col: this.index - this.lastLineBreak,
		      }
		    };

		    StreamLexer.prototype.formatError = function(token, message) {
		        // nb. this gets called after consuming the offending token,
		        // so the culprit is index-1
		        var buffer = this.buffer;
		        if (typeof buffer === 'string') {
		            var lines = buffer
		                .split("\n")
		                .slice(
		                    Math.max(0, this.line - 5), 
		                    this.line
		                );

		            var nextLineBreak = buffer.indexOf('\n', this.index);
		            if (nextLineBreak === -1) nextLineBreak = buffer.length;
		            var col = this.index - this.lastLineBreak;
		            var lastLineDigits = String(this.line).length;
		            message += " at line " + this.line + " col " + col + ":\n\n";
		            message += lines
		                .map(function(line, i) {
		                    return pad(this.line - lines.length + i + 1, lastLineDigits) + " " + line;
		                }, this)
		                .join("\n");
		            message += "\n" + pad("", lastLineDigits + col) + "^\n";
		            return message;
		        } else {
		            return message + " at index " + (this.index - 1);
		        }

		        function pad(n, length) {
		            var s = String(n);
		            return Array(length - s.length + 1).join(" ") + s;
		        }
		    };

		    function Parser(rules, start, options) {
		        if (rules instanceof Grammar) {
		            var grammar = rules;
		            var options = start;
		        } else {
		            var grammar = Grammar.fromCompiled(rules, start);
		        }
		        this.grammar = grammar;

		        // Read options
		        this.options = {
		            keepHistory: false,
		            lexer: grammar.lexer || new StreamLexer,
		        };
		        for (var key in (options || {})) {
		            this.options[key] = options[key];
		        }

		        // Setup lexer
		        this.lexer = this.options.lexer;
		        this.lexerState = undefined;

		        // Setup a table
		        var column = new Column(grammar, 0);
		        this.table = [column];

		        // I could be expecting anything.
		        column.wants[grammar.start] = [];
		        column.predict(grammar.start);
		        // TODO what if start rule is nullable?
		        column.process();
		        this.current = 0; // token index
		    }

		    // create a reserved token for indicating a parse fail
		    Parser.fail = {};

		    Parser.prototype.feed = function(chunk) {
		        var lexer = this.lexer;
		        lexer.reset(chunk, this.lexerState);

		        var token;
		        while (true) {
		            try {
		                token = lexer.next();
		                if (!token) {
		                    break;
		                }
		            } catch (e) {
		                // Create the next column so that the error reporter
		                // can display the correctly predicted states.
		                var nextColumn = new Column(this.grammar, this.current + 1);
		                this.table.push(nextColumn);
		                var err = new Error(this.reportLexerError(e));
		                err.offset = this.current;
		                err.token = e.token;
		                throw err;
		            }
		            // We add new states to table[current+1]
		            var column = this.table[this.current];

		            // GC unused states
		            if (!this.options.keepHistory) {
		                delete this.table[this.current - 1];
		            }

		            var n = this.current + 1;
		            var nextColumn = new Column(this.grammar, n);
		            this.table.push(nextColumn);

		            // Advance all tokens that expect the symbol
		            var literal = token.text !== undefined ? token.text : token.value;
		            var value = lexer.constructor === StreamLexer ? token.value : token;
		            var scannable = column.scannable;
		            for (var w = scannable.length; w--; ) {
		                var state = scannable[w];
		                var expect = state.rule.symbols[state.dot];
		                // Try to consume the token
		                // either regex or literal
		                if (expect.test ? expect.test(value) :
		                    expect.type ? expect.type === token.type
		                                : expect.literal === literal) {
		                    // Add it
		                    var next = state.nextState({data: value, token: token, isToken: true, reference: n - 1});
		                    nextColumn.states.push(next);
		                }
		            }

		            // Next, for each of the rules, we either
		            // (a) complete it, and try to see if the reference row expected that
		            //     rule
		            // (b) predict the next nonterminal it expects by adding that
		            //     nonterminal's start state
		            // To prevent duplication, we also keep track of rules we have already
		            // added

		            nextColumn.process();

		            // If needed, throw an error:
		            if (nextColumn.states.length === 0) {
		                // No states at all! This is not good.
		                var err = new Error(this.reportError(token));
		                err.offset = this.current;
		                err.token = token;
		                throw err;
		            }

		            // maybe save lexer state
		            if (this.options.keepHistory) {
		              column.lexerState = lexer.save();
		            }

		            this.current++;
		        }
		        if (column) {
		          this.lexerState = lexer.save();
		        }

		        // Incrementally keep track of results
		        this.results = this.finish();

		        // Allow chaining, for whatever it's worth
		        return this;
		    };

		    Parser.prototype.reportLexerError = function(lexerError) {
		        var tokenDisplay, lexerMessage;
		        // Planning to add a token property to moo's thrown error
		        // even on erroring tokens to be used in error display below
		        var token = lexerError.token;
		        if (token) {
		            tokenDisplay = "input " + JSON.stringify(token.text[0]) + " (lexer error)";
		            lexerMessage = this.lexer.formatError(token, "Syntax error");
		        } else {
		            tokenDisplay = "input (lexer error)";
		            lexerMessage = lexerError.message;
		        }
		        return this.reportErrorCommon(lexerMessage, tokenDisplay);
		    };

		    Parser.prototype.reportError = function(token) {
		        var tokenDisplay = (token.type ? token.type + " token: " : "") + JSON.stringify(token.value !== undefined ? token.value : token);
		        var lexerMessage = this.lexer.formatError(token, "Syntax error");
		        return this.reportErrorCommon(lexerMessage, tokenDisplay);
		    };

		    Parser.prototype.reportErrorCommon = function(lexerMessage, tokenDisplay) {
		        var lines = [];
		        lines.push(lexerMessage);
		        var lastColumnIndex = this.table.length - 2;
		        var lastColumn = this.table[lastColumnIndex];
		        var expectantStates = lastColumn.states
		            .filter(function(state) {
		                var nextSymbol = state.rule.symbols[state.dot];
		                return nextSymbol && typeof nextSymbol !== "string";
		            });

		        if (expectantStates.length === 0) {
		            lines.push('Unexpected ' + tokenDisplay + '. I did not expect any more input. Here is the state of my parse table:\n');
		            this.displayStateStack(lastColumn.states, lines);
		        } else {
		            lines.push('Unexpected ' + tokenDisplay + '. Instead, I was expecting to see one of the following:\n');
		            // Display a "state stack" for each expectant state
		            // - which shows you how this state came to be, step by step.
		            // If there is more than one derivation, we only display the first one.
		            var stateStacks = expectantStates
		                .map(function(state) {
		                    return this.buildFirstStateStack(state, []) || [state];
		                }, this);
		            // Display each state that is expecting a terminal symbol next.
		            stateStacks.forEach(function(stateStack) {
		                var state = stateStack[0];
		                var nextSymbol = state.rule.symbols[state.dot];
		                var symbolDisplay = this.getSymbolDisplay(nextSymbol);
		                lines.push('A ' + symbolDisplay + ' based on:');
		                this.displayStateStack(stateStack, lines);
		            }, this);
		        }
		        lines.push("");
		        return lines.join("\n");
		    };
		    
		    Parser.prototype.displayStateStack = function(stateStack, lines) {
		        var lastDisplay;
		        var sameDisplayCount = 0;
		        for (var j = 0; j < stateStack.length; j++) {
		            var state = stateStack[j];
		            var display = state.rule.toString(state.dot);
		            if (display === lastDisplay) {
		                sameDisplayCount++;
		            } else {
		                if (sameDisplayCount > 0) {
		                    lines.push('    ^ ' + sameDisplayCount + ' more lines identical to this');
		                }
		                sameDisplayCount = 0;
		                lines.push('    ' + display);
		            }
		            lastDisplay = display;
		        }
		    };

		    Parser.prototype.getSymbolDisplay = function(symbol) {
		        return getSymbolLongDisplay(symbol);
		    };

		    /*
		    Builds a the first state stack. You can think of a state stack as the call stack
		    of the recursive-descent parser which the Nearley parse algorithm simulates.
		    A state stack is represented as an array of state objects. Within a
		    state stack, the first item of the array will be the starting
		    state, with each successive item in the array going further back into history.

		    This function needs to be given a starting state and an empty array representing
		    the visited states, and it returns an single state stack.

		    */
		    Parser.prototype.buildFirstStateStack = function(state, visited) {
		        if (visited.indexOf(state) !== -1) {
		            // Found cycle, return null
		            // to eliminate this path from the results, because
		            // we don't know how to display it meaningfully
		            return null;
		        }
		        if (state.wantedBy.length === 0) {
		            return [state];
		        }
		        var prevState = state.wantedBy[0];
		        var childVisited = [state].concat(visited);
		        var childResult = this.buildFirstStateStack(prevState, childVisited);
		        if (childResult === null) {
		            return null;
		        }
		        return [state].concat(childResult);
		    };

		    Parser.prototype.save = function() {
		        var column = this.table[this.current];
		        column.lexerState = this.lexerState;
		        return column;
		    };

		    Parser.prototype.restore = function(column) {
		        var index = column.index;
		        this.current = index;
		        this.table[index] = column;
		        this.table.splice(index + 1);
		        this.lexerState = column.lexerState;

		        // Incrementally keep track of results
		        this.results = this.finish();
		    };

		    // nb. deprecated: use save/restore instead!
		    Parser.prototype.rewind = function(index) {
		        if (!this.options.keepHistory) {
		            throw new Error('set option `keepHistory` to enable rewinding')
		        }
		        // nb. recall column (table) indicies fall between token indicies.
		        //        col 0   --   token 0   --   col 1
		        this.restore(this.table[index]);
		    };

		    Parser.prototype.finish = function() {
		        // Return the possible parsings
		        var considerations = [];
		        var start = this.grammar.start;
		        var column = this.table[this.table.length - 1];
		        column.states.forEach(function (t) {
		            if (t.rule.name === start
		                    && t.dot === t.rule.symbols.length
		                    && t.reference === 0
		                    && t.data !== Parser.fail) {
		                considerations.push(t);
		            }
		        });
		        return considerations.map(function(c) {return c.data; });
		    };

		    function getSymbolLongDisplay(symbol) {
		        var type = typeof symbol;
		        if (type === "string") {
		            return symbol;
		        } else if (type === "object") {
		            if (symbol.literal) {
		                return JSON.stringify(symbol.literal);
		            } else if (symbol instanceof RegExp) {
		                return 'character matching ' + symbol;
		            } else if (symbol.type) {
		                return symbol.type + ' token';
		            } else if (symbol.test) {
		                return 'token matching ' + String(symbol.test);
		            } else {
		                throw new Error('Unknown symbol type: ' + symbol);
		            }
		        }
		    }

		    function getSymbolShortDisplay(symbol) {
		        var type = typeof symbol;
		        if (type === "string") {
		            return symbol;
		        } else if (type === "object") {
		            if (symbol.literal) {
		                return JSON.stringify(symbol.literal);
		            } else if (symbol instanceof RegExp) {
		                return symbol.toString();
		            } else if (symbol.type) {
		                return '%' + symbol.type;
		            } else if (symbol.test) {
		                return '<' + String(symbol.test) + '>';
		            } else {
		                throw new Error('Unknown symbol type: ' + symbol);
		            }
		        }
		    }

		    return {
		        Parser: Parser,
		        Grammar: Grammar,
		        Rule: Rule,
		    };

		})); 
	} (nearley));
	return nearley.exports;
}

(function (exports) {
	(function(e, a) { for(var i in a) e[i] = a[i]; }(exports, /******/ (function(modules) { // webpackBootstrap
	/******/ 	// The module cache
	/******/ 	var installedModules = {};
	/******/
	/******/ 	// The require function
	/******/ 	function __webpack_require__(moduleId) {
	/******/
	/******/ 		// Check if module is in cache
	/******/ 		if(installedModules[moduleId]) {
	/******/ 			return installedModules[moduleId].exports;
	/******/ 		}
	/******/ 		// Create a new module (and put it into the cache)
	/******/ 		var module = installedModules[moduleId] = {
	/******/ 			i: moduleId,
	/******/ 			l: false,
	/******/ 			exports: {}
	/******/ 		};
	/******/
	/******/ 		// Execute the module function
	/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
	/******/
	/******/ 		// Flag the module as loaded
	/******/ 		module.l = true;
	/******/
	/******/ 		// Return the exports of the module
	/******/ 		return module.exports;
	/******/ 	}
	/******/
	/******/
	/******/ 	// expose the modules object (__webpack_modules__)
	/******/ 	__webpack_require__.m = modules;
	/******/
	/******/ 	// expose the module cache
	/******/ 	__webpack_require__.c = installedModules;
	/******/
	/******/ 	// define getter function for harmony exports
	/******/ 	__webpack_require__.d = function(exports, name, getter) {
	/******/ 		if(!__webpack_require__.o(exports, name)) {
	/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
	/******/ 		}
	/******/ 	};
	/******/
	/******/ 	// define __esModule on exports
	/******/ 	__webpack_require__.r = function(exports) {
	/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
	/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
	/******/ 		}
	/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
	/******/ 	};
	/******/
	/******/ 	// create a fake namespace object
	/******/ 	// mode & 1: value is a module id, require it
	/******/ 	// mode & 2: merge all properties of value into the ns
	/******/ 	// mode & 4: return value when already ns object
	/******/ 	// mode & 8|1: behave like require
	/******/ 	__webpack_require__.t = function(value, mode) {
	/******/ 		if(mode & 1) value = __webpack_require__(value);
	/******/ 		if(mode & 8) return value;
	/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
	/******/ 		var ns = Object.create(null);
	/******/ 		__webpack_require__.r(ns);
	/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
	/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
	/******/ 		return ns;
	/******/ 	};
	/******/
	/******/ 	// getDefaultExport function for compatibility with non-harmony modules
	/******/ 	__webpack_require__.n = function(module) {
	/******/ 		var getter = module && module.__esModule ?
	/******/ 			function getDefault() { return module['default']; } :
	/******/ 			function getModuleExports() { return module; };
	/******/ 		__webpack_require__.d(getter, 'a', getter);
	/******/ 		return getter;
	/******/ 	};
	/******/
	/******/ 	// Object.prototype.hasOwnProperty.call
	/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
	/******/
	/******/ 	// __webpack_public_path__
	/******/ 	__webpack_require__.p = "";
	/******/
	/******/
	/******/ 	// Load entry module and return exports
	/******/ 	return __webpack_require__(__webpack_require__.s = 7);
	/******/ })
	/************************************************************************/
	/******/ ([
	/* 0 */
	/***/ (function(module, exports) {

	module.exports = requireMoo();

	/***/ }),
	/* 1 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	exports.unbox = exports.doubleQuoted = exports.box = exports.track = exports.tracking = exports.trackingComments = exports.lexerAny = exports.lexer = void 0;
	const moo_1 = __webpack_require__(0);
	const keywords_1 = __webpack_require__(3);
	// build keywords
	const keywordsMap = {};
	for (const k of keywords_1.sqlKeywords) {
	    keywordsMap['kw_' + k.toLowerCase()] = k;
	}
	const caseInsensitiveKeywords = (map) => {
	    const transform = (0, moo_1.keywords)(map);
	    return (text) => transform(text.toUpperCase());
	};
	// build lexer
	exports.lexer = (0, moo_1.compile)({
	    word: {
	        match: /[eE](?!')[A-Za-z0-9_]*|[a-df-zA-DF-Z_][A-Za-z0-9_]*/,
	        type: caseInsensitiveKeywords(keywordsMap),
	        value: x => x.toLowerCase(),
	    },
	    wordQuoted: {
	        match: /"(?:[^"\*]|"")+"/,
	        type: () => 'quoted_word',
	        value: x => x.substring(1, x.length - 1),
	    },
	    string: {
	        match: /'(?:[^']|\'\')*'/,
	        value: x => {
	            return x.substring(1, x.length - 1)
	                .replace(/''/g, '\'');
	        },
	    },
	    eString: {
	        match: /\b(?:e|E)'(?:[^'\\]|[\r\n\s]|(?:\\\s)|(?:\\\n)|(?:\\.)|(?:\'\'))+'/,
	        value: x => {
	            return x.substring(2, x.length - 1)
	                .replace(/''/g, '\'')
	                .replace(/\\([\s\n])/g, (_, x) => x)
	                .replace(/\\./g, m => JSON.parse('"' + m + '"'));
	        },
	    },
	    qparam: {
	        match: /\$\d+/,
	    },
	    commentLine: /\-\-.*?$[\s\r\n]*/,
	    commentFullOpen: /\/\*/,
	    commentFullClose: /\*\/[\s\r\n]*/,
	    star: '*',
	    comma: ',',
	    space: { match: /[\s\t\n\v\f\r]+/, lineBreaks: true, },
	    int: /\-?\d+(?![\.\d])/,
	    float: /\-?(?:(?:\d*\.\d+)|(?:\d+\.\d*))/,
	    // word: /[a-zA-Z][A-Za-z0-9_\-]*/,
	    lparen: '(',
	    rparen: ')',
	    lbracket: '[',
	    rbracket: ']',
	    semicolon: ';',
	    dot: /\.(?!\d)/,
	    op_cast: '::',
	    op_colon: ':',
	    op_plus: '+',
	    op_eq: '=',
	    op_neq: {
	        match: /(?:!=)|(?:\<\>)/,
	        value: () => '!=',
	    },
	    op_membertext: '->>',
	    op_member: '->',
	    op_minus: '-',
	    op_div: /\//,
	    op_not_ilike: /\!~~\*/,
	    op_not_like: /\!~~/,
	    op_ilike: /~~\*/,
	    op_like: /~~/,
	    op_mod: '%',
	    op_exp: '^',
	    op_additive: {
	        // group other additive operators
	        match: ['||', '-', '#-', '&&'],
	    },
	    op_compare: {
	        // group other comparison operators
	        // ... to add: "IN" and "NOT IN" that are matched by keywords
	        match: ['>', '>=', '<', '<=', '@>', '<@', '?', '?|', '?&', '#>>', '>>', '<<', '~', '~*', '!~', '!~*', '@@'],
	    },
	    ops_others: {
	        // referenced as (any other operator) in https://www.postgresql.org/docs/12/sql-syntax-lexical.html#SQL-PRECEDENCE
	        // see also https://www.postgresql.org/docs/9.0/functions-math.html
	        match: ['|', '&', '^', '#'],
	    },
	    codeblock: {
	        match: /\$\$(?:.|[\s\t\n\v\f\r])*?\$\$/s,
	        lineBreaks: true,
	        value: (x) => x.substring(2, x.length - 2),
	    },
	});
	exports.lexer.next = (next => () => {
	    let tok;
	    let commentFull = null;
	    while (tok = next.call(exports.lexer)) {
	        // js regex can't be recursive, so we'll keep track of nested opens (/*) and closes (*/).
	        if (tok.type === 'commentFullOpen') {
	            if (commentFull === null) { // initial open - start collecting content
	                commentFull = {
	                    nested: 0,
	                    offset: tok.offset,
	                    text: tok.text
	                };
	                continue;
	            }
	            commentFull.nested++;
	        }
	        if (commentFull != null) {
	            // collect comment content
	            commentFull.text += tok.text;
	            if (tok.type === 'commentFullClose') {
	                if (commentFull.nested === 0) { // finish comment, if not nested
	                    comments === null || comments === void 0 ? void 0 : comments.push(makeComment(commentFull));
	                    commentFull = null;
	                    continue;
	                }
	                commentFull.nested--;
	            }
	            continue;
	        }
	        if (tok.type === 'space') {
	            continue;
	        }
	        if (tok.type === 'commentLine') {
	            comments === null || comments === void 0 ? void 0 : comments.push(makeComment(tok));
	            continue;
	        }
	        break;
	    }
	    if (trackingLoc && tok) {
	        const start = tok.offset;
	        const loc = {
	            start,
	            end: start + tok.text.length,
	        };
	        tok._location = loc;
	    }
	    return tok;
	})(exports.lexer.next);
	exports.lexerAny = exports.lexer;
	let comments = null;
	const makeComment = ({ offset, text }) => ({
	    _location: { start: offset, end: offset + text.length },
	    comment: text,
	});
	function trackingComments(act) {
	    if (comments) {
	        throw new Error('WAT ? Recursive comments tracking  ?');
	    }
	    try {
	        comments = [];
	        const ast = act();
	        return { comments, ast };
	    }
	    finally {
	        comments = null;
	    }
	}
	exports.trackingComments = trackingComments;
	let trackingLoc = false;
	function tracking(act) {
	    if (trackingLoc) {
	        return act();
	    }
	    try {
	        trackingLoc = true;
	        return act();
	    }
	    finally {
	        trackingLoc = false;
	    }
	}
	exports.tracking = tracking;
	function track(xs, ret) {
	    if (!trackingLoc || !ret || typeof ret !== 'object') {
	        return ret;
	    }
	    const start = seek(xs, true);
	    const end = seek(xs, false);
	    if (!start || !end) {
	        return ret;
	    }
	    if (start === end) {
	        ret._location = start;
	    }
	    else {
	        const loc = {
	            start: start.start,
	            end: end.end,
	        };
	        ret._location = loc;
	    }
	    return ret;
	}
	exports.track = track;
	const literal = Symbol('_literal');
	const doubleQuotedSym = Symbol('_doublequoted');
	function box(xs, value, doubleQuoted) {
	    if (!trackingLoc && !doubleQuoted) {
	        return value;
	    }
	    return track(xs, { [literal]: value, [doubleQuotedSym]: doubleQuoted });
	}
	exports.box = box;
	function unwrapNoBox(e) {
	    if (Array.isArray(e) && e.length === 1) {
	        e = unwrapNoBox(e[0]);
	    }
	    if (Array.isArray(e) && !e.length) {
	        return null;
	    }
	    return e;
	}
	function doubleQuoted(value) {
	    const uw = unwrapNoBox(value);
	    if (typeof value === 'object' && (uw === null || uw === void 0 ? void 0 : uw[doubleQuotedSym])) {
	        return { doubleQuoted: true };
	    }
	    return undefined;
	}
	exports.doubleQuoted = doubleQuoted;
	function unbox(value) {
	    var _a;
	    if (typeof value === 'object') {
	        return (_a = value === null || value === void 0 ? void 0 : value[literal]) !== null && _a !== void 0 ? _a : value;
	    }
	    return value;
	}
	exports.unbox = unbox;
	function seek(xs, start) {
	    if (!xs) {
	        return null;
	    }
	    if (Array.isArray(xs)) {
	        const diff = start ? 1 : -1;
	        for (let i = start ? 0 : xs.length - 1; i >= 0 && i < xs.length; i += diff) {
	            const v = seek(xs[i], start);
	            if (v) {
	                return v;
	            }
	        }
	        return null;
	    }
	    if (typeof xs !== 'object') {
	        return null;
	    }
	    return xs._location;
	}


	/***/ }),
	/* 2 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	exports.AstDefaultMapper = exports.arrayNilMap = exports.assignChanged = exports.astMapper = void 0;
	const utils_1 = __webpack_require__(6);
	/**
	 * Builds an AST modifier based on the default implementation, merged with the one you provide.
	 *
	 * Example of a modifier that renames all reference to columns 'foo' to 'bar'
	 * ```ts
	 *  const mapper = astMapper(b => ({
	 *       ref: a => assignChanged(a, {
	 *           name: a.name === 'foo'
	 *               ? 'bar'
	 *               : a.name
	 *       })
	 *   }));
	 *
	 * const modified = mapper.statement(myStatementToModify);
	 * ```
	 */
	function astMapper(modifierBuilder) {
	    const instance = new AstDefaultMapper();
	    instance.wrapped = modifierBuilder(instance);
	    return instance;
	}
	exports.astMapper = astMapper;
	/**
	 * An helper function that returns a copy of an object with modified properties
	 * (similar to Object.assign()), but ONLY if thos properties have changed.
	 * Will return the original object if not.
	 */
	function assignChanged(orig, assign) {
	    if (!orig) {
	        return orig;
	    }
	    let changed = false;
	    for (const k of Object.keys(assign)) {
	        if (orig[k] !== assign[k]) {
	            changed = true;
	            break;
	        }
	    }
	    if (!changed) {
	        return orig;
	    }
	    return (0, utils_1.trimNullish)({
	        ...orig,
	        ...assign,
	    }, 0);
	}
	exports.assignChanged = assignChanged;
	/**
	 * An helper function that returns a map of an array, but:
	 * - It will return the original array if it is null-ish
	 * - It will remove all null-ish entries
	 * - It will return the original array if nothing has changed
	 */
	function arrayNilMap(collection, mapper) {
	    if (!(collection === null || collection === void 0 ? void 0 : collection.length)) {
	        return collection;
	    }
	    let changed = false;
	    let ret = collection;
	    for (let i = 0; i < collection.length; i++) {
	        const orig = collection[i];
	        const val = mapper(orig);
	        if (!changed && (!val || val !== orig)) {
	            changed = true;
	            ret = collection.slice(0, i);
	        }
	        if (!val) {
	            continue;
	        }
	        if (changed) {
	            ret.push(val);
	        }
	    }
	    return ret;
	}
	exports.arrayNilMap = arrayNilMap;
	function withAccepts(val) {
	    switch (val === null || val === void 0 ? void 0 : val.type) {
	        case 'select':
	        case 'delete':
	        case 'insert':
	        case 'update':
	        case 'union':
	        case 'union all':
	        case 'with':
	            return true;
	        default:
	            return false;
	    }
	}
	/**
	 * Can be used to modify an AST.
	 *
	 * You will have to override functions that you're interested in to use this class.
	 *
	 * Example: Will remove all references in
	 */
	class AstDefaultMapper {
	    super() {
	        return new SkipModifier(this);
	    }
	    statement(val) {
	        switch (val.type) {
	            case 'alter table':
	                return this.alterTable(val);
	            case 'alter index':
	                return this.alterIndex(val);
	            case 'commit':
	            case 'start transaction':
	            case 'rollback':
	                return this.transaction(val);
	            case 'create index':
	                return this.createIndex(val);
	            case 'create table':
	                return this.createTable(val);
	            case 'truncate table':
	                return this.truncateTable(val);
	            case 'delete':
	                return this.delete(val);
	            case 'insert':
	                return this.insert(val);
	            case 'with':
	                return this.with(val);
	            case 'with recursive':
	                return this.withRecursive(val);
	            case 'select':
	                return this.selection(val);
	            case 'update':
	                return this.update(val);
	            case 'create extension':
	                return this.createExtension(val);
	            case 'tablespace':
	                return this.tablespace(val);
	            case 'set':
	                return this.setGlobal(val);
	            case 'set timezone':
	                return this.setTimezone(val);
	            case 'set names':
	                return this.setNames(val);
	            case 'create sequence':
	                return this.createSequence(val);
	            case 'alter sequence':
	                return this.alterSequence(val);
	            case 'begin':
	                return this.begin(val);
	            case 'drop table':
	            case 'drop index':
	            case 'drop sequence':
	            case 'drop type':
	            case 'drop trigger':
	                return this.drop(val);
	            case 'create enum':
	                return this.createEnum(val);
	            case 'create composite type':
	                return this.createCompositeType(val);
	            case 'union':
	            case 'union all':
	                return this.union(val);
	            case 'show':
	                return this.show(val);
	            case 'prepare':
	                return this.prepare(val);
	            case 'deallocate':
	                return this.deallocate(val);
	            case 'create view':
	                return this.createView(val);
	            case 'create materialized view':
	                return this.createMaterializedView(val);
	            case 'refresh materialized view':
	                return this.refreshMaterializedView(val);
	            case 'create schema':
	                return this.createSchema(val);
	            case 'raise':
	                return this.raise(val);
	            case 'comment':
	                return this.comment(val);
	            case 'do':
	                return this.do(val);
	            case 'create function':
	                return this.createFunction(val);
	            case 'drop function':
	                return this.dropFunction(val);
	            case 'values':
	                return this.values(val);
	            default:
	                throw utils_1.NotSupported.never(val);
	        }
	    }
	    comment(val) {
	        // not really supported :/
	        return val;
	    }
	    createView(val) {
	        const query = this.select(val.query);
	        if (!query) {
	            return null;
	        }
	        const ref = this.tableRef(val.name);
	        if (!ref) {
	            return null;
	        }
	        return assignChanged(val, {
	            query,
	            name: ref,
	        });
	    }
	    createMaterializedView(val) {
	        const query = this.select(val.query);
	        if (!query) {
	            return null;
	        }
	        const ref = this.tableRef(val.name);
	        if (!ref) {
	            return null;
	        }
	        return assignChanged(val, {
	            query,
	            name: ref,
	        });
	    }
	    refreshMaterializedView(val) {
	        return val;
	    }
	    do(val) {
	        return val;
	    }
	    createFunction(val) {
	        // process arguments
	        const args = arrayNilMap(val.arguments, a => {
	            const type = this.dataType(a.type);
	            return assignChanged(a, { type });
	        });
	        // process return type
	        let returns;
	        if (val.returns) {
	            switch (val.returns.kind) {
	                case 'table':
	                    returns = assignChanged(val.returns, {
	                        columns: arrayNilMap(val.returns.columns, v => {
	                            const type = this.dataType(v.type);
	                            return type && assignChanged(v, { type });
	                        })
	                    });
	                    break;
	                case undefined:
	                case null:
	                case 'array':
	                    returns = this.dataType(val.returns);
	                    break;
	                default:
	                    throw utils_1.NotSupported.never(val.returns);
	            }
	        }
	        return assignChanged(val, {
	            returns,
	            arguments: args,
	        });
	    }
	    dropFunction(val) {
	        const args = arrayNilMap(val.arguments, a => {
	            const type = this.dataType(a.type);
	            return assignChanged(a, { type });
	        });
	        return assignChanged(val, {
	            arguments: args,
	        });
	    }
	    show(val) {
	        return val;
	    }
	    createEnum(val) {
	        return val;
	    }
	    createCompositeType(val) {
	        const attributes = arrayNilMap(val.attributes, a => assignChanged(a, {
	            dataType: this.dataType(a.dataType),
	        }));
	        return assignChanged(val, { attributes });
	    }
	    drop(val) {
	        return val;
	    }
	    alterSequence(seq) {
	        if (seq.change.type === 'set options') {
	            if (seq.change.as) {
	                this.dataType(seq.change.as);
	            }
	        }
	        return seq;
	    }
	    begin(begin) {
	        return begin;
	    }
	    createSequence(seq) {
	        if (seq.options.as) {
	            this.dataType(seq.options.as);
	        }
	        return seq;
	    }
	    tablespace(val) {
	        return val;
	    }
	    setGlobal(val) {
	        return val;
	    }
	    setTimezone(val) {
	        return val;
	    }
	    setNames(val) {
	        return val;
	    }
	    update(val) {
	        if (!val) {
	            return val;
	        }
	        const table = this.tableRef(val.table);
	        if (!table) {
	            return null; // nothing to update
	        }
	        const from = val.from && this.from(val.from);
	        const where = val.where && this.expr(val.where);
	        const sets = arrayNilMap(val.sets, x => this.set(x));
	        if (!(sets === null || sets === void 0 ? void 0 : sets.length)) {
	            return null; // nothing to update
	        }
	        const returning = arrayNilMap(val.returning, c => this.selectionColumn(c));
	        return assignChanged(val, {
	            table,
	            where,
	            sets,
	            from,
	            returning,
	        });
	    }
	    insert(val) {
	        var _a, _b;
	        const into = this.tableRef(val.into);
	        if (!into) {
	            return null; // nowhere to insert into
	        }
	        const select = val.insert && this.select(val.insert);
	        if (!select) {
	            // nothing to insert
	            return null;
	        }
	        const returning = arrayNilMap(val.returning, c => this.selectionColumn(c));
	        let on = (_a = val.onConflict) === null || _a === void 0 ? void 0 : _a.on;
	        switch (on === null || on === void 0 ? void 0 : on.type) {
	            case 'on constraint':
	                // nothing to do
	                break;
	            case 'on expr':
	                on = assignChanged(on, {
	                    exprs: arrayNilMap(on.exprs, e => this.expr(e)),
	                });
	                break;
	            case null:
	            case undefined:
	                break;
	            default:
	                throw utils_1.NotSupported.never(on);
	        }
	        let ocdo = (_b = val.onConflict) === null || _b === void 0 ? void 0 : _b.do;
	        if (ocdo && ocdo !== 'do nothing') {
	            const sets = arrayNilMap(ocdo.sets, x => this.set(x));
	            if (!(sets === null || sets === void 0 ? void 0 : sets.length)) {
	                ocdo = 'do nothing';
	            }
	            else if (ocdo.sets !== sets) {
	                ocdo = { sets };
	            }
	        }
	        return assignChanged(val, {
	            into,
	            insert: select,
	            returning,
	            onConflict: !ocdo ? val.onConflict : assignChanged(val.onConflict, {
	                do: ocdo,
	                on,
	            }),
	        });
	    }
	    raise(val) {
	        return assignChanged(val, {
	            formatExprs: val.formatExprs && arrayNilMap(val.formatExprs, x => this.expr(x)),
	            using: val.using && arrayNilMap(val.using, u => {
	                return assignChanged(u, {
	                    value: this.expr(u.value),
	                });
	            }),
	        });
	    }
	    delete(val) {
	        const from = this.tableRef(val.from);
	        if (!from) {
	            return null; // nothing to delete
	        }
	        const where = val.where && this.expr(val.where);
	        const returning = arrayNilMap(val.returning, c => this.selectionColumn(c));
	        return assignChanged(val, {
	            where,
	            returning,
	            from,
	        });
	    }
	    createSchema(val) {
	        return val;
	    }
	    createTable(val) {
	        const columns = arrayNilMap(val.columns, col => {
	            switch (col.kind) {
	                case 'column':
	                    return this.createColumn(col);
	                case 'like table':
	                    return this.likeTable(col);
	                default:
	                    throw utils_1.NotSupported.never(col);
	            }
	        });
	        if (!(columns === null || columns === void 0 ? void 0 : columns.length)) {
	            return null; // no column to create
	        }
	        return assignChanged(val, {
	            columns,
	        });
	    }
	    likeTable(col) {
	        const like = this.tableRef(col.like);
	        if (!like) {
	            return null;
	        }
	        return assignChanged(col, { like });
	    }
	    truncateTable(val) {
	        return val;
	    }
	    constraint(c) {
	        switch (c.type) {
	            case 'not null':
	            case 'null':
	            case 'primary key':
	            case 'unique':
	            case 'add generated':
	                return c;
	            case 'default': {
	                const def = this.expr(c.default);
	                if (!def) {
	                    return null;
	                }
	                return assignChanged(c, {
	                    default: def,
	                });
	            }
	            case 'check': {
	                const def = this.expr(c.expr);
	                if (!def) {
	                    return null;
	                }
	                return assignChanged(c, {
	                    expr: def,
	                });
	            }
	            case 'reference': {
	                const foreignTable = this.tableRef(c.foreignTable);
	                if (!foreignTable) {
	                    return null;
	                }
	                return assignChanged(c, {
	                    foreignTable,
	                });
	            }
	            default:
	                throw utils_1.NotSupported.never(c);
	        }
	    }
	    set(st) {
	        const value = this.expr(st.value);
	        if (!value) {
	            return null;
	        }
	        return assignChanged(st, {
	            value,
	        });
	    }
	    // =========================================
	    // ================ STUFF ==================
	    // =========================================
	    /** Called when a data type definition is encountered */
	    dataType(dataType) {
	        return dataType;
	    }
	    /** Called when an alias of a table is created */
	    tableRef(st) {
	        return st;
	    }
	    transaction(val) {
	        return val;
	    }
	    createExtension(val) {
	        return val;
	    }
	    createIndex(val) {
	        const expressions = arrayNilMap(val.expressions, e => {
	            const expression = this.expr(e.expression);
	            if (expression === e.expression) {
	                return e;
	            }
	            if (!expression) {
	                return null; // no more index expression
	            }
	            return {
	                ...e,
	                expression,
	            };
	        });
	        if (!(expressions === null || expressions === void 0 ? void 0 : expressions.length)) {
	            return null; // no columns to create index on
	        }
	        return assignChanged(val, {
	            expressions,
	        });
	    }
	    prepare(st) {
	        const statement = this.statement(st.statement);
	        if (!statement) {
	            return null;
	        }
	        return assignChanged(st, {
	            args: arrayNilMap(st.args, a => this.dataType(a)),
	            statement,
	        });
	    }
	    deallocate(st) {
	        return st;
	    }
	    // =========================================
	    // ============== ALTER INDEX ==============
	    // =========================================
	    alterIndex(st) {
	        // not much as of today...might improve this in the future
	        return st;
	    }
	    // =========================================
	    // ============== ALTER TABLE ==============
	    // =========================================
	    alterTable(st) {
	        var _a;
	        const table = this.tableRef(st.table);
	        if (!table) {
	            return null; // no table
	        }
	        let changes = [];
	        let hasChanged = false;
	        for (let i = 0; i < (((_a = st.changes) === null || _a === void 0 ? void 0 : _a.length) || 0); i++) {
	            const currentChange = st.changes[i];
	            const change = this.tableAlteration(currentChange, st.table);
	            hasChanged = hasChanged || (change != currentChange);
	            if (!!change) {
	                changes.push(change);
	            }
	        }
	        if (!changes.length) {
	            return null; // no change left
	        }
	        if (!hasChanged) {
	            return st;
	        }
	        return assignChanged(st, {
	            table,
	            changes,
	        });
	    }
	    tableAlteration(change, table) {
	        switch (change.type) {
	            case 'add column':
	                return this.addColumn(change, table);
	            case 'add constraint':
	                return this.addConstraint(change, table);
	            case 'alter column':
	                return this.alterColumn(change, table);
	            case 'rename':
	                return this.renameTable(change, table);
	            case 'rename column':
	                return this.renameColumn(change, table);
	            case 'rename constraint':
	                return this.renameConstraint(change, table);
	            case 'drop column':
	                return this.dropColumn(change, table);
	            case 'drop constraint':
	                return this.dropConstraint(change, table);
	            case 'owner':
	                return this.setTableOwner(change, table);
	            default:
	                throw utils_1.NotSupported.never(change);
	        }
	    }
	    dropColumn(change, table) {
	        return change;
	    }
	    dropConstraint(change, table) {
	        return change;
	    }
	    setTableOwner(change, table) {
	        return change;
	    }
	    renameConstraint(change, table) {
	        return change;
	    }
	    renameColumn(change, table) {
	        return change;
	    }
	    renameTable(change, table) {
	        return change;
	    }
	    alterColumn(change, inTable) {
	        let alter;
	        switch (change.alter.type) {
	            case 'set default':
	                alter = this.setColumnDefault(change.alter, inTable, change.column);
	                break;
	            case 'set type':
	                alter = this.setColumnType(change.alter, inTable, change.column);
	                break;
	            case 'drop default':
	            case 'set not null':
	            case 'drop not null':
	                alter = this.alterColumnSimple(change.alter, inTable, change.column);
	                break;
	            case 'add generated':
	                alter = this.alterColumnAddGenerated(change.alter, inTable, change.column);
	                break;
	            default:
	                throw utils_1.NotSupported.never(change.alter);
	        }
	        if (!alter) {
	            return null; // no more alter
	        }
	        return assignChanged(change, {
	            alter,
	        });
	    }
	    setColumnType(alter, inTable, inColumn) {
	        const dataType = this.dataType(alter.dataType);
	        return assignChanged(alter, {
	            dataType,
	        });
	    }
	    alterColumnAddGenerated(alter, inTable, inColumn) {
	        return alter;
	    }
	    alterColumnSimple(alter, inTable, inColumn) {
	        return alter;
	    }
	    setColumnDefault(alter, inTable, inColumn) {
	        const def = this.expr(alter.default);
	        if (!def) {
	            return null; // no more default to set
	        }
	        return assignChanged(alter, {
	            default: def,
	        });
	    }
	    addConstraint(change, inTable) {
	        return change;
	    }
	    addColumn(change, inTable) {
	        const column = this.createColumn(change.column);
	        if (!column) {
	            return null; // no more column to add
	        }
	        return assignChanged(change, {
	            column,
	        });
	    }
	    createColumn(col) {
	        var _a;
	        // to be overriden
	        const dataType = this.dataType(col.dataType);
	        if (!dataType) {
	            return null; // no data type => remove column
	        }
	        const constraints = (_a = arrayNilMap(col.constraints, m => this.constraint(m))) !== null && _a !== void 0 ? _a : undefined;
	        return assignChanged(col, {
	            dataType,
	            constraints,
	        });
	    }
	    // =========================================
	    // ============== SELECTIONS ==============
	    // =========================================
	    select(val) {
	        switch (val.type) {
	            case 'select':
	                return this.selection(val);
	            case 'union':
	            case 'union all':
	                return this.union(val);
	            case 'with':
	                return this.with(val);
	            case 'values':
	                return this.values(val);
	            case 'with recursive':
	                return this.withRecursive(val);
	            default:
	                throw utils_1.NotSupported.never(val);
	        }
	    }
	    selection(val) {
	        var _a, _b;
	        const from = arrayNilMap(val.from, c => this.from(c));
	        const columns = arrayNilMap(val.columns, c => this.selectionColumn(c));
	        const where = val.where && this.expr(val.where);
	        const groupBy = arrayNilMap(val.groupBy, c => this.expr(c));
	        const having = val.having && this.expr(val.having);
	        const orderBy = this.orderBy(val.orderBy);
	        const limit = assignChanged(val.limit, {
	            limit: this.expr((_a = val.limit) === null || _a === void 0 ? void 0 : _a.limit),
	            offset: this.expr((_b = val.limit) === null || _b === void 0 ? void 0 : _b.offset),
	        });
	        return assignChanged(val, {
	            from,
	            columns,
	            where,
	            groupBy,
	            having,
	            orderBy,
	            limit,
	        });
	    }
	    orderBy(orderBy) {
	        return arrayNilMap(orderBy, c => {
	            const by = this.expr(c.by);
	            if (!by) {
	                return null;
	            }
	            if (by === c.by) {
	                return c;
	            }
	            return {
	                ...c,
	                by,
	            };
	        });
	    }
	    union(val) {
	        const left = this.select(val.left);
	        const right = this.select(val.right);
	        if (!left || !right) {
	            return left !== null && left !== void 0 ? left : right;
	        }
	        return assignChanged(val, {
	            left,
	            right
	        });
	    }
	    with(val) {
	        const bind = arrayNilMap(val.bind, s => {
	            const statement = this.statement(s.statement);
	            return withAccepts(statement)
	                ? assignChanged(s, { statement })
	                : null;
	        });
	        // no bindngs
	        if (!bind) {
	            return null;
	        }
	        const _in = this.statement(val.in);
	        if (!withAccepts(_in)) {
	            return null;
	        }
	        return assignChanged(val, {
	            bind,
	            in: _in,
	        });
	    }
	    withRecursive(val) {
	        const statement = this.union(val.bind);
	        if (!statement) {
	            return null;
	        }
	        // 'with recursive' only accepts unions
	        if (statement.type !== 'union' && statement.type !== 'union all') {
	            return null;
	        }
	        const _in = this.statement(val.in);
	        if (!withAccepts(_in)) {
	            return null;
	        }
	        return assignChanged(val, {
	            bind: statement,
	            in: _in,
	        });
	    }
	    from(from) {
	        switch (from.type) {
	            case 'table':
	                return this.fromTable(from);
	            case 'statement':
	                return this.fromStatement(from);
	            case 'call':
	                return this.fromCall(from);
	            default:
	                throw utils_1.NotSupported.never(from);
	        }
	    }
	    fromCall(from) {
	        const call = this.call(from);
	        if (!call || call.type !== 'call') {
	            return null;
	        }
	        return assignChanged(from, call);
	    }
	    fromStatement(from) {
	        const statement = this.select(from.statement);
	        if (!statement) {
	            return null; // nothing to select from
	        }
	        const join = from.join && this.join(from.join);
	        return assignChanged(from, {
	            statement,
	            join,
	        });
	    }
	    values(from) {
	        const values = arrayNilMap(from.values, x => arrayNilMap(x, y => this.expr(y)));
	        if (!(values === null || values === void 0 ? void 0 : values.length)) {
	            return null; // nothing to select from
	        }
	        return assignChanged(from, {
	            values,
	        });
	    }
	    join(join) {
	        const on = join.on && this.expr(join.on);
	        if (!on && !join.using) {
	            return join;
	        }
	        return assignChanged(join, {
	            on,
	        });
	    }
	    fromTable(from) {
	        const nfrom = this.tableRef(from.name);
	        if (!nfrom) {
	            return null; // nothing to select from
	        }
	        const join = from.join && this.join(from.join);
	        return assignChanged(from, {
	            name: nfrom,
	            join,
	        });
	    }
	    selectionColumn(val) {
	        const expr = this.expr(val.expr);
	        if (!expr) {
	            return null; // not selected anymore
	        }
	        return assignChanged(val, {
	            expr,
	        });
	    }
	    // =========================================
	    // ============== EXPRESSIONS ==============
	    // =========================================
	    expr(val) {
	        if (!val) {
	            return val;
	        }
	        switch (val.type) {
	            case 'binary':
	                return this.binary(val);
	            case 'unary':
	                return this.unary(val);
	            case 'ref':
	                return this.ref(val);
	            case 'string':
	            case 'numeric':
	            case 'integer':
	            case 'boolean':
	            case 'constant':
	            case 'null':
	                return this.constant(val);
	            case 'list':
	            case 'array':
	                return this.array(val);
	            case 'array select':
	                return this.arraySelect(val);
	            case 'call':
	                return this.call(val);
	            case 'cast':
	                return this.cast(val);
	            case 'case':
	                return this.case(val);
	            case 'member':
	                return this.member(val);
	            case 'arrayIndex':
	                return this.arrayIndex(val);
	            case 'ternary':
	                return this.ternary(val);
	            case 'select':
	            case 'union':
	            case 'union all':
	            case 'with':
	            case 'with recursive':
	                return this.select(val);
	            case 'keyword':
	                return this.valueKeyword(val);
	            case 'parameter':
	                return this.parameter(val);
	            case 'extract':
	                return this.extract(val);
	            case 'overlay':
	                return this.callOverlay(val);
	            case 'substring':
	                return this.callSubstring(val);
	            case 'values':
	                return this.values(val);
	            case 'default':
	                return this.default(val);
	            default:
	                throw utils_1.NotSupported.never(val);
	        }
	    }
	    arraySelect(val) {
	        const select = this.select(val.select);
	        if (!select) {
	            return null;
	        }
	        return assignChanged(val, { select });
	    }
	    extract(st) {
	        const from = this.expr(st.from);
	        if (!from) {
	            return null;
	        }
	        return assignChanged(st, { from });
	    }
	    valueKeyword(val) {
	        return val;
	    }
	    ternary(val) {
	        const value = this.expr(val.value);
	        const lo = this.expr(val.lo);
	        const hi = this.expr(val.hi);
	        if (!value || !lo || !hi) {
	            return null; // missing a branch
	        }
	        return assignChanged(val, {
	            value,
	            lo,
	            hi,
	        });
	    }
	    parameter(st) {
	        return st;
	    }
	    arrayIndex(val) {
	        const array = this.expr(val.array);
	        const index = this.expr(val.index);
	        if (!array || !index) {
	            return null;
	        }
	        return assignChanged(val, {
	            array,
	            index,
	        });
	    }
	    member(val) {
	        const operand = this.expr(val.operand);
	        if (!operand) {
	            return null;
	        }
	        return assignChanged(val, {
	            operand,
	        });
	    }
	    case(val) {
	        const value = val.value && this.expr(val.value);
	        const whens = arrayNilMap(val.whens, w => {
	            const when = this.expr(w.when);
	            const value = this.expr(w.value);
	            if (!when || !value) {
	                return null;
	            }
	            return assignChanged(w, {
	                value,
	                when,
	            });
	        });
	        if (!(whens === null || whens === void 0 ? void 0 : whens.length)) {
	            return null; // no case
	        }
	        const els = val.else && this.expr(val.else);
	        return assignChanged(val, {
	            value,
	            whens,
	            else: els,
	        });
	    }
	    cast(val) {
	        const operand = this.expr(val.operand);
	        if (!operand) {
	            return null;
	        }
	        return assignChanged(val, {
	            operand,
	        });
	    }
	    call(val) {
	        const args = arrayNilMap(val.args, a => this.expr(a));
	        if (!args) {
	            return null;
	        }
	        const orderBy = this.orderBy(val.orderBy);
	        const filter = this.expr(val.filter);
	        return assignChanged(val, {
	            args,
	            orderBy,
	            filter,
	        });
	    }
	    callSubstring(val) {
	        return assignChanged(val, {
	            value: this.expr(val.value),
	            from: this.expr(val.from),
	            for: this.expr(val.for),
	        });
	    }
	    callOverlay(val) {
	        return assignChanged(val, {
	            value: this.expr(val.value),
	            placing: this.expr(val.placing),
	            from: this.expr(val.from),
	            for: this.expr(val.for),
	        });
	    }
	    array(val) {
	        const expressions = arrayNilMap(val.expressions, a => this.expr(a));
	        if (!expressions) {
	            return null;
	        }
	        return assignChanged(val, {
	            expressions,
	        });
	    }
	    constant(value) {
	        return value;
	    }
	    default(value) {
	        return value;
	    }
	    /** Called when a reference is used */
	    ref(val) {
	        return val;
	    }
	    unary(val) {
	        const operand = this.expr(val.operand);
	        if (!operand) {
	            return null;
	        }
	        return assignChanged(val, {
	            operand,
	        });
	    }
	    binary(val) {
	        const left = this.expr(val.left);
	        const right = this.expr(val.right);
	        if (!left || !right) {
	            return null;
	        }
	        return assignChanged(val, {
	            left,
	            right,
	        });
	    }
	}
	exports.AstDefaultMapper = AstDefaultMapper;
	// ====== auto implement the replace mechanism
	const proto = AstDefaultMapper.prototype;
	for (const k of Object.getOwnPropertyNames(proto)) {
	    const orig = proto[k];
	    if (k === 'constructor' || k === 'super' || typeof orig !== 'function') {
	        continue;
	    }
	    Object.defineProperty(proto, k, {
	        configurable: false,
	        get() {
	            return function (...args) {
	                var _a;
	                if (this.skipNext) {
	                    this.skipNext = false;
	                    return orig.apply(this, args);
	                }
	                const impl = (_a = this.wrapped) === null || _a === void 0 ? void 0 : _a[k];
	                if (!impl) {
	                    return orig.apply(this, args);
	                }
	                return impl.apply(this.wrapped, args);
	            };
	        }
	    });
	}
	// ====== auto implement the skip mechanism
	class SkipModifier extends AstDefaultMapper {
	    constructor(parent) {
	        super();
	        this.parent = parent;
	    }
	}
	for (const k of Object.getOwnPropertyNames(proto)) {
	    const orig = proto[k];
	    if (k === 'constructor' || k === 'super' || typeof orig !== 'function') {
	        continue;
	    }
	    Object.defineProperty(SkipModifier.prototype, k, {
	        configurable: false,
	        get() {
	            return function (...args) {
	                this.parent.skipNext = true;
	                return orig.apply(this.parent, args);
	            };
	        }
	    });
	}


	/***/ }),
	/* 3 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	exports.sqlKeywords = void 0;
	// https://www.postgresql.org/docs/current/sql-keywords-appendix.html
	// $('table.table').children('tbody').children().toArray().filter(x => { const txt = $($(x).children()[1]).text(); return txt.includes('reserved') && !txt.includes('non-reserved')}).map(x => $($(x).children()[0]).text())
	exports.sqlKeywords = [
	    "ALL", "ANALYSE", "ANALYZE", "AND", "ANY", "ARRAY", "AS", "ASC", "ASYMMETRIC", "AUTHORIZATION", "BINARY", "BOTH", "CASE", "CAST", "CHECK", "COLLATE", "COLLATION", "CONCURRENTLY", "CONSTRAINT", "CREATE", "CROSS", "CURRENT_CATALOG", "CURRENT_DATE", "CURRENT_ROLE", "CURRENT_SCHEMA", "CURRENT_TIME", "CURRENT_TIMESTAMP", "CURRENT_USER", "DEFAULT", "DEFERRABLE", "DESC", "DISTINCT", "DO", "ELSE", "END", "EXCEPT", "FALSE", "FETCH", "FOR", "FOREIGN", "FREEZE", "FROM", "FULL", "GRANT", "GROUP", "HAVING", "ILIKE", "IN", "INITIALLY", "INNER", "INTERSECT", "INTO", "IS", "ISNULL", "JOIN", "LATERAL", "LEADING", "LEFT", "LIKE", "LIMIT", "LOCALTIME", "LOCALTIMESTAMP", "NATURAL", "NOT", "NOTNULL", "NULL", "OFFSET", "ON", "ONLY", "OR", "ORDER", "OUTER", "OVERLAPS", "PLACING", "PRIMARY", "REFERENCES", "RETURNING", "RIGHT", "SELECT", "SESSION_USER", "SIMILAR", "SOME", "SYMMETRIC", "TABLE", "TABLESAMPLE", "THEN", "TO", "TRAILING", "TRUE", "UNION", "UNIQUE", "USER", "USING", "VARIADIC", "VERBOSE", "WHEN", "WHERE", "WINDOW", "WITH"
	    // added manually
	    ,
	    "PRECISION"
	];


	/***/ }),
	/* 4 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	exports.intervalToString = exports.normalizeInterval = exports.buildInterval = void 0;
	const types = [
	    ['years', 12],
	    ['months', 30],
	    ['days', 24],
	    ['hours', 60],
	    ['minutes', 60],
	    ['seconds', 1000],
	    ['milliseconds', 0],
	];
	function* unwrap(k) {
	    if (typeof k[1] === 'number') {
	        yield k;
	    }
	    else {
	        for (const v of k) {
	            yield* unwrap(v);
	        }
	    }
	}
	function buildInterval(orig, vals) {
	    var _a;
	    const ret = {};
	    if (vals === 'invalid') {
	        throw new Error(`invalid input syntax for type interval: "${orig}"`);
	    }
	    for (const [k, v] of unwrap(vals)) {
	        ret[k] = ((_a = ret[k]) !== null && _a !== void 0 ? _a : 0) + v;
	    }
	    return ret;
	}
	exports.buildInterval = buildInterval;
	/** Returns a normalized copy of the given interval */
	function normalizeInterval(value) {
	    var _a, _b, _c, _d, _e, _f, _g, _h, _j;
	    const ret = { ...value };
	    // trim non-integers
	    for (let i = 0; i < types.length; i++) {
	        const [k, mul] = types[i];
	        const v = (_a = ret[k]) !== null && _a !== void 0 ? _a : 0;
	        const int = v >= 0
	            ? Math.floor(v)
	            : Math.ceil(v);
	        if (!v || int === v) {
	            continue;
	        }
	        const nk = (_b = types[i + 1]) === null || _b === void 0 ? void 0 : _b[0];
	        if (nk) {
	            ret[nk] = ((_c = ret[nk]) !== null && _c !== void 0 ? _c : 0) + mul * (v - int);
	        }
	        ret[k] = int;
	    }
	    if (ret.months || ret.years) {
	        const m = ((_d = ret.months) !== null && _d !== void 0 ? _d : 0) + ((_e = ret.years) !== null && _e !== void 0 ? _e : 0) * 12;
	        ret.months = m % 12;
	        ret.years = (m - ret.months) / 12;
	    }
	    // normalize time
	    let t = ((_f = ret.hours) !== null && _f !== void 0 ? _f : 0) * 3600
	        + ((_g = ret.minutes) !== null && _g !== void 0 ? _g : 0) * 60
	        + ((_h = ret.seconds) !== null && _h !== void 0 ? _h : 0)
	        + ((_j = ret.milliseconds) !== null && _j !== void 0 ? _j : 0) / 1000;
	    let sign = 1;
	    if (t < 0) {
	        sign = -1;
	        t = -t;
	    }
	    if (t >= 3600) {
	        ret.hours = sign * Math.floor(t / 3600);
	        t -= sign * ret.hours * 3600;
	    }
	    else {
	        delete ret.hours;
	    }
	    if (t >= 60) {
	        ret.minutes = sign * Math.floor(t / 60);
	        t -= sign * ret.minutes * 60;
	    }
	    else {
	        delete ret.minutes;
	    }
	    if (t > 0) {
	        ret.seconds = sign * Math.floor(t);
	        t -= sign * ret.seconds;
	    }
	    else {
	        delete ret.seconds;
	    }
	    if (t > 0) {
	        ret.milliseconds = sign * Math.round(t * 1000);
	    }
	    else {
	        delete ret.milliseconds;
	    }
	    // trim zeros.
	    for (const [k] of types) {
	        if (!ret[k]) {
	            delete ret[k];
	        }
	    }
	    return ret;
	}
	exports.normalizeInterval = normalizeInterval;
	/** Interval value to postgres string representation  */
	function intervalToString(value) {
	    var _a, _b, _c;
	    value = normalizeInterval(value);
	    const ret = [];
	    if (value.years) {
	        ret.push(value.years === 1 ? '1 year' : value.years + ' years');
	    }
	    if (value.months) {
	        ret.push(value.months === 1 ? '1 month' : value.months + ' months');
	    }
	    if (value.days) {
	        ret.push(value.days === 1 ? '1 day' : value.days + ' days');
	    }
	    if (value.hours || value.minutes || value.seconds || value.milliseconds) {
	        let time = `${num((_a = value.hours) !== null && _a !== void 0 ? _a : 0)}:${num((_b = value.minutes) !== null && _b !== void 0 ? _b : 0)}:${num((_c = value.seconds) !== null && _c !== void 0 ? _c : 0)}`;
	        if (value.milliseconds) {
	            time = time + (value.milliseconds / 1000).toString().substr(1);
	        }
	        if (neg(value.hours) || neg(value.minutes) || neg(value.seconds) || neg(value.milliseconds)) {
	            time = '-' + time;
	        }
	        ret.push(time);
	    }
	    return ret.join(' ');
	}
	exports.intervalToString = intervalToString;
	function num(v) {
	    v = Math.abs(v);
	    return v < 10 ? '0' + v : v.toString();
	}
	function neg(v) {
	    return v && v < 0;
	}


	/***/ }),
	/* 5 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	exports.astVisitor = void 0;
	const ast_mapper_1 = __webpack_require__(2);
	class Visitor {
	    super() {
	        return new SkipVisitor(this);
	    }
	}
	// =============== auto implement the mapper
	const mapperProto = ast_mapper_1.AstDefaultMapper.prototype;
	for (const k of Object.getOwnPropertyNames(mapperProto)) {
	    const orig = mapperProto[k];
	    if (k === 'constructor' || k === 'super' || typeof orig !== 'function') {
	        continue;
	    }
	    Object.defineProperty(Visitor.prototype, k, {
	        configurable: false,
	        get() {
	            return function (...args) {
	                const impl = this.visitor[k];
	                if (!impl) {
	                    // just ignore & forward call to mapper
	                    return orig.apply(this, args);
	                }
	                // return first argument
	                // ...which means "I dont wana change anything"
	                //    in the ast-modifier language.
	                impl.apply(this.visitor, args);
	                return args[0];
	            };
	        }
	    });
	}
	// ====== auto implement the skip mechanism
	class SkipVisitor {
	    constructor(parent) {
	        this.parent = parent;
	    }
	}
	for (const k of Object.getOwnPropertyNames(mapperProto)) {
	    const orig = mapperProto[k];
	    if (k === 'constructor' || k === 'super' || typeof orig !== 'function') {
	        continue;
	    }
	    Object.defineProperty(SkipVisitor.prototype, k, {
	        configurable: false,
	        get() {
	            return function (...args) {
	                return orig.apply(this.parent, args);
	            };
	        }
	    });
	}
	/**
	 * Builds an AST visitor based on the default implementation, merged with the one you provide.
	 *
	 * Example of visitor which counts references to a column 'foo':
	 *
	 * ```ts
	 * let cnt = 0;
	 * const visitor = astVisitor(v => ({
	 *      ref: r => {
	 *          if (r.name === 'foo') {
	 *              cnt++;
	 *          }
	 *          v.super().ref(r);
	 *      }
	 *  }));
	 *
	 * visitor.statement(myStatementToCount);
	 * console.log(`${cnt} references to foo !`);
	 * ```
	 */
	function astVisitor(visitorBuilder) {
	    return (0, ast_mapper_1.astMapper)(m => {
	        const ret = new Visitor();
	        ret.mapper = m;
	        ret.visitor = visitorBuilder(ret);
	        return ret;
	    });
	}
	exports.astVisitor = astVisitor;


	/***/ }),
	/* 6 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	exports.trimNullish = exports.NotSupported = void 0;
	class NotSupported extends Error {
	    constructor(what) {
	        super('Not supported' + (what ? ': ' + what : ''));
	    }
	    static never(value, msg) {
	        return new NotSupported(`${msg !== null && msg !== void 0 ? msg : ''} ${JSON.stringify(value)}`);
	    }
	}
	exports.NotSupported = NotSupported;
	function trimNullish(value, depth = 5) {
	    if (depth < 0)
	        return value;
	    if (value instanceof Array) {
	        value.forEach(x => trimNullish(x, depth - 1));
	    }
	    if (typeof value !== 'object' || value instanceof Date)
	        return value;
	    if (!value) {
	        return value;
	    }
	    for (const k of Object.keys(value)) {
	        const val = value[k];
	        if (val === undefined || val === null)
	            delete value[k];
	        else
	            trimNullish(val, depth - 1);
	    }
	    return value;
	}
	exports.trimNullish = trimNullish;


	/***/ }),
	/* 7 */
	/***/ (function(module, exports, __webpack_require__) {

	var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    var desc = Object.getOwnPropertyDescriptor(m, k);
	    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
	      desc = { enumerable: true, get: function() { return m[k]; } };
	    }
	    Object.defineProperty(o, k2, desc);
	}) : (function(o, m, k, k2) {
	    if (k2 === undefined) k2 = k;
	    o[k2] = m[k];
	}));
	var __exportStar = (this && this.__exportStar) || function(m, exports) {
	    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.normalizeInterval = exports.intervalToString = exports.toSql = exports.astMapper = exports.assignChanged = exports.arrayNilMap = exports.astVisitor = exports.parseWithComments = exports.parseIntervalLiteral = exports.parseGeometricLiteral = exports.parseArrayLiteral = exports.parseFirst = exports.parse = void 0;
	var parser_1 = __webpack_require__(8);
	Object.defineProperty(exports, "parse", { enumerable: true, get: function () { return parser_1.parse; } });
	Object.defineProperty(exports, "parseFirst", { enumerable: true, get: function () { return parser_1.parseFirst; } });
	Object.defineProperty(exports, "parseArrayLiteral", { enumerable: true, get: function () { return parser_1.parseArrayLiteral; } });
	Object.defineProperty(exports, "parseGeometricLiteral", { enumerable: true, get: function () { return parser_1.parseGeometricLiteral; } });
	Object.defineProperty(exports, "parseIntervalLiteral", { enumerable: true, get: function () { return parser_1.parseIntervalLiteral; } });
	Object.defineProperty(exports, "parseWithComments", { enumerable: true, get: function () { return parser_1.parseWithComments; } });
	var ast_visitor_1 = __webpack_require__(5);
	Object.defineProperty(exports, "astVisitor", { enumerable: true, get: function () { return ast_visitor_1.astVisitor; } });
	var ast_mapper_1 = __webpack_require__(2);
	Object.defineProperty(exports, "arrayNilMap", { enumerable: true, get: function () { return ast_mapper_1.arrayNilMap; } });
	Object.defineProperty(exports, "assignChanged", { enumerable: true, get: function () { return ast_mapper_1.assignChanged; } });
	Object.defineProperty(exports, "astMapper", { enumerable: true, get: function () { return ast_mapper_1.astMapper; } });
	var to_sql_1 = __webpack_require__(19);
	Object.defineProperty(exports, "toSql", { enumerable: true, get: function () { return to_sql_1.toSql; } });
	__exportStar(__webpack_require__(21), exports);
	var interval_builder_1 = __webpack_require__(4);
	Object.defineProperty(exports, "intervalToString", { enumerable: true, get: function () { return interval_builder_1.intervalToString; } });
	Object.defineProperty(exports, "normalizeInterval", { enumerable: true, get: function () { return interval_builder_1.normalizeInterval; } });


	/***/ }),
	/* 8 */
	/***/ (function(module, exports, __webpack_require__) {

	var __importDefault = (this && this.__importDefault) || function (mod) {
	    return (mod && mod.__esModule) ? mod : { "default": mod };
	};
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.parseGeometricLiteral = exports.parseIntervalLiteral = exports.parseArrayLiteral = exports.parse = exports.parseWithComments = exports.parseFirst = void 0;
	const nearley_1 = __webpack_require__(9);
	const main_ne_1 = __importDefault(__webpack_require__(10));
	const array_ne_1 = __importDefault(__webpack_require__(11));
	const geometric_ne_1 = __importDefault(__webpack_require__(13));
	const interval_ne_1 = __importDefault(__webpack_require__(15));
	const interval_iso_ne_1 = __importDefault(__webpack_require__(17));
	const interval_builder_1 = __webpack_require__(4);
	const lexer_1 = __webpack_require__(1);
	let sqlCompiled;
	let arrayCompiled;
	let geometricCompiled;
	let intervalTextCompiled;
	let intervalIsoCompiled;
	/** Parse the first SQL statement in the given text (discards the rest), and return its AST */
	function parseFirst(sql) {
	    const first = parse(sql);
	    return first[0];
	}
	exports.parseFirst = parseFirst;
	/** Parse an AST from SQL, and get the comments */
	function parseWithComments(sql, options) {
	    return (0, lexer_1.trackingComments)(() => parse(sql, options));
	}
	exports.parseWithComments = parseWithComments;
	function parse(sql, optEntry) {
	    if (!sqlCompiled) {
	        sqlCompiled = nearley_1.Grammar.fromCompiled(main_ne_1.default);
	    }
	    const entry = typeof optEntry === 'string'
	        ? optEntry
	        : optEntry === null || optEntry === void 0 ? void 0 : optEntry.entry;
	    const opts = typeof optEntry === 'string' ? null : optEntry;
	    // parse sql
	    const doParse = () => _parse(sql, sqlCompiled, entry);
	    let parsed = (opts === null || opts === void 0 ? void 0 : opts.locationTracking)
	        ? (0, lexer_1.tracking)(doParse)
	        : doParse();
	    // always return an array of statements.
	    if (typeof optEntry !== 'string' && !Array.isArray(parsed)) {
	        parsed = [parsed];
	    }
	    return parsed;
	}
	exports.parse = parse;
	function parseArrayLiteral(sql) {
	    if (!arrayCompiled) {
	        arrayCompiled = nearley_1.Grammar.fromCompiled(array_ne_1.default);
	    }
	    return _parse(sql, arrayCompiled);
	}
	exports.parseArrayLiteral = parseArrayLiteral;
	function parseIntervalLiteral(literal) {
	    if (literal.startsWith('P')) {
	        if (!intervalIsoCompiled) {
	            intervalIsoCompiled = nearley_1.Grammar.fromCompiled(interval_iso_ne_1.default);
	        }
	        return (0, interval_builder_1.buildInterval)(literal, _parse(literal, intervalIsoCompiled));
	    }
	    else {
	        if (!intervalTextCompiled) {
	            intervalTextCompiled = nearley_1.Grammar.fromCompiled(interval_ne_1.default);
	        }
	        const low = literal.toLowerCase(); // full text syntax is case insensitive
	        return (0, interval_builder_1.buildInterval)(literal, _parse(low, intervalTextCompiled));
	    }
	}
	exports.parseIntervalLiteral = parseIntervalLiteral;
	function parseGeometricLiteral(sql, type) {
	    if (!geometricCompiled) {
	        geometricCompiled = nearley_1.Grammar.fromCompiled(geometric_ne_1.default);
	    }
	    return _parse(sql, geometricCompiled, type);
	}
	exports.parseGeometricLiteral = parseGeometricLiteral;
	function _parse(sql, grammar, entry) {
	    try {
	        grammar.start = entry !== null && entry !== void 0 ? entry : 'main';
	        const parser = new nearley_1.Parser(grammar);
	        parser.feed(sql);
	        const asts = parser.finish();
	        if (!asts.length) {
	            throw new Error('Unexpected end of input');
	        }
	        else if (asts.length !== 1) {
	            throw new Error(` Ambiguous SQL syntax: Please file an issue stating the request that has failed at https://github.com/oguimbal/pgsql-ast-parser:

        ${sql}

        `);
	        }
	        return asts[0];
	    }
	    catch (e) {
	        if (typeof (e === null || e === void 0 ? void 0 : e.message) !== 'string') {
	            throw e;
	        }
	        let msg = e.message;
	        // remove all the stack crap of nearley parser
	        let begin = null;
	        const parts = [];
	        const reg = /A (.+) token based on:/g;
	        let m;
	        while (m = reg.exec(msg)) {
	            begin = begin !== null && begin !== void 0 ? begin : msg.substr(0, m.index);
	            parts.push(`    - A "${m[1]}" token`);
	        }
	        if (begin) {
	            msg = begin + parts.join('\n') + '\n\n';
	        }
	        e.message = msg;
	        throw e;
	    }
	}


	/***/ }),
	/* 9 */
	/***/ (function(module, exports) {

	module.exports = requireNearley();

	/***/ }),
	/* 10 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	// Generated automatically by nearley, version unknown
	// http://github.com/Hardmath123/nearley
	// Bypasses TS6133. Allow declared but unused functions.
	// @ts-ignore
	function id(d) { return d[0]; }
	const lexer_1 = __webpack_require__(1);
	const lexer_2 = __webpack_require__(1);
	function asName(val) {
	    return asNameWithColumns(val, undefined);
	}
	function asNameWithColumns(val, columns) {
	    const name = toStr(val);
	    if (!columns || columns.length === 0) {
	        return (0, lexer_2.track)(val, { name });
	    }
	    return (0, lexer_2.track)(val, {
	        name,
	        columns: columns.map(c => ({ name: toStr(c) })),
	    });
	}
	function asLit(val) {
	    const value = toStr(val);
	    return (0, lexer_2.track)(val, { value });
	}
	function unwrap(e) {
	    if (Array.isArray(e) && e.length === 1) {
	        e = unwrap(e[0]);
	    }
	    if (Array.isArray(e) && !e.length) {
	        return null;
	    }
	    return (0, lexer_2.unbox)(e);
	}
	const get = (i) => (x) => (0, lexer_2.track)(x, x[i]);
	const last = (x) => Array.isArray(x) ? (0, lexer_2.track)(x[x.length - 1], x[x.length - 1]) : x;
	function flatten(e) {
	    if (Array.isArray(e)) {
	        const ret = [];
	        for (const i of e) {
	            ret.push(...flatten(i));
	        }
	        return ret;
	    }
	    if (!e) {
	        return [];
	    }
	    return [e];
	}
	function asStr(value) {
	    var _a;
	    value = (0, lexer_2.unbox)(value);
	    return (_a = value === null || value === void 0 ? void 0 : value.value) !== null && _a !== void 0 ? _a : value;
	}
	function flattenStr(e) {
	    const fl = flatten((0, lexer_2.unbox)(e));
	    return fl.filter(x => !!x)
	        .map(x => asStr(x))
	        .filter(x => typeof x === 'string')
	        .map(x => x.trim())
	        .filter(x => !!x);
	}
	function toStr(e, join) {
	    return flattenStr(e).join(join || '');
	}
	function fromEntries(vals) {
	    const ret = {};
	    for (const [k, v] of vals) {
	        ret[k] = v;
	    }
	    return ret;
	}
	const kwSensitivity = { sensitivity: 'accent' };
	const eqInsensitive = (a, b) => a.localeCompare(b, undefined, kwSensitivity) === 0;
	const notReservedKw = (kw) => (x, _, rej) => {
	    const val = asStr(x[0]);
	    if (eqInsensitive(val, kw)) {
	        return (0, lexer_2.box)(x, kw);
	    }
	    return rej;
	};
	const kw = notReservedKw;
	const anyKw = (...kw) => {
	    const kwSet = new Set(kw);
	    return (x, _, rej) => {
	        const val = typeof x[0] === 'string' ? x[0] : x[0].value;
	        return kwSet.has(val) ? val : rej;
	    };
	};
	function setSeqOpts(ret, opts) {
	    const defs = new Set();
	    const unboxed = opts.map(lexer_2.unbox);
	    for (const [k, v] of unboxed) {
	        if (defs.has(k)) {
	            throw new Error('conflicting or redundant options');
	        }
	        defs.add(k);
	        ret[k] = (0, lexer_2.unbox)(v);
	    }
	}
	const grammar = {
	    Lexer: lexer_1.lexerAny,
	    ParserRules: [
	        { "name": "lparen", "symbols": [(lexer_1.lexerAny.has("lparen") ? { type: "lparen" } : lparen)] },
	        { "name": "rparen", "symbols": [(lexer_1.lexerAny.has("rparen") ? { type: "rparen" } : rparen)] },
	        { "name": "number$subexpression$1", "symbols": ["float"] },
	        { "name": "number$subexpression$1", "symbols": ["int"] },
	        { "name": "number", "symbols": ["number$subexpression$1"], "postprocess": unwrap },
	        { "name": "dot", "symbols": [(lexer_1.lexerAny.has("dot") ? { type: "dot" } : dot)], "postprocess": id },
	        { "name": "float", "symbols": [(lexer_1.lexerAny.has("float") ? { type: "float" } : float)], "postprocess": x => (0, lexer_2.box)(x, parseFloat(unwrap(x))) },
	        { "name": "int", "symbols": [(lexer_1.lexerAny.has("int") ? { type: "int" } : int)], "postprocess": x => (0, lexer_2.box)(x, parseInt(unwrap(x), 10)) },
	        { "name": "comma", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma)], "postprocess": id },
	        { "name": "star", "symbols": [(lexer_1.lexerAny.has("star") ? { type: "star" } : star)], "postprocess": x => (0, lexer_2.box)(x, x[0].value) },
	        { "name": "string$subexpression$1", "symbols": [(lexer_1.lexerAny.has("string") ? { type: "string" } : string)] },
	        { "name": "string$subexpression$1", "symbols": [(lexer_1.lexerAny.has("eString") ? { type: "eString" } : eString)] },
	        { "name": "string", "symbols": ["string$subexpression$1"], "postprocess": x => (0, lexer_2.box)(x, unwrap(x[0]).value) },
	        { "name": "ident", "symbols": ["word"], "postprocess": get(0) },
	        { "name": "word", "symbols": [(lexer_1.lexerAny.has("kw_primary") ? { type: "kw_primary" } : kw_primary)], "postprocess": x => (0, lexer_2.box)(x, 'primary') },
	        { "name": "word", "symbols": [(lexer_1.lexerAny.has("kw_unique") ? { type: "kw_unique" } : kw_unique)], "postprocess": x => (0, lexer_2.box)(x, 'unique') },
	        { "name": "word", "symbols": [(lexer_1.lexerAny.has("quoted_word") ? { type: "quoted_word" } : quoted_word)], "postprocess": x => (0, lexer_2.box)(x, x[0].value, true) },
	        { "name": "word", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": x => (0, lexer_2.box)(x, x[0].value) },
	        { "name": "collist_paren", "symbols": ["lparen", "collist", "rparen"], "postprocess": get(1) },
	        { "name": "collist$ebnf$1", "symbols": [] },
	        { "name": "collist$ebnf$1$subexpression$1", "symbols": ["comma", "ident"], "postprocess": last },
	        { "name": "collist$ebnf$1", "symbols": ["collist$ebnf$1", "collist$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "collist", "symbols": ["ident", "collist$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "kw_between", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('between') },
	        { "name": "kw_conflict", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('conflict') },
	        { "name": "kw_nothing", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('nothing') },
	        { "name": "kw_begin", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('begin') },
	        { "name": "kw_if", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('if') },
	        { "name": "kw_exists", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('exists') },
	        { "name": "kw_key", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('key') },
	        { "name": "kw_index", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('index') },
	        { "name": "kw_extension", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('extension') },
	        { "name": "kw_schema", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('schema') },
	        { "name": "kw_nulls", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('nulls') },
	        { "name": "kw_first", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('first') },
	        { "name": "kw_last", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('last') },
	        { "name": "kw_start", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('start') },
	        { "name": "kw_restart", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('restart') },
	        { "name": "kw_filter", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('filter') },
	        { "name": "kw_commit", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('commit') },
	        { "name": "kw_tablespace", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('tablespace') },
	        { "name": "kw_transaction", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('transaction') },
	        { "name": "kw_work", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('work') },
	        { "name": "kw_read", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('read') },
	        { "name": "kw_write", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('write') },
	        { "name": "kw_isolation", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('isolation') },
	        { "name": "kw_level", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('level') },
	        { "name": "kw_serializable", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('serializable') },
	        { "name": "kw_rollback", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('rollback') },
	        { "name": "kw_insert", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('insert') },
	        { "name": "kw_value", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('value') },
	        { "name": "kw_values", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('values') },
	        { "name": "kw_update", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('update') },
	        { "name": "kw_column", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('column') },
	        { "name": "kw_set", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('set') },
	        { "name": "kw_version", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('version') },
	        { "name": "kw_alter", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('alter') },
	        { "name": "kw_rename", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('rename') },
	        { "name": "kw_sequence", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('sequence') },
	        { "name": "kw_temp", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('temp') },
	        { "name": "kw_temporary", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('temporary') },
	        { "name": "kw_add", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('add') },
	        { "name": "kw_owner", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('owner') },
	        { "name": "kw_owned", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('owned') },
	        { "name": "kw_including", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('including') },
	        { "name": "kw_excluding", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('excluding') },
	        { "name": "kw_none", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('none') },
	        { "name": "kw_drop", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('drop') },
	        { "name": "kw_operator", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('operator') },
	        { "name": "kw_minvalue", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('minvalue') },
	        { "name": "kw_maxvalue", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('maxvalue') },
	        { "name": "kw_data", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('data') },
	        { "name": "kw_type", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('type') },
	        { "name": "kw_trigger", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('trigger') },
	        { "name": "kw_delete", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('delete') },
	        { "name": "kw_cache", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('cache') },
	        { "name": "kw_cascade", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('cascade') },
	        { "name": "kw_no", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('no') },
	        { "name": "kw_timestamp", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('timestamp') },
	        { "name": "kw_cycle", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('cycle') },
	        { "name": "kw_function", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('function') },
	        { "name": "kw_returns", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('returns') },
	        { "name": "kw_language", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('language') },
	        { "name": "kw_out", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('out') },
	        { "name": "kw_inout", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('inout') },
	        { "name": "kw_variadic", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('variadic') },
	        { "name": "kw_action", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('action') },
	        { "name": "kw_restrict", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('restrict') },
	        { "name": "kw_truncate", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('truncate') },
	        { "name": "kw_increment", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('increment') },
	        { "name": "kw_by", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('by') },
	        { "name": "kw_row", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('row') },
	        { "name": "kw_rows", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('rows') },
	        { "name": "kw_next", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('next') },
	        { "name": "kw_match", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('match') },
	        { "name": "kw_replace", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('replace') },
	        { "name": "kw_recursive", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('recursive') },
	        { "name": "kw_view", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('view') },
	        { "name": "kw_cascaded", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('cascaded') },
	        { "name": "kw_unlogged", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('unlogged') },
	        { "name": "kw_global", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('global') },
	        { "name": "kw_option", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('option') },
	        { "name": "kw_materialized", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('materialized') },
	        { "name": "kw_partial", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('partial') },
	        { "name": "kw_partition", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('partition') },
	        { "name": "kw_simple", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('simple') },
	        { "name": "kw_generated", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('generated') },
	        { "name": "kw_always", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('always') },
	        { "name": "kw_identity", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('identity') },
	        { "name": "kw_name", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('name') },
	        { "name": "kw_enum", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('enum') },
	        { "name": "kw_show", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('show') },
	        { "name": "kw_ordinality", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('ordinality') },
	        { "name": "kw_overriding", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('overriding') },
	        { "name": "kw_over", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('over') },
	        { "name": "kw_system", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('system') },
	        { "name": "kw_comment", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('comment') },
	        { "name": "kw_time", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('time') },
	        { "name": "kw_names", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('names') },
	        { "name": "kw_at", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('at') },
	        { "name": "kw_zone", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('zone') },
	        { "name": "kw_interval", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('interval') },
	        { "name": "kw_hour", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('hour') },
	        { "name": "kw_minute", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('minute') },
	        { "name": "kw_local", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('local') },
	        { "name": "kw_prepare", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('prepare') },
	        { "name": "kw_deallocate", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('deallocate') },
	        { "name": "kw_raise", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('raise') },
	        { "name": "kw_continue", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('continue') },
	        { "name": "kw_share", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('share') },
	        { "name": "kw_refresh", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('refresh') },
	        { "name": "kw_nowait", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('nowait') },
	        { "name": "kw_skip", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('skip') },
	        { "name": "kw_locked", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": notReservedKw('locked') },
	        { "name": "kw_ifnotexists", "symbols": ["kw_if", (lexer_1.lexerAny.has("kw_not") ? { type: "kw_not" } : kw_not), "kw_exists"] },
	        { "name": "kw_ifexists", "symbols": ["kw_if", "kw_exists"] },
	        { "name": "kw_withordinality", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with), "kw_ordinality"] },
	        { "name": "kw_not_null", "symbols": [(lexer_1.lexerAny.has("kw_not") ? { type: "kw_not" } : kw_not), (lexer_1.lexerAny.has("kw_null") ? { type: "kw_null" } : kw_null)] },
	        { "name": "kw_primary_key", "symbols": [(lexer_1.lexerAny.has("kw_primary") ? { type: "kw_primary" } : kw_primary), "kw_key"] },
	        { "name": "data_type$ebnf$1$subexpression$1$macrocall$2", "symbols": ["int"] },
	        { "name": "data_type$ebnf$1$subexpression$1$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "data_type$ebnf$1$subexpression$1$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "data_type$ebnf$1$subexpression$1$macrocall$2"], "postprocess": last },
	        { "name": "data_type$ebnf$1$subexpression$1$macrocall$1$ebnf$1", "symbols": ["data_type$ebnf$1$subexpression$1$macrocall$1$ebnf$1", "data_type$ebnf$1$subexpression$1$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "data_type$ebnf$1$subexpression$1$macrocall$1", "symbols": ["data_type$ebnf$1$subexpression$1$macrocall$2", "data_type$ebnf$1$subexpression$1$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "data_type$ebnf$1$subexpression$1", "symbols": ["lparen", "data_type$ebnf$1$subexpression$1$macrocall$1", "rparen"], "postprocess": get(1) },
	        { "name": "data_type$ebnf$1", "symbols": ["data_type$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "data_type$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "data_type$ebnf$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_array") ? { type: "kw_array" } : kw_array)] },
	        { "name": "data_type$ebnf$2$subexpression$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("lbracket") ? { type: "lbracket" } : lbracket), (lexer_1.lexerAny.has("rbracket") ? { type: "rbracket" } : rbracket)] },
	        { "name": "data_type$ebnf$2$subexpression$1$ebnf$1", "symbols": ["data_type$ebnf$2$subexpression$1$ebnf$1$subexpression$1"] },
	        { "name": "data_type$ebnf$2$subexpression$1$ebnf$1$subexpression$2", "symbols": [(lexer_1.lexerAny.has("lbracket") ? { type: "lbracket" } : lbracket), (lexer_1.lexerAny.has("rbracket") ? { type: "rbracket" } : rbracket)] },
	        { "name": "data_type$ebnf$2$subexpression$1$ebnf$1", "symbols": ["data_type$ebnf$2$subexpression$1$ebnf$1", "data_type$ebnf$2$subexpression$1$ebnf$1$subexpression$2"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "data_type$ebnf$2$subexpression$1", "symbols": ["data_type$ebnf$2$subexpression$1$ebnf$1"] },
	        { "name": "data_type$ebnf$2", "symbols": ["data_type$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "data_type$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "data_type", "symbols": ["data_type_simple", "data_type$ebnf$1", "data_type$ebnf$2"], "postprocess": x => {
	                let asArray = x[2];
	                const name = unwrap(x[0]);
	                let ret;
	                ret = {
	                    ...name,
	                    ...Array.isArray(x[1]) && x[1].length ? { config: x[1].map(unwrap) } : {},
	                };
	                if (asArray) {
	                    if (asArray[0].type === 'kw_array') {
	                        asArray = [['array']];
	                    }
	                    for (const _ of asArray[0]) {
	                        ret = {
	                            kind: 'array',
	                            arrayOf: ret,
	                        };
	                    }
	                }
	                return (0, lexer_2.track)(x, ret);
	            } },
	        { "name": "data_type_list$ebnf$1", "symbols": [] },
	        { "name": "data_type_list$ebnf$1$subexpression$1", "symbols": ["comma", "data_type"], "postprocess": last },
	        { "name": "data_type_list$ebnf$1", "symbols": ["data_type_list$ebnf$1", "data_type_list$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "data_type_list", "symbols": ["data_type", "data_type_list$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "data_type_simple", "symbols": ["data_type_text"], "postprocess": x => (0, lexer_2.track)(x, { name: toStr(x, ' ') }) },
	        { "name": "data_type_simple", "symbols": ["data_type_numeric"], "postprocess": x => (0, lexer_2.track)(x, { name: toStr(x, ' ') }) },
	        { "name": "data_type_simple", "symbols": ["data_type_date"] },
	        { "name": "data_type_simple", "symbols": ["qualified_name_mark_quotes"] },
	        { "name": "data_type_numeric$subexpression$1", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": kw('double') },
	        { "name": "data_type_numeric", "symbols": ["data_type_numeric$subexpression$1", (lexer_1.lexerAny.has("kw_precision") ? { type: "kw_precision" } : kw_precision)] },
	        { "name": "data_type_text$subexpression$1", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": anyKw('character', 'bit') },
	        { "name": "data_type_text$subexpression$2", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": kw('varying') },
	        { "name": "data_type_text", "symbols": ["data_type_text$subexpression$1", "data_type_text$subexpression$2"] },
	        { "name": "data_type_date$subexpression$1", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": anyKw('timestamp', 'time') },
	        { "name": "data_type_date$subexpression$2", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with)] },
	        { "name": "data_type_date$subexpression$2", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": kw('without') },
	        { "name": "data_type_date$subexpression$3", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": kw('time') },
	        { "name": "data_type_date$subexpression$4", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": kw('zone') },
	        { "name": "data_type_date", "symbols": ["data_type_date$subexpression$1", "data_type_date$subexpression$2", "data_type_date$subexpression$3", "data_type_date$subexpression$4"], "postprocess": x => (0, lexer_2.track)(x, { name: toStr(x, ' ') }) },
	        { "name": "data_type_date$subexpression$5", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": anyKw('timestamp', 'time') },
	        { "name": "data_type_date$subexpression$6", "symbols": ["lparen", "int", "rparen"], "postprocess": get(1) },
	        { "name": "data_type_date$subexpression$7", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with)] },
	        { "name": "data_type_date$subexpression$7", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": kw('without') },
	        { "name": "data_type_date$subexpression$8", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": kw('time') },
	        { "name": "data_type_date$subexpression$9", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": kw('zone') },
	        { "name": "data_type_date", "symbols": ["data_type_date$subexpression$5", "data_type_date$subexpression$6", "data_type_date$subexpression$7", "data_type_date$subexpression$8", "data_type_date$subexpression$9"], "postprocess": x => (0, lexer_2.track)(x, { name: `timestamp ${toStr(x[2])} time zone`, config: [(0, lexer_2.unbox)(x[1])] }) },
	        { "name": "ident_aliased$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as), "ident"], "postprocess": last },
	        { "name": "ident_aliased", "symbols": ["ident_aliased$subexpression$1"] },
	        { "name": "ident_aliased", "symbols": ["ident"], "postprocess": unwrap },
	        { "name": "table_ref", "symbols": ["qualified_name"], "postprocess": unwrap },
	        { "name": "qcolumn$ebnf$1$subexpression$1", "symbols": ["dot", "ident"], "postprocess": last },
	        { "name": "qcolumn$ebnf$1", "symbols": ["qcolumn$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "qcolumn$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "qcolumn", "symbols": ["ident", "dot", "ident", "qcolumn$ebnf$1"], "postprocess": x => {
	                if (!x[3]) {
	                    return (0, lexer_2.track)(x, {
	                        table: (0, lexer_2.unbox)(x[0]),
	                        column: (0, lexer_2.unbox)(x[2]),
	                    });
	                }
	                return (0, lexer_2.track)(x, {
	                    schema: (0, lexer_2.unbox)(x[0]),
	                    table: (0, lexer_2.unbox)(x[2]),
	                    column: (0, lexer_2.unbox)(x[3]),
	                });
	            } },
	        { "name": "table_ref_aliased$ebnf$1", "symbols": ["ident_aliased"], "postprocess": id },
	        { "name": "table_ref_aliased$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "table_ref_aliased", "symbols": ["table_ref", "table_ref_aliased$ebnf$1"], "postprocess": x => {
	                const alias = unwrap(x[1]);
	                return (0, lexer_2.track)(x, {
	                    ...unwrap(x[0]),
	                    ...alias ? { alias } : {},
	                });
	            } },
	        { "name": "qualified_name", "symbols": ["qname_ident"], "postprocess": x => (0, lexer_2.track)(x, { name: toStr(x) }) },
	        { "name": "qualified_name", "symbols": ["ident", "dot", "ident_extended"], "postprocess": x => {
	                const schema = toStr(x[0]);
	                const name = toStr(x[2]);
	                return (0, lexer_2.track)(x, { schema, name });
	            } },
	        { "name": "qualified_name", "symbols": [(lexer_1.lexerAny.has("kw_current_schema") ? { type: "kw_current_schema" } : kw_current_schema)], "postprocess": x => (0, lexer_2.track)(x, { name: 'current_schema' }) },
	        { "name": "qualified_name_mark_quotes", "symbols": ["qname_ident"], "postprocess": x => (0, lexer_2.track)(x, { name: toStr(x), ...(0, lexer_2.doubleQuoted)(x) }) },
	        { "name": "qualified_name_mark_quotes", "symbols": ["ident", "dot", "ident_extended"], "postprocess": x => {
	                const schema = toStr(x[0]);
	                const name = toStr(x[2]);
	                return (0, lexer_2.track)(x, { schema, name, ...(0, lexer_2.doubleQuoted)(x[2]) });
	            } },
	        { "name": "qualified_name_mark_quotes", "symbols": [(lexer_1.lexerAny.has("kw_current_schema") ? { type: "kw_current_schema" } : kw_current_schema)], "postprocess": x => (0, lexer_2.track)(x, { name: 'current_schema' }) },
	        { "name": "qname_ident", "symbols": ["ident"] },
	        { "name": "qname_ident", "symbols": [(lexer_1.lexerAny.has("kw_precision") ? { type: "kw_precision" } : kw_precision)] },
	        { "name": "qname", "symbols": ["qualified_name"], "postprocess": unwrap },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_all") ? { type: "kw_all" } : kw_all)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_analyse") ? { type: "kw_analyse" } : kw_analyse)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_analyze") ? { type: "kw_analyze" } : kw_analyze)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_and") ? { type: "kw_and" } : kw_and)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_any") ? { type: "kw_any" } : kw_any)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_array") ? { type: "kw_array" } : kw_array)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_asc") ? { type: "kw_asc" } : kw_asc)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_asymmetric") ? { type: "kw_asymmetric" } : kw_asymmetric)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_authorization") ? { type: "kw_authorization" } : kw_authorization)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_binary") ? { type: "kw_binary" } : kw_binary)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_both") ? { type: "kw_both" } : kw_both)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_case") ? { type: "kw_case" } : kw_case)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_cast") ? { type: "kw_cast" } : kw_cast)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_check") ? { type: "kw_check" } : kw_check)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_collate") ? { type: "kw_collate" } : kw_collate)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_collation") ? { type: "kw_collation" } : kw_collation)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_concurrently") ? { type: "kw_concurrently" } : kw_concurrently)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_constraint") ? { type: "kw_constraint" } : kw_constraint)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_create") ? { type: "kw_create" } : kw_create)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_cross") ? { type: "kw_cross" } : kw_cross)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_catalog") ? { type: "kw_current_catalog" } : kw_current_catalog)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_date") ? { type: "kw_current_date" } : kw_current_date)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_role") ? { type: "kw_current_role" } : kw_current_role)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_schema") ? { type: "kw_current_schema" } : kw_current_schema)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_time") ? { type: "kw_current_time" } : kw_current_time)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_timestamp") ? { type: "kw_current_timestamp" } : kw_current_timestamp)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_user") ? { type: "kw_current_user" } : kw_current_user)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_default") ? { type: "kw_default" } : kw_default)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_deferrable") ? { type: "kw_deferrable" } : kw_deferrable)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_desc") ? { type: "kw_desc" } : kw_desc)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_distinct") ? { type: "kw_distinct" } : kw_distinct)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_do") ? { type: "kw_do" } : kw_do)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_else") ? { type: "kw_else" } : kw_else)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_end") ? { type: "kw_end" } : kw_end)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_except") ? { type: "kw_except" } : kw_except)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_false") ? { type: "kw_false" } : kw_false)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_fetch") ? { type: "kw_fetch" } : kw_fetch)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_for") ? { type: "kw_for" } : kw_for)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_foreign") ? { type: "kw_foreign" } : kw_foreign)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_freeze") ? { type: "kw_freeze" } : kw_freeze)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_from") ? { type: "kw_from" } : kw_from)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_full") ? { type: "kw_full" } : kw_full)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_grant") ? { type: "kw_grant" } : kw_grant)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_group") ? { type: "kw_group" } : kw_group)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_having") ? { type: "kw_having" } : kw_having)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_ilike") ? { type: "kw_ilike" } : kw_ilike)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_in") ? { type: "kw_in" } : kw_in)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_initially") ? { type: "kw_initially" } : kw_initially)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_inner") ? { type: "kw_inner" } : kw_inner)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_intersect") ? { type: "kw_intersect" } : kw_intersect)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_into") ? { type: "kw_into" } : kw_into)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_is") ? { type: "kw_is" } : kw_is)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_isnull") ? { type: "kw_isnull" } : kw_isnull)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_join") ? { type: "kw_join" } : kw_join)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_lateral") ? { type: "kw_lateral" } : kw_lateral)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_leading") ? { type: "kw_leading" } : kw_leading)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_left") ? { type: "kw_left" } : kw_left)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_like") ? { type: "kw_like" } : kw_like)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_limit") ? { type: "kw_limit" } : kw_limit)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_localtime") ? { type: "kw_localtime" } : kw_localtime)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_localtimestamp") ? { type: "kw_localtimestamp" } : kw_localtimestamp)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_natural") ? { type: "kw_natural" } : kw_natural)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_not") ? { type: "kw_not" } : kw_not)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_notnull") ? { type: "kw_notnull" } : kw_notnull)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_null") ? { type: "kw_null" } : kw_null)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_offset") ? { type: "kw_offset" } : kw_offset)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_on") ? { type: "kw_on" } : kw_on)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_only") ? { type: "kw_only" } : kw_only)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_or") ? { type: "kw_or" } : kw_or)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_order") ? { type: "kw_order" } : kw_order)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_outer") ? { type: "kw_outer" } : kw_outer)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_overlaps") ? { type: "kw_overlaps" } : kw_overlaps)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_placing") ? { type: "kw_placing" } : kw_placing)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_primary") ? { type: "kw_primary" } : kw_primary)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_references") ? { type: "kw_references" } : kw_references)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_returning") ? { type: "kw_returning" } : kw_returning)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_right") ? { type: "kw_right" } : kw_right)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_select") ? { type: "kw_select" } : kw_select)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_session_user") ? { type: "kw_session_user" } : kw_session_user)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_similar") ? { type: "kw_similar" } : kw_similar)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_some") ? { type: "kw_some" } : kw_some)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_symmetric") ? { type: "kw_symmetric" } : kw_symmetric)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_table") ? { type: "kw_table" } : kw_table)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_tablesample") ? { type: "kw_tablesample" } : kw_tablesample)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_then") ? { type: "kw_then" } : kw_then)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_to") ? { type: "kw_to" } : kw_to)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_trailing") ? { type: "kw_trailing" } : kw_trailing)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_true") ? { type: "kw_true" } : kw_true)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_union") ? { type: "kw_union" } : kw_union)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_unique") ? { type: "kw_unique" } : kw_unique)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_user") ? { type: "kw_user" } : kw_user)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_using") ? { type: "kw_using" } : kw_using)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_variadic") ? { type: "kw_variadic" } : kw_variadic)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_verbose") ? { type: "kw_verbose" } : kw_verbose)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_when") ? { type: "kw_when" } : kw_when)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_where") ? { type: "kw_where" } : kw_where)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_window") ? { type: "kw_window" } : kw_window)] },
	        { "name": "any_keyword", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with)] },
	        { "name": "ident_extended", "symbols": ["ident"] },
	        { "name": "ident_extended", "symbols": ["any_keyword"] },
	        { "name": "select_statement$ebnf$1", "symbols": ["select_from"], "postprocess": id },
	        { "name": "select_statement$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_statement$ebnf$2", "symbols": ["select_where"], "postprocess": id },
	        { "name": "select_statement$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "select_statement$ebnf$3$subexpression$1$ebnf$1", "symbols": ["select_having"], "postprocess": id },
	        { "name": "select_statement$ebnf$3$subexpression$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_statement$ebnf$3$subexpression$1", "symbols": ["select_groupby", "select_statement$ebnf$3$subexpression$1$ebnf$1"] },
	        { "name": "select_statement$ebnf$3", "symbols": ["select_statement$ebnf$3$subexpression$1"], "postprocess": id },
	        { "name": "select_statement$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "select_statement$ebnf$4", "symbols": ["select_order_by"], "postprocess": id },
	        { "name": "select_statement$ebnf$4", "symbols": [], "postprocess": () => null },
	        { "name": "select_statement$ebnf$5", "symbols": ["select_limit_offset"], "postprocess": id },
	        { "name": "select_statement$ebnf$5", "symbols": [], "postprocess": () => null },
	        { "name": "select_statement$ebnf$6$subexpression$1$ebnf$1", "symbols": ["select_skip"], "postprocess": id },
	        { "name": "select_statement$ebnf$6$subexpression$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_statement$ebnf$6$subexpression$1", "symbols": ["select_for", "select_statement$ebnf$6$subexpression$1$ebnf$1"] },
	        { "name": "select_statement$ebnf$6", "symbols": ["select_statement$ebnf$6$subexpression$1"], "postprocess": id },
	        { "name": "select_statement$ebnf$6", "symbols": [], "postprocess": () => null },
	        { "name": "select_statement", "symbols": ["select_what", "select_statement$ebnf$1", "select_statement$ebnf$2", "select_statement$ebnf$3", "select_statement$ebnf$4", "select_statement$ebnf$5", "select_statement$ebnf$6"], "postprocess": x => {
	                let [what, from, where, _groupBy, orderBy, limit, _selectFor] = x;
	                from = unwrap(from);
	                let groupBy = _groupBy && _groupBy[0];
	                let having = _groupBy && _groupBy[1];
	                groupBy = groupBy && (groupBy.length === 1 && groupBy[0].type === 'list' ? groupBy[0].expressions : groupBy);
	                having = having && unwrap(having);
	                let selectFor = _selectFor && _selectFor[0];
	                let skip = _selectFor && _selectFor[1];
	                skip = unwrap(skip);
	                return (0, lexer_2.track)(x, {
	                    ...what,
	                    ...from ? { from: Array.isArray(from) ? from : [from] } : {},
	                    ...groupBy ? { groupBy } : {},
	                    ...having ? { having } : {},
	                    ...limit ? { limit: unwrap(limit) } : {},
	                    ...orderBy ? { orderBy } : {},
	                    ...where ? { where } : {},
	                    ...selectFor ? { for: selectFor[1] } : {},
	                    ...skip ? { skip } : {},
	                    type: 'select',
	                });
	            } },
	        { "name": "select_from", "symbols": [(lexer_1.lexerAny.has("kw_from") ? { type: "kw_from" } : kw_from), "select_from_items"], "postprocess": last },
	        { "name": "select_from_items$ebnf$1", "symbols": [] },
	        { "name": "select_from_items$ebnf$1$subexpression$1", "symbols": ["comma", "select_from_item"], "postprocess": last },
	        { "name": "select_from_items$ebnf$1", "symbols": ["select_from_items$ebnf$1", "select_from_items$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "select_from_items", "symbols": ["select_from_item", "select_from_items$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [...head, ...(flatten(tail) || [])];
	            } },
	        { "name": "select_from_item", "symbols": ["select_from_subject"] },
	        { "name": "select_from_item", "symbols": ["select_from_item_joins"], "postprocess": get(0) },
	        { "name": "select_from_item_joins$subexpression$1", "symbols": ["select_from_item"], "postprocess": get(0) },
	        { "name": "select_from_item_joins", "symbols": ["select_from_item_joins$subexpression$1", "select_table_join"], "postprocess": flatten },
	        { "name": "select_from_item_joins", "symbols": ["lparen", "select_from_item_joins", "rparen"], "postprocess": get(1) },
	        { "name": "select_from_subject", "symbols": ["stb_table"], "postprocess": unwrap },
	        { "name": "select_from_subject", "symbols": ["stb_statement"], "postprocess": unwrap },
	        { "name": "select_from_subject", "symbols": ["stb_call"], "postprocess": unwrap },
	        { "name": "stb_opts$ebnf$1", "symbols": ["collist_paren"], "postprocess": id },
	        { "name": "stb_opts$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "stb_opts", "symbols": ["ident_aliased", "stb_opts$ebnf$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                alias: toStr(x[0]),
	                ...x[1] && { columnNames: (0, lexer_2.unbox)(x[1]).map(asName) },
	            }) },
	        { "name": "stb_table$ebnf$1", "symbols": ["stb_opts"], "postprocess": id },
	        { "name": "stb_table$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "stb_table", "symbols": ["table_ref", "stb_table$ebnf$1"], "postprocess": x => {
	                return (0, lexer_2.track)(x, {
	                    type: 'table',
	                    name: (0, lexer_2.track)(x, {
	                        ...x[0],
	                        ...x[1],
	                    }),
	                });
	            } },
	        { "name": "stb_statement", "symbols": ["selection_paren", "stb_opts"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'statement',
	                statement: unwrap(x[0]),
	                ...x[1],
	            }) },
	        { "name": "select_values", "symbols": ["kw_values", "insert_values"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'values',
	                values: x[1],
	            }) },
	        { "name": "stb_call$ebnf$1", "symbols": ["kw_withordinality"], "postprocess": id },
	        { "name": "stb_call$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "stb_call$ebnf$2", "symbols": ["stb_call_alias"], "postprocess": id },
	        { "name": "stb_call$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "stb_call", "symbols": ["expr_function_call", "stb_call$ebnf$1", "stb_call$ebnf$2"], "postprocess": x => {
	                const withOrdinality = x[1];
	                const alias = x[2];
	                if (!withOrdinality && !alias) {
	                    return x[0];
	                }
	                return (0, lexer_2.track)(x, {
	                    ...x[0],
	                    ...withOrdinality && { withOrdinality: true },
	                    alias: alias ? asNameWithColumns(alias[0], alias[1]) : undefined,
	                });
	            } },
	        { "name": "stb_call_alias$subexpression$1$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as)], "postprocess": id },
	        { "name": "stb_call_alias$subexpression$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "stb_call_alias$subexpression$1", "symbols": ["stb_call_alias$subexpression$1$ebnf$1", "ident"], "postprocess": last },
	        { "name": "stb_call_alias$ebnf$1", "symbols": ["stb_call_alias_list"], "postprocess": id },
	        { "name": "stb_call_alias$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "stb_call_alias", "symbols": ["stb_call_alias$subexpression$1", "stb_call_alias$ebnf$1"] },
	        { "name": "stb_call_alias_list", "symbols": ["lparen", "stb_call_alias_list_raw", "rparen"], "postprocess": get(1) },
	        { "name": "stb_call_alias_list_raw$ebnf$1", "symbols": [] },
	        { "name": "stb_call_alias_list_raw$ebnf$1$subexpression$1", "symbols": ["comma", "ident"], "postprocess": last },
	        { "name": "stb_call_alias_list_raw$ebnf$1", "symbols": ["stb_call_alias_list_raw$ebnf$1", "stb_call_alias_list_raw$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "stb_call_alias_list_raw", "symbols": ["ident", "stb_call_alias_list_raw$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "select_table_join$ebnf$1", "symbols": ["select_table_join_clause"], "postprocess": id },
	        { "name": "select_table_join$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_table_join", "symbols": ["select_join_op", (lexer_1.lexerAny.has("kw_join") ? { type: "kw_join" } : kw_join), "select_from_subject", "select_table_join$ebnf$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                ...unwrap(x[2]),
	                join: {
	                    type: toStr(x[0], ' '),
	                    ...x[3] && unwrap(x[3]),
	                }
	            }) },
	        { "name": "select_table_join_clause", "symbols": [(lexer_1.lexerAny.has("kw_on") ? { type: "kw_on" } : kw_on), "expr"], "postprocess": x => (0, lexer_2.track)(x, { on: last(x) }) },
	        { "name": "select_table_join_clause$macrocall$2", "symbols": ["ident"] },
	        { "name": "select_table_join_clause$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "select_table_join_clause$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "select_table_join_clause$macrocall$2"], "postprocess": last },
	        { "name": "select_table_join_clause$macrocall$1$ebnf$1", "symbols": ["select_table_join_clause$macrocall$1$ebnf$1", "select_table_join_clause$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "select_table_join_clause$macrocall$1", "symbols": ["select_table_join_clause$macrocall$2", "select_table_join_clause$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "select_table_join_clause", "symbols": [(lexer_1.lexerAny.has("kw_using") ? { type: "kw_using" } : kw_using), "lparen", "select_table_join_clause$macrocall$1", "rparen"], "postprocess": x => (0, lexer_2.track)(x, { using: x[2].map(asName) }) },
	        { "name": "select_join_op$subexpression$1$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_inner") ? { type: "kw_inner" } : kw_inner)], "postprocess": id },
	        { "name": "select_join_op$subexpression$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_join_op$subexpression$1", "symbols": ["select_join_op$subexpression$1$ebnf$1"], "postprocess": x => (0, lexer_2.box)(x, 'INNER JOIN') },
	        { "name": "select_join_op", "symbols": ["select_join_op$subexpression$1"] },
	        { "name": "select_join_op$subexpression$2", "symbols": [(lexer_1.lexerAny.has("kw_cross") ? { type: "kw_cross" } : kw_cross)], "postprocess": x => (0, lexer_2.box)(x, 'CROSS JOIN') },
	        { "name": "select_join_op", "symbols": ["select_join_op$subexpression$2"] },
	        { "name": "select_join_op$subexpression$3$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_outer") ? { type: "kw_outer" } : kw_outer)], "postprocess": id },
	        { "name": "select_join_op$subexpression$3$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_join_op$subexpression$3", "symbols": [(lexer_1.lexerAny.has("kw_left") ? { type: "kw_left" } : kw_left), "select_join_op$subexpression$3$ebnf$1"], "postprocess": x => (0, lexer_2.box)(x, 'LEFT JOIN') },
	        { "name": "select_join_op", "symbols": ["select_join_op$subexpression$3"] },
	        { "name": "select_join_op$subexpression$4$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_outer") ? { type: "kw_outer" } : kw_outer)], "postprocess": id },
	        { "name": "select_join_op$subexpression$4$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_join_op$subexpression$4", "symbols": [(lexer_1.lexerAny.has("kw_right") ? { type: "kw_right" } : kw_right), "select_join_op$subexpression$4$ebnf$1"], "postprocess": x => (0, lexer_2.box)(x, 'RIGHT JOIN') },
	        { "name": "select_join_op", "symbols": ["select_join_op$subexpression$4"] },
	        { "name": "select_join_op$subexpression$5$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_outer") ? { type: "kw_outer" } : kw_outer)], "postprocess": id },
	        { "name": "select_join_op$subexpression$5$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_join_op$subexpression$5", "symbols": [(lexer_1.lexerAny.has("kw_full") ? { type: "kw_full" } : kw_full), "select_join_op$subexpression$5$ebnf$1"], "postprocess": x => (0, lexer_2.box)(x, 'FULL JOIN') },
	        { "name": "select_join_op", "symbols": ["select_join_op$subexpression$5"] },
	        { "name": "select_what$ebnf$1", "symbols": ["select_distinct"], "postprocess": id },
	        { "name": "select_what$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_what$ebnf$2", "symbols": ["select_expr_list_aliased"], "postprocess": id },
	        { "name": "select_what$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "select_what", "symbols": [(lexer_1.lexerAny.has("kw_select") ? { type: "kw_select" } : kw_select), "select_what$ebnf$1", "select_what$ebnf$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                columns: x[2],
	                ...x[1] && { distinct: (0, lexer_2.unbox)(x[1]) },
	            }) },
	        { "name": "select_expr_list_aliased$ebnf$1", "symbols": [] },
	        { "name": "select_expr_list_aliased$ebnf$1$subexpression$1", "symbols": ["comma", "select_expr_list_item"], "postprocess": last },
	        { "name": "select_expr_list_aliased$ebnf$1", "symbols": ["select_expr_list_aliased$ebnf$1", "select_expr_list_aliased$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "select_expr_list_aliased", "symbols": ["select_expr_list_item", "select_expr_list_aliased$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "select_expr_list_item$ebnf$1", "symbols": ["ident_aliased"], "postprocess": id },
	        { "name": "select_expr_list_item$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_expr_list_item", "symbols": ["expr", "select_expr_list_item$ebnf$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                expr: x[0],
	                ...x[1] ? { alias: asName(x[1]) } : {},
	            }) },
	        { "name": "select_distinct", "symbols": [(lexer_1.lexerAny.has("kw_all") ? { type: "kw_all" } : kw_all)], "postprocess": x => (0, lexer_2.box)(x, 'all') },
	        { "name": "select_distinct$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_on") ? { type: "kw_on" } : kw_on), "lparen", "expr_list_raw", "rparen"], "postprocess": get(2) },
	        { "name": "select_distinct$ebnf$1", "symbols": ["select_distinct$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "select_distinct$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_distinct", "symbols": [(lexer_1.lexerAny.has("kw_distinct") ? { type: "kw_distinct" } : kw_distinct), "select_distinct$ebnf$1"], "postprocess": x => (0, lexer_2.box)(x, x[1] || 'distinct') },
	        { "name": "select_where", "symbols": [(lexer_1.lexerAny.has("kw_where") ? { type: "kw_where" } : kw_where), "expr"], "postprocess": last },
	        { "name": "select_groupby", "symbols": [(lexer_1.lexerAny.has("kw_group") ? { type: "kw_group" } : kw_group), "kw_by", "expr_list_raw"], "postprocess": last },
	        { "name": "select_having", "symbols": [(lexer_1.lexerAny.has("kw_having") ? { type: "kw_having" } : kw_having), "expr"], "postprocess": last },
	        { "name": "select_limit_offset$ebnf$1$subexpression$1", "symbols": ["select_offset"] },
	        { "name": "select_limit_offset$ebnf$1$subexpression$1", "symbols": ["select_limit"] },
	        { "name": "select_limit_offset$ebnf$1", "symbols": ["select_limit_offset$ebnf$1$subexpression$1"] },
	        { "name": "select_limit_offset$ebnf$1$subexpression$2", "symbols": ["select_offset"] },
	        { "name": "select_limit_offset$ebnf$1$subexpression$2", "symbols": ["select_limit"] },
	        { "name": "select_limit_offset$ebnf$1", "symbols": ["select_limit_offset$ebnf$1", "select_limit_offset$ebnf$1$subexpression$2"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "select_limit_offset", "symbols": ["select_limit_offset$ebnf$1"], "postprocess": (x, rej) => {
	                const value = unwrap(x);
	                if (!Array.isArray(value)) {
	                    return (0, lexer_2.track)(x, value);
	                }
	                if (value.length != 2) {
	                    return rej;
	                }
	                const a = unwrap(value[0]);
	                const b = unwrap(value[1]);
	                if (a.offset && b.offset || a.limit && b.limit) {
	                    return rej;
	                }
	                return (0, lexer_2.track)(x, {
	                    ...a,
	                    ...b,
	                });
	            } },
	        { "name": "select_offset$ebnf$1$subexpression$1", "symbols": ["kw_row"] },
	        { "name": "select_offset$ebnf$1$subexpression$1", "symbols": ["kw_rows"] },
	        { "name": "select_offset$ebnf$1", "symbols": ["select_offset$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "select_offset$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_offset", "symbols": [(lexer_1.lexerAny.has("kw_offset") ? { type: "kw_offset" } : kw_offset), "expr_nostar", "select_offset$ebnf$1"], "postprocess": x => (0, lexer_2.track)(x, { offset: unwrap(x[1]) }) },
	        { "name": "select_limit$subexpression$1", "symbols": ["select_limit_1"] },
	        { "name": "select_limit$subexpression$1", "symbols": ["select_limit_2"] },
	        { "name": "select_limit", "symbols": ["select_limit$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, { limit: unwrap(x) }) },
	        { "name": "select_limit_1", "symbols": [(lexer_1.lexerAny.has("kw_limit") ? { type: "kw_limit" } : kw_limit), "expr_nostar"], "postprocess": last },
	        { "name": "select_limit_2$ebnf$1$subexpression$1", "symbols": ["kw_first"] },
	        { "name": "select_limit_2$ebnf$1$subexpression$1", "symbols": ["kw_next"] },
	        { "name": "select_limit_2$ebnf$1", "symbols": ["select_limit_2$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "select_limit_2$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_limit_2$subexpression$1", "symbols": ["kw_row"] },
	        { "name": "select_limit_2$subexpression$1", "symbols": ["kw_rows"] },
	        { "name": "select_limit_2", "symbols": [(lexer_1.lexerAny.has("kw_fetch") ? { type: "kw_fetch" } : kw_fetch), "select_limit_2$ebnf$1", "expr_nostar", "select_limit_2$subexpression$1", (lexer_1.lexerAny.has("kw_only") ? { type: "kw_only" } : kw_only)], "postprocess": get(2) },
	        { "name": "select_for$subexpression$1", "symbols": ["kw_update"], "postprocess": x => (0, lexer_2.track)(x, { type: 'update' }) },
	        { "name": "select_for$subexpression$1", "symbols": ["kw_no", "kw_key", "kw_update"], "postprocess": x => (0, lexer_2.track)(x, { type: 'no key update' }) },
	        { "name": "select_for$subexpression$1", "symbols": ["kw_share"], "postprocess": x => (0, lexer_2.track)(x, { type: 'share' }) },
	        { "name": "select_for$subexpression$1", "symbols": ["kw_key", "kw_share"], "postprocess": x => (0, lexer_2.track)(x, { type: 'key share' }) },
	        { "name": "select_for", "symbols": [(lexer_1.lexerAny.has("kw_for") ? { type: "kw_for" } : kw_for), "select_for$subexpression$1"] },
	        { "name": "select_skip$subexpression$1", "symbols": ["kw_nowait"], "postprocess": x => (0, lexer_2.track)(x, { type: 'nowait' }) },
	        { "name": "select_skip$subexpression$1", "symbols": ["kw_skip", "kw_locked"], "postprocess": x => (0, lexer_2.track)(x, { type: 'skip locked' }) },
	        { "name": "select_skip", "symbols": ["select_skip$subexpression$1"] },
	        { "name": "select_order_by$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_order") ? { type: "kw_order" } : kw_order), "kw_by"] },
	        { "name": "select_order_by$ebnf$1", "symbols": [] },
	        { "name": "select_order_by$ebnf$1$subexpression$1", "symbols": ["comma", "select_order_by_expr"], "postprocess": last },
	        { "name": "select_order_by$ebnf$1", "symbols": ["select_order_by$ebnf$1", "select_order_by$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "select_order_by", "symbols": ["select_order_by$subexpression$1", "select_order_by_expr", "select_order_by$ebnf$1"], "postprocess": ([_, head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "select_order_by_expr$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_asc") ? { type: "kw_asc" } : kw_asc)] },
	        { "name": "select_order_by_expr$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_desc") ? { type: "kw_desc" } : kw_desc)] },
	        { "name": "select_order_by_expr$ebnf$1", "symbols": ["select_order_by_expr$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "select_order_by_expr$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "select_order_by_expr$ebnf$2$subexpression$1$subexpression$1", "symbols": ["kw_first"] },
	        { "name": "select_order_by_expr$ebnf$2$subexpression$1$subexpression$1", "symbols": ["kw_last"] },
	        { "name": "select_order_by_expr$ebnf$2$subexpression$1", "symbols": ["kw_nulls", "select_order_by_expr$ebnf$2$subexpression$1$subexpression$1"], "postprocess": last },
	        { "name": "select_order_by_expr$ebnf$2", "symbols": ["select_order_by_expr$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "select_order_by_expr$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "select_order_by_expr", "symbols": ["expr", "select_order_by_expr$ebnf$1", "select_order_by_expr$ebnf$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                by: x[0],
	                ...x[1] && { order: toStr(x[1]).toUpperCase() },
	                ...x[2] && { nulls: toStr(x[2]).toUpperCase() },
	            }) },
	        { "name": "expr", "symbols": ["expr_nostar"], "postprocess": unwrap },
	        { "name": "expr", "symbols": ["expr_star"], "postprocess": unwrap },
	        { "name": "expr_nostar", "symbols": ["expr_paren"], "postprocess": unwrap },
	        { "name": "expr_nostar", "symbols": ["expr_or"], "postprocess": unwrap },
	        { "name": "expr_paren$subexpression$1", "symbols": ["expr_or_select"] },
	        { "name": "expr_paren$subexpression$1", "symbols": ["expr_list_many"] },
	        { "name": "expr_paren", "symbols": ["lparen", "expr_paren$subexpression$1", "rparen"], "postprocess": get(1) },
	        { "name": "expr_or$macrocall$2$macrocall$2", "symbols": [(lexer_1.lexerAny.has("kw_or") ? { type: "kw_or" } : kw_or)] },
	        { "name": "expr_or$macrocall$2$macrocall$1", "symbols": ["expr_or$macrocall$2$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_or$macrocall$2", "symbols": ["expr_or$macrocall$2$macrocall$1"] },
	        { "name": "expr_or$macrocall$3", "symbols": ["expr_or"] },
	        { "name": "expr_or$macrocall$4", "symbols": ["expr_and"] },
	        { "name": "expr_or$macrocall$1$subexpression$1", "symbols": ["expr_or$macrocall$3"] },
	        { "name": "expr_or$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_or$macrocall$1$subexpression$2", "symbols": ["expr_or$macrocall$4"] },
	        { "name": "expr_or$macrocall$1$subexpression$2", "symbols": ["expr_paren"] },
	        { "name": "expr_or$macrocall$1", "symbols": ["expr_or$macrocall$1$subexpression$1", "expr_or$macrocall$2", "expr_or$macrocall$1$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'binary',
	                left: unwrap(x[0]),
	                right: unwrap(x[2]),
	                ...unwrap(x[1]),
	            }) },
	        { "name": "expr_or$macrocall$1", "symbols": ["expr_or$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_or", "symbols": ["expr_or$macrocall$1"] },
	        { "name": "expr_and$macrocall$2$macrocall$2", "symbols": [(lexer_1.lexerAny.has("kw_and") ? { type: "kw_and" } : kw_and)] },
	        { "name": "expr_and$macrocall$2$macrocall$1", "symbols": ["expr_and$macrocall$2$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_and$macrocall$2", "symbols": ["expr_and$macrocall$2$macrocall$1"] },
	        { "name": "expr_and$macrocall$3", "symbols": ["expr_and"] },
	        { "name": "expr_and$macrocall$4", "symbols": ["expr_not"] },
	        { "name": "expr_and$macrocall$1$subexpression$1", "symbols": ["expr_and$macrocall$3"] },
	        { "name": "expr_and$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_and$macrocall$1$subexpression$2", "symbols": ["expr_and$macrocall$4"] },
	        { "name": "expr_and$macrocall$1$subexpression$2", "symbols": ["expr_paren"] },
	        { "name": "expr_and$macrocall$1", "symbols": ["expr_and$macrocall$1$subexpression$1", "expr_and$macrocall$2", "expr_and$macrocall$1$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'binary',
	                left: unwrap(x[0]),
	                right: unwrap(x[2]),
	                ...unwrap(x[1]),
	            }) },
	        { "name": "expr_and$macrocall$1", "symbols": ["expr_and$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_and", "symbols": ["expr_and$macrocall$1"] },
	        { "name": "expr_not$macrocall$2$macrocall$2", "symbols": [(lexer_1.lexerAny.has("kw_not") ? { type: "kw_not" } : kw_not)] },
	        { "name": "expr_not$macrocall$2$macrocall$1", "symbols": ["expr_not$macrocall$2$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_not$macrocall$2", "symbols": ["expr_not$macrocall$2$macrocall$1"] },
	        { "name": "expr_not$macrocall$3", "symbols": ["expr_not"] },
	        { "name": "expr_not$macrocall$4", "symbols": ["expr_eq"] },
	        { "name": "expr_not$macrocall$1$subexpression$1", "symbols": ["expr_not$macrocall$3"] },
	        { "name": "expr_not$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_not$macrocall$1", "symbols": ["expr_not$macrocall$2", "expr_not$macrocall$1$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'unary',
	                ...unwrap(x[0]),
	                operand: unwrap(x[1]),
	            }) },
	        { "name": "expr_not$macrocall$1", "symbols": ["expr_not$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_not", "symbols": ["expr_not$macrocall$1"] },
	        { "name": "expr_eq$macrocall$2$macrocall$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_eq") ? { type: "op_eq" } : op_eq)] },
	        { "name": "expr_eq$macrocall$2$macrocall$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_neq") ? { type: "op_neq" } : op_neq)] },
	        { "name": "expr_eq$macrocall$2$macrocall$2", "symbols": ["expr_eq$macrocall$2$macrocall$2$subexpression$1"] },
	        { "name": "expr_eq$macrocall$2$macrocall$1$macrocall$2", "symbols": ["expr_eq$macrocall$2$macrocall$2"] },
	        { "name": "expr_eq$macrocall$2$macrocall$1$macrocall$1", "symbols": ["expr_eq$macrocall$2$macrocall$1$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_eq$macrocall$2$macrocall$1", "symbols": ["expr_eq$macrocall$2$macrocall$1$macrocall$1"], "postprocess": unwrap },
	        { "name": "expr_eq$macrocall$2$macrocall$1", "symbols": ["kw_operator", "lparen", "ident", "dot", "expr_eq$macrocall$2$macrocall$2", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x[4], ' ') || '<error>').toUpperCase(),
	                opSchema: toStr(x[2]),
	            }) },
	        { "name": "expr_eq$macrocall$2", "symbols": ["expr_eq$macrocall$2$macrocall$1"] },
	        { "name": "expr_eq$macrocall$3", "symbols": ["expr_eq"] },
	        { "name": "expr_eq$macrocall$4", "symbols": ["expr_is"] },
	        { "name": "expr_eq$macrocall$1$subexpression$1", "symbols": ["expr_eq$macrocall$3"] },
	        { "name": "expr_eq$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_eq$macrocall$1$subexpression$2", "symbols": ["expr_eq$macrocall$4"] },
	        { "name": "expr_eq$macrocall$1$subexpression$2", "symbols": ["expr_paren"] },
	        { "name": "expr_eq$macrocall$1", "symbols": ["expr_eq$macrocall$1$subexpression$1", "expr_eq$macrocall$2", "expr_eq$macrocall$1$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'binary',
	                left: unwrap(x[0]),
	                right: unwrap(x[2]),
	                ...unwrap(x[1]),
	            }) },
	        { "name": "expr_eq$macrocall$1", "symbols": ["expr_eq$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_eq", "symbols": ["expr_eq$macrocall$1"] },
	        { "name": "expr_star", "symbols": ["star"], "postprocess": x => (0, lexer_2.track)(x, { type: 'ref', name: '*' }) },
	        { "name": "expr_is$subexpression$1", "symbols": ["expr_is"] },
	        { "name": "expr_is$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_is$subexpression$2", "symbols": [(lexer_1.lexerAny.has("kw_isnull") ? { type: "kw_isnull" } : kw_isnull)] },
	        { "name": "expr_is$subexpression$2", "symbols": [(lexer_1.lexerAny.has("kw_is") ? { type: "kw_is" } : kw_is), (lexer_1.lexerAny.has("kw_null") ? { type: "kw_null" } : kw_null)] },
	        { "name": "expr_is", "symbols": ["expr_is$subexpression$1", "expr_is$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, { type: 'unary', op: 'IS NULL', operand: unwrap(x[0]) }) },
	        { "name": "expr_is$subexpression$3", "symbols": ["expr_is"] },
	        { "name": "expr_is$subexpression$3", "symbols": ["expr_paren"] },
	        { "name": "expr_is$subexpression$4", "symbols": [(lexer_1.lexerAny.has("kw_notnull") ? { type: "kw_notnull" } : kw_notnull)] },
	        { "name": "expr_is$subexpression$4", "symbols": [(lexer_1.lexerAny.has("kw_is") ? { type: "kw_is" } : kw_is), "kw_not_null"] },
	        { "name": "expr_is", "symbols": ["expr_is$subexpression$3", "expr_is$subexpression$4"], "postprocess": x => (0, lexer_2.track)(x, { type: 'unary', op: 'IS NOT NULL', operand: unwrap(x[0]) }) },
	        { "name": "expr_is$subexpression$5", "symbols": ["expr_is"] },
	        { "name": "expr_is$subexpression$5", "symbols": ["expr_paren"] },
	        { "name": "expr_is$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_not") ? { type: "kw_not" } : kw_not)], "postprocess": id },
	        { "name": "expr_is$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "expr_is$subexpression$6", "symbols": [(lexer_1.lexerAny.has("kw_true") ? { type: "kw_true" } : kw_true)] },
	        { "name": "expr_is$subexpression$6", "symbols": [(lexer_1.lexerAny.has("kw_false") ? { type: "kw_false" } : kw_false)] },
	        { "name": "expr_is", "symbols": ["expr_is$subexpression$5", (lexer_1.lexerAny.has("kw_is") ? { type: "kw_is" } : kw_is), "expr_is$ebnf$1", "expr_is$subexpression$6"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'unary',
	                op: 'IS ' + flattenStr([x[2], x[3]])
	                    .join(' ')
	                    .toUpperCase(),
	                operand: unwrap(x[0]),
	            }) },
	        { "name": "expr_is", "symbols": ["expr_compare"], "postprocess": unwrap },
	        { "name": "expr_compare$macrocall$2$macrocall$2", "symbols": [(lexer_1.lexerAny.has("op_compare") ? { type: "op_compare" } : op_compare)] },
	        { "name": "expr_compare$macrocall$2$macrocall$1$macrocall$2", "symbols": ["expr_compare$macrocall$2$macrocall$2"] },
	        { "name": "expr_compare$macrocall$2$macrocall$1$macrocall$1", "symbols": ["expr_compare$macrocall$2$macrocall$1$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_compare$macrocall$2$macrocall$1", "symbols": ["expr_compare$macrocall$2$macrocall$1$macrocall$1"], "postprocess": unwrap },
	        { "name": "expr_compare$macrocall$2$macrocall$1", "symbols": ["kw_operator", "lparen", "ident", "dot", "expr_compare$macrocall$2$macrocall$2", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x[4], ' ') || '<error>').toUpperCase(),
	                opSchema: toStr(x[2]),
	            }) },
	        { "name": "expr_compare$macrocall$2", "symbols": ["expr_compare$macrocall$2$macrocall$1"] },
	        { "name": "expr_compare$macrocall$3", "symbols": ["expr_compare"] },
	        { "name": "expr_compare$macrocall$4", "symbols": ["expr_range"] },
	        { "name": "expr_compare$macrocall$1$subexpression$1", "symbols": ["expr_compare$macrocall$3"] },
	        { "name": "expr_compare$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_compare$macrocall$1$subexpression$2", "symbols": ["expr_compare$macrocall$4"] },
	        { "name": "expr_compare$macrocall$1$subexpression$2", "symbols": ["expr_paren"] },
	        { "name": "expr_compare$macrocall$1", "symbols": ["expr_compare$macrocall$1$subexpression$1", "expr_compare$macrocall$2", "expr_compare$macrocall$1$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'binary',
	                left: unwrap(x[0]),
	                right: unwrap(x[2]),
	                ...unwrap(x[1]),
	            }) },
	        { "name": "expr_compare$macrocall$1", "symbols": ["expr_compare$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_compare", "symbols": ["expr_compare$macrocall$1"] },
	        { "name": "expr_range$macrocall$2", "symbols": ["ops_between"] },
	        { "name": "expr_range$macrocall$3", "symbols": [(lexer_1.lexerAny.has("kw_and") ? { type: "kw_and" } : kw_and)] },
	        { "name": "expr_range$macrocall$4", "symbols": ["expr_range"] },
	        { "name": "expr_range$macrocall$5", "symbols": ["expr_others"] },
	        { "name": "expr_range$macrocall$1$subexpression$1", "symbols": ["expr_range$macrocall$4"] },
	        { "name": "expr_range$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_range$macrocall$1$subexpression$2", "symbols": ["expr_range$macrocall$4"] },
	        { "name": "expr_range$macrocall$1$subexpression$2", "symbols": ["expr_paren"] },
	        { "name": "expr_range$macrocall$1$subexpression$3", "symbols": ["expr_range$macrocall$5"] },
	        { "name": "expr_range$macrocall$1$subexpression$3", "symbols": ["expr_paren"] },
	        { "name": "expr_range$macrocall$1", "symbols": ["expr_range$macrocall$1$subexpression$1", "expr_range$macrocall$2", "expr_range$macrocall$1$subexpression$2", "expr_range$macrocall$3", "expr_range$macrocall$1$subexpression$3"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'ternary',
	                value: unwrap(x[0]),
	                lo: unwrap(x[2]),
	                hi: unwrap(x[4]),
	                op: (flattenStr(x[1]).join(' ') || '<error>').toUpperCase(),
	            }) },
	        { "name": "expr_range$macrocall$1", "symbols": ["expr_range$macrocall$5"], "postprocess": unwrap },
	        { "name": "expr_range", "symbols": ["expr_range$macrocall$1"] },
	        { "name": "expr_others$macrocall$2$macrocall$2", "symbols": [(lexer_1.lexerAny.has("ops_others") ? { type: "ops_others" } : ops_others)] },
	        { "name": "expr_others$macrocall$2$macrocall$1$macrocall$2", "symbols": ["expr_others$macrocall$2$macrocall$2"] },
	        { "name": "expr_others$macrocall$2$macrocall$1$macrocall$1", "symbols": ["expr_others$macrocall$2$macrocall$1$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_others$macrocall$2$macrocall$1", "symbols": ["expr_others$macrocall$2$macrocall$1$macrocall$1"], "postprocess": unwrap },
	        { "name": "expr_others$macrocall$2$macrocall$1", "symbols": ["kw_operator", "lparen", "ident", "dot", "expr_others$macrocall$2$macrocall$2", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x[4], ' ') || '<error>').toUpperCase(),
	                opSchema: toStr(x[2]),
	            }) },
	        { "name": "expr_others$macrocall$2", "symbols": ["expr_others$macrocall$2$macrocall$1"] },
	        { "name": "expr_others$macrocall$3", "symbols": ["expr_others"] },
	        { "name": "expr_others$macrocall$4", "symbols": ["expr_like"] },
	        { "name": "expr_others$macrocall$1$subexpression$1", "symbols": ["expr_others$macrocall$3"] },
	        { "name": "expr_others$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_others$macrocall$1$subexpression$2", "symbols": ["expr_others$macrocall$4"] },
	        { "name": "expr_others$macrocall$1$subexpression$2", "symbols": ["expr_paren"] },
	        { "name": "expr_others$macrocall$1", "symbols": ["expr_others$macrocall$1$subexpression$1", "expr_others$macrocall$2", "expr_others$macrocall$1$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'binary',
	                left: unwrap(x[0]),
	                right: unwrap(x[2]),
	                ...unwrap(x[1]),
	            }) },
	        { "name": "expr_others$macrocall$1", "symbols": ["expr_others$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_others", "symbols": ["expr_others$macrocall$1"] },
	        { "name": "expr_like$macrocall$2$macrocall$2", "symbols": ["ops_like"] },
	        { "name": "expr_like$macrocall$2$macrocall$1", "symbols": ["expr_like$macrocall$2$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_like$macrocall$2", "symbols": ["expr_like$macrocall$2$macrocall$1"] },
	        { "name": "expr_like$macrocall$3", "symbols": ["expr_like"] },
	        { "name": "expr_like$macrocall$4", "symbols": ["expr_in"] },
	        { "name": "expr_like$macrocall$1$subexpression$1", "symbols": ["expr_like$macrocall$3"] },
	        { "name": "expr_like$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_like$macrocall$1$subexpression$2", "symbols": ["expr_like$macrocall$4"] },
	        { "name": "expr_like$macrocall$1$subexpression$2", "symbols": ["expr_paren"] },
	        { "name": "expr_like$macrocall$1", "symbols": ["expr_like$macrocall$1$subexpression$1", "expr_like$macrocall$2", "expr_like$macrocall$1$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'binary',
	                left: unwrap(x[0]),
	                right: unwrap(x[2]),
	                ...unwrap(x[1]),
	            }) },
	        { "name": "expr_like$macrocall$1", "symbols": ["expr_like$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_like", "symbols": ["expr_like$macrocall$1"] },
	        { "name": "expr_in$macrocall$2$macrocall$2", "symbols": ["ops_in"] },
	        { "name": "expr_in$macrocall$2$macrocall$1", "symbols": ["expr_in$macrocall$2$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_in$macrocall$2", "symbols": ["expr_in$macrocall$2$macrocall$1"] },
	        { "name": "expr_in$macrocall$3", "symbols": ["expr_in"] },
	        { "name": "expr_in$macrocall$4", "symbols": ["expr_add"] },
	        { "name": "expr_in$macrocall$1$subexpression$1", "symbols": ["expr_in$macrocall$3"] },
	        { "name": "expr_in$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_in$macrocall$1$subexpression$2", "symbols": ["expr_in$macrocall$4"] },
	        { "name": "expr_in$macrocall$1$subexpression$2", "symbols": ["expr_paren"] },
	        { "name": "expr_in$macrocall$1", "symbols": ["expr_in$macrocall$1$subexpression$1", "expr_in$macrocall$2", "expr_in$macrocall$1$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'binary',
	                left: unwrap(x[0]),
	                right: unwrap(x[2]),
	                ...unwrap(x[1]),
	            }) },
	        { "name": "expr_in$macrocall$1", "symbols": ["expr_in$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_in", "symbols": ["expr_in$macrocall$1"] },
	        { "name": "expr_add$macrocall$2$macrocall$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_plus") ? { type: "op_plus" } : op_plus)] },
	        { "name": "expr_add$macrocall$2$macrocall$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_minus") ? { type: "op_minus" } : op_minus)] },
	        { "name": "expr_add$macrocall$2$macrocall$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_additive") ? { type: "op_additive" } : op_additive)] },
	        { "name": "expr_add$macrocall$2$macrocall$2", "symbols": ["expr_add$macrocall$2$macrocall$2$subexpression$1"] },
	        { "name": "expr_add$macrocall$2$macrocall$1$macrocall$2", "symbols": ["expr_add$macrocall$2$macrocall$2"] },
	        { "name": "expr_add$macrocall$2$macrocall$1$macrocall$1", "symbols": ["expr_add$macrocall$2$macrocall$1$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_add$macrocall$2$macrocall$1", "symbols": ["expr_add$macrocall$2$macrocall$1$macrocall$1"], "postprocess": unwrap },
	        { "name": "expr_add$macrocall$2$macrocall$1", "symbols": ["kw_operator", "lparen", "ident", "dot", "expr_add$macrocall$2$macrocall$2", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x[4], ' ') || '<error>').toUpperCase(),
	                opSchema: toStr(x[2]),
	            }) },
	        { "name": "expr_add$macrocall$2", "symbols": ["expr_add$macrocall$2$macrocall$1"] },
	        { "name": "expr_add$macrocall$3", "symbols": ["expr_add"] },
	        { "name": "expr_add$macrocall$4", "symbols": ["expr_mult"] },
	        { "name": "expr_add$macrocall$1$subexpression$1", "symbols": ["expr_add$macrocall$3"] },
	        { "name": "expr_add$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_add$macrocall$1$subexpression$2", "symbols": ["expr_add$macrocall$4"] },
	        { "name": "expr_add$macrocall$1$subexpression$2", "symbols": ["expr_paren"] },
	        { "name": "expr_add$macrocall$1", "symbols": ["expr_add$macrocall$1$subexpression$1", "expr_add$macrocall$2", "expr_add$macrocall$1$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'binary',
	                left: unwrap(x[0]),
	                right: unwrap(x[2]),
	                ...unwrap(x[1]),
	            }) },
	        { "name": "expr_add$macrocall$1", "symbols": ["expr_add$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_add", "symbols": ["expr_add$macrocall$1"] },
	        { "name": "expr_mult$macrocall$2$macrocall$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("star") ? { type: "star" } : star)] },
	        { "name": "expr_mult$macrocall$2$macrocall$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_div") ? { type: "op_div" } : op_div)] },
	        { "name": "expr_mult$macrocall$2$macrocall$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_mod") ? { type: "op_mod" } : op_mod)] },
	        { "name": "expr_mult$macrocall$2$macrocall$2", "symbols": ["expr_mult$macrocall$2$macrocall$2$subexpression$1"] },
	        { "name": "expr_mult$macrocall$2$macrocall$1$macrocall$2", "symbols": ["expr_mult$macrocall$2$macrocall$2"] },
	        { "name": "expr_mult$macrocall$2$macrocall$1$macrocall$1", "symbols": ["expr_mult$macrocall$2$macrocall$1$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_mult$macrocall$2$macrocall$1", "symbols": ["expr_mult$macrocall$2$macrocall$1$macrocall$1"], "postprocess": unwrap },
	        { "name": "expr_mult$macrocall$2$macrocall$1", "symbols": ["kw_operator", "lparen", "ident", "dot", "expr_mult$macrocall$2$macrocall$2", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x[4], ' ') || '<error>').toUpperCase(),
	                opSchema: toStr(x[2]),
	            }) },
	        { "name": "expr_mult$macrocall$2", "symbols": ["expr_mult$macrocall$2$macrocall$1"] },
	        { "name": "expr_mult$macrocall$3", "symbols": ["expr_mult"] },
	        { "name": "expr_mult$macrocall$4", "symbols": ["expr_exp"] },
	        { "name": "expr_mult$macrocall$1$subexpression$1", "symbols": ["expr_mult$macrocall$3"] },
	        { "name": "expr_mult$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_mult$macrocall$1$subexpression$2", "symbols": ["expr_mult$macrocall$4"] },
	        { "name": "expr_mult$macrocall$1$subexpression$2", "symbols": ["expr_paren"] },
	        { "name": "expr_mult$macrocall$1", "symbols": ["expr_mult$macrocall$1$subexpression$1", "expr_mult$macrocall$2", "expr_mult$macrocall$1$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'binary',
	                left: unwrap(x[0]),
	                right: unwrap(x[2]),
	                ...unwrap(x[1]),
	            }) },
	        { "name": "expr_mult$macrocall$1", "symbols": ["expr_mult$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_mult", "symbols": ["expr_mult$macrocall$1"] },
	        { "name": "expr_exp$macrocall$2$macrocall$2", "symbols": [(lexer_1.lexerAny.has("op_exp") ? { type: "op_exp" } : op_exp)] },
	        { "name": "expr_exp$macrocall$2$macrocall$1$macrocall$2", "symbols": ["expr_exp$macrocall$2$macrocall$2"] },
	        { "name": "expr_exp$macrocall$2$macrocall$1$macrocall$1", "symbols": ["expr_exp$macrocall$2$macrocall$1$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_exp$macrocall$2$macrocall$1", "symbols": ["expr_exp$macrocall$2$macrocall$1$macrocall$1"], "postprocess": unwrap },
	        { "name": "expr_exp$macrocall$2$macrocall$1", "symbols": ["kw_operator", "lparen", "ident", "dot", "expr_exp$macrocall$2$macrocall$2", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x[4], ' ') || '<error>').toUpperCase(),
	                opSchema: toStr(x[2]),
	            }) },
	        { "name": "expr_exp$macrocall$2", "symbols": ["expr_exp$macrocall$2$macrocall$1"] },
	        { "name": "expr_exp$macrocall$3", "symbols": ["expr_exp"] },
	        { "name": "expr_exp$macrocall$4", "symbols": ["expr_unary_add"] },
	        { "name": "expr_exp$macrocall$1$subexpression$1", "symbols": ["expr_exp$macrocall$3"] },
	        { "name": "expr_exp$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_exp$macrocall$1$subexpression$2", "symbols": ["expr_exp$macrocall$4"] },
	        { "name": "expr_exp$macrocall$1$subexpression$2", "symbols": ["expr_paren"] },
	        { "name": "expr_exp$macrocall$1", "symbols": ["expr_exp$macrocall$1$subexpression$1", "expr_exp$macrocall$2", "expr_exp$macrocall$1$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'binary',
	                left: unwrap(x[0]),
	                right: unwrap(x[2]),
	                ...unwrap(x[1]),
	            }) },
	        { "name": "expr_exp$macrocall$1", "symbols": ["expr_exp$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_exp", "symbols": ["expr_exp$macrocall$1"] },
	        { "name": "expr_unary_add$macrocall$2$macrocall$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_plus") ? { type: "op_plus" } : op_plus)] },
	        { "name": "expr_unary_add$macrocall$2$macrocall$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_minus") ? { type: "op_minus" } : op_minus)] },
	        { "name": "expr_unary_add$macrocall$2$macrocall$2", "symbols": ["expr_unary_add$macrocall$2$macrocall$2$subexpression$1"] },
	        { "name": "expr_unary_add$macrocall$2$macrocall$1$macrocall$2", "symbols": ["expr_unary_add$macrocall$2$macrocall$2"] },
	        { "name": "expr_unary_add$macrocall$2$macrocall$1$macrocall$1", "symbols": ["expr_unary_add$macrocall$2$macrocall$1$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_unary_add$macrocall$2$macrocall$1", "symbols": ["expr_unary_add$macrocall$2$macrocall$1$macrocall$1"], "postprocess": unwrap },
	        { "name": "expr_unary_add$macrocall$2$macrocall$1", "symbols": ["kw_operator", "lparen", "ident", "dot", "expr_unary_add$macrocall$2$macrocall$2", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x[4], ' ') || '<error>').toUpperCase(),
	                opSchema: toStr(x[2]),
	            }) },
	        { "name": "expr_unary_add$macrocall$2", "symbols": ["expr_unary_add$macrocall$2$macrocall$1"] },
	        { "name": "expr_unary_add$macrocall$3", "symbols": ["expr_unary_add"] },
	        { "name": "expr_unary_add$macrocall$4", "symbols": ["expr_various_constructs"] },
	        { "name": "expr_unary_add$macrocall$1$subexpression$1", "symbols": ["expr_unary_add$macrocall$3"] },
	        { "name": "expr_unary_add$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_unary_add$macrocall$1", "symbols": ["expr_unary_add$macrocall$2", "expr_unary_add$macrocall$1$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'unary',
	                ...unwrap(x[0]),
	                operand: unwrap(x[1]),
	            }) },
	        { "name": "expr_unary_add$macrocall$1", "symbols": ["expr_unary_add$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_unary_add", "symbols": ["expr_unary_add$macrocall$1"] },
	        { "name": "expr_various_constructs$macrocall$2$macrocall$2", "symbols": ["various_binaries"] },
	        { "name": "expr_various_constructs$macrocall$2$macrocall$1", "symbols": ["expr_various_constructs$macrocall$2$macrocall$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                op: (toStr(x, ' ') || '<error>').toUpperCase()
	            }) },
	        { "name": "expr_various_constructs$macrocall$2", "symbols": ["expr_various_constructs$macrocall$2$macrocall$1"] },
	        { "name": "expr_various_constructs$macrocall$3", "symbols": ["expr_various_constructs"] },
	        { "name": "expr_various_constructs$macrocall$4", "symbols": ["expr_array_index"] },
	        { "name": "expr_various_constructs$macrocall$1$subexpression$1", "symbols": ["expr_various_constructs$macrocall$3"] },
	        { "name": "expr_various_constructs$macrocall$1$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_various_constructs$macrocall$1$subexpression$2", "symbols": ["expr_various_constructs$macrocall$4"] },
	        { "name": "expr_various_constructs$macrocall$1$subexpression$2", "symbols": ["expr_paren"] },
	        { "name": "expr_various_constructs$macrocall$1", "symbols": ["expr_various_constructs$macrocall$1$subexpression$1", "expr_various_constructs$macrocall$2", "expr_various_constructs$macrocall$1$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'binary',
	                left: unwrap(x[0]),
	                right: unwrap(x[2]),
	                ...unwrap(x[1]),
	            }) },
	        { "name": "expr_various_constructs$macrocall$1", "symbols": ["expr_various_constructs$macrocall$4"], "postprocess": unwrap },
	        { "name": "expr_various_constructs", "symbols": ["expr_various_constructs$macrocall$1"] },
	        { "name": "expr_array_index$subexpression$1", "symbols": ["expr_array_index"] },
	        { "name": "expr_array_index$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_array_index", "symbols": ["expr_array_index$subexpression$1", (lexer_1.lexerAny.has("lbracket") ? { type: "lbracket" } : lbracket), "expr_nostar", (lexer_1.lexerAny.has("rbracket") ? { type: "rbracket" } : rbracket)], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'arrayIndex',
	                array: unwrap(x[0]),
	                index: unwrap(x[2]),
	            }) },
	        { "name": "expr_array_index", "symbols": ["expr_member"], "postprocess": unwrap },
	        { "name": "expr_member$subexpression$1", "symbols": ["expr_member"] },
	        { "name": "expr_member$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "expr_member$subexpression$2", "symbols": ["string"] },
	        { "name": "expr_member$subexpression$2", "symbols": ["int"] },
	        { "name": "expr_member", "symbols": ["expr_member$subexpression$1", "ops_member", "expr_member$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'member',
	                operand: unwrap(x[0]),
	                op: x[1],
	                member: unwrap(x[2])
	            }) },
	        { "name": "expr_member$subexpression$3", "symbols": ["expr_member"] },
	        { "name": "expr_member$subexpression$3", "symbols": ["expr_paren"] },
	        { "name": "expr_member", "symbols": ["expr_member$subexpression$3", (lexer_1.lexerAny.has("op_cast") ? { type: "op_cast" } : op_cast), "data_type"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'cast',
	                operand: unwrap(x[0]),
	                to: x[2],
	            }) },
	        { "name": "expr_member", "symbols": [(lexer_1.lexerAny.has("kw_cast") ? { type: "kw_cast" } : kw_cast), "lparen", "expr_nostar", (lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as), "data_type", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'cast',
	                operand: unwrap(x[2]),
	                to: x[4],
	            }) },
	        { "name": "expr_member", "symbols": ["data_type", "string"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'cast',
	                operand: (0, lexer_2.track)(x[1], {
	                    type: 'string',
	                    value: (0, lexer_2.unbox)(x[1]),
	                }),
	                to: (0, lexer_2.unbox)(x[0]),
	            }) },
	        { "name": "expr_member", "symbols": ["expr_dot"], "postprocess": unwrap },
	        { "name": "expr_dot$subexpression$1", "symbols": ["word"] },
	        { "name": "expr_dot$subexpression$1", "symbols": ["star"] },
	        { "name": "expr_dot", "symbols": ["qname", (lexer_1.lexerAny.has("dot") ? { type: "dot" } : dot), "expr_dot$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'ref',
	                table: unwrap(x[0]),
	                name: toStr(x[2])
	            }) },
	        { "name": "expr_dot", "symbols": ["expr_final"], "postprocess": unwrap },
	        { "name": "expr_final", "symbols": ["expr_basic"] },
	        { "name": "expr_final", "symbols": ["expr_primary"] },
	        { "name": "expr_basic", "symbols": ["expr_special_calls"] },
	        { "name": "expr_basic", "symbols": ["expr_call"] },
	        { "name": "expr_basic", "symbols": ["expr_array"] },
	        { "name": "expr_basic", "symbols": ["expr_case"] },
	        { "name": "expr_basic", "symbols": ["expr_extract"] },
	        { "name": "expr_basic", "symbols": ["word"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'ref',
	                name: unwrap(x[0]),
	            }) },
	        { "name": "expr_array$ebnf$1", "symbols": ["expr_subarray_items"], "postprocess": id },
	        { "name": "expr_array$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "expr_array", "symbols": [(lexer_1.lexerAny.has("kw_array") ? { type: "kw_array" } : kw_array), (lexer_1.lexerAny.has("lbracket") ? { type: "lbracket" } : lbracket), "expr_array$ebnf$1", (lexer_1.lexerAny.has("rbracket") ? { type: "rbracket" } : rbracket)], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'array',
	                expressions: x[2] || [],
	            }) },
	        { "name": "expr_array", "symbols": [(lexer_1.lexerAny.has("kw_array") ? { type: "kw_array" } : kw_array), "lparen", "selection", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'array select',
	                select: unwrap(x[2]),
	            }) },
	        { "name": "expr_subarray$ebnf$1", "symbols": ["expr_subarray_items"], "postprocess": id },
	        { "name": "expr_subarray$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "expr_subarray", "symbols": [(lexer_1.lexerAny.has("lbracket") ? { type: "lbracket" } : lbracket), "expr_subarray$ebnf$1", (lexer_1.lexerAny.has("rbracket") ? { type: "rbracket" } : rbracket)], "postprocess": get(1) },
	        { "name": "expr_subarray_items$macrocall$2", "symbols": ["expr_list_item"] },
	        { "name": "expr_subarray_items$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "expr_subarray_items$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "expr_subarray_items$macrocall$2"], "postprocess": last },
	        { "name": "expr_subarray_items$macrocall$1$ebnf$1", "symbols": ["expr_subarray_items$macrocall$1$ebnf$1", "expr_subarray_items$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "expr_subarray_items$macrocall$1", "symbols": ["expr_subarray_items$macrocall$2", "expr_subarray_items$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "expr_subarray_items", "symbols": ["expr_subarray_items$macrocall$1"], "postprocess": x => x[0].map(unwrap) },
	        { "name": "expr_subarray_items$macrocall$4", "symbols": ["expr_subarray"] },
	        { "name": "expr_subarray_items$macrocall$3$ebnf$1", "symbols": [] },
	        { "name": "expr_subarray_items$macrocall$3$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "expr_subarray_items$macrocall$4"], "postprocess": last },
	        { "name": "expr_subarray_items$macrocall$3$ebnf$1", "symbols": ["expr_subarray_items$macrocall$3$ebnf$1", "expr_subarray_items$macrocall$3$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "expr_subarray_items$macrocall$3", "symbols": ["expr_subarray_items$macrocall$4", "expr_subarray_items$macrocall$3$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "expr_subarray_items", "symbols": ["expr_subarray_items$macrocall$3"], "postprocess": (x) => {
	                return x[0].map((v) => {
	                    return (0, lexer_2.track)(v, {
	                        type: 'array',
	                        expressions: v[0].map(unwrap),
	                    });
	                });
	            } },
	        { "name": "expr_function_call$ebnf$1", "symbols": ["expr_list_raw"], "postprocess": id },
	        { "name": "expr_function_call$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "expr_function_call", "symbols": ["expr_fn_name", "lparen", "expr_function_call$ebnf$1", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'call',
	                function: unwrap(x[0]),
	                args: x[2] || [],
	            }) },
	        { "name": "expr_call$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_all") ? { type: "kw_all" } : kw_all)] },
	        { "name": "expr_call$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_distinct") ? { type: "kw_distinct" } : kw_distinct)] },
	        { "name": "expr_call$ebnf$1", "symbols": ["expr_call$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "expr_call$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "expr_call$ebnf$2", "symbols": ["expr_list_raw"], "postprocess": id },
	        { "name": "expr_call$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "expr_call$ebnf$3", "symbols": ["select_order_by"], "postprocess": id },
	        { "name": "expr_call$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "expr_call$ebnf$4$subexpression$1", "symbols": ["kw_filter", "lparen", (lexer_1.lexerAny.has("kw_where") ? { type: "kw_where" } : kw_where), "expr", "rparen"], "postprocess": get(3) },
	        { "name": "expr_call$ebnf$4", "symbols": ["expr_call$ebnf$4$subexpression$1"], "postprocess": id },
	        { "name": "expr_call$ebnf$4", "symbols": [], "postprocess": () => null },
	        { "name": "expr_call$ebnf$5", "symbols": ["expr_call_over"], "postprocess": id },
	        { "name": "expr_call$ebnf$5", "symbols": [], "postprocess": () => null },
	        { "name": "expr_call", "symbols": ["expr_fn_name", "lparen", "expr_call$ebnf$1", "expr_call$ebnf$2", "expr_call$ebnf$3", "rparen", "expr_call$ebnf$4", "expr_call$ebnf$5"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'call',
	                function: unwrap(x[0]),
	                ...x[2] && { distinct: toStr(x[2]) },
	                args: x[3] || [],
	                ...x[4] && { orderBy: x[4] },
	                ...x[6] && { filter: unwrap(x[6]) },
	                ...x[7] && { over: unwrap(x[7]) },
	            }) },
	        { "name": "expr_call_over$ebnf$1$subexpression$1", "symbols": ["kw_partition", "kw_by", "expr_list_raw"], "postprocess": last },
	        { "name": "expr_call_over$ebnf$1", "symbols": ["expr_call_over$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "expr_call_over$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "expr_call_over$ebnf$2", "symbols": ["select_order_by"], "postprocess": id },
	        { "name": "expr_call_over$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "expr_call_over", "symbols": ["kw_over", "lparen", "expr_call_over$ebnf$1", "expr_call_over$ebnf$2", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                ...x[2] && { partitionBy: x[2] },
	                ...x[3] && { orderBy: x[3] },
	            }) },
	        { "name": "expr_extract$subexpression$1", "symbols": ["word"], "postprocess": kw('extract') },
	        { "name": "expr_extract", "symbols": ["expr_extract$subexpression$1", "lparen", "word", (lexer_1.lexerAny.has("kw_from") ? { type: "kw_from" } : kw_from), "expr", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'extract',
	                field: asName(x[2]),
	                from: x[4],
	            }) },
	        { "name": "expr_primary", "symbols": ["float"], "postprocess": x => (0, lexer_2.track)(x, { type: 'numeric', value: (0, lexer_2.unbox)(x[0]) }) },
	        { "name": "expr_primary", "symbols": ["int"], "postprocess": x => (0, lexer_2.track)(x, { type: 'integer', value: (0, lexer_2.unbox)(x[0]) }) },
	        { "name": "expr_primary", "symbols": ["string"], "postprocess": x => (0, lexer_2.track)(x, { type: 'string', value: (0, lexer_2.unbox)(x[0]) }) },
	        { "name": "expr_primary", "symbols": [(lexer_1.lexerAny.has("kw_true") ? { type: "kw_true" } : kw_true)], "postprocess": x => (0, lexer_2.track)(x, { type: 'boolean', value: true }) },
	        { "name": "expr_primary", "symbols": [(lexer_1.lexerAny.has("kw_false") ? { type: "kw_false" } : kw_false)], "postprocess": x => (0, lexer_2.track)(x, { type: 'boolean', value: false }) },
	        { "name": "expr_primary", "symbols": [(lexer_1.lexerAny.has("kw_null") ? { type: "kw_null" } : kw_null)], "postprocess": x => (0, lexer_2.track)(x, { type: 'null' }) },
	        { "name": "expr_primary", "symbols": ["value_keyword"], "postprocess": x => (0, lexer_2.track)(x, { type: 'keyword', keyword: toStr(x) }) },
	        { "name": "expr_primary", "symbols": [(lexer_1.lexerAny.has("qparam") ? { type: "qparam" } : qparam)], "postprocess": x => (0, lexer_2.track)(x, { type: 'parameter', name: toStr(x[0]) }) },
	        { "name": "expr_primary", "symbols": [(lexer_1.lexerAny.has("kw_default") ? { type: "kw_default" } : kw_default)], "postprocess": x => (0, lexer_2.track)(x, { type: 'default' }) },
	        { "name": "ops_like", "symbols": ["ops_like_keywors"] },
	        { "name": "ops_like", "symbols": ["ops_like_operators"] },
	        { "name": "ops_like_keywors$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_not") ? { type: "kw_not" } : kw_not)], "postprocess": id },
	        { "name": "ops_like_keywors$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "ops_like_keywors$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_like") ? { type: "kw_like" } : kw_like)] },
	        { "name": "ops_like_keywors$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_ilike") ? { type: "kw_ilike" } : kw_ilike)] },
	        { "name": "ops_like_keywors", "symbols": ["ops_like_keywors$ebnf$1", "ops_like_keywors$subexpression$1"] },
	        { "name": "ops_like_operators$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_like") ? { type: "op_like" } : op_like)], "postprocess": () => 'LIKE' },
	        { "name": "ops_like_operators", "symbols": ["ops_like_operators$subexpression$1"] },
	        { "name": "ops_like_operators$subexpression$2", "symbols": [(lexer_1.lexerAny.has("op_ilike") ? { type: "op_ilike" } : op_ilike)], "postprocess": () => 'ILIKE' },
	        { "name": "ops_like_operators", "symbols": ["ops_like_operators$subexpression$2"] },
	        { "name": "ops_like_operators$subexpression$3", "symbols": [(lexer_1.lexerAny.has("op_not_like") ? { type: "op_not_like" } : op_not_like)], "postprocess": () => 'NOT LIKE' },
	        { "name": "ops_like_operators", "symbols": ["ops_like_operators$subexpression$3"] },
	        { "name": "ops_like_operators$subexpression$4", "symbols": [(lexer_1.lexerAny.has("op_not_ilike") ? { type: "op_not_ilike" } : op_not_ilike)], "postprocess": () => 'NOT ILIKE' },
	        { "name": "ops_like_operators", "symbols": ["ops_like_operators$subexpression$4"] },
	        { "name": "ops_in$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_not") ? { type: "kw_not" } : kw_not)], "postprocess": id },
	        { "name": "ops_in$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "ops_in", "symbols": ["ops_in$ebnf$1", (lexer_1.lexerAny.has("kw_in") ? { type: "kw_in" } : kw_in)] },
	        { "name": "ops_between$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_not") ? { type: "kw_not" } : kw_not)], "postprocess": id },
	        { "name": "ops_between$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "ops_between", "symbols": ["ops_between$ebnf$1", "kw_between"] },
	        { "name": "ops_member$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_member") ? { type: "op_member" } : op_member)] },
	        { "name": "ops_member$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_membertext") ? { type: "op_membertext" } : op_membertext)] },
	        { "name": "ops_member", "symbols": ["ops_member$subexpression$1"], "postprocess": x => { var _a; return (_a = unwrap(x)) === null || _a === void 0 ? void 0 : _a.value; } },
	        { "name": "expr_list_item", "symbols": ["expr_or_select"], "postprocess": unwrap },
	        { "name": "expr_list_item", "symbols": ["expr_star"], "postprocess": unwrap },
	        { "name": "expr_list_raw$macrocall$2", "symbols": ["expr_list_item"] },
	        { "name": "expr_list_raw$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "expr_list_raw$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "expr_list_raw$macrocall$2"], "postprocess": last },
	        { "name": "expr_list_raw$macrocall$1$ebnf$1", "symbols": ["expr_list_raw$macrocall$1$ebnf$1", "expr_list_raw$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "expr_list_raw$macrocall$1", "symbols": ["expr_list_raw$macrocall$2", "expr_list_raw$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "expr_list_raw", "symbols": ["expr_list_raw$macrocall$1"], "postprocess": ([x]) => x.map(unwrap) },
	        { "name": "expr_list_raw_many$macrocall$2", "symbols": ["expr_list_item"] },
	        { "name": "expr_list_raw_many$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "expr_list_raw_many$macrocall$2"], "postprocess": last },
	        { "name": "expr_list_raw_many$macrocall$1$ebnf$1", "symbols": ["expr_list_raw_many$macrocall$1$ebnf$1$subexpression$1"] },
	        { "name": "expr_list_raw_many$macrocall$1$ebnf$1$subexpression$2", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "expr_list_raw_many$macrocall$2"], "postprocess": last },
	        { "name": "expr_list_raw_many$macrocall$1$ebnf$1", "symbols": ["expr_list_raw_many$macrocall$1$ebnf$1", "expr_list_raw_many$macrocall$1$ebnf$1$subexpression$2"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "expr_list_raw_many$macrocall$1", "symbols": ["expr_list_raw_many$macrocall$2", "expr_list_raw_many$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "expr_list_raw_many", "symbols": ["expr_list_raw_many$macrocall$1"], "postprocess": ([x]) => x.map(unwrap) },
	        { "name": "expr_or_select", "symbols": ["expr_nostar"], "postprocess": unwrap },
	        { "name": "expr_or_select", "symbols": ["selection"], "postprocess": unwrap },
	        { "name": "expr_list_many", "symbols": ["expr_list_raw_many"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'list',
	                expressions: x[0],
	            }) },
	        { "name": "expr_case$ebnf$1", "symbols": ["expr_nostar"], "postprocess": id },
	        { "name": "expr_case$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "expr_case$ebnf$2", "symbols": [] },
	        { "name": "expr_case$ebnf$2", "symbols": ["expr_case$ebnf$2", "expr_case_whens"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "expr_case$ebnf$3", "symbols": ["expr_case_else"], "postprocess": id },
	        { "name": "expr_case$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "expr_case", "symbols": [(lexer_1.lexerAny.has("kw_case") ? { type: "kw_case" } : kw_case), "expr_case$ebnf$1", "expr_case$ebnf$2", "expr_case$ebnf$3", (lexer_1.lexerAny.has("kw_end") ? { type: "kw_end" } : kw_end)], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'case',
	                value: x[1],
	                whens: x[2],
	                else: x[3],
	            }) },
	        { "name": "expr_case_whens", "symbols": [(lexer_1.lexerAny.has("kw_when") ? { type: "kw_when" } : kw_when), "expr_nostar", (lexer_1.lexerAny.has("kw_then") ? { type: "kw_then" } : kw_then), "expr_nostar"], "postprocess": x => (0, lexer_2.track)(x, {
	                when: x[1],
	                value: x[3],
	            }) },
	        { "name": "expr_case_else", "symbols": [(lexer_1.lexerAny.has("kw_else") ? { type: "kw_else" } : kw_else), "expr_nostar"], "postprocess": last },
	        { "name": "expr_fn_name$subexpression$1$ebnf$1$subexpression$1", "symbols": ["word", (lexer_1.lexerAny.has("dot") ? { type: "dot" } : dot)] },
	        { "name": "expr_fn_name$subexpression$1$ebnf$1", "symbols": ["expr_fn_name$subexpression$1$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "expr_fn_name$subexpression$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "expr_fn_name$subexpression$1", "symbols": ["expr_fn_name$subexpression$1$ebnf$1", "word_or_keyword"], "postprocess": x => (0, lexer_2.track)(x, {
	                name: (0, lexer_2.unbox)(unwrap(x[1])),
	                ...x[0] && { schema: toStr(x[0][0]) },
	            }) },
	        { "name": "expr_fn_name", "symbols": ["expr_fn_name$subexpression$1"] },
	        { "name": "expr_fn_name$subexpression$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_any") ? { type: "kw_any" } : kw_any)] },
	        { "name": "expr_fn_name$subexpression$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_some") ? { type: "kw_some" } : kw_some)] },
	        { "name": "expr_fn_name$subexpression$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_all") ? { type: "kw_all" } : kw_all)] },
	        { "name": "expr_fn_name$subexpression$2", "symbols": ["expr_fn_name$subexpression$2$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                name: toStr(unwrap(x)),
	            }) },
	        { "name": "expr_fn_name", "symbols": ["expr_fn_name$subexpression$2"] },
	        { "name": "word_or_keyword", "symbols": ["word"] },
	        { "name": "word_or_keyword", "symbols": ["value_keyword"], "postprocess": x => (0, lexer_2.box)(x, toStr(x)) },
	        { "name": "value_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_catalog") ? { type: "kw_current_catalog" } : kw_current_catalog)] },
	        { "name": "value_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_date") ? { type: "kw_current_date" } : kw_current_date)] },
	        { "name": "value_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_role") ? { type: "kw_current_role" } : kw_current_role)] },
	        { "name": "value_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_schema") ? { type: "kw_current_schema" } : kw_current_schema)] },
	        { "name": "value_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_timestamp") ? { type: "kw_current_timestamp" } : kw_current_timestamp)] },
	        { "name": "value_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_time") ? { type: "kw_current_time" } : kw_current_time)] },
	        { "name": "value_keyword", "symbols": [(lexer_1.lexerAny.has("kw_localtimestamp") ? { type: "kw_localtimestamp" } : kw_localtimestamp)] },
	        { "name": "value_keyword", "symbols": [(lexer_1.lexerAny.has("kw_localtime") ? { type: "kw_localtime" } : kw_localtime)] },
	        { "name": "value_keyword", "symbols": [(lexer_1.lexerAny.has("kw_session_user") ? { type: "kw_session_user" } : kw_session_user)] },
	        { "name": "value_keyword", "symbols": [(lexer_1.lexerAny.has("kw_user") ? { type: "kw_user" } : kw_user)] },
	        { "name": "value_keyword", "symbols": [(lexer_1.lexerAny.has("kw_current_user") ? { type: "kw_current_user" } : kw_current_user)] },
	        { "name": "expr_special_calls", "symbols": ["spe_overlay"] },
	        { "name": "expr_special_calls", "symbols": ["spe_substring"] },
	        { "name": "spe_overlay$subexpression$1", "symbols": ["word"], "postprocess": kw('overlay') },
	        { "name": "spe_overlay$subexpression$2", "symbols": [(lexer_1.lexerAny.has("lparen") ? { type: "lparen" } : lparen), "expr_nostar"] },
	        { "name": "spe_overlay$subexpression$3", "symbols": [(lexer_1.lexerAny.has("kw_placing") ? { type: "kw_placing" } : kw_placing), "expr_nostar"] },
	        { "name": "spe_overlay$subexpression$4", "symbols": [(lexer_1.lexerAny.has("kw_from") ? { type: "kw_from" } : kw_from), "expr_nostar"] },
	        { "name": "spe_overlay$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_for") ? { type: "kw_for" } : kw_for), "expr_nostar"] },
	        { "name": "spe_overlay$ebnf$1", "symbols": ["spe_overlay$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "spe_overlay$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "spe_overlay", "symbols": ["spe_overlay$subexpression$1", "spe_overlay$subexpression$2", "spe_overlay$subexpression$3", "spe_overlay$subexpression$4", "spe_overlay$ebnf$1", (lexer_1.lexerAny.has("rparen") ? { type: "rparen" } : rparen)], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'overlay',
	                value: x[1][1],
	                placing: x[2][1],
	                from: x[3][1],
	                ...x[4] && { for: x[4][1] },
	            }) },
	        { "name": "spe_substring$subexpression$1", "symbols": ["word"], "postprocess": kw('substring') },
	        { "name": "spe_substring$subexpression$2", "symbols": [(lexer_1.lexerAny.has("lparen") ? { type: "lparen" } : lparen), "expr_nostar"] },
	        { "name": "spe_substring$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_from") ? { type: "kw_from" } : kw_from), "expr_nostar"] },
	        { "name": "spe_substring$ebnf$1", "symbols": ["spe_substring$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "spe_substring$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "spe_substring$ebnf$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_for") ? { type: "kw_for" } : kw_for), "expr_nostar"] },
	        { "name": "spe_substring$ebnf$2", "symbols": ["spe_substring$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "spe_substring$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "spe_substring", "symbols": ["spe_substring$subexpression$1", "spe_substring$subexpression$2", "spe_substring$ebnf$1", "spe_substring$ebnf$2", (lexer_1.lexerAny.has("rparen") ? { type: "rparen" } : rparen)], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'substring',
	                value: x[1][1],
	                ...x[2] && { from: x[2][1] },
	                ...x[3] && { for: x[3][1] },
	            }) },
	        { "name": "various_binaries", "symbols": ["kw_at", "kw_time", "kw_zone"], "postprocess": () => 'AT TIME ZONE' },
	        { "name": "createtable_statement$ebnf$1", "symbols": ["createtable_modifiers"], "postprocess": id },
	        { "name": "createtable_statement$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "createtable_statement$ebnf$2", "symbols": ["kw_ifnotexists"], "postprocess": id },
	        { "name": "createtable_statement$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "createtable_statement$ebnf$3", "symbols": ["createtable_opts"], "postprocess": id },
	        { "name": "createtable_statement$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "createtable_statement", "symbols": [(lexer_1.lexerAny.has("kw_create") ? { type: "kw_create" } : kw_create), "createtable_statement$ebnf$1", (lexer_1.lexerAny.has("kw_table") ? { type: "kw_table" } : kw_table), "createtable_statement$ebnf$2", "qname", "lparen", "createtable_declarationlist", "rparen", "createtable_statement$ebnf$3"], "postprocess": x => {
	                const cols = x[6].filter((v) => 'kind' in v);
	                const constraints = x[6].filter((v) => !('kind' in v));
	                return (0, lexer_2.track)(x, {
	                    type: 'create table',
	                    ...!!x[3] ? { ifNotExists: true } : {},
	                    name: x[4],
	                    columns: cols,
	                    ...unwrap(x[1]),
	                    ...constraints.length ? { constraints } : {},
	                    ...last(x),
	                });
	            } },
	        { "name": "createtable_modifiers", "symbols": ["kw_unlogged"], "postprocess": x => x[0] ? { unlogged: true } : {} },
	        { "name": "createtable_modifiers", "symbols": ["m_locglob"] },
	        { "name": "createtable_modifiers", "symbols": ["m_tmp"] },
	        { "name": "createtable_modifiers", "symbols": ["m_locglob", "m_tmp"], "postprocess": ([a, b]) => ({ ...a, ...b }) },
	        { "name": "m_locglob$subexpression$1", "symbols": ["kw_local"] },
	        { "name": "m_locglob$subexpression$1", "symbols": ["kw_global"] },
	        { "name": "m_locglob", "symbols": ["m_locglob$subexpression$1"], "postprocess": x => ({ locality: toStr(x) }) },
	        { "name": "m_tmp$subexpression$1", "symbols": ["kw_temp"] },
	        { "name": "m_tmp$subexpression$1", "symbols": ["kw_temporary"] },
	        { "name": "m_tmp", "symbols": ["m_tmp$subexpression$1"], "postprocess": x => ({ temporary: true }) },
	        { "name": "createtable_declarationlist$ebnf$1", "symbols": [] },
	        { "name": "createtable_declarationlist$ebnf$1$subexpression$1", "symbols": ["comma", "createtable_declaration"], "postprocess": last },
	        { "name": "createtable_declarationlist$ebnf$1", "symbols": ["createtable_declarationlist$ebnf$1", "createtable_declarationlist$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "createtable_declarationlist", "symbols": ["createtable_declaration", "createtable_declarationlist$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "createtable_declaration$subexpression$1", "symbols": ["createtable_constraint"] },
	        { "name": "createtable_declaration$subexpression$1", "symbols": ["createtable_column"] },
	        { "name": "createtable_declaration$subexpression$1", "symbols": ["createtable_like"] },
	        { "name": "createtable_declaration", "symbols": ["createtable_declaration$subexpression$1"], "postprocess": unwrap },
	        { "name": "createtable_constraint$macrocall$2", "symbols": ["createtable_constraint_def"] },
	        { "name": "createtable_constraint$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_constraint") ? { type: "kw_constraint" } : kw_constraint), "word"] },
	        { "name": "createtable_constraint$macrocall$1$ebnf$1", "symbols": ["createtable_constraint$macrocall$1$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "createtable_constraint$macrocall$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "createtable_constraint$macrocall$1", "symbols": ["createtable_constraint$macrocall$1$ebnf$1", "createtable_constraint$macrocall$2"], "postprocess": x => {
	                const name = x[0] && asName(x[0][1]);
	                if (!name) {
	                    return (0, lexer_2.track)(x, unwrap(x[1]));
	                }
	                return (0, lexer_2.track)(x, {
	                    constraintName: name,
	                    ...unwrap(x[1]),
	                });
	            } },
	        { "name": "createtable_constraint", "symbols": ["createtable_constraint$macrocall$1"], "postprocess": unwrap },
	        { "name": "createtable_constraint_def", "symbols": ["createtable_constraint_def_unique"] },
	        { "name": "createtable_constraint_def", "symbols": ["createtable_constraint_def_check"] },
	        { "name": "createtable_constraint_def", "symbols": ["createtable_constraint_foreignkey"] },
	        { "name": "createtable_constraint_def_unique$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_unique") ? { type: "kw_unique" } : kw_unique)] },
	        { "name": "createtable_constraint_def_unique$subexpression$1", "symbols": ["kw_primary_key"] },
	        { "name": "createtable_constraint_def_unique", "symbols": ["createtable_constraint_def_unique$subexpression$1", "lparen", "createtable_collist", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: toStr(x[0], ' '),
	                columns: x[2].map(asName),
	            }) },
	        { "name": "createtable_constraint_def_check", "symbols": [(lexer_1.lexerAny.has("kw_check") ? { type: "kw_check" } : kw_check), "expr_paren"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'check',
	                expr: unwrap(x[1]),
	            }) },
	        { "name": "createtable_constraint_foreignkey", "symbols": [(lexer_1.lexerAny.has("kw_foreign") ? { type: "kw_foreign" } : kw_foreign), "kw_key", "collist_paren", "createtable_references"], "postprocess": (x) => {
	                return (0, lexer_2.track)(x, {
	                    type: 'foreign key',
	                    localColumns: x[2].map(asName),
	                    ...x[3],
	                });
	            } },
	        { "name": "createtable_references$ebnf$1", "symbols": [] },
	        { "name": "createtable_references$ebnf$1", "symbols": ["createtable_references$ebnf$1", "createtable_constraint_foreignkey_onsometing"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "createtable_references", "symbols": [(lexer_1.lexerAny.has("kw_references") ? { type: "kw_references" } : kw_references), "table_ref", "collist_paren", "createtable_references$ebnf$1"], "postprocess": (x) => {
	                return (0, lexer_2.track)(x, {
	                    foreignTable: unwrap(x[1]),
	                    foreignColumns: x[2].map(asName),
	                    ...x[3].reduce((a, b) => ({ ...a, ...b }), {}),
	                });
	            } },
	        { "name": "createtable_constraint_foreignkey_onsometing", "symbols": [(lexer_1.lexerAny.has("kw_on") ? { type: "kw_on" } : kw_on), "kw_delete", "createtable_constraint_on_action"], "postprocess": x => (0, lexer_2.track)(x, { onDelete: last(x) }) },
	        { "name": "createtable_constraint_foreignkey_onsometing", "symbols": [(lexer_1.lexerAny.has("kw_on") ? { type: "kw_on" } : kw_on), "kw_update", "createtable_constraint_on_action"], "postprocess": x => (0, lexer_2.track)(x, { onUpdate: last(x) }) },
	        { "name": "createtable_constraint_foreignkey_onsometing$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_full") ? { type: "kw_full" } : kw_full)] },
	        { "name": "createtable_constraint_foreignkey_onsometing$subexpression$1", "symbols": ["kw_partial"] },
	        { "name": "createtable_constraint_foreignkey_onsometing$subexpression$1", "symbols": ["kw_simple"] },
	        { "name": "createtable_constraint_foreignkey_onsometing", "symbols": ["kw_match", "createtable_constraint_foreignkey_onsometing$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, { match: toStr(last(x)) }) },
	        { "name": "createtable_constraint_on_action$subexpression$1", "symbols": ["kw_cascade"] },
	        { "name": "createtable_constraint_on_action$subexpression$1$subexpression$1", "symbols": ["kw_no", "kw_action"] },
	        { "name": "createtable_constraint_on_action$subexpression$1", "symbols": ["createtable_constraint_on_action$subexpression$1$subexpression$1"] },
	        { "name": "createtable_constraint_on_action$subexpression$1", "symbols": ["kw_restrict"] },
	        { "name": "createtable_constraint_on_action$subexpression$1$subexpression$2", "symbols": [(lexer_1.lexerAny.has("kw_null") ? { type: "kw_null" } : kw_null)] },
	        { "name": "createtable_constraint_on_action$subexpression$1$subexpression$2", "symbols": [(lexer_1.lexerAny.has("kw_default") ? { type: "kw_default" } : kw_default)] },
	        { "name": "createtable_constraint_on_action$subexpression$1", "symbols": ["kw_set", "createtable_constraint_on_action$subexpression$1$subexpression$2"] },
	        { "name": "createtable_constraint_on_action", "symbols": ["createtable_constraint_on_action$subexpression$1"], "postprocess": x => toStr(x, ' ') },
	        { "name": "createtable_collist$ebnf$1", "symbols": [] },
	        { "name": "createtable_collist$ebnf$1$subexpression$1", "symbols": ["comma", "ident"], "postprocess": last },
	        { "name": "createtable_collist$ebnf$1", "symbols": ["createtable_collist$ebnf$1", "createtable_collist$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "createtable_collist", "symbols": ["ident", "createtable_collist$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "createtable_column$ebnf$1", "symbols": ["createtable_collate"], "postprocess": id },
	        { "name": "createtable_column$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "createtable_column$ebnf$2", "symbols": [] },
	        { "name": "createtable_column$ebnf$2", "symbols": ["createtable_column$ebnf$2", "createtable_column_constraint"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "createtable_column", "symbols": ["word", "data_type", "createtable_column$ebnf$1", "createtable_column$ebnf$2"], "postprocess": x => {
	                return (0, lexer_2.track)(x, {
	                    kind: 'column',
	                    name: asName(x[0]),
	                    dataType: x[1],
	                    ...x[2] ? { collate: x[2][1] } : {},
	                    ...x[3] && x[3].length ? { constraints: x[3] } : {},
	                });
	            } },
	        { "name": "createtable_like$ebnf$1", "symbols": [] },
	        { "name": "createtable_like$ebnf$1", "symbols": ["createtable_like$ebnf$1", "createtable_like_opt"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "createtable_like", "symbols": [(lexer_1.lexerAny.has("kw_like") ? { type: "kw_like" } : kw_like), "qname", "createtable_like$ebnf$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                kind: 'like table',
	                like: x[1],
	                options: x[2],
	            }) },
	        { "name": "createtable_like_opt$subexpression$1", "symbols": ["kw_including"] },
	        { "name": "createtable_like_opt$subexpression$1", "symbols": ["kw_excluding"] },
	        { "name": "createtable_like_opt", "symbols": ["createtable_like_opt$subexpression$1", "createtable_like_opt_val"], "postprocess": x => (0, lexer_2.track)(x, {
	                verb: toStr(x[0]),
	                option: toStr(x[1]),
	            }) },
	        { "name": "createtable_like_opt_val", "symbols": ["word"], "postprocess": anyKw('defaults', 'constraints', 'indexes', 'storage', 'comments') },
	        { "name": "createtable_like_opt_val", "symbols": [(lexer_1.lexerAny.has("kw_all") ? { type: "kw_all" } : kw_all)] },
	        { "name": "createtable_column_constraint$macrocall$2", "symbols": ["createtable_column_constraint_def"] },
	        { "name": "createtable_column_constraint$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_constraint") ? { type: "kw_constraint" } : kw_constraint), "word"] },
	        { "name": "createtable_column_constraint$macrocall$1$ebnf$1", "symbols": ["createtable_column_constraint$macrocall$1$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "createtable_column_constraint$macrocall$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "createtable_column_constraint$macrocall$1", "symbols": ["createtable_column_constraint$macrocall$1$ebnf$1", "createtable_column_constraint$macrocall$2"], "postprocess": x => {
	                const name = x[0] && asName(x[0][1]);
	                if (!name) {
	                    return (0, lexer_2.track)(x, unwrap(x[1]));
	                }
	                return (0, lexer_2.track)(x, {
	                    constraintName: name,
	                    ...unwrap(x[1]),
	                });
	            } },
	        { "name": "createtable_column_constraint", "symbols": ["createtable_column_constraint$macrocall$1"], "postprocess": unwrap },
	        { "name": "createtable_column_constraint_def", "symbols": [(lexer_1.lexerAny.has("kw_unique") ? { type: "kw_unique" } : kw_unique)], "postprocess": x => (0, lexer_2.track)(x, { type: 'unique' }) },
	        { "name": "createtable_column_constraint_def", "symbols": ["kw_primary_key"], "postprocess": x => (0, lexer_2.track)(x, { type: 'primary key' }) },
	        { "name": "createtable_column_constraint_def", "symbols": ["kw_not_null"], "postprocess": x => (0, lexer_2.track)(x, { type: 'not null' }) },
	        { "name": "createtable_column_constraint_def", "symbols": [(lexer_1.lexerAny.has("kw_null") ? { type: "kw_null" } : kw_null)], "postprocess": x => (0, lexer_2.track)(x, { type: 'null' }) },
	        { "name": "createtable_column_constraint_def", "symbols": [(lexer_1.lexerAny.has("kw_default") ? { type: "kw_default" } : kw_default), "expr"], "postprocess": x => (0, lexer_2.track)(x, { type: 'default', default: unwrap(x[1]) }) },
	        { "name": "createtable_column_constraint_def", "symbols": [(lexer_1.lexerAny.has("kw_check") ? { type: "kw_check" } : kw_check), "expr_paren"], "postprocess": x => (0, lexer_2.track)(x, { type: 'check', expr: unwrap(x[1]) }) },
	        { "name": "createtable_column_constraint_def", "symbols": ["createtable_references"], "postprocess": x => (0, lexer_2.track)(x, { type: 'reference', ...unwrap(x) }) },
	        { "name": "createtable_column_constraint_def", "symbols": ["altercol_generated"] },
	        { "name": "createtable_collate", "symbols": [(lexer_1.lexerAny.has("kw_collate") ? { type: "kw_collate" } : kw_collate), "qualified_name"] },
	        { "name": "createtable_opts$subexpression$1", "symbols": ["word"], "postprocess": kw('inherits') },
	        { "name": "createtable_opts$macrocall$2", "symbols": ["qname"] },
	        { "name": "createtable_opts$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "createtable_opts$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "createtable_opts$macrocall$2"], "postprocess": last },
	        { "name": "createtable_opts$macrocall$1$ebnf$1", "symbols": ["createtable_opts$macrocall$1$ebnf$1", "createtable_opts$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "createtable_opts$macrocall$1", "symbols": ["createtable_opts$macrocall$2", "createtable_opts$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "createtable_opts", "symbols": ["createtable_opts$subexpression$1", "lparen", "createtable_opts$macrocall$1", "rparen"], "postprocess": x => (0, lexer_2.track)(x, { inherits: x[2] }) },
	        { "name": "createindex_statement$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_unique") ? { type: "kw_unique" } : kw_unique)], "postprocess": id },
	        { "name": "createindex_statement$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "createindex_statement$ebnf$2", "symbols": ["kw_ifnotexists"], "postprocess": id },
	        { "name": "createindex_statement$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "createindex_statement$ebnf$3", "symbols": ["word"], "postprocess": id },
	        { "name": "createindex_statement$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "createindex_statement$ebnf$4$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_using") ? { type: "kw_using" } : kw_using), "ident"], "postprocess": last },
	        { "name": "createindex_statement$ebnf$4", "symbols": ["createindex_statement$ebnf$4$subexpression$1"], "postprocess": id },
	        { "name": "createindex_statement$ebnf$4", "symbols": [], "postprocess": () => null },
	        { "name": "createindex_statement$ebnf$5", "symbols": ["createindex_with"], "postprocess": id },
	        { "name": "createindex_statement$ebnf$5", "symbols": [], "postprocess": () => null },
	        { "name": "createindex_statement$ebnf$6", "symbols": ["createindex_tblspace"], "postprocess": id },
	        { "name": "createindex_statement$ebnf$6", "symbols": [], "postprocess": () => null },
	        { "name": "createindex_statement$ebnf$7", "symbols": ["createindex_predicate"], "postprocess": id },
	        { "name": "createindex_statement$ebnf$7", "symbols": [], "postprocess": () => null },
	        { "name": "createindex_statement", "symbols": [(lexer_1.lexerAny.has("kw_create") ? { type: "kw_create" } : kw_create), "createindex_statement$ebnf$1", "kw_index", "createindex_statement$ebnf$2", "createindex_statement$ebnf$3", (lexer_1.lexerAny.has("kw_on") ? { type: "kw_on" } : kw_on), "table_ref", "createindex_statement$ebnf$4", "lparen", "createindex_expressions", "rparen", "createindex_statement$ebnf$5", "createindex_statement$ebnf$6", "createindex_statement$ebnf$7"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'create index',
	                ...x[1] && { unique: true },
	                ...x[3] && { ifNotExists: true },
	                ...x[4] && { indexName: asName(x[4]) },
	                table: x[6],
	                ...x[7] && { using: asName(x[7]) },
	                expressions: x[9],
	                ...x[11] && { with: x[11] },
	                ...x[12] && { tablespace: unwrap(x[12]) },
	                ...x[13] && { where: unwrap(x[13]) },
	            }) },
	        { "name": "createindex_expressions$ebnf$1", "symbols": [] },
	        { "name": "createindex_expressions$ebnf$1$subexpression$1", "symbols": ["comma", "createindex_expression"], "postprocess": last },
	        { "name": "createindex_expressions$ebnf$1", "symbols": ["createindex_expressions$ebnf$1", "createindex_expressions$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "createindex_expressions", "symbols": ["createindex_expression", "createindex_expressions$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "createindex_expression$subexpression$1", "symbols": ["expr_basic"] },
	        { "name": "createindex_expression$subexpression$1", "symbols": ["expr_paren"] },
	        { "name": "createindex_expression$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_collate") ? { type: "kw_collate" } : kw_collate), "qualified_name"], "postprocess": last },
	        { "name": "createindex_expression$ebnf$1", "symbols": ["createindex_expression$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "createindex_expression$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "createindex_expression$ebnf$2", "symbols": ["qualified_name"], "postprocess": id },
	        { "name": "createindex_expression$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "createindex_expression$ebnf$3$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_asc") ? { type: "kw_asc" } : kw_asc)] },
	        { "name": "createindex_expression$ebnf$3$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_desc") ? { type: "kw_desc" } : kw_desc)] },
	        { "name": "createindex_expression$ebnf$3", "symbols": ["createindex_expression$ebnf$3$subexpression$1"], "postprocess": id },
	        { "name": "createindex_expression$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "createindex_expression$ebnf$4$subexpression$1$subexpression$1", "symbols": ["kw_first"] },
	        { "name": "createindex_expression$ebnf$4$subexpression$1$subexpression$1", "symbols": ["kw_last"] },
	        { "name": "createindex_expression$ebnf$4$subexpression$1", "symbols": ["kw_nulls", "createindex_expression$ebnf$4$subexpression$1$subexpression$1"], "postprocess": last },
	        { "name": "createindex_expression$ebnf$4", "symbols": ["createindex_expression$ebnf$4$subexpression$1"], "postprocess": id },
	        { "name": "createindex_expression$ebnf$4", "symbols": [], "postprocess": () => null },
	        { "name": "createindex_expression", "symbols": ["createindex_expression$subexpression$1", "createindex_expression$ebnf$1", "createindex_expression$ebnf$2", "createindex_expression$ebnf$3", "createindex_expression$ebnf$4"], "postprocess": x => (0, lexer_2.track)(x, {
	                expression: unwrap(x[0]),
	                ...x[1] && { collate: unwrap(x[1]) },
	                ...x[2] && { opclass: unwrap(x[2]) },
	                ...x[3] && { order: unwrap(x[3]).value },
	                ...x[4] && { nulls: unwrap(x[4]) },
	            }) },
	        { "name": "createindex_predicate", "symbols": [(lexer_1.lexerAny.has("kw_where") ? { type: "kw_where" } : kw_where), "expr"], "postprocess": last },
	        { "name": "createindex_with$macrocall$2", "symbols": ["createindex_with_item"] },
	        { "name": "createindex_with$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "createindex_with$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "createindex_with$macrocall$2"], "postprocess": last },
	        { "name": "createindex_with$macrocall$1$ebnf$1", "symbols": ["createindex_with$macrocall$1$ebnf$1", "createindex_with$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "createindex_with$macrocall$1", "symbols": ["createindex_with$macrocall$2", "createindex_with$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "createindex_with", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with), "lparen", "createindex_with$macrocall$1", "rparen"], "postprocess": get(2) },
	        { "name": "createindex_with_item$subexpression$1", "symbols": ["string"] },
	        { "name": "createindex_with_item$subexpression$1", "symbols": ["int"] },
	        { "name": "createindex_with_item", "symbols": ["ident", (lexer_1.lexerAny.has("op_eq") ? { type: "op_eq" } : op_eq), "createindex_with_item$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, { parameter: toStr(x[0]), value: unwrap(x[2]).toString() }) },
	        { "name": "createindex_tblspace", "symbols": ["kw_tablespace", "ident"], "postprocess": last },
	        { "name": "createextension_statement$ebnf$1", "symbols": ["kw_ifnotexists"], "postprocess": id },
	        { "name": "createextension_statement$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "createextension_statement$ebnf$2", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with)], "postprocess": id },
	        { "name": "createextension_statement$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "createextension_statement$ebnf$3$subexpression$1", "symbols": ["kw_schema", "word"], "postprocess": last },
	        { "name": "createextension_statement$ebnf$3", "symbols": ["createextension_statement$ebnf$3$subexpression$1"], "postprocess": id },
	        { "name": "createextension_statement$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "createextension_statement$ebnf$4$subexpression$1", "symbols": ["kw_version", "string"], "postprocess": last },
	        { "name": "createextension_statement$ebnf$4", "symbols": ["createextension_statement$ebnf$4$subexpression$1"], "postprocess": id },
	        { "name": "createextension_statement$ebnf$4", "symbols": [], "postprocess": () => null },
	        { "name": "createextension_statement$ebnf$5$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_from") ? { type: "kw_from" } : kw_from), "string"], "postprocess": last },
	        { "name": "createextension_statement$ebnf$5", "symbols": ["createextension_statement$ebnf$5$subexpression$1"], "postprocess": id },
	        { "name": "createextension_statement$ebnf$5", "symbols": [], "postprocess": () => null },
	        { "name": "createextension_statement", "symbols": [(lexer_1.lexerAny.has("kw_create") ? { type: "kw_create" } : kw_create), "kw_extension", "createextension_statement$ebnf$1", "word", "createextension_statement$ebnf$2", "createextension_statement$ebnf$3", "createextension_statement$ebnf$4", "createextension_statement$ebnf$5"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'create extension',
	                ...!!x[2] ? { ifNotExists: true } : {},
	                extension: asName(x[3]),
	                ...!!x[5] ? { schema: asName(x[5]) } : {},
	                ...!!x[6] ? { version: asLit(x[6]) } : {},
	                ...!!x[7] ? { from: asLit(x[7]) } : {},
	            }) },
	        { "name": "simplestatements_all", "symbols": ["simplestatements_start_transaction"] },
	        { "name": "simplestatements_all", "symbols": ["simplestatements_commit"] },
	        { "name": "simplestatements_all", "symbols": ["simplestatements_rollback"] },
	        { "name": "simplestatements_all", "symbols": ["simplestatements_tablespace"] },
	        { "name": "simplestatements_all", "symbols": ["simplestatements_set"] },
	        { "name": "simplestatements_all", "symbols": ["simplestatements_show"] },
	        { "name": "simplestatements_all", "symbols": ["simplestatements_begin"] },
	        { "name": "simplestatements_start_transaction$subexpression$1", "symbols": ["kw_start", "kw_transaction"] },
	        { "name": "simplestatements_start_transaction", "symbols": ["simplestatements_start_transaction$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, { type: 'start transaction' }) },
	        { "name": "simplestatements_commit", "symbols": ["kw_commit"], "postprocess": x => (0, lexer_2.track)(x, { type: 'commit' }) },
	        { "name": "simplestatements_rollback", "symbols": ["kw_rollback"], "postprocess": x => (0, lexer_2.track)(x, { type: 'rollback' }) },
	        { "name": "simplestatements_tablespace", "symbols": ["kw_tablespace", "word"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'tablespace',
	                tablespace: asName(x[1]),
	            }) },
	        { "name": "simplestatements_set$subexpression$1", "symbols": ["simplestatements_set_simple"] },
	        { "name": "simplestatements_set$subexpression$1", "symbols": ["simplestatements_set_timezone"] },
	        { "name": "simplestatements_set$subexpression$1", "symbols": ["simplestatements_set_names"] },
	        { "name": "simplestatements_set", "symbols": ["kw_set", "simplestatements_set$subexpression$1"], "postprocess": last },
	        { "name": "simplestatements_set_timezone", "symbols": ["kw_time", "kw_zone", "simplestatements_set_timezone_val"], "postprocess": x => (0, lexer_2.track)(x, { type: 'set timezone', to: x[2] }) },
	        { "name": "simplestatements_set_timezone_val$subexpression$1", "symbols": ["string"] },
	        { "name": "simplestatements_set_timezone_val$subexpression$1", "symbols": ["int"] },
	        { "name": "simplestatements_set_timezone_val", "symbols": ["simplestatements_set_timezone_val$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, { type: 'value', value: unwrap(x[0]) }) },
	        { "name": "simplestatements_set_timezone_val", "symbols": ["kw_local"], "postprocess": x => (0, lexer_2.track)(x, { type: 'local' }) },
	        { "name": "simplestatements_set_timezone_val", "symbols": [(lexer_1.lexerAny.has("kw_default") ? { type: "kw_default" } : kw_default)], "postprocess": x => (0, lexer_2.track)(x, { type: 'default' }) },
	        { "name": "simplestatements_set_timezone_val", "symbols": ["kw_interval", "string", "kw_hour", (lexer_1.lexerAny.has("kw_to") ? { type: "kw_to" } : kw_to), "kw_minute"], "postprocess": x => (0, lexer_2.track)(x, { type: 'interval', value: (0, lexer_2.unbox)(x[1]) }) },
	        { "name": "simplestatements_set_names", "symbols": ["kw_names", "simplestatements_set_names_val"], "postprocess": x => (0, lexer_2.track)(x, { type: 'set names', to: x[1] }) },
	        { "name": "simplestatements_set_names_val$subexpression$1", "symbols": ["string"] },
	        { "name": "simplestatements_set_names_val", "symbols": ["simplestatements_set_names_val$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, { type: 'value', value: unwrap(x[0]) }) },
	        { "name": "simplestatements_set_simple$subexpression$1", "symbols": [(lexer_1.lexerAny.has("op_eq") ? { type: "op_eq" } : op_eq)] },
	        { "name": "simplestatements_set_simple$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_to") ? { type: "kw_to" } : kw_to)] },
	        { "name": "simplestatements_set_simple", "symbols": ["ident", "simplestatements_set_simple$subexpression$1", "simplestatements_set_val"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'set',
	                variable: asName(x[0]),
	                set: (0, lexer_2.unbox)(x[2]),
	            }) },
	        { "name": "simplestatements_set_val", "symbols": ["simplestatements_set_val_raw"], "postprocess": unwrap },
	        { "name": "simplestatements_set_val", "symbols": [(lexer_1.lexerAny.has("kw_default") ? { type: "kw_default" } : kw_default)], "postprocess": x => (0, lexer_2.track)(x, { type: 'default' }) },
	        { "name": "simplestatements_set_val$ebnf$1$subexpression$1", "symbols": ["comma", "simplestatements_set_val_raw"] },
	        { "name": "simplestatements_set_val$ebnf$1", "symbols": ["simplestatements_set_val$ebnf$1$subexpression$1"] },
	        { "name": "simplestatements_set_val$ebnf$1$subexpression$2", "symbols": ["comma", "simplestatements_set_val_raw"] },
	        { "name": "simplestatements_set_val$ebnf$1", "symbols": ["simplestatements_set_val$ebnf$1", "simplestatements_set_val$ebnf$1$subexpression$2"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "simplestatements_set_val", "symbols": ["simplestatements_set_val_raw", "simplestatements_set_val$ebnf$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'list',
	                values: [x[0], ...(x[1] || [])]
	            }) },
	        { "name": "simplestatements_set_val_raw$subexpression$1", "symbols": ["string"] },
	        { "name": "simplestatements_set_val_raw$subexpression$1", "symbols": ["int"] },
	        { "name": "simplestatements_set_val_raw", "symbols": ["simplestatements_set_val_raw$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, { type: 'value', value: unwrap(x) }) },
	        { "name": "simplestatements_set_val_raw$subexpression$2", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)] },
	        { "name": "simplestatements_set_val_raw$subexpression$2", "symbols": [(lexer_1.lexerAny.has("kw_on") ? { type: "kw_on" } : kw_on)] },
	        { "name": "simplestatements_set_val_raw$subexpression$2", "symbols": [(lexer_1.lexerAny.has("kw_true") ? { type: "kw_true" } : kw_true)] },
	        { "name": "simplestatements_set_val_raw$subexpression$2", "symbols": [(lexer_1.lexerAny.has("kw_false") ? { type: "kw_false" } : kw_false)] },
	        { "name": "simplestatements_set_val_raw", "symbols": ["simplestatements_set_val_raw$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, { type: 'identifier', name: unwrap(x).value }) },
	        { "name": "simplestatements_set_val_raw", "symbols": [(lexer_1.lexerAny.has("quoted_word") ? { type: "quoted_word" } : quoted_word)], "postprocess": x => (0, lexer_2.track)(x, { type: 'identifier', doubleQuoted: true, name: unwrap(x).value }) },
	        { "name": "simplestatements_show", "symbols": ["kw_show", "ident"], "postprocess": x => (0, lexer_2.track)(x, { type: 'show', variable: asName(x[1]) }) },
	        { "name": "create_schema$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_create") ? { type: "kw_create" } : kw_create), "kw_schema"] },
	        { "name": "create_schema$ebnf$1", "symbols": ["kw_ifnotexists"], "postprocess": id },
	        { "name": "create_schema$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "create_schema", "symbols": ["create_schema$subexpression$1", "create_schema$ebnf$1", "ident"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'create schema',
	                name: asName(x[2]),
	                ...!!x[1] ? { ifNotExists: true } : {},
	            }) },
	        { "name": "raise_statement$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": anyKw('debug', 'log', 'info', 'notice', 'warning', 'exception') },
	        { "name": "raise_statement$ebnf$1", "symbols": ["raise_statement$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "raise_statement$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "raise_statement$ebnf$2$subexpression$1", "symbols": ["comma", "expr_list_raw"], "postprocess": last },
	        { "name": "raise_statement$ebnf$2", "symbols": ["raise_statement$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "raise_statement$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "raise_statement$ebnf$3", "symbols": ["raise_using"], "postprocess": id },
	        { "name": "raise_statement$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "raise_statement", "symbols": ["kw_raise", "raise_statement$ebnf$1", "string", "raise_statement$ebnf$2", "raise_statement$ebnf$3"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'raise',
	                format: toStr(x[2]),
	                ...x[1] && { level: toStr(x[1]) },
	                ...x[3] && x[3].length && { formatExprs: x[3] },
	                ...x[4] && x[4].length && { using: x[4] },
	            }) },
	        { "name": "raise_using$macrocall$2", "symbols": ["raise_using_one"] },
	        { "name": "raise_using$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "raise_using$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "raise_using$macrocall$2"], "postprocess": last },
	        { "name": "raise_using$macrocall$1$ebnf$1", "symbols": ["raise_using$macrocall$1$ebnf$1", "raise_using$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "raise_using$macrocall$1", "symbols": ["raise_using$macrocall$2", "raise_using$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "raise_using", "symbols": [(lexer_1.lexerAny.has("kw_using") ? { type: "kw_using" } : kw_using), "raise_using$macrocall$1"], "postprocess": last },
	        { "name": "raise_using_one", "symbols": ["raise_using_what", (lexer_1.lexerAny.has("op_eq") ? { type: "op_eq" } : op_eq), "expr"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: toStr(x[0]),
	                value: x[2],
	            }) },
	        { "name": "raise_using_what", "symbols": [(lexer_1.lexerAny.has("kw_table") ? { type: "kw_table" } : kw_table)] },
	        { "name": "raise_using_what", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": anyKw('message', 'detail', 'hint', 'errcode', 'column', 'constraint', 'datatype', 'schema') },
	        { "name": "comment_statement", "symbols": ["kw_comment", (lexer_1.lexerAny.has("kw_on") ? { type: "kw_on" } : kw_on), "comment_what", (lexer_1.lexerAny.has("kw_is") ? { type: "kw_is" } : kw_is), "string"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'comment',
	                comment: (0, lexer_2.unbox)(last(x)),
	                on: unwrap(x[2]),
	            }) },
	        { "name": "comment_what", "symbols": ["comment_what_col"] },
	        { "name": "comment_what", "symbols": ["comment_what_nm"] },
	        { "name": "comment_what_nm$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_table") ? { type: "kw_table" } : kw_table)] },
	        { "name": "comment_what_nm$subexpression$1", "symbols": ["kw_materialized", "kw_view"] },
	        { "name": "comment_what_nm$subexpression$1", "symbols": [(lexer_1.lexerAny.has("word") ? { type: "word" } : word)], "postprocess": anyKw('database', 'index', 'trigger', 'type', 'view') },
	        { "name": "comment_what_nm", "symbols": ["comment_what_nm$subexpression$1", "qualified_name"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: toStr(x[0]),
	                name: x[1],
	            }) },
	        { "name": "comment_what_col", "symbols": ["kw_column", "qcolumn"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'column',
	                column: last(x),
	            }) },
	        { "name": "simplestatements_begin$ebnf$1$subexpression$1", "symbols": ["kw_transaction"] },
	        { "name": "simplestatements_begin$ebnf$1$subexpression$1", "symbols": ["kw_work"] },
	        { "name": "simplestatements_begin$ebnf$1", "symbols": ["simplestatements_begin$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "simplestatements_begin$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "simplestatements_begin$ebnf$2", "symbols": [] },
	        { "name": "simplestatements_begin$ebnf$2$subexpression$1", "symbols": ["simplestatements_begin_isol"] },
	        { "name": "simplestatements_begin$ebnf$2$subexpression$1", "symbols": ["simplestatements_begin_writ"] },
	        { "name": "simplestatements_begin$ebnf$2$subexpression$1", "symbols": ["simplestatements_begin_def"] },
	        { "name": "simplestatements_begin$ebnf$2", "symbols": ["simplestatements_begin$ebnf$2", "simplestatements_begin$ebnf$2$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "simplestatements_begin", "symbols": ["kw_begin", "simplestatements_begin$ebnf$1", "simplestatements_begin$ebnf$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'begin',
	                ...x[2].reduce((a, b) => ({ ...unwrap(a), ...unwrap(b) }), {}),
	            })
	        },
	        { "name": "simplestatements_begin_isol$subexpression$1", "symbols": ["kw_isolation", "kw_level"] },
	        { "name": "simplestatements_begin_isol$subexpression$2", "symbols": ["kw_serializable"] },
	        { "name": "simplestatements_begin_isol$subexpression$2$subexpression$1", "symbols": ["word"], "postprocess": kw('repeatable') },
	        { "name": "simplestatements_begin_isol$subexpression$2", "symbols": ["simplestatements_begin_isol$subexpression$2$subexpression$1", "kw_read"] },
	        { "name": "simplestatements_begin_isol$subexpression$2$subexpression$2", "symbols": ["word"], "postprocess": kw('committed') },
	        { "name": "simplestatements_begin_isol$subexpression$2", "symbols": ["kw_read", "simplestatements_begin_isol$subexpression$2$subexpression$2"] },
	        { "name": "simplestatements_begin_isol$subexpression$2$subexpression$3", "symbols": ["word"], "postprocess": kw('uncommitted') },
	        { "name": "simplestatements_begin_isol$subexpression$2", "symbols": ["kw_read", "simplestatements_begin_isol$subexpression$2$subexpression$3"] },
	        { "name": "simplestatements_begin_isol", "symbols": ["simplestatements_begin_isol$subexpression$1", "simplestatements_begin_isol$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                isolationLevel: toStr(x[1], ' '),
	            }) },
	        { "name": "simplestatements_begin_writ$subexpression$1", "symbols": ["kw_read", "kw_write"] },
	        { "name": "simplestatements_begin_writ$subexpression$1", "symbols": ["kw_read", (lexer_1.lexerAny.has("kw_only") ? { type: "kw_only" } : kw_only)] },
	        { "name": "simplestatements_begin_writ", "symbols": ["simplestatements_begin_writ$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                writeable: toStr(x, ' '),
	            }) },
	        { "name": "simplestatements_begin_def$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_not") ? { type: "kw_not" } : kw_not)], "postprocess": id },
	        { "name": "simplestatements_begin_def$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "simplestatements_begin_def", "symbols": ["simplestatements_begin_def$ebnf$1", (lexer_1.lexerAny.has("kw_deferrable") ? { type: "kw_deferrable" } : kw_deferrable)], "postprocess": x => (0, lexer_2.track)(x, {
	                deferrable: !x[0]
	            }) },
	        { "name": "insert_statement$subexpression$1", "symbols": ["kw_insert", (lexer_1.lexerAny.has("kw_into") ? { type: "kw_into" } : kw_into)] },
	        { "name": "insert_statement$ebnf$1", "symbols": ["collist_paren"], "postprocess": id },
	        { "name": "insert_statement$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "insert_statement$ebnf$2$subexpression$1$subexpression$1", "symbols": ["kw_system"] },
	        { "name": "insert_statement$ebnf$2$subexpression$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_user") ? { type: "kw_user" } : kw_user)] },
	        { "name": "insert_statement$ebnf$2$subexpression$1", "symbols": ["kw_overriding", "insert_statement$ebnf$2$subexpression$1$subexpression$1", "kw_value"], "postprocess": get(1) },
	        { "name": "insert_statement$ebnf$2", "symbols": ["insert_statement$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "insert_statement$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "insert_statement$ebnf$3$subexpression$1", "symbols": ["selection"] },
	        { "name": "insert_statement$ebnf$3$subexpression$1", "symbols": ["selection_paren"] },
	        { "name": "insert_statement$ebnf$3", "symbols": ["insert_statement$ebnf$3$subexpression$1"], "postprocess": id },
	        { "name": "insert_statement$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "insert_statement$ebnf$4$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_on") ? { type: "kw_on" } : kw_on), "kw_conflict", "insert_on_conflict"], "postprocess": last },
	        { "name": "insert_statement$ebnf$4", "symbols": ["insert_statement$ebnf$4$subexpression$1"], "postprocess": id },
	        { "name": "insert_statement$ebnf$4", "symbols": [], "postprocess": () => null },
	        { "name": "insert_statement$ebnf$5$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_returning") ? { type: "kw_returning" } : kw_returning), "select_expr_list_aliased"], "postprocess": last },
	        { "name": "insert_statement$ebnf$5", "symbols": ["insert_statement$ebnf$5$subexpression$1"], "postprocess": id },
	        { "name": "insert_statement$ebnf$5", "symbols": [], "postprocess": () => null },
	        { "name": "insert_statement", "symbols": ["insert_statement$subexpression$1", "table_ref_aliased", "insert_statement$ebnf$1", "insert_statement$ebnf$2", "insert_statement$ebnf$3", "insert_statement$ebnf$4", "insert_statement$ebnf$5"], "postprocess": x => {
	                const columns = x[2] && x[2].map(asName);
	                const overriding = toStr(x[3]);
	                const insert = unwrap(x[4]);
	                const onConflict = x[5];
	                const returning = x[6];
	                return (0, lexer_2.track)(x, {
	                    type: 'insert',
	                    into: unwrap(x[1]),
	                    insert,
	                    ...overriding && { overriding },
	                    ...columns && { columns },
	                    ...returning && { returning },
	                    ...onConflict && { onConflict },
	                });
	            } },
	        { "name": "insert_values$ebnf$1", "symbols": [] },
	        { "name": "insert_values$ebnf$1$subexpression$1", "symbols": ["comma", "insert_value"], "postprocess": last },
	        { "name": "insert_values$ebnf$1", "symbols": ["insert_values$ebnf$1", "insert_values$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "insert_values", "symbols": ["insert_value", "insert_values$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "insert_value", "symbols": ["lparen", "insert_expr_list_raw", "rparen"], "postprocess": get(1) },
	        { "name": "insert_expr_list_raw$ebnf$1", "symbols": [] },
	        { "name": "insert_expr_list_raw$ebnf$1$subexpression$1", "symbols": ["comma", "expr_or_select"], "postprocess": last },
	        { "name": "insert_expr_list_raw$ebnf$1", "symbols": ["insert_expr_list_raw$ebnf$1", "insert_expr_list_raw$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "insert_expr_list_raw", "symbols": ["expr_or_select", "insert_expr_list_raw$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "insert_on_conflict$ebnf$1", "symbols": ["insert_on_conflict_what"], "postprocess": id },
	        { "name": "insert_on_conflict$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "insert_on_conflict", "symbols": ["insert_on_conflict$ebnf$1", "insert_on_conflict_do"], "postprocess": x => (0, lexer_2.track)(x, {
	                ...x[0] ? { on: unwrap(x[0]) } : {},
	                ...x[1],
	            }) },
	        { "name": "insert_on_conflict_what", "symbols": ["lparen", "expr_list_raw", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'on expr',
	                exprs: x[1],
	            }) },
	        { "name": "insert_on_conflict_what", "symbols": [(lexer_1.lexerAny.has("kw_on") ? { type: "kw_on" } : kw_on), (lexer_1.lexerAny.has("kw_constraint") ? { type: "kw_constraint" } : kw_constraint), "qname"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'on constraint',
	                constraint: last(x),
	            }) },
	        { "name": "insert_on_conflict_do", "symbols": [(lexer_1.lexerAny.has("kw_do") ? { type: "kw_do" } : kw_do), "kw_nothing"], "postprocess": x => ({ do: 'do nothing' }) },
	        { "name": "insert_on_conflict_do$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_do") ? { type: "kw_do" } : kw_do), "kw_update", "kw_set"] },
	        { "name": "insert_on_conflict_do$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_where") ? { type: "kw_where" } : kw_where), "expr"], "postprocess": last },
	        { "name": "insert_on_conflict_do$ebnf$1", "symbols": ["insert_on_conflict_do$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "insert_on_conflict_do$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "insert_on_conflict_do", "symbols": ["insert_on_conflict_do$subexpression$1", "update_set_list", "insert_on_conflict_do$ebnf$1"], "postprocess": x => ({
	                do: { sets: x[1] },
	                ...x[2] && { where: x[2] },
	            }) },
	        { "name": "update_statement$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_from") ? { type: "kw_from" } : kw_from), "select_from_subject"], "postprocess": last },
	        { "name": "update_statement$ebnf$1", "symbols": ["update_statement$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "update_statement$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "update_statement$ebnf$2", "symbols": ["select_where"], "postprocess": id },
	        { "name": "update_statement$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "update_statement$ebnf$3$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_returning") ? { type: "kw_returning" } : kw_returning), "select_expr_list_aliased"], "postprocess": last },
	        { "name": "update_statement$ebnf$3", "symbols": ["update_statement$ebnf$3$subexpression$1"], "postprocess": id },
	        { "name": "update_statement$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "update_statement", "symbols": ["kw_update", "table_ref_aliased", "kw_set", "update_set_list", "update_statement$ebnf$1", "update_statement$ebnf$2", "update_statement$ebnf$3"], "postprocess": x => {
	                const from = unwrap(x[4]);
	                const where = unwrap(x[5]);
	                const returning = x[6];
	                return (0, lexer_2.track)(x, {
	                    type: 'update',
	                    table: unwrap(x[1]),
	                    sets: x[3],
	                    ...where ? { where } : {},
	                    ...from ? { from } : {},
	                    ...returning ? { returning } : {},
	                });
	            } },
	        { "name": "update_set_list$ebnf$1", "symbols": [] },
	        { "name": "update_set_list$ebnf$1$subexpression$1", "symbols": ["comma", "update_set"], "postprocess": last },
	        { "name": "update_set_list$ebnf$1", "symbols": ["update_set_list$ebnf$1", "update_set_list$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "update_set_list", "symbols": ["update_set", "update_set_list$ebnf$1"], "postprocess": ([head, tail]) => {
	                const ret = [];
	                for (const _t of [head, ...(tail || [])]) {
	                    const t = unwrap(_t);
	                    if (Array.isArray(t)) {
	                        ret.push(...t);
	                    }
	                    else {
	                        ret.push(t);
	                    }
	                }
	                return ret;
	            } },
	        { "name": "update_set", "symbols": ["update_set_one"] },
	        { "name": "update_set", "symbols": ["update_set_multiple"] },
	        { "name": "update_set_one", "symbols": ["ident", (lexer_1.lexerAny.has("op_eq") ? { type: "op_eq" } : op_eq), "expr"], "postprocess": x => (0, lexer_2.box)(x, {
	                column: asName(x[0]),
	                value: unwrap(x[2]),
	            }) },
	        { "name": "update_set_multiple$subexpression$1", "symbols": ["lparen", "expr_list_raw", "rparen"], "postprocess": get(1) },
	        { "name": "update_set_multiple", "symbols": ["collist_paren", (lexer_1.lexerAny.has("op_eq") ? { type: "op_eq" } : op_eq), "update_set_multiple$subexpression$1"], "postprocess": x => {
	                const cols = x[0];
	                const exprs = x[2];
	                if (cols.length !== exprs.length) {
	                    throw new Error('number of columns does not match number of values');
	                }
	                return (0, lexer_2.box)(x, cols.map((x, i) => ({
	                    column: asName(x),
	                    value: unwrap(exprs[i]),
	                })));
	            } },
	        { "name": "altertable_statement$ebnf$1", "symbols": ["kw_ifexists"], "postprocess": id },
	        { "name": "altertable_statement$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "altertable_statement$ebnf$2", "symbols": [(lexer_1.lexerAny.has("kw_only") ? { type: "kw_only" } : kw_only)], "postprocess": id },
	        { "name": "altertable_statement$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "altertable_statement", "symbols": ["kw_alter", (lexer_1.lexerAny.has("kw_table") ? { type: "kw_table" } : kw_table), "altertable_statement$ebnf$1", "altertable_statement$ebnf$2", "table_ref", "altertable_actions"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'alter table',
	                ...x[2] ? { ifExists: true } : {},
	                ...x[3] ? { only: true } : {},
	                table: unwrap(x[4]),
	                changes: (0, lexer_2.unbox)(x[5]).map(unwrap),
	            }) },
	        { "name": "altertable_actions$ebnf$1", "symbols": [] },
	        { "name": "altertable_actions$ebnf$1$subexpression$1", "symbols": ["comma", "altertable_action"], "postprocess": last },
	        { "name": "altertable_actions$ebnf$1", "symbols": ["altertable_actions$ebnf$1", "altertable_actions$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "altertable_actions", "symbols": ["altertable_action", "altertable_actions$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "altertable_action", "symbols": ["altertable_rename_table"] },
	        { "name": "altertable_action", "symbols": ["altertable_rename_column"] },
	        { "name": "altertable_action", "symbols": ["altertable_rename_constraint"] },
	        { "name": "altertable_action", "symbols": ["altertable_add_column"] },
	        { "name": "altertable_action", "symbols": ["altertable_drop_column"] },
	        { "name": "altertable_action", "symbols": ["altertable_alter_column"] },
	        { "name": "altertable_action", "symbols": ["altertable_add_constraint"] },
	        { "name": "altertable_action", "symbols": ["altertable_drop_constraint"] },
	        { "name": "altertable_action", "symbols": ["altertable_owner"] },
	        { "name": "altertable_rename_table", "symbols": ["kw_rename", (lexer_1.lexerAny.has("kw_to") ? { type: "kw_to" } : kw_to), "word"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'rename',
	                to: asName(last(x)),
	            }) },
	        { "name": "altertable_rename_column$ebnf$1", "symbols": ["kw_column"], "postprocess": id },
	        { "name": "altertable_rename_column$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "altertable_rename_column", "symbols": ["kw_rename", "altertable_rename_column$ebnf$1", "ident", (lexer_1.lexerAny.has("kw_to") ? { type: "kw_to" } : kw_to), "ident"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'rename column',
	                column: asName(x[2]),
	                to: asName(last(x)),
	            }) },
	        { "name": "altertable_rename_constraint", "symbols": ["kw_rename", (lexer_1.lexerAny.has("kw_constraint") ? { type: "kw_constraint" } : kw_constraint), "ident", (lexer_1.lexerAny.has("kw_to") ? { type: "kw_to" } : kw_to), "ident"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'rename constraint',
	                constraint: asName(x[2]),
	                to: asName(last(x)),
	            }) },
	        { "name": "altertable_add_column$ebnf$1", "symbols": ["kw_column"], "postprocess": id },
	        { "name": "altertable_add_column$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "altertable_add_column$ebnf$2", "symbols": ["kw_ifnotexists"], "postprocess": id },
	        { "name": "altertable_add_column$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "altertable_add_column", "symbols": ["kw_add", "altertable_add_column$ebnf$1", "altertable_add_column$ebnf$2", "createtable_column"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'add column',
	                ...x[2] ? { ifNotExists: true } : {},
	                column: unwrap(x[3]),
	            }) },
	        { "name": "altertable_drop_column$ebnf$1", "symbols": ["kw_column"], "postprocess": id },
	        { "name": "altertable_drop_column$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "altertable_drop_column$ebnf$2", "symbols": ["kw_ifexists"], "postprocess": id },
	        { "name": "altertable_drop_column$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "altertable_drop_column$ebnf$3$subexpression$1", "symbols": ["kw_restrict"] },
	        { "name": "altertable_drop_column$ebnf$3$subexpression$1", "symbols": ["kw_cascade"] },
	        { "name": "altertable_drop_column$ebnf$3", "symbols": ["altertable_drop_column$ebnf$3$subexpression$1"], "postprocess": id },
	        { "name": "altertable_drop_column$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "altertable_drop_column", "symbols": ["kw_drop", "altertable_drop_column$ebnf$1", "altertable_drop_column$ebnf$2", "ident", "altertable_drop_column$ebnf$3"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'drop column',
	                ...x[2] ? { ifExists: true } : {},
	                column: asName(x[3]),
	                ...x[4] ? { behaviour: toStr(x[4], ' ') } : {},
	            }) },
	        { "name": "altertable_alter_column$ebnf$1", "symbols": ["kw_column"], "postprocess": id },
	        { "name": "altertable_alter_column$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "altertable_alter_column", "symbols": ["kw_alter", "altertable_alter_column$ebnf$1", "ident", "altercol"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'alter column',
	                column: asName(x[2]),
	                alter: unwrap(x[3])
	            }) },
	        { "name": "altercol$ebnf$1$subexpression$1", "symbols": ["kw_set", "kw_data"] },
	        { "name": "altercol$ebnf$1", "symbols": ["altercol$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "altercol$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "altercol", "symbols": ["altercol$ebnf$1", "kw_type", "data_type"], "postprocess": x => (0, lexer_2.track)(x, { type: 'set type', dataType: unwrap(last(x)) }) },
	        { "name": "altercol", "symbols": ["kw_set", (lexer_1.lexerAny.has("kw_default") ? { type: "kw_default" } : kw_default), "expr"], "postprocess": x => (0, lexer_2.track)(x, { type: 'set default', default: unwrap(last(x)) }) },
	        { "name": "altercol", "symbols": ["kw_drop", (lexer_1.lexerAny.has("kw_default") ? { type: "kw_default" } : kw_default)], "postprocess": x => (0, lexer_2.track)(x, { type: 'drop default' }) },
	        { "name": "altercol$subexpression$1", "symbols": ["kw_set"] },
	        { "name": "altercol$subexpression$1", "symbols": ["kw_drop"] },
	        { "name": "altercol", "symbols": ["altercol$subexpression$1", "kw_not_null"], "postprocess": x => (0, lexer_2.track)(x, { type: toStr(x, ' ') }) },
	        { "name": "altercol", "symbols": ["altercol_generated_add"], "postprocess": unwrap },
	        { "name": "altertable_add_constraint", "symbols": ["kw_add", "createtable_constraint"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'add constraint',
	                constraint: unwrap(last(x)),
	            }) },
	        { "name": "altertable_drop_constraint$ebnf$1", "symbols": ["kw_ifexists"], "postprocess": id },
	        { "name": "altertable_drop_constraint$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "altertable_drop_constraint$ebnf$2$subexpression$1", "symbols": ["kw_restrict"] },
	        { "name": "altertable_drop_constraint$ebnf$2$subexpression$1", "symbols": ["kw_cascade"] },
	        { "name": "altertable_drop_constraint$ebnf$2", "symbols": ["altertable_drop_constraint$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "altertable_drop_constraint$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "altertable_drop_constraint", "symbols": ["kw_drop", (lexer_1.lexerAny.has("kw_constraint") ? { type: "kw_constraint" } : kw_constraint), "altertable_drop_constraint$ebnf$1", "ident", "altertable_drop_constraint$ebnf$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'drop constraint',
	                ...x[2] ? { ifExists: true } : {},
	                constraint: asName(x[3]),
	                ...x[4] ? { behaviour: toStr(x[4], ' ') } : {},
	            }) },
	        { "name": "altertable_owner", "symbols": ["kw_owner", (lexer_1.lexerAny.has("kw_to") ? { type: "kw_to" } : kw_to), "ident"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'owner',
	                to: asName(last(x)),
	            }) },
	        { "name": "altercol_generated_add", "symbols": ["kw_add", "altercol_generated"], "postprocess": last },
	        { "name": "altercol_generated$ebnf$1$subexpression$1", "symbols": ["kw_always"] },
	        { "name": "altercol_generated$ebnf$1$subexpression$1", "symbols": ["kw_by", (lexer_1.lexerAny.has("kw_default") ? { type: "kw_default" } : kw_default)] },
	        { "name": "altercol_generated$ebnf$1", "symbols": ["altercol_generated$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "altercol_generated$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "altercol_generated$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as), "kw_identity"] },
	        { "name": "altercol_generated$ebnf$2$subexpression$1", "symbols": ["lparen", "altercol_generated_seq", "rparen"], "postprocess": get(1) },
	        { "name": "altercol_generated$ebnf$2", "symbols": ["altercol_generated$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "altercol_generated$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "altercol_generated", "symbols": ["kw_generated", "altercol_generated$ebnf$1", "altercol_generated$subexpression$1", "altercol_generated$ebnf$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'add generated',
	                ...x[1] && { always: toStr(x[1], ' ') },
	                ...x[3] && { sequence: unwrap(x[3]) },
	            }) },
	        { "name": "altercol_generated_seq$ebnf$1$subexpression$1", "symbols": ["kw_sequence", "kw_name", "qualified_name"] },
	        { "name": "altercol_generated_seq$ebnf$1", "symbols": ["altercol_generated_seq$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "altercol_generated_seq$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "altercol_generated_seq$ebnf$2", "symbols": [] },
	        { "name": "altercol_generated_seq$ebnf$2", "symbols": ["altercol_generated_seq$ebnf$2", "create_sequence_option"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "altercol_generated_seq", "symbols": ["altercol_generated_seq$ebnf$1", "altercol_generated_seq$ebnf$2"], "postprocess": x => {
	                const ret = {
	                    ...x[0] && { name: unwrap(last(x[0])) },
	                };
	                setSeqOpts(ret, x[1]);
	                return (0, lexer_2.track)(x, ret);
	            } },
	        { "name": "alterindex_statement$ebnf$1", "symbols": ["kw_ifexists"], "postprocess": id },
	        { "name": "alterindex_statement$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "alterindex_statement", "symbols": ["kw_alter", "kw_index", "alterindex_statement$ebnf$1", "table_ref", "alterindex_action"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'alter index',
	                ...x[2] ? { ifExists: true } : {},
	                index: unwrap(x[3]),
	                change: unwrap(x[4]),
	            }) },
	        { "name": "alterindex_action", "symbols": ["alterindex_rename"] },
	        { "name": "alterindex_action", "symbols": ["alterindex_set_tablespace"] },
	        { "name": "alterindex_rename", "symbols": ["kw_rename", (lexer_1.lexerAny.has("kw_to") ? { type: "kw_to" } : kw_to), "word"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'rename',
	                to: asName(last(x)),
	            }) },
	        { "name": "alterindex_set_tablespace", "symbols": ["kw_set", "kw_tablespace", "word"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'set tablespace',
	                tablespace: asName(last(x)),
	            }) },
	        { "name": "delete_statement", "symbols": ["delete_delete"] },
	        { "name": "delete_statement", "symbols": ["delete_truncate"] },
	        { "name": "delete_delete$subexpression$1", "symbols": ["kw_delete", (lexer_1.lexerAny.has("kw_from") ? { type: "kw_from" } : kw_from)] },
	        { "name": "delete_delete$ebnf$1", "symbols": ["select_where"], "postprocess": id },
	        { "name": "delete_delete$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "delete_delete$ebnf$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_returning") ? { type: "kw_returning" } : kw_returning), "select_expr_list_aliased"], "postprocess": last },
	        { "name": "delete_delete$ebnf$2", "symbols": ["delete_delete$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "delete_delete$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "delete_delete", "symbols": ["delete_delete$subexpression$1", "table_ref_aliased", "delete_delete$ebnf$1", "delete_delete$ebnf$2"], "postprocess": x => {
	                const where = x[2];
	                const returning = x[3];
	                return (0, lexer_2.track)(x, {
	                    type: 'delete',
	                    from: unwrap(x[1]),
	                    ...where ? { where } : {},
	                    ...returning ? { returning } : {},
	                });
	            } },
	        { "name": "delete_truncate$subexpression$1$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_table") ? { type: "kw_table" } : kw_table)], "postprocess": id },
	        { "name": "delete_truncate$subexpression$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "delete_truncate$subexpression$1", "symbols": ["kw_truncate", "delete_truncate$subexpression$1$ebnf$1"] },
	        { "name": "delete_truncate$macrocall$2", "symbols": ["table_ref"] },
	        { "name": "delete_truncate$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "delete_truncate$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "delete_truncate$macrocall$2"], "postprocess": last },
	        { "name": "delete_truncate$macrocall$1$ebnf$1", "symbols": ["delete_truncate$macrocall$1$ebnf$1", "delete_truncate$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "delete_truncate$macrocall$1", "symbols": ["delete_truncate$macrocall$2", "delete_truncate$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "delete_truncate$ebnf$1$subexpression$1$subexpression$1", "symbols": ["kw_restart"] },
	        { "name": "delete_truncate$ebnf$1$subexpression$1$subexpression$1", "symbols": ["kw_continue"] },
	        { "name": "delete_truncate$ebnf$1$subexpression$1", "symbols": ["delete_truncate$ebnf$1$subexpression$1$subexpression$1", "kw_identity"] },
	        { "name": "delete_truncate$ebnf$1", "symbols": ["delete_truncate$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "delete_truncate$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "delete_truncate$ebnf$2$subexpression$1", "symbols": ["kw_restrict"] },
	        { "name": "delete_truncate$ebnf$2$subexpression$1", "symbols": ["kw_cascade"] },
	        { "name": "delete_truncate$ebnf$2", "symbols": ["delete_truncate$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "delete_truncate$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "delete_truncate", "symbols": ["delete_truncate$subexpression$1", "delete_truncate$macrocall$1", "delete_truncate$ebnf$1", "delete_truncate$ebnf$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'truncate table',
	                tables: x[1],
	                ...x[2] && { identity: toStr(x[2][0]) },
	                ...x[3] && { cascade: toStr(x[3]) },
	            }) },
	        { "name": "create_sequence_statement$ebnf$1$subexpression$1", "symbols": ["kw_temp"] },
	        { "name": "create_sequence_statement$ebnf$1$subexpression$1", "symbols": ["kw_temporary"] },
	        { "name": "create_sequence_statement$ebnf$1", "symbols": ["create_sequence_statement$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "create_sequence_statement$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "create_sequence_statement$ebnf$2", "symbols": ["kw_ifnotexists"], "postprocess": id },
	        { "name": "create_sequence_statement$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "create_sequence_statement$ebnf$3", "symbols": [] },
	        { "name": "create_sequence_statement$ebnf$3", "symbols": ["create_sequence_statement$ebnf$3", "create_sequence_option"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "create_sequence_statement", "symbols": [(lexer_1.lexerAny.has("kw_create") ? { type: "kw_create" } : kw_create), "create_sequence_statement$ebnf$1", "kw_sequence", "create_sequence_statement$ebnf$2", "qualified_name", "create_sequence_statement$ebnf$3"], "postprocess": x => {
	                const ret = {
	                    type: 'create sequence',
	                    ...x[1] && { temp: true },
	                    ...x[3] && { ifNotExists: true },
	                    name: unwrap(x[4]),
	                    options: {},
	                };
	                setSeqOpts(ret.options, x[5]);
	                return (0, lexer_2.track)(x, ret);
	            } },
	        { "name": "create_sequence_option", "symbols": [(lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as), "data_type"], "postprocess": x => (0, lexer_2.box)(x, ['as', x[1]]) },
	        { "name": "create_sequence_option$ebnf$1", "symbols": ["kw_by"], "postprocess": id },
	        { "name": "create_sequence_option$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "create_sequence_option", "symbols": ["kw_increment", "create_sequence_option$ebnf$1", "int"], "postprocess": x => (0, lexer_2.box)(x, ['incrementBy', x[2]]) },
	        { "name": "create_sequence_option", "symbols": ["create_sequence_minvalue"], "postprocess": x => (0, lexer_2.box)(x, ['minValue', x[0]]) },
	        { "name": "create_sequence_option", "symbols": ["create_sequence_maxvalue"], "postprocess": x => (0, lexer_2.box)(x, ['maxValue', x[0]]) },
	        { "name": "create_sequence_option$ebnf$2", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with)], "postprocess": id },
	        { "name": "create_sequence_option$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "create_sequence_option", "symbols": ["kw_start", "create_sequence_option$ebnf$2", "int"], "postprocess": x => (0, lexer_2.box)(x, ['startWith', x[2]]) },
	        { "name": "create_sequence_option", "symbols": ["kw_cache", "int"], "postprocess": x => (0, lexer_2.box)(x, ['cache', x[1]]) },
	        { "name": "create_sequence_option$ebnf$3", "symbols": ["kw_no"], "postprocess": id },
	        { "name": "create_sequence_option$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "create_sequence_option", "symbols": ["create_sequence_option$ebnf$3", "kw_cycle"], "postprocess": x => (0, lexer_2.box)(x, ['cycle', toStr(x, ' ')]) },
	        { "name": "create_sequence_option", "symbols": ["create_sequence_owned_by"], "postprocess": x => (0, lexer_2.box)(x, ['ownedBy', unwrap(x)]) },
	        { "name": "create_sequence_minvalue", "symbols": ["kw_minvalue", "int"], "postprocess": last },
	        { "name": "create_sequence_minvalue", "symbols": ["kw_no", "kw_minvalue"], "postprocess": x => (0, lexer_2.box)(x, 'no minvalue') },
	        { "name": "create_sequence_maxvalue", "symbols": ["kw_maxvalue", "int"], "postprocess": last },
	        { "name": "create_sequence_maxvalue", "symbols": ["kw_no", "kw_maxvalue"], "postprocess": x => (0, lexer_2.box)(x, 'no maxvalue') },
	        { "name": "create_sequence_owned_by$subexpression$1", "symbols": ["kw_none"] },
	        { "name": "create_sequence_owned_by$subexpression$1", "symbols": ["qcolumn"] },
	        { "name": "create_sequence_owned_by", "symbols": ["kw_owned", "kw_by", "create_sequence_owned_by$subexpression$1"], "postprocess": x => (0, lexer_2.box)(x, unwrap(last(x))) },
	        { "name": "alter_sequence_statement$ebnf$1", "symbols": ["kw_ifexists"], "postprocess": id },
	        { "name": "alter_sequence_statement$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "alter_sequence_statement", "symbols": ["kw_alter", "kw_sequence", "alter_sequence_statement$ebnf$1", "qualified_name", "alter_sequence_statement_body"], "postprocess": x => {
	                const ret = {
	                    type: 'alter sequence',
	                    ...x[2] && { ifExists: true },
	                    name: unwrap(x[3]),
	                    change: x[4],
	                };
	                return (0, lexer_2.track)(x, ret);
	            } },
	        { "name": "alter_sequence_statement_body$ebnf$1", "symbols": ["alter_sequence_option"] },
	        { "name": "alter_sequence_statement_body$ebnf$1", "symbols": ["alter_sequence_statement_body$ebnf$1", "alter_sequence_option"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "alter_sequence_statement_body", "symbols": ["alter_sequence_statement_body$ebnf$1"], "postprocess": x => {
	                const ret = {
	                    type: 'set options',
	                };
	                setSeqOpts(ret, x[0]);
	                return (0, lexer_2.track)(x, ret);
	            } },
	        { "name": "alter_sequence_statement_body$subexpression$1", "symbols": ["ident"] },
	        { "name": "alter_sequence_statement_body$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_session_user") ? { type: "kw_session_user" } : kw_session_user)] },
	        { "name": "alter_sequence_statement_body$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_current_user") ? { type: "kw_current_user" } : kw_current_user)] },
	        { "name": "alter_sequence_statement_body", "symbols": ["kw_owner", (lexer_1.lexerAny.has("kw_to") ? { type: "kw_to" } : kw_to), "alter_sequence_statement_body$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, { type: 'owner to', owner: asName(last(x)), }) },
	        { "name": "alter_sequence_statement_body", "symbols": ["kw_rename", (lexer_1.lexerAny.has("kw_to") ? { type: "kw_to" } : kw_to), "ident"], "postprocess": x => (0, lexer_2.track)(x, { type: 'rename', newName: asName(last(x)) }) },
	        { "name": "alter_sequence_statement_body", "symbols": ["kw_set", "kw_schema", "ident"], "postprocess": x => (0, lexer_2.track)(x, { type: 'set schema', newSchema: asName(last(x)) }) },
	        { "name": "alter_sequence_option", "symbols": ["create_sequence_option"], "postprocess": unwrap },
	        { "name": "alter_sequence_option$ebnf$1$subexpression$1$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with)], "postprocess": id },
	        { "name": "alter_sequence_option$ebnf$1$subexpression$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "alter_sequence_option$ebnf$1$subexpression$1", "symbols": ["alter_sequence_option$ebnf$1$subexpression$1$ebnf$1", "int"], "postprocess": last },
	        { "name": "alter_sequence_option$ebnf$1", "symbols": ["alter_sequence_option$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "alter_sequence_option$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "alter_sequence_option", "symbols": ["kw_restart", "alter_sequence_option$ebnf$1"], "postprocess": x => (0, lexer_2.box)(x, ['restart', typeof (0, lexer_2.unbox)(x[1]) === 'number' ? (0, lexer_2.unbox)(x[1]) : true]) },
	        { "name": "drop_statement$ebnf$1", "symbols": ["kw_ifexists"], "postprocess": id },
	        { "name": "drop_statement$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "drop_statement$macrocall$2", "symbols": ["qualified_name"] },
	        { "name": "drop_statement$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "drop_statement$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "drop_statement$macrocall$2"], "postprocess": last },
	        { "name": "drop_statement$macrocall$1$ebnf$1", "symbols": ["drop_statement$macrocall$1$ebnf$1", "drop_statement$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "drop_statement$macrocall$1", "symbols": ["drop_statement$macrocall$2", "drop_statement$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "drop_statement$ebnf$2$subexpression$1", "symbols": ["kw_cascade"] },
	        { "name": "drop_statement$ebnf$2$subexpression$1", "symbols": ["kw_restrict"] },
	        { "name": "drop_statement$ebnf$2", "symbols": ["drop_statement$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "drop_statement$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "drop_statement", "symbols": ["kw_drop", "drop_what", "drop_statement$ebnf$1", "drop_statement$macrocall$1", "drop_statement$ebnf$2"], "postprocess": (x, rej) => {
	                const v = unwrap(x[1]);
	                return (0, lexer_2.track)(x, {
	                    ...v,
	                    ...x[2] && { ifExists: true },
	                    names: x[3],
	                    ...x[4] && { cascade: toStr(x[4]) },
	                });
	            } },
	        { "name": "drop_what", "symbols": [(lexer_1.lexerAny.has("kw_table") ? { type: "kw_table" } : kw_table)], "postprocess": x => (0, lexer_2.track)(x, { type: 'drop table' }) },
	        { "name": "drop_what", "symbols": ["kw_sequence"], "postprocess": x => (0, lexer_2.track)(x, { type: 'drop sequence' }) },
	        { "name": "drop_what", "symbols": ["kw_type"], "postprocess": x => (0, lexer_2.track)(x, { type: 'drop type' }) },
	        { "name": "drop_what", "symbols": ["kw_trigger"], "postprocess": x => (0, lexer_2.track)(x, { type: 'drop trigger' }) },
	        { "name": "drop_what$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_concurrently") ? { type: "kw_concurrently" } : kw_concurrently)], "postprocess": id },
	        { "name": "drop_what$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "drop_what", "symbols": ["kw_index", "drop_what$ebnf$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'drop index',
	                ...x[1] && { concurrently: true },
	            }) },
	        { "name": "with_statement", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with), "with_statement_bindings", "with_statement_statement"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'with',
	                bind: x[1],
	                in: unwrap(x[2]),
	            }) },
	        { "name": "with_recursive_statement$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with), "kw_recursive"] },
	        { "name": "with_recursive_statement", "symbols": ["with_recursive_statement$subexpression$1", "ident", "collist_paren", (lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as), "lparen", "union_statement", "rparen", "with_statement_statement"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'with recursive',
	                alias: asName(x[1]),
	                columnNames: x[2].map(asName),
	                bind: x[5],
	                in: unwrap(x[7]),
	            }) },
	        { "name": "with_statement_bindings$ebnf$1", "symbols": [] },
	        { "name": "with_statement_bindings$ebnf$1$subexpression$1", "symbols": ["comma", "with_statement_binding"], "postprocess": last },
	        { "name": "with_statement_bindings$ebnf$1", "symbols": ["with_statement_bindings$ebnf$1", "with_statement_bindings$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "with_statement_bindings", "symbols": ["with_statement_binding", "with_statement_bindings$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "with_statement_binding", "symbols": ["word", (lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as), "lparen", "with_statement_statement", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                alias: asName(x[0]),
	                statement: unwrap(x[3]),
	            }) },
	        { "name": "with_statement_statement", "symbols": ["selection"] },
	        { "name": "with_statement_statement", "symbols": ["insert_statement"] },
	        { "name": "with_statement_statement", "symbols": ["update_statement"] },
	        { "name": "with_statement_statement", "symbols": ["delete_statement"] },
	        { "name": "createtype_statement$subexpression$1", "symbols": ["createtype_enum"] },
	        { "name": "createtype_statement$subexpression$1", "symbols": ["createtype_composite"] },
	        { "name": "createtype_statement", "symbols": [(lexer_1.lexerAny.has("kw_create") ? { type: "kw_create" } : kw_create), "kw_type", "qualified_name", "createtype_statement$subexpression$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                name: x[2],
	                ...unwrap(x[3]),
	            }) },
	        { "name": "createtype_enum$macrocall$2", "symbols": ["enum_value"] },
	        { "name": "createtype_enum$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "createtype_enum$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "createtype_enum$macrocall$2"], "postprocess": last },
	        { "name": "createtype_enum$macrocall$1$ebnf$1", "symbols": ["createtype_enum$macrocall$1$ebnf$1", "createtype_enum$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "createtype_enum$macrocall$1", "symbols": ["createtype_enum$macrocall$2", "createtype_enum$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "createtype_enum", "symbols": [(lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as), "kw_enum", "lparen", "createtype_enum$macrocall$1", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'create enum',
	                values: x[3],
	            }) },
	        { "name": "enum_value", "symbols": ["string"], "postprocess": x => (0, lexer_2.track)(x, { value: toStr(x) }) },
	        { "name": "createtype_composite$macrocall$2", "symbols": ["createtype_composite_attr"] },
	        { "name": "createtype_composite$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "createtype_composite$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "createtype_composite$macrocall$2"], "postprocess": last },
	        { "name": "createtype_composite$macrocall$1$ebnf$1", "symbols": ["createtype_composite$macrocall$1$ebnf$1", "createtype_composite$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "createtype_composite$macrocall$1", "symbols": ["createtype_composite$macrocall$2", "createtype_composite$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "createtype_composite", "symbols": [(lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as), "lparen", "createtype_composite$macrocall$1", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'create composite type',
	                attributes: x[2],
	            }) },
	        { "name": "createtype_composite_attr$ebnf$1", "symbols": ["createtable_collate"], "postprocess": id },
	        { "name": "createtype_composite_attr$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "createtype_composite_attr", "symbols": ["word", "data_type", "createtype_composite_attr$ebnf$1"], "postprocess": x => {
	                return (0, lexer_2.track)(x, {
	                    name: asName(x[0]),
	                    dataType: x[1],
	                    ...x[2] ? { collate: x[2][1] } : {},
	                });
	            } },
	        { "name": "union_left", "symbols": ["select_statement"] },
	        { "name": "union_left", "symbols": ["select_values"] },
	        { "name": "union_left", "symbols": ["selection_paren"] },
	        { "name": "union_right", "symbols": ["selection"] },
	        { "name": "union_right", "symbols": ["selection_paren"] },
	        { "name": "union_statement$subexpression$1$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_all") ? { type: "kw_all" } : kw_all)], "postprocess": id },
	        { "name": "union_statement$subexpression$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "union_statement$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_union") ? { type: "kw_union" } : kw_union), "union_statement$subexpression$1$ebnf$1"] },
	        { "name": "union_statement", "symbols": ["union_left", "union_statement$subexpression$1", "union_right"], "postprocess": x => {
	                return (0, lexer_2.track)(x, {
	                    type: toStr(x[1], ' '),
	                    left: unwrap(x[0]),
	                    right: unwrap(x[2]),
	                });
	            } },
	        { "name": "prepare$ebnf$1$subexpression$1", "symbols": ["lparen", "data_type_list", "rparen"], "postprocess": get(1) },
	        { "name": "prepare$ebnf$1", "symbols": ["prepare$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "prepare$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "prepare", "symbols": ["kw_prepare", "ident", "prepare$ebnf$1", (lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as), "statement_noprep"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'prepare',
	                name: asName(x[1]),
	                ...x[2] && { args: x[2] },
	                statement: unwrap(last(x)),
	            }) },
	        { "name": "deallocate$ebnf$1", "symbols": ["kw_prepare"], "postprocess": id },
	        { "name": "deallocate$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "deallocate", "symbols": ["kw_deallocate", "deallocate$ebnf$1", "deallocate_target"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'deallocate',
	                target: x[2],
	            }) },
	        { "name": "deallocate_target", "symbols": ["deallocate_all"], "postprocess": unwrap },
	        { "name": "deallocate_target", "symbols": ["deallocate_name"], "postprocess": unwrap },
	        { "name": "deallocate_name", "symbols": ["ident"], "postprocess": x => (0, lexer_2.track)(x, asName(x[0])) },
	        { "name": "deallocate_all", "symbols": [(lexer_1.lexerAny.has("kw_all") ? { type: "kw_all" } : kw_all)], "postprocess": x => (0, lexer_2.track)(x, { option: 'all' }) },
	        { "name": "create_view_statements", "symbols": ["create_view"] },
	        { "name": "create_view_statements", "symbols": ["create_materialized_view"] },
	        { "name": "create_view$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_or") ? { type: "kw_or" } : kw_or), "kw_replace"] },
	        { "name": "create_view$ebnf$1", "symbols": ["create_view$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "create_view$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "create_view$ebnf$2$subexpression$1", "symbols": ["kw_temp"] },
	        { "name": "create_view$ebnf$2$subexpression$1", "symbols": ["kw_temporary"] },
	        { "name": "create_view$ebnf$2", "symbols": ["create_view$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "create_view$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "create_view$ebnf$3", "symbols": ["kw_recursive"], "postprocess": id },
	        { "name": "create_view$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "create_view$ebnf$4$subexpression$1$macrocall$2", "symbols": ["ident"] },
	        { "name": "create_view$ebnf$4$subexpression$1$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "create_view$ebnf$4$subexpression$1$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "create_view$ebnf$4$subexpression$1$macrocall$2"], "postprocess": last },
	        { "name": "create_view$ebnf$4$subexpression$1$macrocall$1$ebnf$1", "symbols": ["create_view$ebnf$4$subexpression$1$macrocall$1$ebnf$1", "create_view$ebnf$4$subexpression$1$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "create_view$ebnf$4$subexpression$1$macrocall$1", "symbols": ["create_view$ebnf$4$subexpression$1$macrocall$2", "create_view$ebnf$4$subexpression$1$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "create_view$ebnf$4$subexpression$1", "symbols": ["lparen", "create_view$ebnf$4$subexpression$1$macrocall$1", "rparen"], "postprocess": get(1) },
	        { "name": "create_view$ebnf$4", "symbols": ["create_view$ebnf$4$subexpression$1"], "postprocess": id },
	        { "name": "create_view$ebnf$4", "symbols": [], "postprocess": () => null },
	        { "name": "create_view$ebnf$5", "symbols": ["create_view_opts"], "postprocess": id },
	        { "name": "create_view$ebnf$5", "symbols": [], "postprocess": () => null },
	        { "name": "create_view$ebnf$6$subexpression$1$subexpression$1", "symbols": ["kw_local"] },
	        { "name": "create_view$ebnf$6$subexpression$1$subexpression$1", "symbols": ["kw_cascaded"] },
	        { "name": "create_view$ebnf$6$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with), "create_view$ebnf$6$subexpression$1$subexpression$1", (lexer_1.lexerAny.has("kw_check") ? { type: "kw_check" } : kw_check), "kw_option"], "postprocess": get(1) },
	        { "name": "create_view$ebnf$6", "symbols": ["create_view$ebnf$6$subexpression$1"], "postprocess": id },
	        { "name": "create_view$ebnf$6", "symbols": [], "postprocess": () => null },
	        { "name": "create_view", "symbols": [(lexer_1.lexerAny.has("kw_create") ? { type: "kw_create" } : kw_create), "create_view$ebnf$1", "create_view$ebnf$2", "create_view$ebnf$3", "kw_view", "qualified_name", "create_view$ebnf$4", "create_view$ebnf$5", (lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as), "selection", "create_view$ebnf$6"], "postprocess": x => {
	                return (0, lexer_2.track)(x, {
	                    type: 'create view',
	                    ...x[1] && { orReplace: true },
	                    ...x[2] && { temp: true },
	                    ...x[3] && { recursive: true },
	                    name: x[5],
	                    ...x[6] && { columnNames: x[6].map(asName) },
	                    ...x[7] && { parameters: fromEntries(x[7]) },
	                    query: x[9],
	                    ...x[10] && { checkOption: toStr(x[10]) },
	                });
	            } },
	        { "name": "create_view_opt", "symbols": ["ident", (lexer_1.lexerAny.has("op_eq") ? { type: "op_eq" } : op_eq), "ident"], "postprocess": ([a, _, b]) => [toStr(a), toStr(b)] },
	        { "name": "create_view_opts$macrocall$2", "symbols": ["create_view_opt"] },
	        { "name": "create_view_opts$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "create_view_opts$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "create_view_opts$macrocall$2"], "postprocess": last },
	        { "name": "create_view_opts$macrocall$1$ebnf$1", "symbols": ["create_view_opts$macrocall$1$ebnf$1", "create_view_opts$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "create_view_opts$macrocall$1", "symbols": ["create_view_opts$macrocall$2", "create_view_opts$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "create_view_opts", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with), "create_view_opts$macrocall$1"], "postprocess": last },
	        { "name": "create_materialized_view$ebnf$1", "symbols": ["kw_ifnotexists"], "postprocess": id },
	        { "name": "create_materialized_view$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "create_materialized_view$ebnf$2$subexpression$1$macrocall$2", "symbols": ["ident"] },
	        { "name": "create_materialized_view$ebnf$2$subexpression$1$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "create_materialized_view$ebnf$2$subexpression$1$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "create_materialized_view$ebnf$2$subexpression$1$macrocall$2"], "postprocess": last },
	        { "name": "create_materialized_view$ebnf$2$subexpression$1$macrocall$1$ebnf$1", "symbols": ["create_materialized_view$ebnf$2$subexpression$1$macrocall$1$ebnf$1", "create_materialized_view$ebnf$2$subexpression$1$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "create_materialized_view$ebnf$2$subexpression$1$macrocall$1", "symbols": ["create_materialized_view$ebnf$2$subexpression$1$macrocall$2", "create_materialized_view$ebnf$2$subexpression$1$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "create_materialized_view$ebnf$2$subexpression$1", "symbols": ["lparen", "create_materialized_view$ebnf$2$subexpression$1$macrocall$1", "rparen"], "postprocess": get(1) },
	        { "name": "create_materialized_view$ebnf$2", "symbols": ["create_materialized_view$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "create_materialized_view$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "create_materialized_view$ebnf$3", "symbols": ["create_view_opts"], "postprocess": id },
	        { "name": "create_materialized_view$ebnf$3", "symbols": [], "postprocess": () => null },
	        { "name": "create_materialized_view$ebnf$4$subexpression$1", "symbols": ["kw_tablespace", "ident"], "postprocess": last },
	        { "name": "create_materialized_view$ebnf$4", "symbols": ["create_materialized_view$ebnf$4$subexpression$1"], "postprocess": id },
	        { "name": "create_materialized_view$ebnf$4", "symbols": [], "postprocess": () => null },
	        { "name": "create_materialized_view$ebnf$5$subexpression$1$ebnf$1", "symbols": ["kw_no"], "postprocess": id },
	        { "name": "create_materialized_view$ebnf$5$subexpression$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "create_materialized_view$ebnf$5$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with), "create_materialized_view$ebnf$5$subexpression$1$ebnf$1", "kw_data"] },
	        { "name": "create_materialized_view$ebnf$5", "symbols": ["create_materialized_view$ebnf$5$subexpression$1"], "postprocess": id },
	        { "name": "create_materialized_view$ebnf$5", "symbols": [], "postprocess": () => null },
	        { "name": "create_materialized_view", "symbols": [(lexer_1.lexerAny.has("kw_create") ? { type: "kw_create" } : kw_create), "kw_materialized", "kw_view", "create_materialized_view$ebnf$1", "qualified_name", "create_materialized_view$ebnf$2", "create_materialized_view$ebnf$3", "create_materialized_view$ebnf$4", (lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as), "selection", "create_materialized_view$ebnf$5"], "postprocess": x => {
	                return (0, lexer_2.track)(x, {
	                    type: 'create materialized view',
	                    ...x[3] && { ifNotExists: true },
	                    name: x[4],
	                    ...x[5] && { columnNames: x[6].map(asName) },
	                    ...x[6] && { parameters: fromEntries(x[6]) },
	                    ...x[7] && { tablespace: asName(x[7]) },
	                    query: x[9],
	                    ...x[10] && { withData: toStr(x[10][1]) !== 'no' },
	                });
	            } },
	        { "name": "refresh_view_statements$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_concurrently") ? { type: "kw_concurrently" } : kw_concurrently)], "postprocess": id },
	        { "name": "refresh_view_statements$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "refresh_view_statements$ebnf$2$subexpression$1$ebnf$1", "symbols": ["kw_no"], "postprocess": id },
	        { "name": "refresh_view_statements$ebnf$2$subexpression$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "refresh_view_statements$ebnf$2$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_with") ? { type: "kw_with" } : kw_with), "refresh_view_statements$ebnf$2$subexpression$1$ebnf$1", "kw_data"] },
	        { "name": "refresh_view_statements$ebnf$2", "symbols": ["refresh_view_statements$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "refresh_view_statements$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "refresh_view_statements", "symbols": ["kw_refresh", "kw_materialized", "kw_view", "refresh_view_statements$ebnf$1", "qname", "refresh_view_statements$ebnf$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'refresh materialized view',
	                ...!!x[3] ? { concurrently: true } : {},
	                name: x[4],
	                ...!!x[5] ? { withData: toStr(x[5][1]) !== 'no' } : {},
	            }) },
	        { "name": "functions_statements", "symbols": ["create_func"] },
	        { "name": "functions_statements", "symbols": ["do_stm"] },
	        { "name": "functions_statements", "symbols": ["drop_func"] },
	        { "name": "create_func$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("kw_or") ? { type: "kw_or" } : kw_or), "kw_replace"] },
	        { "name": "create_func$ebnf$1", "symbols": ["create_func$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "create_func$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "create_func$subexpression$1$ebnf$1$macrocall$2", "symbols": ["func_argdef"] },
	        { "name": "create_func$subexpression$1$ebnf$1$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "create_func$subexpression$1$ebnf$1$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "create_func$subexpression$1$ebnf$1$macrocall$2"], "postprocess": last },
	        { "name": "create_func$subexpression$1$ebnf$1$macrocall$1$ebnf$1", "symbols": ["create_func$subexpression$1$ebnf$1$macrocall$1$ebnf$1", "create_func$subexpression$1$ebnf$1$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "create_func$subexpression$1$ebnf$1$macrocall$1", "symbols": ["create_func$subexpression$1$ebnf$1$macrocall$2", "create_func$subexpression$1$ebnf$1$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "create_func$subexpression$1$ebnf$1", "symbols": ["create_func$subexpression$1$ebnf$1$macrocall$1"], "postprocess": id },
	        { "name": "create_func$subexpression$1$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "create_func$subexpression$1", "symbols": ["lparen", "create_func$subexpression$1$ebnf$1", "rparen"], "postprocess": get(1) },
	        { "name": "create_func$ebnf$2", "symbols": ["func_spec"] },
	        { "name": "create_func$ebnf$2", "symbols": ["create_func$ebnf$2", "func_spec"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "create_func", "symbols": [(lexer_1.lexerAny.has("kw_create") ? { type: "kw_create" } : kw_create), "create_func$ebnf$1", "kw_function", "qname", "create_func$subexpression$1", "create_func$ebnf$2"], "postprocess": (x, rej) => {
	                var _a;
	                const specs = {};
	                for (const s of x[5]) {
	                    for (const k in s) {
	                        if (k[0] !== '_' && k in specs) {
	                            throw new Error('conflicting or redundant options ' + k);
	                        }
	                    }
	                    Object.assign(specs, s);
	                }
	                return (0, lexer_2.track)(x, {
	                    type: 'create function',
	                    ...x[1] && { orReplace: true },
	                    name: x[3],
	                    arguments: (_a = x[4]) !== null && _a !== void 0 ? _a : [],
	                    ...specs,
	                });
	            } },
	        { "name": "func_argdef$ebnf$1", "symbols": ["func_argopts"], "postprocess": id },
	        { "name": "func_argdef$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "func_argdef$ebnf$2", "symbols": ["func_argdefault"], "postprocess": id },
	        { "name": "func_argdef$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "func_argdef", "symbols": ["func_argdef$ebnf$1", "data_type", "func_argdef$ebnf$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                default: x[2],
	                type: x[1],
	                ...x[0],
	            }) },
	        { "name": "func_argdefault", "symbols": [(lexer_1.lexerAny.has("kw_default") ? { type: "kw_default" } : kw_default), "expr"], "postprocess": x => x[1]
	        },
	        { "name": "func_argdefault", "symbols": [(lexer_1.lexerAny.has("op_eq") ? { type: "op_eq" } : op_eq), "expr"], "postprocess": x => x[1] },
	        { "name": "func_argopts$ebnf$1", "symbols": ["word"], "postprocess": id },
	        { "name": "func_argopts$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "func_argopts", "symbols": ["func_argmod", "func_argopts$ebnf$1"], "postprocess": x => (0, lexer_2.track)(x, {
	                mode: toStr(x[0]),
	                ...x[1] && { name: asName(x[1]) },
	            }) },
	        { "name": "func_argopts", "symbols": ["word"], "postprocess": (x, rej) => {
	                const name = asName(x);
	                if (name === 'out' || name === 'inout' || name === 'variadic') {
	                    return rej; // avoid ambiguous syntax
	                }
	                return (0, lexer_2.track)(x, { name });
	            } },
	        { "name": "func_argmod", "symbols": [(lexer_1.lexerAny.has("kw_in") ? { type: "kw_in" } : kw_in)] },
	        { "name": "func_argmod", "symbols": ["kw_out"] },
	        { "name": "func_argmod", "symbols": ["kw_inout"] },
	        { "name": "func_argmod", "symbols": ["kw_variadic"] },
	        { "name": "func_spec", "symbols": ["kw_language", "word"], "postprocess": x => (0, lexer_2.track)(x, { language: asName(last(x)) }) },
	        { "name": "func_spec", "symbols": ["func_purity"], "postprocess": x => (0, lexer_2.track)(x, { purity: toStr(x) }) },
	        { "name": "func_spec$subexpression$1", "symbols": [(lexer_1.lexerAny.has("codeblock") ? { type: "codeblock" } : codeblock)] },
	        { "name": "func_spec$subexpression$1", "symbols": ["string"] },
	        { "name": "func_spec", "symbols": [(lexer_1.lexerAny.has("kw_as") ? { type: "kw_as" } : kw_as), "func_spec$subexpression$1"], "postprocess": x => ({ code: toStr(last(x)) }) },
	        { "name": "func_spec$ebnf$1", "symbols": [(lexer_1.lexerAny.has("kw_not") ? { type: "kw_not" } : kw_not)], "postprocess": id },
	        { "name": "func_spec$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "func_spec$subexpression$2", "symbols": ["word"], "postprocess": kw('leakproof') },
	        { "name": "func_spec", "symbols": ["func_spec$ebnf$1", "func_spec$subexpression$2"], "postprocess": x => (0, lexer_2.track)(x, { leakproof: !x[0] }) },
	        { "name": "func_spec", "symbols": ["func_returns"], "postprocess": x => (0, lexer_2.track)(x, { returns: unwrap(x) }) },
	        { "name": "func_spec$subexpression$3", "symbols": ["word"], "postprocess": kw('called') },
	        { "name": "func_spec", "symbols": ["func_spec$subexpression$3", "oninp"], "postprocess": () => ({ onNullInput: 'call' }) },
	        { "name": "func_spec$subexpression$4", "symbols": ["word"], "postprocess": kw('returns') },
	        { "name": "func_spec", "symbols": ["func_spec$subexpression$4", (lexer_1.lexerAny.has("kw_null") ? { type: "kw_null" } : kw_null), "oninp"], "postprocess": () => ({ onNullInput: 'null' }) },
	        { "name": "func_spec$subexpression$5", "symbols": ["word"], "postprocess": kw('strict') },
	        { "name": "func_spec", "symbols": ["func_spec$subexpression$5"], "postprocess": () => ({ onNullInput: 'strict' }) },
	        { "name": "func_purity", "symbols": ["word"], "postprocess": kw('immutable') },
	        { "name": "func_purity", "symbols": ["word"], "postprocess": kw('stable') },
	        { "name": "func_purity", "symbols": ["word"], "postprocess": kw('volatile') },
	        { "name": "oninp$subexpression$1", "symbols": ["word"], "postprocess": kw('input') },
	        { "name": "oninp", "symbols": [(lexer_1.lexerAny.has("kw_on") ? { type: "kw_on" } : kw_on), (lexer_1.lexerAny.has("kw_null") ? { type: "kw_null" } : kw_null), "oninp$subexpression$1"] },
	        { "name": "func_returns", "symbols": ["kw_returns", "data_type"], "postprocess": last },
	        { "name": "func_returns$macrocall$2", "symbols": ["func_ret_table_col"] },
	        { "name": "func_returns$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "func_returns$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "func_returns$macrocall$2"], "postprocess": last },
	        { "name": "func_returns$macrocall$1$ebnf$1", "symbols": ["func_returns$macrocall$1$ebnf$1", "func_returns$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "func_returns$macrocall$1", "symbols": ["func_returns$macrocall$2", "func_returns$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "func_returns", "symbols": ["kw_returns", (lexer_1.lexerAny.has("kw_table") ? { type: "kw_table" } : kw_table), "lparen", "func_returns$macrocall$1", "rparen"], "postprocess": x => (0, lexer_2.track)(x, {
	                kind: 'table',
	                columns: x[3],
	            }) },
	        { "name": "func_ret_table_col", "symbols": ["word", "data_type"], "postprocess": x => (0, lexer_2.track)(x, { name: asName(x[0]), type: x[1] }) },
	        { "name": "do_stm$ebnf$1$subexpression$1", "symbols": ["kw_language", "word"], "postprocess": last },
	        { "name": "do_stm$ebnf$1", "symbols": ["do_stm$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "do_stm$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "do_stm", "symbols": [(lexer_1.lexerAny.has("kw_do") ? { type: "kw_do" } : kw_do), "do_stm$ebnf$1", (lexer_1.lexerAny.has("codeblock") ? { type: "codeblock" } : codeblock)], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'do',
	                ...x[1] && { language: asName(x[1]) },
	                code: x[2].value,
	            }) },
	        { "name": "drop_func$ebnf$1$subexpression$1", "symbols": ["kw_if", "kw_exists"] },
	        { "name": "drop_func$ebnf$1", "symbols": ["drop_func$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "drop_func$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "drop_func$ebnf$2", "symbols": ["drop_func_overload"], "postprocess": id },
	        { "name": "drop_func$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "drop_func", "symbols": ["kw_drop", "kw_function", "drop_func$ebnf$1", "qname", "drop_func$ebnf$2"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: 'drop function',
	                ...x[2] && { ifExists: true },
	                name: x[3],
	                ...x[4] && { arguments: x[4] },
	            }) },
	        { "name": "drop_func_overload$macrocall$2", "symbols": ["drop_func_overload_col"] },
	        { "name": "drop_func_overload$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "drop_func_overload$macrocall$1$ebnf$1$subexpression$1", "symbols": [(lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "drop_func_overload$macrocall$2"], "postprocess": last },
	        { "name": "drop_func_overload$macrocall$1$ebnf$1", "symbols": ["drop_func_overload$macrocall$1$ebnf$1", "drop_func_overload$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "drop_func_overload$macrocall$1", "symbols": ["drop_func_overload$macrocall$2", "drop_func_overload$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "drop_func_overload", "symbols": ["lparen", "drop_func_overload$macrocall$1", "rparen"], "postprocess": get(1) },
	        { "name": "drop_func_overload_col$ebnf$1", "symbols": ["word"], "postprocess": id },
	        { "name": "drop_func_overload_col$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "drop_func_overload_col", "symbols": ["drop_func_overload_col$ebnf$1", "qname"], "postprocess": x => (0, lexer_2.track)(x, {
	                type: x[1],
	                ...x[0] && { name: asName(x[0]) },
	            }) },
	        { "name": "main$ebnf$1", "symbols": [] },
	        { "name": "main$ebnf$1", "symbols": ["main$ebnf$1", "statement_separator"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "main$ebnf$2", "symbols": [] },
	        { "name": "main$ebnf$2$subexpression$1$ebnf$1", "symbols": ["statement_separator"] },
	        { "name": "main$ebnf$2$subexpression$1$ebnf$1", "symbols": ["main$ebnf$2$subexpression$1$ebnf$1", "statement_separator"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "main$ebnf$2$subexpression$1", "symbols": ["main$ebnf$2$subexpression$1$ebnf$1", "statement"] },
	        { "name": "main$ebnf$2", "symbols": ["main$ebnf$2", "main$ebnf$2$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "main$ebnf$3", "symbols": [] },
	        { "name": "main$ebnf$3", "symbols": ["main$ebnf$3", "statement_separator"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "main", "symbols": ["main$ebnf$1", "statement", "main$ebnf$2", "main$ebnf$3"], "postprocess": ([_, head, _tail]) => {
	                const tail = _tail;
	                const ret = [unwrap(head), ...tail.map((x) => unwrap(x[1]))];
	                return ret.length === 1
	                    ? ret[0]
	                    : ret;
	            } },
	        { "name": "statement_separator", "symbols": [(lexer_1.lexerAny.has("semicolon") ? { type: "semicolon" } : semicolon)] },
	        { "name": "statement", "symbols": ["statement_noprep"] },
	        { "name": "statement", "symbols": ["prepare"] },
	        { "name": "statement", "symbols": ["deallocate"] },
	        { "name": "statement_noprep", "symbols": ["selection"] },
	        { "name": "statement_noprep", "symbols": ["createtable_statement"] },
	        { "name": "statement_noprep", "symbols": ["createextension_statement"] },
	        { "name": "statement_noprep", "symbols": ["createindex_statement"] },
	        { "name": "statement_noprep", "symbols": ["simplestatements_all"] },
	        { "name": "statement_noprep", "symbols": ["insert_statement"] },
	        { "name": "statement_noprep", "symbols": ["update_statement"] },
	        { "name": "statement_noprep", "symbols": ["altertable_statement"] },
	        { "name": "statement_noprep", "symbols": ["alterindex_statement"] },
	        { "name": "statement_noprep", "symbols": ["delete_statement"] },
	        { "name": "statement_noprep", "symbols": ["create_sequence_statement"] },
	        { "name": "statement_noprep", "symbols": ["alter_sequence_statement"] },
	        { "name": "statement_noprep", "symbols": ["drop_statement"] },
	        { "name": "statement_noprep", "symbols": ["createtype_statement"] },
	        { "name": "statement_noprep", "symbols": ["create_view_statements"] },
	        { "name": "statement_noprep", "symbols": ["refresh_view_statements"] },
	        { "name": "statement_noprep", "symbols": ["create_schema"] },
	        { "name": "statement_noprep", "symbols": ["raise_statement"] },
	        { "name": "statement_noprep", "symbols": ["comment_statement"] },
	        { "name": "statement_noprep", "symbols": ["functions_statements"] },
	        { "name": "selection", "symbols": ["select_statement"], "postprocess": unwrap },
	        { "name": "selection", "symbols": ["select_values"], "postprocess": unwrap },
	        { "name": "selection", "symbols": ["with_statement"], "postprocess": unwrap },
	        { "name": "selection", "symbols": ["with_recursive_statement"], "postprocess": unwrap },
	        { "name": "selection", "symbols": ["union_statement"], "postprocess": unwrap },
	        { "name": "selection_paren", "symbols": ["lparen", "selection", "rparen"], "postprocess": get(1) }
	    ],
	    ParserStart: "main",
	};
	exports.default = grammar;


	/***/ }),
	/* 11 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	// Generated automatically by nearley, version unknown
	// http://github.com/Hardmath123/nearley
	// Bypasses TS6133. Allow declared but unused functions.
	// @ts-ignore
	function id(d) { return d[0]; }
	const array_lexer_1 = __webpack_require__(12);
	const last = (x) => x && x[x.length - 1];
	const grammar = {
	    Lexer: array_lexer_1.lexerAny,
	    ParserRules: [
	        { "name": "main$ebnf$1", "symbols": ["elements"], "postprocess": id },
	        { "name": "main$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "main", "symbols": [(array_lexer_1.lexerAny.has("start_list") ? { type: "start_list" } : start_list), "main$ebnf$1", (array_lexer_1.lexerAny.has("end_list") ? { type: "end_list" } : end_list)], "postprocess": x => x[1] || [] },
	        { "name": "elements$ebnf$1", "symbols": [] },
	        { "name": "elements$ebnf$1$subexpression$1", "symbols": [(array_lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "elt"], "postprocess": last },
	        { "name": "elements$ebnf$1", "symbols": ["elements$ebnf$1", "elements$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "elements", "symbols": ["elt", "elements$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [head, ...(tail || [])];
	            } },
	        { "name": "elt", "symbols": [(array_lexer_1.lexerAny.has("value") ? { type: "value" } : value)], "postprocess": x => x[0].value },
	        { "name": "elt", "symbols": ["main"], "postprocess": x => x[0] }
	    ],
	    ParserStart: "main",
	};
	exports.default = grammar;


	/***/ }),
	/* 12 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	exports.lexerAny = exports.lexer = void 0;
	const moo_1 = __webpack_require__(0);
	// build lexer
	exports.lexer = (0, moo_1.compile)({
	    valueString: {
	        match: /"(?:\\["\\]|[^\n"\\])*"/,
	        value: x => JSON.parse(x),
	        type: x => 'value',
	    },
	    valueRaw: {
	        match: /[^\s,\{\}"](?:[^,\{\}"]*[^\s,\{\}"])?/,
	        type: () => 'value',
	    },
	    comma: ',',
	    space: { match: /[\s\t\n\v\f\r]+/, lineBreaks: true, },
	    start_list: '{',
	    end_list: '}',
	});
	exports.lexer.next = (next => () => {
	    let tok;
	    while ((tok = next.call(exports.lexer)) && (tok.type === 'space')) {
	    }
	    return tok;
	})(exports.lexer.next);
	exports.lexerAny = exports.lexer;


	/***/ }),
	/* 13 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	// Generated automatically by nearley, version unknown
	// http://github.com/Hardmath123/nearley
	// Bypasses TS6133. Allow declared but unused functions.
	// @ts-ignore
	function id(d) { return d[0]; }
	const geometric_lexer_1 = __webpack_require__(14);
	const get = (i) => (x) => x[i];
	const last = (x) => x && x[x.length - 1];
	function unwrap(e) {
	    if (Array.isArray(e) && e.length === 1) {
	        e = unwrap(e[0]);
	    }
	    if (Array.isArray(e) && !e.length) {
	        return null;
	    }
	    return e;
	}
	const grammar = {
	    Lexer: geometric_lexer_1.lexerAny,
	    ParserRules: [
	        { "name": "number$subexpression$1", "symbols": ["float"] },
	        { "name": "number$subexpression$1", "symbols": ["int"] },
	        { "name": "number", "symbols": ["number$subexpression$1"], "postprocess": unwrap },
	        { "name": "float", "symbols": [(geometric_lexer_1.lexerAny.has("float") ? { type: "float" } : float)], "postprocess": args => parseFloat(unwrap(args)) },
	        { "name": "int", "symbols": [(geometric_lexer_1.lexerAny.has("int") ? { type: "int" } : int)], "postprocess": arg => parseInt(unwrap(arg), 10) },
	        { "name": "comma", "symbols": [(geometric_lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma)], "postprocess": id },
	        { "name": "point$macrocall$2", "symbols": ["point_content"] },
	        { "name": "point$macrocall$1$subexpression$1", "symbols": ["point$macrocall$2"] },
	        { "name": "point$macrocall$1$subexpression$1", "symbols": [(geometric_lexer_1.lexerAny.has("lparen") ? { type: "lparen" } : lparen), "point$macrocall$2", (geometric_lexer_1.lexerAny.has("rparen") ? { type: "rparen" } : rparen)], "postprocess": get(1) },
	        { "name": "point$macrocall$1", "symbols": ["point$macrocall$1$subexpression$1"], "postprocess": unwrap },
	        { "name": "point", "symbols": ["point$macrocall$1"], "postprocess": unwrap },
	        { "name": "point_content", "symbols": ["number", "comma", "number"], "postprocess": x => ({ x: x[0], y: x[2] }) },
	        { "name": "line", "symbols": [(geometric_lexer_1.lexerAny.has("lcurl") ? { type: "lcurl" } : lcurl), "number", "comma", "number", "comma", "number", (geometric_lexer_1.lexerAny.has("rcurl") ? { type: "rcurl" } : rcurl)], "postprocess": x => ({
	                a: x[1],
	                b: x[3],
	                c: x[5],
	            }) },
	        { "name": "box", "symbols": ["closed_path"], "postprocess": ([x], rej) => {
	                if (x.length !== 2) {
	                    return rej;
	                }
	                return x;
	            } },
	        { "name": "lseg", "symbols": ["path"], "postprocess": ([x], rej) => {
	                if (x.path.length !== 2) {
	                    return rej;
	                }
	                return x.path;
	            } },
	        { "name": "path", "symbols": ["open_path"], "postprocess": ([path]) => ({ closed: false, path }) },
	        { "name": "path", "symbols": ["closed_path"], "postprocess": ([path]) => ({ closed: true, path }) },
	        { "name": "open_path$macrocall$2", "symbols": [(geometric_lexer_1.lexerAny.has("lbracket") ? { type: "lbracket" } : lbracket)] },
	        { "name": "open_path$macrocall$3", "symbols": [(geometric_lexer_1.lexerAny.has("rbracket") ? { type: "rbracket" } : rbracket)] },
	        { "name": "open_path$macrocall$1$macrocall$2", "symbols": ["point"] },
	        { "name": "open_path$macrocall$1$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "open_path$macrocall$1$macrocall$1$ebnf$1$subexpression$1", "symbols": [(geometric_lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "open_path$macrocall$1$macrocall$2"], "postprocess": last },
	        { "name": "open_path$macrocall$1$macrocall$1$ebnf$1", "symbols": ["open_path$macrocall$1$macrocall$1$ebnf$1", "open_path$macrocall$1$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "open_path$macrocall$1$macrocall$1", "symbols": ["open_path$macrocall$1$macrocall$2", "open_path$macrocall$1$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "open_path$macrocall$1", "symbols": ["open_path$macrocall$2", "open_path$macrocall$1$macrocall$1", "open_path$macrocall$3"], "postprocess": get(1) },
	        { "name": "open_path", "symbols": ["open_path$macrocall$1"], "postprocess": last },
	        { "name": "closed_path$subexpression$1$macrocall$2", "symbols": [(geometric_lexer_1.lexerAny.has("lparen") ? { type: "lparen" } : lparen)] },
	        { "name": "closed_path$subexpression$1$macrocall$3", "symbols": [(geometric_lexer_1.lexerAny.has("rparen") ? { type: "rparen" } : rparen)] },
	        { "name": "closed_path$subexpression$1$macrocall$1$macrocall$2", "symbols": ["point"] },
	        { "name": "closed_path$subexpression$1$macrocall$1$macrocall$1$ebnf$1", "symbols": [] },
	        { "name": "closed_path$subexpression$1$macrocall$1$macrocall$1$ebnf$1$subexpression$1", "symbols": [(geometric_lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "closed_path$subexpression$1$macrocall$1$macrocall$2"], "postprocess": last },
	        { "name": "closed_path$subexpression$1$macrocall$1$macrocall$1$ebnf$1", "symbols": ["closed_path$subexpression$1$macrocall$1$macrocall$1$ebnf$1", "closed_path$subexpression$1$macrocall$1$macrocall$1$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "closed_path$subexpression$1$macrocall$1$macrocall$1", "symbols": ["closed_path$subexpression$1$macrocall$1$macrocall$2", "closed_path$subexpression$1$macrocall$1$macrocall$1$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "closed_path$subexpression$1$macrocall$1", "symbols": ["closed_path$subexpression$1$macrocall$2", "closed_path$subexpression$1$macrocall$1$macrocall$1", "closed_path$subexpression$1$macrocall$3"], "postprocess": get(1) },
	        { "name": "closed_path$subexpression$1", "symbols": ["closed_path$subexpression$1$macrocall$1"], "postprocess": last },
	        { "name": "closed_path$subexpression$1$macrocall$5", "symbols": ["point"] },
	        { "name": "closed_path$subexpression$1$macrocall$4$ebnf$1", "symbols": [] },
	        { "name": "closed_path$subexpression$1$macrocall$4$ebnf$1$subexpression$1", "symbols": [(geometric_lexer_1.lexerAny.has("comma") ? { type: "comma" } : comma), "closed_path$subexpression$1$macrocall$5"], "postprocess": last },
	        { "name": "closed_path$subexpression$1$macrocall$4$ebnf$1", "symbols": ["closed_path$subexpression$1$macrocall$4$ebnf$1", "closed_path$subexpression$1$macrocall$4$ebnf$1$subexpression$1"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "closed_path$subexpression$1$macrocall$4", "symbols": ["closed_path$subexpression$1$macrocall$5", "closed_path$subexpression$1$macrocall$4$ebnf$1"], "postprocess": ([head, tail]) => {
	                return [unwrap(head), ...(tail.map(unwrap) || [])];
	            } },
	        { "name": "closed_path$subexpression$1", "symbols": ["closed_path$subexpression$1$macrocall$4"], "postprocess": last },
	        { "name": "closed_path", "symbols": ["closed_path$subexpression$1"], "postprocess": get(0) },
	        { "name": "polygon", "symbols": ["closed_path"], "postprocess": get(0) },
	        { "name": "circle_body", "symbols": ["point", "comma", "number"], "postprocess": x => ({ c: x[0], r: x[2] }) },
	        { "name": "circle$subexpression$1$macrocall$2", "symbols": [(geometric_lexer_1.lexerAny.has("lcomp") ? { type: "lcomp" } : lcomp)] },
	        { "name": "circle$subexpression$1$macrocall$3", "symbols": [(geometric_lexer_1.lexerAny.has("rcomp") ? { type: "rcomp" } : rcomp)] },
	        { "name": "circle$subexpression$1$macrocall$1", "symbols": ["circle$subexpression$1$macrocall$2", "circle_body", "circle$subexpression$1$macrocall$3"], "postprocess": get(1) },
	        { "name": "circle$subexpression$1", "symbols": ["circle$subexpression$1$macrocall$1"] },
	        { "name": "circle$subexpression$1$macrocall$5", "symbols": [(geometric_lexer_1.lexerAny.has("lparen") ? { type: "lparen" } : lparen)] },
	        { "name": "circle$subexpression$1$macrocall$6", "symbols": [(geometric_lexer_1.lexerAny.has("rparen") ? { type: "rparen" } : rparen)] },
	        { "name": "circle$subexpression$1$macrocall$4", "symbols": ["circle$subexpression$1$macrocall$5", "circle_body", "circle$subexpression$1$macrocall$6"], "postprocess": get(1) },
	        { "name": "circle$subexpression$1", "symbols": ["circle$subexpression$1$macrocall$4"] },
	        { "name": "circle$subexpression$1", "symbols": ["circle_body"] },
	        { "name": "circle", "symbols": ["circle$subexpression$1"], "postprocess": unwrap }
	    ],
	    ParserStart: "number",
	};
	exports.default = grammar;


	/***/ }),
	/* 14 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	exports.lexerAny = exports.lexer = void 0;
	const moo_1 = __webpack_require__(0);
	// build lexer
	exports.lexer = (0, moo_1.compile)({
	    comma: ',',
	    space: { match: /[\s\t\n\v\f\r]+/, lineBreaks: true, },
	    int: /\-?\d+(?![\.\d])/,
	    float: /\-?(?:(?:\d*\.\d+)|(?:\d+\.\d*))/,
	    lcurl: '{',
	    rcurl: '}',
	    lparen: '(',
	    rparen: ')',
	    lbracket: '[',
	    rbracket: ']',
	    lcomp: '<',
	    rcomp: '>',
	});
	exports.lexer.next = (next => () => {
	    let tok;
	    while ((tok = next.call(exports.lexer)) && (tok.type === 'space')) {
	    }
	    return tok;
	})(exports.lexer.next);
	exports.lexerAny = exports.lexer;


	/***/ }),
	/* 15 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	// Generated automatically by nearley, version unknown
	// http://github.com/Hardmath123/nearley
	// Bypasses TS6133. Allow declared but unused functions.
	// @ts-ignore
	function id(d) { return d[0]; }
	const interval_lexer_1 = __webpack_require__(16);
	const grammar = {
	    Lexer: interval_lexer_1.lexerAny,
	    ParserRules: [
	        { "name": "main$ebnf$1", "symbols": ["elt"] },
	        { "name": "main$ebnf$1", "symbols": ["main$ebnf$1", "elt"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "main", "symbols": ["main$ebnf$1"], "postprocess": ([elts]) => {
	                // check unicity
	                const s = new Set();
	                for (const e of elts) {
	                    const k = typeof e[1] === 'number'
	                        ? e[0]
	                        : 'time';
	                    if (s.has(k)) {
	                        return 'invalid';
	                    }
	                    s.add(k);
	                }
	                return elts;
	            } },
	        { "name": "elt", "symbols": ["time"] },
	        { "name": "elt", "symbols": ["num", "unit"], "postprocess": ([[n], u]) => {
	                u = u[0].type;
	                return [u, n];
	            } },
	        { "name": "unit", "symbols": [(interval_lexer_1.lexerAny.has("years") ? { type: "years" } : years)] },
	        { "name": "unit", "symbols": [(interval_lexer_1.lexerAny.has("months") ? { type: "months" } : months)] },
	        { "name": "unit", "symbols": [(interval_lexer_1.lexerAny.has("days") ? { type: "days" } : days)] },
	        { "name": "unit", "symbols": [(interval_lexer_1.lexerAny.has("hours") ? { type: "hours" } : hours)] },
	        { "name": "unit", "symbols": [(interval_lexer_1.lexerAny.has("minutes") ? { type: "minutes" } : minutes)] },
	        { "name": "unit", "symbols": [(interval_lexer_1.lexerAny.has("seconds") ? { type: "seconds" } : seconds)] },
	        { "name": "unit", "symbols": [(interval_lexer_1.lexerAny.has("milliseconds") ? { type: "milliseconds" } : milliseconds)] },
	        { "name": "num", "symbols": ["int"] },
	        { "name": "num", "symbols": ["float"] },
	        { "name": "uint", "symbols": [(interval_lexer_1.lexerAny.has("int") ? { type: "int" } : int)], "postprocess": ([x]) => parseInt(x, 10) },
	        { "name": "int$ebnf$1$subexpression$1", "symbols": [(interval_lexer_1.lexerAny.has("neg") ? { type: "neg" } : neg)] },
	        { "name": "int$ebnf$1", "symbols": ["int$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "int$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "int", "symbols": ["int$ebnf$1", (interval_lexer_1.lexerAny.has("int") ? { type: "int" } : int)], "postprocess": ([neg, x]) => parseInt(x, 10) * (neg ? -1 : 1) },
	        { "name": "float$ebnf$1$subexpression$1", "symbols": [(interval_lexer_1.lexerAny.has("neg") ? { type: "neg" } : neg)] },
	        { "name": "float$ebnf$1", "symbols": ["float$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "float$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "float$ebnf$2", "symbols": [(interval_lexer_1.lexerAny.has("int") ? { type: "int" } : int)], "postprocess": id },
	        { "name": "float$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "float", "symbols": ["float$ebnf$1", "float$ebnf$2", (interval_lexer_1.lexerAny.has("dot") ? { type: "dot" } : dot), (interval_lexer_1.lexerAny.has("int") ? { type: "int" } : int)], "postprocess": ([neg, ...v]) => parseFloat(v.map(v => v ? v.text : '0').join('')) * (neg ? -1 : 1) },
	        { "name": "time$ebnf$1$subexpression$1", "symbols": [(interval_lexer_1.lexerAny.has("colon") ? { type: "colon" } : colon), "uint"] },
	        { "name": "time$ebnf$1", "symbols": ["time$ebnf$1$subexpression$1"], "postprocess": id },
	        { "name": "time$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "time$ebnf$2$subexpression$1", "symbols": [(interval_lexer_1.lexerAny.has("dot") ? { type: "dot" } : dot), (interval_lexer_1.lexerAny.has("int") ? { type: "int" } : int)] },
	        { "name": "time$ebnf$2", "symbols": ["time$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "time$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "time", "symbols": ["uint", (interval_lexer_1.lexerAny.has("colon") ? { type: "colon" } : colon), "uint", "time$ebnf$1", "time$ebnf$2"], "postprocess": ([a, _, b, c, d]) => {
	                c = c && c[1];
	                d = d && d[1];
	                const ret = typeof c === 'number' ? [
	                    ['hours', a],
	                    ['minutes', b],
	                    ['seconds', c],
	                ] : [
	                    ['minutes', a],
	                    ['seconds', b],
	                ];
	                if (d) {
	                    ret.push(['milliseconds', parseFloat('0.' + d) * 1000]);
	                }
	                return ret;
	            } }
	    ],
	    ParserStart: "main",
	};
	exports.default = grammar;


	/***/ }),
	/* 16 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	exports.lexerAny = exports.lexer = void 0;
	const moo_1 = __webpack_require__(0);
	// build lexer
	exports.lexer = (0, moo_1.compile)({
	    int: /\d+/,
	    neg: '-',
	    dot: '.',
	    years: /(?:y|yrs?|years?)\b/,
	    months: /(?:mon(?:th)?s?)\b/,
	    days: /(?:d|days?)\b/,
	    hours: /(?:h|hrs?|hours?)\b/,
	    minutes: /(?:m|mins?|minutes?)\b/,
	    seconds: /(?:s|secs?|seconds?)\b/,
	    milliseconds: /(?:ms|milliseconds?)\b/,
	    space: { match: /[\s\t\n\v\f\r]+/, lineBreaks: true, },
	    colon: ':',
	});
	exports.lexer.next = (next => () => {
	    let tok;
	    while ((tok = next.call(exports.lexer)) && (tok.type === 'space')) {
	    }
	    return tok;
	})(exports.lexer.next);
	exports.lexerAny = exports.lexer;


	/***/ }),
	/* 17 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	// Generated automatically by nearley, version unknown
	// http://github.com/Hardmath123/nearley
	// Bypasses TS6133. Allow declared but unused functions.
	// @ts-ignore
	function id(d) { return d[0]; }
	const interval_iso_lexer_1 = __webpack_require__(18);
	const grammar = {
	    Lexer: interval_iso_lexer_1.lexerAny,
	    ParserRules: [
	        { "name": "num", "symbols": [(interval_iso_lexer_1.lexerAny.has("int") ? { type: "int" } : int)] },
	        { "name": "num", "symbols": [(interval_iso_lexer_1.lexerAny.has("float") ? { type: "float" } : float)] },
	        { "name": "main$ebnf$1", "symbols": [] },
	        { "name": "main$ebnf$1", "symbols": ["main$ebnf$1", "long"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "main$ebnf$2$subexpression$1$ebnf$1", "symbols": ["short"] },
	        { "name": "main$ebnf$2$subexpression$1$ebnf$1", "symbols": ["main$ebnf$2$subexpression$1$ebnf$1", "short"], "postprocess": (d) => d[0].concat([d[1]]) },
	        { "name": "main$ebnf$2$subexpression$1", "symbols": [(interval_iso_lexer_1.lexerAny.has("T") ? { type: "T" } : T), "main$ebnf$2$subexpression$1$ebnf$1"] },
	        { "name": "main$ebnf$2", "symbols": ["main$ebnf$2$subexpression$1"], "postprocess": id },
	        { "name": "main$ebnf$2", "symbols": [], "postprocess": () => null },
	        { "name": "main", "symbols": [(interval_iso_lexer_1.lexerAny.has("P") ? { type: "P" } : P), "main$ebnf$1", "main$ebnf$2"], "postprocess": ([_, a, b], rej) => {
	                b = !b ? [] : b[1];
	                if (!a.length && !b.length) {
	                    return rej;
	                }
	                return !a.length ? b
	                    : !b.length ? a
	                        : [...a, ...b];
	            } },
	        { "name": "long$subexpression$1", "symbols": [(interval_iso_lexer_1.lexerAny.has("Y") ? { type: "Y" } : Y)] },
	        { "name": "long$subexpression$1", "symbols": [(interval_iso_lexer_1.lexerAny.has("M") ? { type: "M" } : M)] },
	        { "name": "long$subexpression$1", "symbols": [(interval_iso_lexer_1.lexerAny.has("W") ? { type: "W" } : W)] },
	        { "name": "long$subexpression$1", "symbols": [(interval_iso_lexer_1.lexerAny.has("D") ? { type: "D" } : D)] },
	        { "name": "long", "symbols": ["num", "long$subexpression$1"], "postprocess": ([n, u]) => {
	                n = parseFloat(n[0].value);
	                u = u[0].type;
	                switch (u) {
	                    case 'Y':
	                        return ['years', n];
	                    case 'M':
	                        return ['months', n];
	                    case 'W':
	                        return ['days', n * 7];
	                    case 'D':
	                        return ['days', n];
	                    default:
	                        throw new Error('Unexpected unit ' + u);
	                }
	            } },
	        { "name": "short$ebnf$1", "symbols": [(interval_iso_lexer_1.lexerAny.has("T") ? { type: "T" } : T)], "postprocess": id },
	        { "name": "short$ebnf$1", "symbols": [], "postprocess": () => null },
	        { "name": "short$subexpression$1", "symbols": [(interval_iso_lexer_1.lexerAny.has("H") ? { type: "H" } : H)] },
	        { "name": "short$subexpression$1", "symbols": [(interval_iso_lexer_1.lexerAny.has("M") ? { type: "M" } : M)] },
	        { "name": "short$subexpression$1", "symbols": [(interval_iso_lexer_1.lexerAny.has("S") ? { type: "S" } : S)] },
	        { "name": "short", "symbols": ["short$ebnf$1", "num", "short$subexpression$1"], "postprocess": ([_, n, u]) => {
	                n = parseFloat(n[0].value);
	                u = u[0].type;
	                switch (u) {
	                    case 'H':
	                        return ['hours', n];
	                    case 'M':
	                        return ['minutes', n];
	                    case 'S':
	                        return ['seconds', n];
	                    default:
	                        throw new Error('Unexpected unit ' + u);
	                }
	            } }
	    ],
	    ParserStart: "num",
	};
	exports.default = grammar;


	/***/ }),
	/* 18 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	exports.lexerAny = exports.lexer = void 0;
	const moo_1 = __webpack_require__(0);
	// build lexer
	exports.lexer = (0, moo_1.compile)({
	    int: /\-?\d+(?![\.\d])/,
	    float: /\-?(?:(?:\d*\.\d+)|(?:\d+\.\d*))/,
	    P: 'P',
	    Y: 'Y',
	    M: 'M',
	    W: 'W',
	    D: 'D',
	    H: 'H',
	    S: 'S',
	    T: 'T',
	});
	exports.lexerAny = exports.lexer;


	/***/ }),
	/* 19 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	exports.toSql = void 0;
	const ast_mapper_1 = __webpack_require__(2);
	const ast_visitor_1 = __webpack_require__(5);
	const utils_1 = __webpack_require__(6);
	const pg_escape_1 = __webpack_require__(20);
	const keywords_1 = __webpack_require__(3);
	const kwSet = new Set(keywords_1.sqlKeywords.map(x => x.toLowerCase()));
	let ret = [];
	function name(nm) {
	    return ident(nm.name);
	}
	function ident(nm, forceDoubleQuote) {
	    if (!forceDoubleQuote) {
	        // only add quotes if has upper cases, or if it is a keyword.
	        const low = nm.toLowerCase();
	        if (low === nm && !kwSet.has(low) && /^[a-z][a-z0-9_]*$/.test(low)) {
	            return nm;
	        }
	    }
	    return '"' + nm + '"';
	}
	function list(elems, act, addParen) {
	    if (addParen) {
	        ret.push('(');
	    }
	    let first = true;
	    for (const e of elems) {
	        if (!first) {
	            ret.push(', ');
	        }
	        first = false;
	        act(e);
	    }
	    if (addParen) {
	        ret.push(')');
	    }
	}
	function addConstraint(c, m) {
	    switch (c.type) {
	        case 'foreign key':
	            ret.push(' foreign key (', ...c.localColumns.map(name).join(', '), ')');
	        //  There is no "break" here... that's not an error, we want to fall throught the 'reference' case
	        case 'reference':
	            ret.push(' REFERENCES ');
	            m.tableRef(c.foreignTable);
	            ret.push('(', ...c.foreignColumns.map(name).join(', '), ') ');
	            if (c.match) {
	                ret.push(' MATCH ', c.match.toUpperCase());
	            }
	            if (c.onDelete) {
	                ret.push(' ON DELETE ', c.onDelete);
	            }
	            if (c.onUpdate) {
	                ret.push(' ON UPDATE ', c.onUpdate);
	            }
	            break;
	        case 'primary key':
	        case 'unique':
	            ret.push(' ', c.type, ' ');
	            if ('columns' in c) {
	                ret.push('(', ...c.columns.map(name).join(', '), ') ');
	            }
	            break;
	        case 'check':
	            ret.push(' check ');
	            m.expr(c.expr);
	            break;
	        case 'not null':
	        case 'null':
	            ret.push(' ', c.type, ' ');
	            break;
	        case 'default':
	            ret.push(' default ');
	            m.expr(c.default);
	            break;
	        case 'add generated':
	            ret.push(' GENERATED ');
	            visitGenerated(m, c);
	            break;
	        default:
	            throw utils_1.NotSupported.never(c);
	    }
	    ret.push(' ');
	}
	function visitQualifiedName(cs, forceDoubleQuote) {
	    if (cs.schema) {
	        ret.push(ident(cs.schema), '.');
	    }
	    ret.push(ident(cs.name, forceDoubleQuote), ' ');
	}
	function visitQualifiedNameAliased(cs) {
	    visitQualifiedName(cs);
	    if (cs.alias) {
	        ret.push(' AS ', ident(cs.alias), ' ');
	    }
	}
	function visitOrderBy(m, orderBy) {
	    ret.push(' ORDER BY ');
	    list(orderBy, e => {
	        m.expr(e.by);
	        if (e.order) {
	            ret.push(' ', e.order, ' ');
	        }
	        if (e.nulls) {
	            ret.push(' NULLS ', e.nulls, ' ');
	        }
	    }, false);
	}
	function visitSetVal(set) {
	    switch (set.type) {
	        case 'default':
	            ret.push('DEFAULT ');
	            break;
	        case 'identifier':
	            ret.push(set.name);
	            break;
	        case 'list':
	            let first = true;
	            for (const v of set.values) {
	                if (!first) {
	                    ret.push(', ');
	                }
	                first = false;
	                visitSetVal(v);
	            }
	            break;
	        case 'value':
	            ret.push(typeof set.value === 'number' ? set.value.toString() : (0, pg_escape_1.literal)(set.value));
	            break;
	        default:
	            throw utils_1.NotSupported.never(set);
	    }
	}
	function visitGenerated(m, alter) {
	    if (alter.always) {
	        ret.push(alter.always.toUpperCase(), ' ');
	    }
	    ret.push('AS IDENTITY ');
	    if (alter.sequence) {
	        ret.push('(');
	        if (alter.sequence.name) {
	            ret.push('SEQUENCE NAME ');
	            visitQualifiedName(alter.sequence.name);
	            ret.push(' ');
	        }
	        visitSeqOpts(m, alter.sequence);
	        ret.push(') ');
	    }
	}
	function visitSeqOpts(m, cs) {
	    if (cs.as) {
	        ret.push('AS ');
	        m.dataType(cs.as);
	        ret.push(' ');
	    }
	    if (typeof cs.incrementBy === 'number') {
	        ret.push('INCREMENT BY ', cs.incrementBy.toString(), ' ');
	    }
	    if (cs.minValue === 'no minvalue') {
	        ret.push('NO MINVALUE ');
	    }
	    if (typeof cs.minValue === 'number') {
	        ret.push('MINVALUE ', cs.minValue.toString(), ' ');
	    }
	    if (cs.maxValue === 'no maxvalue') {
	        ret.push('NO MAXVALUE ');
	    }
	    if (typeof cs.maxValue === 'number') {
	        ret.push('MAXVALUE ', cs.maxValue.toString(), ' ');
	    }
	    if (typeof cs.startWith === 'number') {
	        ret.push('START WITH ', cs.startWith.toString(), ' ');
	    }
	    if (typeof cs.cache === 'number') {
	        ret.push('CACHE ', cs.cache.toString(), ' ');
	    }
	    if (cs.cycle) {
	        ret.push(cs.cycle, ' ');
	    }
	    if (cs.ownedBy === 'none') {
	        ret.push('OWNED BY NONE ');
	    }
	    else if (cs.ownedBy) {
	        ret.push('OWNED BY ');
	        visitQColumn(cs.ownedBy);
	    }
	    if ('restart' in cs) {
	        if (cs.restart === true) {
	            ret.push('RESTART ');
	        }
	        else if (cs.restart) {
	            ret.push('RESTART WITH ', cs.restart.toString(), ' ');
	        }
	    }
	}
	function visitQColumn(col) {
	    if (col.schema) {
	        ret.push(ident(col.schema), '.');
	    }
	    ret.push(ident(col.table), '.', ident(col.column), ' ');
	}
	function join(m, j, tbl) {
	    if (!j) {
	        tbl();
	        return;
	    }
	    ret.push(j.type, ' ');
	    tbl();
	    if (j.on) {
	        ret.push('ON ');
	        m.expr(j.on);
	    }
	    if (j.using) {
	        ret.push('USING (');
	        list(j.using, x => ret.push(name(x)), false);
	        ret.push(') ');
	    }
	    ret.push(' ');
	}
	function visitOp(v) {
	    if (v.opSchema) {
	        ret.push(' operator(', ident(v.opSchema), '.', v.op, ') ');
	    }
	    else {
	        ret.push(' ', v.op, ' ');
	    }
	}
	const visitor = (0, ast_visitor_1.astVisitor)(m => ({
	    addColumn: (...args) => {
	        ret.push(' ADD COLUMN ');
	        if (args[0].ifNotExists) {
	            ret.push('IF NOT EXISTS ');
	        }
	        m.super().addColumn(...args);
	    },
	    createExtension: e => {
	        ret.push('CREATE EXTENSION ');
	        if (e.ifNotExists) {
	            ret.push(' IF NOT EXISTS ');
	        }
	        ret.push(name(e.extension));
	        if (!e.from && !e.version && !e.schema) {
	            return;
	        }
	        ret.push(' WITH');
	        if (e.schema) {
	            ret.push(' SCHEMA ', name(e.schema));
	        }
	        if (e.version) {
	            ret.push(' VERSION ', (0, pg_escape_1.literal)(e.version.value));
	        }
	        if (e.from) {
	            ret.push(' FROM ', (0, pg_escape_1.literal)(e.from.value));
	        }
	    },
	    tablespace: t => {
	        ret.push('TABLESPACE ', name(t.tablespace));
	    },
	    addConstraint: c => {
	        ret.push(' ADD ');
	        const cname = c.constraint.constraintName;
	        if (cname) {
	            ret.push(' CONSTRAINT ', name(cname), ' ');
	        }
	        addConstraint(c.constraint, m);
	    },
	    alterColumn: (c, t) => {
	        ret.push(' ALTER COLUMN ', name(c.column), ' ');
	        m.super().alterColumn(c, t);
	    },
	    setColumnDefault: (a, t, c) => {
	        ret.push(' SET DEFAULT ');
	        m.expr(a.default);
	        if (a.updateExisting) {
	            throw new Error('Not implemented: updateExisting on set column default');
	        }
	    },
	    createEnum: t => {
	        ret.push('CREATE TYPE ');
	        visitQualifiedName(t.name);
	        ret.push(' AS ENUM ');
	        list(t.values, x => ret.push((0, pg_escape_1.literal)(x.value)), true);
	        ret.push(' ');
	    },
	    createCompositeType: c => {
	        ret.push('CREATE TYPE ');
	        visitQualifiedName(c.name);
	        ret.push(' AS ');
	        list(c.attributes, x => {
	            ret.push(name(x.name), ' ');
	            m.dataType(x.dataType);
	            if (x.collate) {
	                ret.push('COLLATE ');
	                visitQualifiedName(x.collate);
	            }
	        }, true);
	        ret.push(' ');
	    },
	    setTableOwner: o => {
	        ret.push(' OWNER TO ', name(o.to));
	    },
	    alterColumnSimple: c => ret.push(c.type),
	    alterColumnAddGenerated: (alter) => {
	        ret.push(' ADD GENERATED ');
	        visitGenerated(m, alter);
	    },
	    setColumnType: t => {
	        ret.push(' SET DATA TYPE ');
	        m.dataType(t.dataType);
	        ret.push(' ');
	    },
	    alterTable: t => {
	        ret.push('ALTER TABLE ');
	        if (t.ifExists) {
	            ret.push(' IF EXISTS ');
	        }
	        if (t.only) {
	            ret.push(' ONLY ');
	        }
	        visitQualifiedNameAliased(t.table);
	        list(t.changes, change => m.tableAlteration(change, t.table), false);
	    },
	    alterIndex: t => {
	        ret.push('ALTER INDEX ');
	        if (t.ifExists) {
	            ret.push(' IF EXISTS ');
	        }
	        visitQualifiedNameAliased(t.index);
	        switch (t.change.type) {
	            case 'rename':
	                ret.push(' RENAME TO ');
	                visitQualifiedName(t.change.to);
	                ret.push(' ');
	                break;
	            case 'set tablespace':
	                ret.push(' SET TABLESPACE ');
	                visitQualifiedName(t.change.tablespace);
	                ret.push(' ');
	                break;
	            default:
	                throw utils_1.NotSupported.never(t.change, 'Alter index type not supported: ');
	        }
	    },
	    tableAlteration: (change, table) => {
	        switch (change.type) {
	            case 'add column':
	                return m.addColumn(change, table);
	            case 'add constraint':
	                return m.addConstraint(change, table);
	            case 'alter column':
	                return m.alterColumn(change, table);
	            case 'rename':
	                return m.renameTable(change, table);
	            case 'rename column':
	                return m.renameColumn(change, table);
	            case 'rename constraint':
	                return m.renameConstraint(change, table);
	            case 'drop column':
	                return m.dropColumn(change, table);
	            case 'drop constraint':
	                return m.dropConstraint(change, table);
	            case 'owner':
	                return m.setTableOwner(change, table);
	            default:
	                throw utils_1.NotSupported.never(change);
	        }
	    },
	    array: v => {
	        ret.push(v.type === 'array' ? 'ARRAY[' : '(');
	        list(v.expressions, e => m.expr(e), false);
	        ret.push(v.type === 'array' ? ']' : ')');
	    },
	    arrayIndex: v => {
	        m.expr(v.array);
	        ret.push('[');
	        m.expr(v.index);
	        ret.push('] ');
	    },
	    expr: e => {
	        if (e.type === 'ref') {
	            m.ref(e);
	            return;
	        }
	        // lists can become incorrect with an additional set of parentheses
	        if (e.type === 'list') {
	            m.super().expr(e);
	            return;
	        }
	        // this forces to respect precedence
	        // (however, it will introduce lots of unecessary parenthesis)
	        ret.push('(');
	        m.super().expr(e);
	        ret.push(')');
	    },
	    callOverlay: o => {
	        ret.push('OVERLAY(');
	        m.expr(o.value);
	        ret.push(' PLACING ');
	        m.expr(o.placing);
	        ret.push(' FROM ');
	        m.expr(o.from);
	        if (o.for) {
	            ret.push(' FOR ');
	            m.expr(o.for);
	        }
	        ret.push(')');
	    },
	    callSubstring: s => {
	        ret.push('SUBSTRING(');
	        m.expr(s.value);
	        if (s.from) {
	            ret.push(' FROM ');
	            m.expr(s.from);
	        }
	        if (s.for) {
	            ret.push(' FOR ');
	            m.expr(s.for);
	        }
	        ret.push(')');
	    },
	    binary: v => {
	        m.expr(v.left);
	        visitOp(v);
	        m.expr(v.right);
	    },
	    call: v => {
	        visitQualifiedName(v.function);
	        ret.push('(');
	        if (v.distinct) {
	            ret.push(v.distinct, ' ');
	        }
	        list(v.args, e => m.expr(e), false);
	        if (v.orderBy) {
	            visitOrderBy(m, v.orderBy);
	        }
	        ret.push(') ');
	        if (v.filter) {
	            ret.push('filter (where ');
	            m.expr(v.filter);
	            ret.push(') ');
	        }
	        if (v.over) {
	            ret.push('over (');
	            if (v.over.partitionBy) {
	                ret.push('PARTITION BY ');
	                list(v.over.partitionBy, x => m.expr(x), false);
	                ret.push(' ');
	            }
	            if (v.over.orderBy) {
	                visitOrderBy(m, v.over.orderBy);
	                ret.push(' ');
	            }
	            ret.push(') ');
	        }
	    },
	    case: c => {
	        ret.push('CASE ');
	        if (c.value) {
	            m.expr(c.value);
	        }
	        for (const e of c.whens) {
	            ret.push(' WHEN ');
	            m.expr(e.when);
	            ret.push(' THEN ');
	            m.expr(e.value);
	        }
	        if (c.else) {
	            ret.push(' ELSE ');
	            m.expr(c.else);
	        }
	        ret.push(' END ');
	    },
	    cast: c => {
	        m.expr(c.operand);
	        ret.push('::');
	        m.dataType(c.to);
	    },
	    constant: c => {
	        switch (c.type) {
	            case 'boolean':
	                ret.push(c.value ? 'true' : 'false');
	                break;
	            case 'integer':
	                ret.push(c.value.toString(10));
	                break;
	            case 'numeric':
	                ret.push(c.value.toString());
	                if (Number.isInteger(c.value)) {
	                    ret.push('.');
	                }
	                break;
	            case 'null':
	                ret.push('null');
	                break;
	            case 'constant':
	                break;
	            case 'string':
	                ret.push((0, pg_escape_1.literal)(c.value));
	                break;
	            default:
	                throw utils_1.NotSupported.never(c);
	        }
	    },
	    valueKeyword: v => {
	        ret.push(v.keyword, ' ');
	    },
	    comment: c => {
	        ret.push('COMMENT ON ', c.on.type.toUpperCase(), ' ');
	        switch (c.on.type) {
	            case 'column':
	                visitQColumn(c.on.column);
	                break;
	            default:
	                visitQualifiedName(c.on.name);
	                break;
	        }
	        ret.push(' IS ', (0, pg_escape_1.literal)(c.comment), ' ');
	    },
	    extract: v => {
	        ret.push('EXTRACT (', v.field.name.toUpperCase(), ' FROM ');
	        m.expr(v.from);
	        ret.push(') ');
	    },
	    createColumn: c => {
	        var _a;
	        ret.push(name(c.name), ' ');
	        m.dataType(c.dataType);
	        ret.push(' ');
	        if (c.collate) {
	            ret.push('COLLATE ');
	            visitQualifiedName(c.collate);
	        }
	        for (const cst of (_a = c.constraints) !== null && _a !== void 0 ? _a : []) {
	            m.constraint(cst);
	        }
	    },
	    begin: beg => {
	        ret.push('BEGIN ');
	        if (beg.isolationLevel) {
	            ret.push('ISOLATION LEVEL ', beg.isolationLevel.toUpperCase(), ' ');
	        }
	        if (beg.writeable) {
	            ret.push(beg.writeable.toUpperCase(), ' ');
	        }
	        if (typeof beg.deferrable === 'boolean') {
	            if (!beg.deferrable) {
	                ret.push('NOT ');
	            }
	            ret.push('DEFERRABLE ');
	        }
	    },
	    alterSequence: cs => {
	        ret.push('ALTER SEQUENCE ');
	        if (cs.ifExists) {
	            ret.push('IF EXISTS ');
	        }
	        visitQualifiedName(cs.name);
	        switch (cs.change.type) {
	            case 'set options':
	                visitSeqOpts(m, cs.change);
	                break;
	            case 'rename':
	                ret.push('RENAME TO ', name(cs.change.newName), ' ');
	                break;
	            case 'set schema':
	                ret.push('SET SCHEMA ', name(cs.change.newSchema), ' ');
	                break;
	            case 'owner to':
	                cs.change.owner;
	                ret.push('OWNER TO ', name(cs.change.owner), ' ');
	                break;
	            default:
	                throw utils_1.NotSupported.never(cs.change);
	        }
	    },
	    createSequence: cs => {
	        ret.push('CREATE ');
	        if (cs.temp) {
	            ret.push('TEMPORARY ');
	        }
	        ret.push('SEQUENCE ');
	        if (cs.ifNotExists) {
	            ret.push('IF NOT EXISTS ');
	        }
	        visitQualifiedName(cs.name);
	        visitSeqOpts(m, cs.options);
	    },
	    drop: val => {
	        ret.push(val.type.toUpperCase(), ' ');
	        if (val.concurrently) {
	            ret.push('CONCURRENTLY ');
	        }
	        if (val.ifExists) {
	            ret.push('IF EXISTS ');
	        }
	        list(val.names, x => m.tableRef(x), false);
	        if (val.cascade) {
	            ret.push(val.cascade.toUpperCase(), ' ');
	        }
	    },
	    constraint: cst => {
	        if (cst.constraintName) {
	            ret.push(' CONSTRAINT ', name(cst.constraintName), ' ');
	        }
	        addConstraint(cst, m);
	    },
	    do: d => {
	        ret.push('DO');
	        if (d.language) {
	            ret.push(' LANGUAGE ', d.language.name);
	        }
	        ret.push(' $$', d.code, '$$');
	    },
	    createFunction: c => {
	        var _a;
	        ret.push(c.orReplace ? 'CREATE OR REPLACE FUNCTION ' : 'CREATE FUNCTION ');
	        visitQualifiedName(c.name);
	        // args
	        list(c.arguments, a => {
	            if (a.mode) {
	                ret.push(a.mode, ' ');
	            }
	            if (a.name) {
	                ret.push(name(a.name), ' ');
	            }
	            m.dataType(a.type);
	            if (a.default) {
	                ret.push(" = ");
	                m.expr(a.default);
	            }
	        }, true);
	        // ret type
	        if (c.returns) {
	            switch (c.returns.kind) {
	                case 'table':
	                    ret.push(' RETURNS TABLE ');
	                    list(c.returns.columns, t => {
	                        ret.push(name(t.name), ' ');
	                        m.dataType(t.type);
	                    }, true);
	                    break;
	                case undefined:
	                case null:
	                case 'array':
	                    ret.push(' RETURNS ');
	                    m.dataType(c.returns);
	                    break;
	                default:
	                    throw utils_1.NotSupported.never(c.returns);
	            }
	        }
	        ret.push(' AS $$', (_a = c.code) !== null && _a !== void 0 ? _a : '', '$$');
	        // function settings
	        if (c.language) {
	            ret.push('LANGUAGE ', c.language.name, ' ');
	        }
	        if (c.purity) {
	            ret.push(c.purity.toUpperCase(), ' ');
	        }
	        if (typeof c.leakproof === 'boolean') {
	            ret.push(c.leakproof ? 'LEAKPROOF ' : 'NOT LEAKPROOF ');
	        }
	        switch (c.onNullInput) {
	            case 'call':
	                ret.push('CALLED ON NULL INPUT ');
	                break;
	            case 'null':
	                ret.push('RETURNS NULL ON NULL INPUT ');
	                break;
	            case 'strict':
	                ret.push('STRICT ');
	                break;
	            case null:
	            case undefined:
	                break;
	            default:
	                throw utils_1.NotSupported.never(c.onNullInput);
	        }
	    },
	    dropFunction: d => {
	        ret.push('DROP FUNCTION ');
	        if (d.ifExists) {
	            ret.push('IF EXISTS ');
	        }
	        visitQualifiedName(d.name);
	        if (d.arguments) {
	            list(d.arguments, a => {
	                if (a.name) {
	                    visitQualifiedName(a.name);
	                    ret.push(' ');
	                }
	                m.dataType(a.type);
	            }, true);
	        }
	        ret.push(' ');
	    },
	    with: w => {
	        ret.push('WITH ');
	        list(w.bind, b => {
	            ret.push(name(b.alias), ' AS (');
	            m.statement(b.statement);
	            ret.push(') ');
	        }, false);
	        m.statement(w.in);
	    },
	    withRecursive: val => {
	        ret.push('WITH RECURSIVE ', name(val.alias), '(', ...val.columnNames.map(name).join(', '), ') AS (');
	        m.union(val.bind);
	        ret.push(') ');
	        m.statement(val.in);
	    },
	    setGlobal: g => {
	        ret.push('SET ', name(g.variable), ' = ');
	        visitSetVal(g.set);
	    },
	    setTimezone: g => {
	        ret.push('SET TIME ZONE ');
	        switch (g.to.type) {
	            case 'default':
	            case 'local':
	                ret.push(g.to.type.toUpperCase(), ' ');
	                break;
	            case 'value':
	                ret.push(typeof g.to.value === 'string'
	                    ? (0, pg_escape_1.literal)(g.to.value)
	                    : g.to.value.toString(10));
	                break;
	            case 'interval':
	                ret.push('INTERVAL ', (0, pg_escape_1.literal)(g.to.value), ' HOUR TO MINUTE');
	                break;
	            default:
	                throw utils_1.NotSupported.never(g.to);
	        }
	    },
	    setNames: g => {
	        ret.push('SET NAMES ');
	        switch (g.to.type) {
	            case 'value':
	                ret.push((0, pg_escape_1.literal)(g.to.value));
	                break;
	        }
	    },
	    dataType: d => {
	        var _a, _b;
	        if ((d === null || d === void 0 ? void 0 : d.kind) === 'array') {
	            m.dataType(d.arrayOf);
	            ret.push('[]');
	            return;
	        }
	        if (!(d === null || d === void 0 ? void 0 : d.name)) {
	            ret.push('unkown');
	            return;
	        }
	        let appendConfig = true;
	        if (d.schema) {
	            visitQualifiedName(d, d.doubleQuoted);
	        }
	        else {
	            // see https://www.postgresql.org/docs/13/datatype.html
	            // & issue https://github.com/oguimbal/pgsql-ast-parser/issues/38
	            if (d.doubleQuoted) {
	                visitQualifiedName(d, true);
	            }
	            else {
	                switch (d.name) {
	                    case 'double precision':
	                    case 'character varying':
	                    case 'bit varying':
	                        ret.push(d.name, ' ');
	                        break;
	                    case 'time without time zone':
	                    case 'timestamp without time zone':
	                    case 'time with time zone':
	                    case 'timestamp with time zone':
	                        const parts = d.name.split(' ');
	                        ret.push(parts.shift());
	                        if ((_a = d.config) === null || _a === void 0 ? void 0 : _a.length) {
	                            list(d.config, v => ret.push(v.toString(10)), true);
	                        }
	                        ret.push(' ');
	                        ret.push(parts.join(' '), ' ');
	                        appendConfig = false;
	                        break;
	                    default:
	                        visitQualifiedName(d);
	                        break;
	                }
	            }
	        }
	        if (appendConfig && ((_b = d.config) === null || _b === void 0 ? void 0 : _b.length)) {
	            list(d.config, v => ret.push(v.toString(10)), true);
	        }
	    },
	    createIndex: c => {
	        ret.push(c.unique ? 'CREATE UNIQUE INDEX ' : 'CREATE INDEX ');
	        if (c.ifNotExists) {
	            ret.push(' IF NOT EXISTS ');
	        }
	        if (c.indexName) {
	            ret.push(name(c.indexName), ' ');
	        }
	        ret.push('ON ');
	        m.tableRef(c.table);
	        if (c.using) {
	            ret.push('USING ', name(c.using), ' ');
	        }
	        list(c.expressions, e => {
	            m.expr(e.expression);
	            ret.push(' ');
	            if (e.collate) {
	                ret.push('COLLATE ');
	                visitQualifiedName(e.collate);
	            }
	            if (e.opclass) {
	                visitQualifiedName(e.opclass);
	            }
	            if (e.order) {
	                ret.push(e.order, ' ');
	            }
	            if (e.nulls) {
	                ret.push('nulls ', e.nulls, ' ');
	            }
	        }, true);
	        if (c.with) {
	            ret.push('WITH ');
	            list(c.with, w => {
	                ret.push(w.parameter, ' = ', (0, pg_escape_1.literal)(w.value));
	            }, true);
	        }
	        if (c.tablespace) {
	            ret.push('TABLESPACE ', ident(c.tablespace));
	        }
	        if (c.where) {
	            ret.push(' WHERE ');
	            m.expr(c.where);
	        }
	        ret.push(' ');
	    },
	    createTable: t => {
	        var _a;
	        ret.push('CREATE ');
	        if (t.locality) {
	            ret.push(t.locality.toUpperCase(), ' ');
	        }
	        if (t.temporary) {
	            ret.push('TEMPORARY ');
	        }
	        if (t.unlogged) {
	            ret.push('UNLOGGED ');
	        }
	        ret.push(t.ifNotExists ? 'TABLE IF NOT EXISTS ' : 'TABLE ');
	        m.tableRef(t.name);
	        ret.push('(');
	        list(t.columns, c => {
	            switch (c.kind) {
	                case 'column':
	                    return m.createColumn(c);
	                case 'like table':
	                    return m.likeTable(c);
	                default:
	                    throw utils_1.NotSupported.never(c);
	            }
	        }, false);
	        if (t.constraints) {
	            ret.push(', ');
	            list(t.constraints, c => {
	                const cname = c.constraintName;
	                if (cname) {
	                    ret.push('CONSTRAINT ', name(cname), ' ');
	                }
	                addConstraint(c, m);
	            }, false);
	        }
	        ret.push(') ');
	        if ((_a = t.inherits) === null || _a === void 0 ? void 0 : _a.length) {
	            ret.push(' INHERITS ');
	            list(t.inherits, i => visitQualifiedName(i), true);
	        }
	    },
	    likeTable: l => {
	        ret.push(' LIKE ');
	        m.tableRef(l.like);
	        ret.push(' ');
	        for (const { verb, option } of l.options) {
	            ret.push(verb.toUpperCase(), ' ', option.toUpperCase(), ' ');
	        }
	    },
	    createSchema: s => {
	        ret.push(s.ifNotExists ? 'CREATE SCHEMA IF NOT EXISTS ' : 'CREATE SCHEMA ');
	        ret.push(name(s.name));
	    },
	    truncateTable: t => {
	        ret.push('TRUNCATE TABLE ');
	        let first = true;
	        for (const tbl of t.tables) {
	            if (!first) {
	                ret.push(', ');
	            }
	            first = false;
	            m.tableRef(tbl);
	        }
	        if (t.identity) {
	            switch (t.identity) {
	                case 'restart':
	                    ret.push(' RESTART IDENTITY ');
	                    break;
	                case 'continue':
	                    ret.push(' CONTINUE IDENTITY ');
	                    break;
	            }
	        }
	        if (t.cascade) {
	            ret.push(' ', t.cascade, ' ');
	        }
	    },
	    delete: t => {
	        ret.push('DELETE FROM ');
	        m.tableRef(t.from);
	        if (t.where) {
	            ret.push(' WHERE ');
	            m.expr(t.where);
	        }
	        if (t.returning) {
	            ret.push(' RETURNING ');
	            list(t.returning, r => m.selectionColumn(r), false);
	        }
	        ret.push(' ');
	    },
	    dropColumn: t => {
	        ret.push(' DROP COLUMN ');
	        if (t.ifExists) {
	            ret.push(' IF EXISTS ');
	        }
	        ret.push(name(t.column));
	        if (t.behaviour) {
	            ret.push(' ', t.behaviour);
	        }
	        ret.push(' ');
	    },
	    dropConstraint: t => {
	        ret.push(' DROP CONSTRAINT ');
	        if (t.ifExists) {
	            ret.push(' IF EXISTS ');
	        }
	        ret.push(name(t.constraint));
	        if (t.behaviour) {
	            ret.push(' ', t.behaviour.toUpperCase(), ' ');
	        }
	    },
	    from: t => m.super().from(t),
	    fromCall: s => {
	        join(m, s.join, () => {
	            var _a, _b;
	            m.call(s);
	            if (s.withOrdinality) {
	                ret.push(' WITH ORDINALITY');
	            }
	            if (s.alias) {
	                ret.push(' AS ', name(s.alias), ' ');
	                const len = (_b = (_a = s.alias.columns) === null || _a === void 0 ? void 0 : _a.length) !== null && _b !== void 0 ? _b : 0;
	                if (len > 0) {
	                    ret.push('(');
	                    for (let ix = 0; ix < len; ++ix) {
	                        if (ix !== 0) {
	                            ret.push(', ');
	                        }
	                        ret.push(name(s.alias.columns[ix]));
	                    }
	                    ret.push(')');
	                }
	            }
	        });
	        ret.push(' ');
	    },
	    fromStatement: s => {
	        // todo: use 's.db' if defined
	        join(m, s.join, () => {
	            ret.push('(');
	            m.select(s.statement);
	            ret.push(') ');
	            if (s.alias) {
	                ret.push(' AS ', ident(s.alias));
	                if (s.columnNames) {
	                    list(s.columnNames, c => ret.push(name(c)), true);
	                }
	                ret.push(' ');
	            }
	        });
	        ret.push(' ');
	    },
	    values: s => {
	        ret.push('VALUES ');
	        list(s.values, vlist => {
	            list(vlist, e => {
	                m.expr(e);
	            }, true);
	        }, false);
	    },
	    fromTable: s => {
	        join(m, s.join, () => {
	            m.tableRef(s.name);
	            if (s.name.columnNames) {
	                if (!s.name.alias) {
	                    throw new Error('Cannot specify aliased column names without an alias');
	                }
	                list(s.name.columnNames, c => ret.push(name(c)), true);
	            }
	        });
	    },
	    join: j => {
	        throw new Error('Should not happen ');
	    },
	    insert: i => {
	        ret.push('INSERT INTO ');
	        m.tableRef(i.into);
	        if (i.columns) {
	            ret.push('(', i.columns.map(name).join(', '), ')');
	        }
	        ret.push(' ');
	        if (i.overriding) {
	            ret.push('OVERRIDING ', i.overriding.toUpperCase(), ' VALUE ');
	        }
	        m.select(i.insert);
	        ret.push(' ');
	        if (i.onConflict) {
	            ret.push('ON CONFLICT ');
	            const on = i.onConflict.on;
	            switch (on === null || on === void 0 ? void 0 : on.type) {
	                case 'on expr':
	                    list(on.exprs, e => m.expr(e), true);
	                    break;
	                case 'on constraint':
	                    ret.push('ON CONSTRAINT ');
	                    visitQualifiedName(on.constraint);
	                case null:
	                case undefined:
	                    break;
	                default:
	                    throw utils_1.NotSupported.never(on);
	            }
	            if (i.onConflict.do === 'do nothing') {
	                ret.push(' DO NOTHING');
	            }
	            else {
	                ret.push(' DO UPDATE SET ');
	                list(i.onConflict.do.sets, s => m.set(s), false);
	                if (i.onConflict.where) {
	                    ret.push(' WHERE ');
	                    m.expr(i.onConflict.where);
	                }
	            }
	            ret.push(' ');
	        }
	        if (i.returning) {
	            ret.push(' RETURNING ');
	            list(i.returning, r => m.selectionColumn(r), false);
	        }
	    },
	    raise: r => {
	        var _a, _b;
	        ret.push('RAISE ');
	        if (r.level) {
	            ret.push(r.level.toUpperCase(), ' ');
	        }
	        ret.push((0, pg_escape_1.literal)(r.format), ' ');
	        if ((_a = r.formatExprs) === null || _a === void 0 ? void 0 : _a.length) {
	            ret.push(', ');
	            list(r.formatExprs, e => m.expr(e), false);
	        }
	        if ((_b = r.using) === null || _b === void 0 ? void 0 : _b.length) {
	            ret.push(' USING ');
	            list(r.using, ({ type, value }) => {
	                ret.push(type.toUpperCase(), '=');
	                m.expr(value);
	            }, false);
	        }
	        ret.push(' ');
	    },
	    default: () => {
	        ret.push(' DEFAULT ');
	    },
	    member: e => {
	        m.expr(e.operand);
	        ret.push(e.op);
	        ret.push(typeof e.member === 'number'
	            ? e.member.toString(10)
	            : (0, pg_escape_1.literal)(e.member));
	    },
	    ref: r => {
	        if (r.table) {
	            visitQualifiedName(r.table);
	            ret.push('.');
	        }
	        ret.push(r.name === '*' ? '*' : ident(r.name));
	    },
	    parameter: p => {
	        ret.push(p.name);
	    },
	    renameColumn: r => {
	        ret.push(' RENAME COLUMN ', name(r.column), ' TO ', name(r.to));
	    },
	    renameConstraint: r => {
	        ret.push(' RENAME CONSTRAINT ', name(r.constraint), ' TO ', name(r.to));
	    },
	    renameTable: r => {
	        ret.push(' RENAME TO ', name(r.to));
	    },
	    createView: c => {
	        ret.push('CREATE ');
	        if (c.orReplace) {
	            ret.push('OR REPLACE ');
	        }
	        if (c.temp) {
	            ret.push('TEMP ');
	        }
	        if (c.recursive) {
	            ret.push('RECURSIVE ');
	        }
	        ret.push('VIEW ');
	        m.tableRef(c.name);
	        if (c.columnNames) {
	            list(c.columnNames, c => ret.push(name(c)), true);
	        }
	        const opts = c.parameters && Object.entries(c.parameters);
	        if (opts === null || opts === void 0 ? void 0 : opts.length) {
	            ret.push(' WITH ');
	            list(opts, ([k, v]) => ret.push(k, '=', v), false);
	        }
	        ret.push(' AS ');
	        m.select(c.query);
	        if (c.checkOption) {
	            ret.push(' WITH ', c.checkOption.toUpperCase(), ' CHECK OPTION');
	        }
	    },
	    createMaterializedView: c => {
	        ret.push('CREATE MATERIALIZED VIEW ');
	        if (c.ifNotExists) {
	            ret.push('IF NOT EXISTS ');
	        }
	        m.tableRef(c.name);
	        if (c.columnNames) {
	            list(c.columnNames, c => ret.push(name(c)), true);
	        }
	        const opts = c.parameters && Object.entries(c.parameters);
	        if (opts === null || opts === void 0 ? void 0 : opts.length) {
	            ret.push(' WITH ');
	            list(opts, ([k, v]) => ret.push(k, '=', v), false);
	        }
	        if (c.tablespace) {
	            ret.push(' TABLESPACE ', name(c.tablespace));
	        }
	        ret.push(' AS ');
	        m.select(c.query);
	        if (typeof c.withData === 'boolean') {
	            ret.push(c.withData ? ' WITH DATA' : ' WITH NO DATA');
	        }
	    },
	    refreshMaterializedView: val => {
	        ret.push('REFRESH MATERIALIZED VIEW ');
	        if (val.concurrently) {
	            ret.push('CONCURRENTLY ');
	        }
	        m.tableRef(val.name);
	        if (typeof val.withData === 'boolean') {
	            ret.push(val.withData ? ' WITH DATA' : ' WITH NO DATA');
	        }
	    },
	    select: s => m.super().select(s),
	    selection: s => {
	        ret.push('SELECT ');
	        if (s.distinct) {
	            if (typeof s.distinct === 'string') {
	                ret.push(s.distinct.toUpperCase());
	            }
	            else {
	                ret.push(' DISTINCT ON ');
	                list(s.distinct, v => m.expr(v), true);
	            }
	            ret.push(' ');
	        }
	        if (s.columns) {
	            list(s.columns, c => m.selectionColumn(c), false);
	        }
	        ret.push(' ');
	        if (s.from) {
	            ret.push('FROM ');
	            const tblCnt = s.from.length;
	            for (let i = 0; i < tblCnt; i++) {
	                const f = s.from[i];
	                if (i > 0 && !f.join) {
	                    // implicit cross join (https://www.postgresql.org/docs/9.5/sql-select.html#SQL-FROM)
	                    ret.push(',');
	                }
	                m.from(f);
	            }
	            ret.push(' ');
	        }
	        if (s.where) {
	            ret.push('WHERE ');
	            m.expr(s.where);
	            ret.push(' ');
	        }
	        if (s.groupBy) {
	            ret.push('GROUP BY ');
	            list(s.groupBy, e => m.expr(e), false);
	            ret.push(' ');
	            if (s.having) {
	                ret.push(' HAVING ');
	                m.expr(s.having);
	                ret.push(' ');
	            }
	        }
	        if (s.orderBy) {
	            visitOrderBy(m, s.orderBy);
	            ret.push(' ');
	        }
	        if (s.limit) {
	            if (s.limit.offset) {
	                ret.push(`OFFSET `);
	                m.expr(s.limit.offset);
	            }
	            if (s.limit.limit) {
	                ret.push(`LIMIT `);
	                m.expr(s.limit.limit);
	            }
	        }
	        if (s.for) {
	            ret.push('FOR ', s.for.type.toUpperCase());
	            if (s.skip) {
	                ret.push(' ', s.skip.type.toUpperCase());
	            }
	        }
	    },
	    show: s => {
	        ret.push('SHOW ', name(s.variable));
	    },
	    prepare: s => {
	        var _a;
	        ret.push('PREPARE ', name(s.name));
	        if ((_a = s.args) === null || _a === void 0 ? void 0 : _a.length) {
	            list(s.args, a => m.dataType(a), true);
	        }
	        ret.push(' AS ');
	        m.statement(s.statement);
	    },
	    deallocate: s => {
	        ret.push('DEALLOCATE ');
	        if ('name' in s.target) {
	            ret.push(s.target.name);
	            return;
	        }
	        ret.push('ALL');
	    },
	    arraySelect: s => {
	        ret.push('array(');
	        m.select(s.select);
	        ret.push(')');
	    },
	    union: s => {
	        ret.push('(');
	        m.statement(s.left);
	        ret.push(') ', s.type.toUpperCase(), ' ');
	        if (s.right.type === 'union' || s.right.type === 'union all') {
	            m.union(s.right);
	        }
	        else {
	            ret.push('(');
	            m.statement(s.right);
	            ret.push(')');
	        }
	    },
	    selectionColumn: c => {
	        m.expr(c.expr);
	        if (c.alias) {
	            ret.push(' AS ', name(c.alias));
	        }
	        ret.push(' ');
	    },
	    set: s => {
	        ret.push(name(s.column), ' = ');
	        m.expr(s.value);
	        ret.push(' ');
	    },
	    statement: s => m.super().statement(s),
	    tableRef: r => {
	        visitQualifiedName(r);
	        if (r.alias) {
	            ret.push(' AS ', ident(r.alias));
	        }
	        ret.push(' ');
	    },
	    ternary: t => {
	        m.expr(t.value);
	        ret.push(' ', t.op, ' ');
	        m.expr(t.lo);
	        ret.push(' AND ');
	        m.expr(t.hi);
	        ret.push(' ');
	    },
	    transaction: t => {
	        ret.push(t.type);
	    },
	    unary: t => {
	        switch (t.op) {
	            case '+':
	            case '-':
	                // prefix ops
	                visitOp(t);
	                m.expr(t.operand);
	                break;
	            case 'NOT':
	                // prefix ops
	                ret.push(t.op);
	                ret.push(' ');
	                m.expr(t.operand);
	                break;
	            default:
	                // postfix ops
	                m.expr(t.operand);
	                ret.push(' ');
	                ret.push(t.op);
	        }
	    },
	    update: u => {
	        ret.push('UPDATE ');
	        m.tableRef(u.table);
	        ret.push(' SET ');
	        list(u.sets, s => m.set(s), false);
	        ret.push(' ');
	        if (u.from) {
	            ret.push('FROM ');
	            m.from(u.from);
	            ret.push(' ');
	        }
	        if (u.where) {
	            ret.push('WHERE ');
	            m.expr(u.where);
	            ret.push(' ');
	        }
	        if (u.returning) {
	            ret.push(' RETURNING ');
	            list(u.returning, r => m.selectionColumn(r), false);
	            ret.push(' ');
	        }
	    },
	}));
	exports.toSql = {};
	const proto = ast_mapper_1.AstDefaultMapper.prototype;
	for (const k of Object.getOwnPropertyNames(proto)) {
	    const orig = proto[k];
	    if (k === 'constructor' || k === 'super' || typeof orig !== 'function') {
	        continue;
	    }
	    exports.toSql[k] = function (...args) {
	        try {
	            visitor[k].apply(visitor, args);
	            return ret.join('').trim();
	        }
	        finally {
	            ret = [];
	        }
	    };
	}


	/***/ }),
	/* 20 */
	/***/ (function(module, exports, __webpack_require__) {

	// stolen from https://github.com/segmentio/pg-escape/blob/master/index.js
	Object.defineProperty(exports, "__esModule", { value: true });
	exports.literal = void 0;
	function literal(val) {
	    if (null == val)
	        return 'NULL';
	    if (Array.isArray(val)) {
	        var vals = val.map(literal);
	        return "(" + vals.join(", ") + ")";
	    }
	    var backslash = ~val.indexOf('\\');
	    var prefix = backslash ? 'E' : '';
	    val = val.replace(/'/g, "''");
	    val = val.replace(/\\/g, '\\\\');
	    return prefix + "'" + val + "'";
	}
	exports.literal = literal;


	/***/ }),
	/* 21 */
	/***/ (function(module, exports, __webpack_require__) {

	Object.defineProperty(exports, "__esModule", { value: true });
	exports.locationOf = void 0;
	function locationOf(node) {
	    const n = node._location;
	    if (!n) {
	        throw new Error('This statement has not been parsed using location tracking (which has a small performance hit). ');
	    }
	    return n;
	}
	exports.locationOf = locationOf;


	/***/ })
	/******/ ])));
	
} (pgsqlAstParser));

const DEFAULT_TAG = 'default';
const DEFAULT_SCHEMA = 'public';
/**
 * Some pattern matching SourceTables.
 */
class TablePattern {
    constructor(schema, tablePattern) {
        schema ?? (schema = DEFAULT_SCHEMA);
        const splitSchema = schema.split('.');
        if (splitSchema.length > 2) {
            throw new Error(`Invalid schema: ${schema}`);
        }
        if (splitSchema.length == 2) {
            this.connectionTag = splitSchema[0];
            this.schema = splitSchema[1];
        }
        else {
            this.connectionTag = DEFAULT_TAG;
            this.schema = schema;
        }
        this.tablePattern = tablePattern;
    }
    get isWildcard() {
        return this.tablePattern.endsWith('%');
    }
    get tablePrefix() {
        if (!this.isWildcard) {
            throw new Error('Not a wildcard table');
        }
        return this.tablePattern.substring(0, this.tablePattern.length - 1);
    }
    get name() {
        if (this.isWildcard) {
            throw new Error('Cannot get name for wildcard table');
        }
        return this.tablePattern;
    }
    matches(table) {
        if (this.connectionTag != table.connectionTag || this.schema != table.schema) {
            return false;
        }
        if (this.isWildcard) {
            return table.table.startsWith(this.tablePrefix);
        }
        else {
            return this.tablePattern == table.table;
        }
    }
    suffix(table) {
        if (!this.isWildcard) {
            return '';
        }
        return table.substring(this.tablePrefix.length);
    }
}

class TableQuerySchema {
    constructor(tables, alias) {
        this.tables = tables;
        this.alias = alias;
    }
    getType(table, column) {
        if (table != this.alias) {
            return ExpressionType.NONE;
        }
        for (let table of this.tables) {
            const t = table.getType(column);
            if (t != null) {
                return t;
            }
        }
        return ExpressionType.NONE;
    }
    getColumns(table) {
        if (table != this.alias) {
            return [];
        }
        let columns = {};
        for (let table of this.tables) {
            for (let col of table.getColumns()) {
                if (!(col.name in columns)) {
                    columns[col.name] = col;
                }
            }
        }
        return Object.values(columns);
    }
}

class SqlDataQuery {
    static fromSql(descriptor_name, bucket_parameters, sql, schema) {
        const parsed = pgsqlAstParser.parse(sql, { locationTracking: true });
        const rows = new SqlDataQuery();
        if (parsed.length > 1) {
            throw new SqlRuleError('Only a single SELECT statement is supported', sql, parsed[1]?._location);
        }
        const q = parsed[0];
        if (!isSelectStatement(q)) {
            throw new SqlRuleError('Only SELECT statements are supported', sql, q._location);
        }
        rows.errors.push(...checkUnsupportedFeatures(sql, q));
        if (q.from == null || q.from.length != 1 || q.from[0].type != 'table') {
            throw new SqlRuleError('Must SELECT from a single table', sql, q.from?.[0]._location);
        }
        const tableRef = q.from?.[0].name;
        if (tableRef?.name == null) {
            throw new SqlRuleError('Must SELECT from a single table', sql, q.from?.[0]._location);
        }
        const alias = tableRef.alias ?? tableRef.name;
        const sourceTable = new TablePattern(tableRef.schema, tableRef.name);
        let querySchema = undefined;
        if (schema) {
            const tables = schema.getTables(sourceTable);
            if (tables.length == 0) {
                const e = new SqlRuleError(`Table ${sourceTable.schema}.${sourceTable.tablePattern} not found`, sql, q.from?.[0]?._location);
                e.type = 'warning';
                rows.errors.push(e);
            }
            else {
                querySchema = new TableQuerySchema(tables, alias);
            }
        }
        const where = q.where;
        const tools = new SqlTools({
            table: alias,
            parameter_tables: ['bucket'],
            value_tables: [alias],
            sql,
            schema: querySchema
        });
        const filter = tools.compileWhereClause(where);
        const inputParameterNames = filter.inputParameters.map((p) => p.key);
        const bucketParameterNames = bucket_parameters.map((p) => `bucket.${p}`);
        const allParams = new Set([...inputParameterNames, ...bucketParameterNames]);
        if ((!filter.error && allParams.size != filter.inputParameters.length) ||
            allParams.size != bucket_parameters.length) {
            rows.errors.push(new SqlRuleError(`Query must cover all bucket parameters. Expected: ${JSONBig.stringify(bucketParameterNames)} Got: ${JSONBig.stringify(inputParameterNames)}`, sql, q._location));
        }
        rows.sourceTable = sourceTable;
        rows.table = alias;
        rows.sql = sql;
        rows.filter = filter;
        rows.descriptor_name = descriptor_name;
        rows.bucket_parameters = bucket_parameters;
        rows.columns = q.columns ?? [];
        rows.tools = tools;
        let hasId = false;
        let hasWildcard = false;
        for (let column of q.columns ?? []) {
            const name = tools.getOutputName(column);
            if (name != '*') {
                const clause = tools.compileRowValueExtractor(column.expr);
                if (isClauseError(clause)) {
                    // Error logged already
                    continue;
                }
                rows.extractors.push({
                    extract: (tables, output) => {
                        output[name] = clause.evaluate(tables);
                    },
                    getTypes(schema, into) {
                        into[name] = { name, type: clause.getType(schema) };
                    }
                });
            }
            else {
                rows.extractors.push({
                    extract: (tables, output) => {
                        const row = tables[alias];
                        for (let key in row) {
                            if (key.startsWith('_')) {
                                continue;
                            }
                            output[key] ?? (output[key] = row[key]);
                        }
                    },
                    getTypes(schema, into) {
                        var _a;
                        for (let column of schema.getColumns(alias)) {
                            into[_a = column.name] ?? (into[_a] = column);
                        }
                    }
                });
            }
            if (name == 'id') {
                hasId = true;
            }
            else if (name == '*') {
                hasWildcard = true;
                if (querySchema == null) {
                    // Not performing schema-based validation - assume there is an id
                    hasId = true;
                }
                else {
                    const idType = querySchema.getType(alias, 'id');
                    if (!idType.isNone()) {
                        hasId = true;
                    }
                }
            }
        }
        if (!hasId) {
            const error = new SqlRuleError(`Query must return an "id" column`, sql, q.columns?.[0]._location);
            if (hasWildcard) {
                // Schema-based validations are always warnings
                error.type = 'warning';
            }
            rows.errors.push(error);
        }
        rows.errors.push(...tools.errors);
        return rows;
    }
    constructor() {
        this.extractors = [];
        this.errors = [];
    }
    applies(table) {
        return this.sourceTable?.matches(table);
    }
    addSpecialParameters(table, row) {
        if (this.sourceTable.isWildcard) {
            return {
                ...row,
                _table_suffix: this.sourceTable.suffix(table.table)
            };
        }
        else {
            return row;
        }
    }
    getOutputName(sourceTable) {
        if (this.isUnaliasedWildcard()) {
            // Wildcard without alias - use source
            return sourceTable;
        }
        else {
            return this.table;
        }
    }
    isUnaliasedWildcard() {
        return this.sourceTable.isWildcard && this.table == this.sourceTable.tablePattern;
    }
    evaluateRow(table, row) {
        try {
            const tables = { [this.table]: this.addSpecialParameters(table, row) };
            const bucketParameters = this.filter.filterRow(tables);
            const bucketIds = bucketParameters.map((params) => getBucketId(this.descriptor_name, this.bucket_parameters, params));
            const data = this.transformRow(tables);
            let id = data.id;
            if (typeof id != 'string') {
                // While an explicit cast would be better, this covers against very common
                // issues when initially testing out sync, for example when the id column is an
                // auto-incrementing integer.
                // If there is no id column, we use a blank id. This will result in the user syncing
                // a single arbitrary row for this table - better than just not being able to sync
                // anything.
                id = castAsText(id) ?? '';
            }
            const outputTable = this.getOutputName(table.table);
            return bucketIds.map((bucketId) => {
                return {
                    bucket: bucketId,
                    table: outputTable,
                    id: id,
                    data,
                    ruleId: this.ruleId
                };
            });
        }
        catch (e) {
            return [{ error: e.message ?? `Evaluating data query failed` }];
        }
    }
    transformRow(tables) {
        let result = {};
        for (let extractor of this.extractors) {
            extractor.extract(tables, result);
        }
        return filterJsonRow(result);
    }
    columnOutputNames() {
        return this.columns.map((c) => {
            return this.tools.getOutputName(c);
        });
    }
    getColumnOutputs(schema) {
        let result = [];
        if (this.isUnaliasedWildcard()) {
            // Separate results
            for (let schemaTable of schema.getTables(this.sourceTable)) {
                let output = {};
                this.getColumnOutputsFor(schemaTable, output);
                result.push({
                    name: this.getOutputName(schemaTable.table),
                    columns: Object.values(output)
                });
            }
        }
        else {
            // Merged results
            let output = {};
            for (let schemaTable of schema.getTables(this.sourceTable)) {
                this.getColumnOutputsFor(schemaTable, output);
            }
            result.push({
                name: this.table,
                columns: Object.values(output)
            });
        }
        return result;
    }
    getColumnOutputsFor(schemaTable, output) {
        const querySchema = {
            getType: (table, column) => {
                if (table == this.table) {
                    return schemaTable.getType(column) ?? ExpressionType.NONE;
                }
                else {
                    // TODO: bucket parameters?
                    return ExpressionType.NONE;
                }
            },
            getColumns: (table) => {
                if (table == this.table) {
                    return schemaTable.getColumns();
                }
                else {
                    return [];
                }
            }
        };
        for (let extractor of this.extractors) {
            extractor.getTypes(querySchema, output);
        }
    }
}

/**
 * Represents a bucket parameter query without any tables, e.g.:
 *
 *    SELECT token_parameters.user_id
 *    SELECT token_parameters.user_id as user_id WHERE token_parameters.is_admin
 */
class StaticSqlParameterQuery {
    constructor() {
        this.parameter_extractors = {};
        this.errors = [];
    }
    static fromSql(descriptor_name, sql, q, options) {
        const query = new StaticSqlParameterQuery();
        query.errors.push(...checkUnsupportedFeatures(sql, q));
        const tools = new SqlTools({
            table: undefined,
            parameter_tables: ['token_parameters', 'user_parameters'],
            supports_parameter_expressions: true,
            sql
        });
        const where = q.where;
        const filter = tools.compileParameterValueExtractor(where);
        const columns = q.columns ?? [];
        const bucket_parameters = columns.map((column) => tools.getOutputName(column));
        query.sql = sql;
        query.descriptor_name = descriptor_name;
        query.bucket_parameters = bucket_parameters;
        query.columns = columns;
        query.tools = tools;
        if (!isClauseError(filter)) {
            query.filter = filter;
        }
        for (let column of columns) {
            const name = tools.getSpecificOutputName(column);
            const extractor = tools.compileParameterValueExtractor(column.expr);
            if (isClauseError(extractor)) {
                // Error logged already
                continue;
            }
            query.parameter_extractors[name] = extractor;
        }
        query.errors.push(...tools.errors);
        if (query.usesDangerousRequestParameters && !options?.accept_potentially_dangerous_queries) {
            let err = new SqlRuleError("Potentially dangerous query based on parameters set by the client. The client can send any value for these parameters so it's not a good place to do authorization.", sql);
            err.type = 'warning';
            query.errors.push(err);
        }
        return query;
    }
    getStaticBucketIds(parameters) {
        if (this.filter == null) {
            // Error in filter clause
            return [];
        }
        const filterValue = this.filter.lookupParameterValue(parameters);
        if (sqliteBool(filterValue) === 0n) {
            return [];
        }
        let result = {};
        for (let name of this.bucket_parameters) {
            const value = this.parameter_extractors[name].lookupParameterValue(parameters);
            if (isJsonValue(value)) {
                result[`bucket.${name}`] = value;
            }
            else {
                // Not valid.
                // Should we error instead?
                return [];
            }
        }
        return [getBucketId(this.descriptor_name, this.bucket_parameters, result)];
    }
    get hasAuthenticatedBucketParameters() {
        // select where request.jwt() ->> 'role' == 'authorized'
        // we do not count this as a sufficient check
        // const authenticatedFilter = this.filter!.usesAuthenticatedRequestParameters;
        // select request.user_id() as user_id
        const authenticatedExtractor = Object.values(this.parameter_extractors).find((clause) => isParameterValueClause(clause) && clause.usesAuthenticatedRequestParameters) != null;
        return authenticatedExtractor;
    }
    get usesUnauthenticatedRequestParameters() {
        // select where request.parameters() ->> 'include_comments'
        const unauthenticatedFilter = this.filter.usesUnauthenticatedRequestParameters;
        // select request.parameters() ->> 'project_id'
        const unauthenticatedExtractor = Object.values(this.parameter_extractors).find((clause) => isParameterValueClause(clause) && clause.usesUnauthenticatedRequestParameters) != null;
        return unauthenticatedFilter || unauthenticatedExtractor;
    }
    get usesDangerousRequestParameters() {
        return this.usesUnauthenticatedRequestParameters && !this.hasAuthenticatedBucketParameters;
    }
}

/**
 * Represents a parameter query, such as:
 *
 *  SELECT id as user_id FROM users WHERE users.user_id = token_parameters.user_id
 *  SELECT id as user_id, token_parameters.is_admin as is_admin FROM users WHERE users.user_id = token_parameters.user_id
 */
class SqlParameterQuery {
    static fromSql(descriptor_name, sql, schema, options) {
        const parsed = pgsqlAstParser.parse(sql, { locationTracking: true });
        const rows = new SqlParameterQuery();
        if (parsed.length > 1) {
            throw new SqlRuleError('Only a single SELECT statement is supported', sql, parsed[1]?._location);
        }
        const q = parsed[0];
        if (!isSelectStatement(q)) {
            throw new SqlRuleError('Only SELECT statements are supported', sql, q._location);
        }
        if (q.from == null) {
            // E.g. SELECT token_parameters.user_id as user_id WHERE token_parameters.is_admin
            return StaticSqlParameterQuery.fromSql(descriptor_name, sql, q, options);
        }
        rows.errors.push(...checkUnsupportedFeatures(sql, q));
        if (q.from.length != 1 || q.from[0].type != 'table') {
            throw new SqlRuleError('Must SELECT from a single table', sql, q.from?.[0]._location);
        }
        const tableRef = q.from?.[0].name;
        if (tableRef?.name == null) {
            throw new SqlRuleError('Must SELECT from a single table', sql, q.from?.[0]._location);
        }
        const alias = q.from?.[0].name.alias ?? tableRef.name;
        if (tableRef.name != alias) {
            rows.errors.push(new SqlRuleError('Table aliases not supported in parameter queries', sql, q.from?.[0]._location));
        }
        const sourceTable = new TablePattern(tableRef.schema, tableRef.name);
        let querySchema = undefined;
        if (schema) {
            const tables = schema.getTables(sourceTable);
            if (tables.length == 0) {
                const e = new SqlRuleError(`Table ${sourceTable.schema}.${sourceTable.tablePattern} not found`, sql, q.from?.[0]?._location);
                e.type = 'warning';
                rows.errors.push(e);
            }
            else {
                querySchema = new TableQuerySchema(tables, alias);
            }
        }
        const tools = new SqlTools({
            table: alias,
            parameter_tables: ['token_parameters', 'user_parameters'],
            sql,
            supports_expanding_parameters: true,
            supports_parameter_expressions: true,
            schema: querySchema
        });
        const where = q.where;
        const filter = tools.compileWhereClause(where);
        const bucket_parameters = (q.columns ?? []).map((column) => tools.getOutputName(column));
        rows.sourceTable = sourceTable;
        rows.table = alias;
        rows.sql = sql;
        rows.filter = filter;
        rows.descriptor_name = descriptor_name;
        rows.bucket_parameters = bucket_parameters;
        rows.input_parameters = filter.inputParameters;
        const expandedParams = rows.input_parameters.filter((param) => param.expands);
        if (expandedParams.length > 1) {
            rows.errors.push(new SqlRuleError('Cannot have multiple array input parameters', sql));
        }
        rows.expanded_input_parameter = expandedParams[0];
        rows.columns = q.columns ?? [];
        rows.static_columns = [];
        rows.lookup_columns = [];
        for (let column of q.columns ?? []) {
            const name = tools.getSpecificOutputName(column);
            if (tools.isTableRef(column.expr)) {
                rows.lookup_columns.push(column);
                const extractor = tools.compileRowValueExtractor(column.expr);
                if (isClauseError(extractor)) {
                    // Error logged already
                    continue;
                }
                rows.lookup_extractors[name] = extractor;
            }
            else {
                rows.static_columns.push(column);
                const extractor = tools.compileParameterValueExtractor(column.expr);
                if (isClauseError(extractor)) {
                    // Error logged already
                    continue;
                }
                rows.parameter_extractors[name] = extractor;
            }
        }
        rows.tools = tools;
        rows.errors.push(...tools.errors);
        if (rows.usesDangerousRequestParameters && !options?.accept_potentially_dangerous_queries) {
            let err = new SqlRuleError("Potentially dangerous query based on parameters set by the client. The client can send any value for these parameters so it's not a good place to do authorization.", sql);
            err.type = 'warning';
            rows.errors.push(err);
        }
        return rows;
    }
    constructor() {
        /**
         * Example: SELECT *user.id* FROM users WHERE ...
         */
        this.lookup_extractors = {};
        /**
         * Example: SELECT *token_parameters.user_id*
         */
        this.parameter_extractors = {};
        this.errors = [];
    }
    applies(table) {
        return this.sourceTable.matches(table);
    }
    evaluateParameterRow(row) {
        const tables = {
            [this.table]: row
        };
        try {
            const filterParameters = this.filter.filterRow(tables);
            let result = [];
            for (let filterParamSet of filterParameters) {
                let lookup = [this.descriptor_name, this.id];
                lookup.push(...this.input_parameters.map((param) => {
                    return param.filteredRowToLookupValue(filterParamSet);
                }));
                const data = this.transformRows(row);
                const role = {
                    bucket_parameters: data.map((row) => filterJsonRow(row)),
                    lookup: lookup
                };
                result.push(role);
            }
            return result;
        }
        catch (e) {
            return [{ error: e.message ?? `Evaluating parameter query failed` }];
        }
    }
    transformRows(row) {
        const tables = { [this.table]: row };
        let result = {};
        for (let key in this.lookup_extractors) {
            const extractor = this.lookup_extractors[key];
            result[key] = extractor.evaluate(tables);
        }
        return [result];
    }
    /**
     * Given partial parameter rows, turn into bucket ids.
     */
    resolveBucketIds(bucketParameters, parameters) {
        // Filters have already been applied and gotten us the set of bucketParameters - don't attempt to filter again.
        // We _do_ need to evaluate the output columns here, using a combination of precomputed bucketParameters,
        // and values from token parameters.
        return bucketParameters
            .map((lookup) => {
            let result = {};
            for (let name of this.bucket_parameters) {
                if (name in this.lookup_extractors) {
                    result[`bucket.${name}`] = lookup[name];
                }
                else {
                    const value = this.parameter_extractors[name].lookupParameterValue(parameters);
                    if (!isJsonValue(value)) {
                        // Not valid - exclude.
                        // Should we error instead?
                        return null;
                    }
                    else {
                        result[`bucket.${name}`] = value;
                    }
                }
            }
            return getBucketId(this.descriptor_name, this.bucket_parameters, result);
        })
            .filter((lookup) => lookup != null);
    }
    /**
     * Given sync parameters, get lookups we need to perform on the database.
     *
     * Each lookup is [bucket definition name, parameter query index, ...lookup values]
     */
    getLookups(parameters) {
        if (!this.expanded_input_parameter) {
            let lookup = [this.descriptor_name, this.id];
            let valid = true;
            lookup.push(...this.input_parameters.map((param) => {
                // Scalar value
                const value = param.parametersToLookupValue(parameters);
                if (isJsonValue(value)) {
                    return value;
                }
                else {
                    valid = false;
                    return null;
                }
            }));
            if (!valid) {
                return [];
            }
            return [lookup];
        }
        else {
            const arrayString = this.expanded_input_parameter.parametersToLookupValue(parameters);
            if (arrayString == null || typeof arrayString != 'string') {
                return [];
            }
            let values;
            try {
                values = JSON.parse(arrayString);
                if (!Array.isArray(values)) {
                    return [];
                }
            }
            catch (e) {
                return [];
            }
            return values
                .map((expandedValue) => {
                let lookup = [this.descriptor_name, this.id];
                let valid = true;
                lookup.push(...this.input_parameters.map((param) => {
                    if (param == this.expanded_input_parameter) {
                        // Expand array value
                        return expandedValue;
                    }
                    else {
                        // Scalar value
                        const value = param.parametersToLookupValue(parameters);
                        if (isJsonValue(value)) {
                            return value;
                        }
                        else {
                            valid = false;
                            return null;
                        }
                    }
                }));
                if (!valid) {
                    return null;
                }
                return lookup;
            })
                .filter((lookup) => lookup != null);
        }
    }
    /**
     * Given sync parameters (token and user parameters), return bucket ids.
     *
     * This is done in three steps:
     * 1. Given the parameters, get lookups we need to perform on the database.
     * 2. Perform the lookups, returning parameter sets (partial rows).
     * 3. Given the parameter sets, resolve bucket ids.
     */
    async queryBucketIds(options) {
        let lookups = this.getLookups(options.parameters);
        if (lookups.length == 0) {
            return [];
        }
        const parameters = await options.getParameterSets(lookups);
        return this.resolveBucketIds(parameters, options.parameters);
    }
    get hasAuthenticatedBucketParameters() {
        // select request.user_id() as user_id where ...
        const authenticatedExtractor = Object.values(this.parameter_extractors).find((clause) => isParameterValueClause(clause) && clause.usesAuthenticatedRequestParameters) != null;
        return authenticatedExtractor;
    }
    get hasAuthenticatedMatchClause() {
        // select ... where user_id = request.user_id()
        this.filter?.inputParameters.find;
        const authenticatedInputParameter = this.filter.usesAuthenticatedRequestParameters;
        return authenticatedInputParameter;
    }
    get usesUnauthenticatedRequestParameters() {
        // select ... where request.parameters() ->> 'include_comments'
        const unauthenticatedInputParameter = this.filter.usesUnauthenticatedRequestParameters;
        // select request.parameters() ->> 'project_id'
        const unauthenticatedExtractor = Object.values(this.parameter_extractors).find((clause) => isParameterValueClause(clause) && clause.usesUnauthenticatedRequestParameters) != null;
        return unauthenticatedInputParameter || unauthenticatedExtractor;
    }
    /**
     * Safe:
     * SELECT id as user_id FROM users WHERE users.user_id = request.user_id()
     * SELECT request.jwt() ->> 'org_id' as org_id, id as project_id FROM projects WHERE id = request.parameters() ->> 'project_id'
     * SELECT id as project_id FROM projects WHERE org_id = request.jwt() ->> 'org_id' AND id = request.parameters() ->> 'project_id'
     * SELECT id as category_id FROM categories
     *
     * Dangerous:
     * SELECT id as project_id FROM projects WHERE id = request.parameters() ->> 'project_id'
     * SELECT id as project_id FROM projects WHERE id = request.parameters() ->> 'project_id' AND request.jwt() ->> 'role' = 'authenticated'
     * SELECT id as category_id, request.parameters() ->> 'project_id' as project_id FROM categories
     * SELECT id as category_id FROM categories WHERE request.parameters() ->> 'include_categories'
     */
    get usesDangerousRequestParameters() {
        return (this.usesUnauthenticatedRequestParameters &&
            !this.hasAuthenticatedBucketParameters &&
            !this.hasAuthenticatedMatchClause);
    }
}

class SqlBucketDescriptor {
    constructor(name, idSequence) {
        this.idSequence = idSequence;
        /**
         * source table -> queries
         */
        this.data_queries = [];
        this.parameter_queries = [];
        this.global_parameter_queries = [];
        this.parameterIdSequence = new IdSequence();
        this.name = name;
    }
    addDataQuery(sql, schema) {
        if (this.bucket_parameters == null) {
            throw new Error('Bucket parameters must be defined');
        }
        const dataRows = SqlDataQuery.fromSql(this.name, this.bucket_parameters, sql, schema);
        dataRows.ruleId = this.idSequence.nextId();
        this.data_queries.push(dataRows);
        return {
            parsed: true,
            errors: dataRows.errors
        };
    }
    addParameterQuery(sql, schema, options) {
        const parameterQuery = SqlParameterQuery.fromSql(this.name, sql, schema, options);
        if (this.bucket_parameters == null) {
            this.bucket_parameters = parameterQuery.bucket_parameters;
        }
        else {
            if (new Set([...parameterQuery.bucket_parameters, ...this.bucket_parameters]).size != this.bucket_parameters.length) {
                throw new Error('Bucket parameters must match for each parameter query within a bucket');
            }
        }
        parameterQuery.id = this.parameterIdSequence.nextId();
        if (parameterQuery instanceof SqlParameterQuery) {
            this.parameter_queries.push(parameterQuery);
        }
        else {
            this.global_parameter_queries.push(parameterQuery);
        }
        return {
            parsed: true,
            errors: parameterQuery.errors
        };
    }
    evaluateRow(options) {
        let results = [];
        for (let query of this.data_queries) {
            if (!query.applies(options.sourceTable)) {
                continue;
            }
            results.push(...query.evaluateRow(options.sourceTable, options.record));
        }
        return results;
    }
    evaluateParameterRow(sourceTable, row) {
        let results = [];
        for (let query of this.parameter_queries) {
            if (query.applies(sourceTable)) {
                results.push(...query.evaluateParameterRow(row));
            }
        }
        return results;
    }
    getStaticBucketIds(parameters) {
        let results = [];
        for (let query of this.global_parameter_queries) {
            results.push(...query.getStaticBucketIds(parameters));
        }
        return results;
    }
    async queryBucketIds(options) {
        let result = this.getStaticBucketIds(options.parameters);
        for (let query of this.parameter_queries) {
            result.push(...(await query.queryBucketIds(options)));
        }
        return result;
    }
    getSourceTables() {
        let result = new Set();
        for (let query of this.parameter_queries) {
            result.add(query.sourceTable);
        }
        for (let query of this.data_queries) {
            result.add(query.sourceTable);
        }
        // Note: No physical tables for global_parameter_queries
        return result;
    }
    tableSyncsData(table) {
        for (let query of this.data_queries) {
            if (query.applies(table)) {
                return true;
            }
        }
        return false;
    }
    tableSyncsParameters(table) {
        for (let query of this.parameter_queries) {
            if (query.applies(table)) {
                return true;
            }
        }
        return false;
    }
}

function isEvaluationError(e) {
    return typeof e.error == 'string';
}
function isEvaluatedRow(e) {
    return typeof e.bucket == 'string';
}
function isEvaluatedParameters(e) {
    return Array.isArray(e.lookup);
}

const ACCEPT_POTENTIALLY_DANGEROUS_QUERIES = Symbol('ACCEPT_POTENTIALLY_DANGEROUS_QUERIES');
class SqlSyncRules {
    static validate(yaml, options) {
        try {
            const rules = this.fromYaml(yaml, options);
            return rules.errors;
        }
        catch (e) {
            if (e instanceof SyncRulesErrors) {
                return e.errors;
            }
            else if (e instanceof YamlError) {
                return [e];
            }
            else {
                return [new YamlError(e)];
            }
        }
    }
    static fromYaml(yaml, options) {
        const throwOnError = options?.throwOnError ?? true;
        const schema = options?.schema;
        const lineCounter = new LineCounter();
        const parsed = parseDocument(yaml, {
            schema: 'core',
            keepSourceTokens: true,
            lineCounter,
            customTags: [
                {
                    tag: '!accept_potentially_dangerous_queries',
                    resolve(_text, _onError) {
                        return ACCEPT_POTENTIALLY_DANGEROUS_QUERIES;
                    }
                }
            ]
        });
        const rules = new SqlSyncRules(yaml);
        if (parsed.errors.length > 0) {
            rules.errors.push(...parsed.errors.map((error) => {
                return new YamlError(error);
            }));
            if (throwOnError) {
                rules.throwOnError();
            }
            return rules;
        }
        const bucketMap = parsed.get('bucket_definitions');
        if (bucketMap == null) {
            rules.errors.push(new YamlError(new Error(`'bucket_definitions' is required`)));
            if (throwOnError) {
                rules.throwOnError();
            }
            return rules;
        }
        for (let entry of bucketMap.items) {
            const { key: keyScalar, value } = entry;
            const key = keyScalar.toString();
            const accept_potentially_dangerous_queries = value.get('accept_potentially_dangerous_queries', true)?.value == true;
            const options = {
                accept_potentially_dangerous_queries
            };
            const parameters = value.get('parameters', true);
            const dataQueries = value.get('data', true);
            const descriptor = new SqlBucketDescriptor(key, rules.idSequence);
            if (parameters instanceof Scalar) {
                rules.withScalar(parameters, (q) => {
                    return descriptor.addParameterQuery(q, schema, options);
                });
            }
            else if (parameters instanceof YAMLSeq) {
                for (let item of parameters.items) {
                    rules.withScalar(item, (q) => {
                        return descriptor.addParameterQuery(q, schema, options);
                    });
                }
            }
            else {
                descriptor.addParameterQuery('SELECT', schema, options);
            }
            if (!(dataQueries instanceof YAMLSeq)) {
                rules.errors.push(this.tokenError(dataQueries ?? value, `'data' must be an array`));
                continue;
            }
            for (let query of dataQueries.items) {
                rules.withScalar(query, (q) => {
                    return descriptor.addDataQuery(q, schema);
                });
            }
            rules.bucket_descriptors.push(descriptor);
        }
        // Validate that there are no additional properties.
        // Since these errors don't contain line numbers, do this last.
        const valid = validateSyncRulesSchema(parsed.toJSON());
        if (!valid) {
            rules.errors.push(...validateSyncRulesSchema.errors.map((e) => {
                return new YamlError(e);
            }));
        }
        if (throwOnError) {
            rules.throwOnError();
        }
        return rules;
    }
    throwOnError() {
        if (this.errors.filter((e) => e.type != 'warning').length > 0) {
            throw new SyncRulesErrors(this.errors);
        }
    }
    static tokenError(token, message) {
        const start = token?.srcToken?.offset ?? 0;
        const end = start + 1;
        return new YamlError(new Error(message), { start, end });
    }
    withScalar(scalar, cb) {
        const value = scalar.toString();
        const wrapped = (value) => {
            try {
                return cb(value);
            }
            catch (e) {
                return {
                    parsed: false,
                    errors: [e]
                };
            }
        };
        const result = wrapped(value);
        for (let err of result.errors) {
            let sourceOffset = scalar.srcToken.offset;
            if (scalar.type == Scalar.QUOTE_DOUBLE || scalar.type == Scalar.QUOTE_SINGLE) {
                // TODO: Is there a better way to do this?
                sourceOffset += 1;
            }
            let offset;
            let end;
            if (err instanceof SqlRuleError && err.location) {
                offset = err.location.start + sourceOffset;
                end = err.location.end + sourceOffset;
            }
            else if (typeof err.token?._location?.start == 'number') {
                offset = sourceOffset + err.token?._location?.start;
                end = sourceOffset + err.token?._location?.end;
            }
            else {
                offset = sourceOffset;
                end = sourceOffset + Math.max(value.length, 1);
            }
            const pos = { start: offset, end };
            this.errors.push(new YamlError(err, pos));
        }
        return result;
    }
    constructor(content) {
        this.bucket_descriptors = [];
        this.idSequence = new IdSequence();
        this.errors = [];
        this.content = content;
    }
    /**
     * Throws errors.
     */
    evaluateRow(options) {
        const { results, errors } = this.evaluateRowWithErrors(options);
        if (errors.length > 0) {
            throw new Error(errors[0].error);
        }
        return results;
    }
    evaluateRowWithErrors(options) {
        let rawResults = [];
        for (let query of this.bucket_descriptors) {
            rawResults.push(...query.evaluateRow(options));
        }
        const results = rawResults.filter(isEvaluatedRow);
        const errors = rawResults.filter(isEvaluationError);
        return { results, errors };
    }
    /**
     * Throws errors.
     */
    evaluateParameterRow(table, row) {
        const { results, errors } = this.evaluateParameterRowWithErrors(table, row);
        if (errors.length > 0) {
            throw new Error(errors[0].error);
        }
        return results;
    }
    evaluateParameterRowWithErrors(table, row) {
        let rawResults = [];
        for (let query of this.bucket_descriptors) {
            rawResults.push(...query.evaluateParameterRow(table, row));
        }
        const results = rawResults.filter(isEvaluatedParameters);
        const errors = rawResults.filter(isEvaluationError);
        return { results, errors };
    }
    /**
     * @deprecated For testing only.
     */
    getStaticBucketIds(parameters) {
        let results = [];
        for (let bucket of this.bucket_descriptors) {
            results.push(...bucket.getStaticBucketIds(parameters));
        }
        return results;
    }
    /**
     * Note: This can error hard.
     */
    async queryBucketIds(options) {
        let results = [];
        for (let bucket of this.bucket_descriptors) {
            results.push(...(await bucket.queryBucketIds(options)));
        }
        return results;
    }
    getSourceTables() {
        let sourceTables = new Map();
        for (let bucket of this.bucket_descriptors) {
            for (let r of bucket.getSourceTables()) {
                const key = `${r.connectionTag}.${r.schema}.${r.tablePattern}`;
                sourceTables.set(key, r);
            }
        }
        return [...sourceTables.values()];
    }
    tableSyncsData(table) {
        for (let bucket of this.bucket_descriptors) {
            if (bucket.tableSyncsData(table)) {
                return true;
            }
        }
        return false;
    }
    tableSyncsParameters(table) {
        for (let bucket of this.bucket_descriptors) {
            if (bucket.tableSyncsParameters(table)) {
                return true;
            }
        }
        return false;
    }
    debugGetOutputTables() {
        var _a;
        let result = {};
        for (let bucket of this.bucket_descriptors) {
            for (let q of bucket.data_queries) {
                result[_a = q.table] ?? (result[_a] = []);
                const r = {
                    query: q.sql
                };
                result[q.table].push(r);
            }
        }
        return result;
    }
}

class SourceTableDetails {
    constructor(connection, schema, table) {
        this.connectionTag = connection.tag;
        this.schema = schema.name;
        this.table = table.name;
        this.columns = Object.fromEntries(table.columns.map((column) => {
            return [column.name, mapColumn(column)];
        }));
    }
    getType(column) {
        return this.columns[column]?.type;
    }
    getColumns() {
        return Object.values(this.columns);
    }
}
class StaticSchema {
    constructor(connections) {
        this.tables = [];
        for (let connection of connections) {
            for (let schema of connection.schemas) {
                for (let table of schema.tables) {
                    this.tables.push(new SourceTableDetails(connection, schema, table));
                }
            }
        }
    }
    getTables(sourceTable) {
        const filtered = this.tables.filter((t) => sourceTable.matches(t));
        return filtered;
    }
}
function mapColumn(column) {
    return {
        name: column.name,
        type: mapType(column.pg_type)
    };
}
function mapType(type) {
    if (type?.endsWith('[]')) {
        return ExpressionType.TEXT;
    }
    switch (type) {
        case 'bool':
            return ExpressionType.INTEGER;
        case 'bytea':
            return ExpressionType.BLOB;
        case 'int2':
        case 'int4':
        case 'int8':
        case 'oid':
            return ExpressionType.INTEGER;
        case 'float4':
        case 'float8':
            return ExpressionType.REAL;
        default:
            return ExpressionType.TEXT;
    }
}

class SchemaGenerator {
    getAllTables(source, schema) {
        var _a, _b, _c;
        let tables = {};
        for (let descriptor of source.bucket_descriptors) {
            for (let query of descriptor.data_queries) {
                const outTables = query.getColumnOutputs(schema);
                for (let table of outTables) {
                    tables[_a = table.name] ?? (tables[_a] = {});
                    for (let column of table.columns) {
                        if (column.name != 'id') {
                            (_b = tables[table.name])[_c = column.name] ?? (_b[_c] = column);
                        }
                    }
                }
            }
        }
        return Object.entries(tables).map(([name, columns]) => {
            return {
                name: name,
                columns: Object.values(columns)
            };
        });
    }
}

class DartSchemaGenerator extends SchemaGenerator {
    constructor() {
        super(...arguments);
        this.key = 'dart';
        this.label = 'Dart';
        this.mediaType = 'text/x-dart';
        this.fileName = 'schema.dart';
    }
    generate(source, schema) {
        const tables = super.getAllTables(source, schema);
        return `Schema([
  ${tables.map((table) => this.generateTable(table.name, table.columns)).join(',\n  ')}
]);
`;
    }
    generateTable(name, columns) {
        return `Table('${name}', [
    ${columns.map((c) => this.generateColumn(c)).join(',\n    ')}
  ])`;
    }
    generateColumn(column) {
        const t = column.type;
        if (t.typeFlags & TYPE_TEXT) {
            return `Column.text('${column.name}')`;
        }
        else if (t.typeFlags & TYPE_REAL) {
            return `Column.real('${column.name}')`;
        }
        else if (t.typeFlags & TYPE_INTEGER) {
            return `Column.integer('${column.name}')`;
        }
        else {
            return `Column.text('${column.name}')`;
        }
    }
}

class JsLegacySchemaGenerator extends SchemaGenerator {
    constructor() {
        super(...arguments);
        this.key = 'jsLegacy';
        this.label = 'JavaScript (legacy syntax)';
        this.mediaType = 'text/javascript';
        this.fileName = 'schema.js';
    }
    generate(source, schema) {
        const tables = super.getAllTables(source, schema);
        return `new Schema([
  ${tables.map((table) => this.generateTable(table.name, table.columns)).join(',\n  ')}
])
`;
    }
    generateTable(name, columns) {
        return `new Table({
    name: '${name}',
    columns: [
      ${columns.map((c) => this.generateColumn(c)).join(',\n      ')}
    ]
  })`;
    }
    generateColumn(column) {
        const t = column.type;
        if (t.typeFlags & TYPE_TEXT) {
            return `new Column({ name: '${column.name}', type: ColumnType.TEXT })`;
        }
        else if (t.typeFlags & TYPE_REAL) {
            return `new Column({ name: '${column.name}', type: ColumnType.REAL })`;
        }
        else if (t.typeFlags & TYPE_INTEGER) {
            return `new Column({ name: '${column.name}', type: ColumnType.INTEGER })`;
        }
        else {
            return `new Column({ name: '${column.name}', type: ColumnType.TEXT })`;
        }
    }
}

var TsSchemaLanguage;
(function (TsSchemaLanguage) {
    TsSchemaLanguage["ts"] = "ts";
    /** Excludes types from the generated schema. */
    TsSchemaLanguage["js"] = "js";
})(TsSchemaLanguage || (TsSchemaLanguage = {}));
var TsSchemaImports;
(function (TsSchemaImports) {
    TsSchemaImports["web"] = "web";
    TsSchemaImports["reactNative"] = "reactNative";
    /**
     * Emits imports for `@powersync/web`, with comments for `@powersync/react-native`.
     */
    TsSchemaImports["auto"] = "auto";
})(TsSchemaImports || (TsSchemaImports = {}));
class TsSchemaGenerator extends SchemaGenerator {
    constructor(options = {}) {
        super();
        this.options = options;
        this.language = options.language ?? TsSchemaLanguage.ts;
        this.key = this.language;
        if (this.language == TsSchemaLanguage.ts) {
            this.fileName = 'schema.ts';
            this.mediaType = 'text/typescript';
            this.label = 'TypeScript';
        }
        else {
            this.fileName = 'schema.js';
            this.mediaType = 'text/javascript';
            this.label = 'JavaScript';
        }
    }
    generate(source, schema) {
        const tables = super.getAllTables(source, schema);
        return `${this.generateImports()}

${tables.map((table) => this.generateTable(table.name, table.columns)).join('\n\n')}

export const AppSchema = new Schema({
  ${tables.map((table) => table.name).join(',\n  ')}
});

${this.generateTypeExports()}`;
    }
    generateTypeExports() {
        if (this.language == TsSchemaLanguage.ts) {
            return `export type Database = (typeof AppSchema)['types'];\n`;
        }
        else {
            return ``;
        }
    }
    generateImports() {
        const importStyle = this.options.imports ?? 'auto';
        if (importStyle == TsSchemaImports.web) {
            return `import { column, Schema, TableV2 } from '@powersync/web';`;
        }
        else if (importStyle == TsSchemaImports.reactNative) {
            return `import { column, Schema, TableV2 } from '@powersync/react-native';`;
        }
        else {
            return `import { column, Schema, TableV2 } from '@powersync/web';
// OR: import { column, Schema, TableV2 } from '@powersync/react-native';`;
        }
    }
    generateTable(name, columns) {
        return `const ${name} = new TableV2(
  {
    // id column (text) is automatically included
    ${columns.map((c) => this.generateColumn(c)).join(',\n    ')}
  },
  { indexes: {} }
);`;
    }
    generateColumn(column) {
        const t = column.type;
        if (t.typeFlags & TYPE_TEXT) {
            return `${column.name}: column.text`;
        }
        else if (t.typeFlags & TYPE_REAL) {
            return `${column.name}: column.real`;
        }
        else if (t.typeFlags & TYPE_INTEGER) {
            return `${column.name}: column.integer`;
        }
        else {
            return `${column.name}: column.text`;
        }
    }
}

const schemaGenerators = {
    ts: new TsSchemaGenerator(),
    js: new TsSchemaGenerator({ language: TsSchemaLanguage.js }),
    jsLegacy: new JsLegacySchemaGenerator(),
    dart: new DartSchemaGenerator()
};

config_1({ path: ENV_FILE_PATH });
const { AUTH_TOKEN, INSTANCE_ID, ORG_ID, PROJECT_ID } = process.env;
var ENV_VARIABLES;
(function(ENV_VARIABLES2) {
  ENV_VARIABLES2["AUTH_TOKEN"] = "AUTH_TOKEN";
  ENV_VARIABLES2["INSTANCE_ID"] = "INSTANCE_ID";
  ENV_VARIABLES2["ORG_ID"] = "ORG_ID";
  ENV_VARIABLES2["PROJECT_ID"] = "PROJECT_ID";
})(ENV_VARIABLES || (ENV_VARIABLES = {}));
const powerSyncClient = ({ authToken } = {}) => {
  const finalToken = authToken || AUTH_TOKEN;
  if (!finalToken) {
    throw new Error("No auth token found");
  }
  const HEADERS = generateHeader(finalToken);
  return new Client_1({
    client: dist$8.createWebNetworkClient({ headers: HEADERS }),
    endpoint: ENDPOINTS.POWERSYNC_URL
  });
};
const getRegions = async () => {
  const result = await powerSyncClient().listRegions(void 0);
  const regions = result.regions.filter((region) => region.deployable).map((region) => region.name);
  return regions;
};
const getInstancesList = async () => {
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  return powerSyncClient().listInstances({
    app_id: PROJECT_ID,
    org_id: ORG_ID
  });
};
const getInstanceConfig = async () => {
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  checkInstanceId(INSTANCE_ID);
  return powerSyncClient().getInstanceConfig({
    app_id: PROJECT_ID,
    id: INSTANCE_ID,
    org_id: ORG_ID
  });
};
const getInstanceDiagnostics = async ({ authToken, instanceId, orgId, projectId }) => {
  const finalProjectId = projectId || PROJECT_ID;
  const finalInstanceId = instanceId || INSTANCE_ID;
  const finalOrgId = orgId || ORG_ID;
  checkOrgId(finalOrgId);
  checkProjectId(finalProjectId);
  checkInstanceId(finalInstanceId);
  return powerSyncClient({ authToken }).getInstanceDiagnostics({
    app_id: finalProjectId,
    id: finalInstanceId,
    org_id: finalOrgId
  });
};
const getInstanceSchema = async () => {
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  checkInstanceId(INSTANCE_ID);
  return powerSyncClient().getInstanceSchema({
    app_id: PROJECT_ID,
    id: INSTANCE_ID,
    org_id: ORG_ID
  });
};
const getInstanceStatus = async (instanceId) => {
  const finalInstanceId = instanceId || INSTANCE_ID;
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  checkInstanceId(finalInstanceId);
  return powerSyncClient().getInstanceStatus({
    app_id: PROJECT_ID,
    id: instanceId ?? INSTANCE_ID,
    org_id: ORG_ID
  });
};
const destroyInstance = async () => {
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  checkInstanceId(INSTANCE_ID);
  return powerSyncClient().destroyInstance({
    app_id: PROJECT_ID,
    id: INSTANCE_ID,
    org_id: ORG_ID
  });
};
const deactivateInstance = async () => {
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  checkInstanceId(INSTANCE_ID);
  return powerSyncClient().deactivateInstance({
    app_id: PROJECT_ID,
    id: INSTANCE_ID,
    org_id: ORG_ID
  });
};
const createInstance = async (name) => {
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  return powerSyncClient().createInstance({
    app_id: PROJECT_ID,
    name,
    org_id: ORG_ID
  });
};
const testConnection = async (connection) => {
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  return powerSyncClient().testConnection({
    app_id: PROJECT_ID,
    connection,
    org_id: ORG_ID
  });
};
const deployInstance = async (config, instanceId) => {
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  return powerSyncClient().deployInstance({
    app_id: PROJECT_ID,
    config,
    id: instanceId,
    org_id: ORG_ID
  });
};
const validateSyncRules = async (syncRules) => {
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  checkInstanceId(INSTANCE_ID);
  return powerSyncClient().validateSyncRules({
    app_id: PROJECT_ID,
    id: INSTANCE_ID,
    org_id: ORG_ID,
    sync_rules: syncRules
  });
};
const deploySyncRules = async (syncRules) => {
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  checkInstanceId(INSTANCE_ID);
  const config = await getInstanceConfig();
  if (!config.config) {
    throw new Error("No instance config found");
  }
  if (!syncRules) {
    throw new Error("No sync rules found");
  }
  return powerSyncClient().deployInstance({
    app_id: PROJECT_ID,
    config: config.config,
    id: INSTANCE_ID,
    org_id: ORG_ID,
    sync_rules: syncRules
  });
};
const processSyncRules = async () => {
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  checkInstanceId(INSTANCE_ID);
  powerSyncClient().reprocessSyncRules({
    app_id: PROJECT_ID,
    id: INSTANCE_ID,
    org_id: ORG_ID
  });
};
const generateDevToken = async (userId, expiresInSeconds = 43200) => {
  checkOrgId(ORG_ID);
  checkProjectId(PROJECT_ID);
  checkInstanceId(INSTANCE_ID);
  const result = await powerSyncClient().generateDevToken({
    app_id: PROJECT_ID,
    expiresInSeconds,
    id: INSTANCE_ID,
    org_id: ORG_ID,
    subject: userId
  });
  return result.token;
};
const waitForStatusChange = async (instanceId) => {
  const interval = 5e3;
  try {
    const result = await getInstanceStatus(instanceId);
    let { status } = result.operations[0];
    while (status !== "failed" && status !== "completed") {
      await new Promise((resolve) => {
        setTimeout(resolve, interval);
      });
      const response = await getInstanceStatus(instanceId);
      status = response.operations[0].status;
    }
    return status;
  } catch (error) {
    throw new Error(error.message);
  }
};

export { ENV_VARIABLES, SqlSyncRules, StaticSchema, createInstance, deactivateInstance, deployInstance, deploySyncRules, destroyInstance, generateDevToken, getInstanceConfig, getInstanceDiagnostics, getInstanceSchema, getInstanceStatus, getInstancesList, getRegions, powerSyncClient, processSyncRules, schemaGenerators, testConnection, validateSyncRules, waitForStatusChange };
